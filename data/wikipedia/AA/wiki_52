{"id": "6291", "revid": "746004", "url": "https://en.wikipedia.org/wiki?curid=6291", "title": "Roman censor", "text": "The censor (at any time, there were two) was a magistrate in ancient Rome who was responsible for maintaining the census, supervising public morality, and overseeing certain aspects of the government's finances.\nThe power of the censor was absolute: no magistrate could oppose his decisions, and only another censor who succeeded him could cancel those decisions.\nThe censor's regulation of public morality is the origin of the modern meaning of the words \"censor\" and \"censorship\".\nEarly history of the magistracy.\nThe \"census\" was first instituted by Servius Tullius, sixth king of Rome, c. 575\u2013535 BC. After the abolition of the monarchy and the founding of the Republic in 509 BC, the consuls had responsibility for the census until 443 BC. In 442 BC, no consuls were elected, but tribunes with consular power were appointed instead. This was a move by the plebeians to try to attain higher magistracies: only patricians could be elected consuls, while some military tribunes were plebeians. To prevent the possibility of plebeians obtaining control of the census, the patricians removed the right to take the census from the consuls and tribunes, and appointed for this duty two magistrates, called \"censores\" (censors), elected exclusively from the patricians in Rome. \nThe magistracy continued to be controlled by patricians until 351 BC, when Gaius Marcius Rutilus was appointed the first plebeian censor. Twelve years later, in 339 BC, one of the Publilian laws required that one censor had to be a plebeian. Despite this, no plebeian censor performed the solemn purification of the people (the \"lustrum\"; \"Livy\" Periochae 13) until 280 BC. In 131 BC, for the first time, both censors were plebeians.\nThe reason for having two censors was that the two consuls had previously taken the census together. If one of the censors died during his term of office, another was chosen to replace him, just as with consuls. This happened only once, in 393 BC. However, the Gauls captured Rome in that \"lustrum\" (five-year period), and the Romans thereafter regarded such replacement as \"an offense against religion\". From then on, if one of the censors died, his colleague resigned, and two new censors were chosen to replace them.\nInitially the office of censor was limited to eighteen months by a law of the dictator Mamercus Aemilius Mamercinus; and the office therefore was of less importance in the 5th and 4th centuries BC. However, during the censorship of Appius Claudius Caecus (312\u2013308 BC) the prestige of the censorship massively increased: Caecus built the first-ever Roman road (the Via Appia) and the first Roman aqueduct (the Aqua Appia), both named after him; he changed the organisation of the Roman tribes and was the first censor to draw the list of senators; and he also advocated the founding of Roman colonies (colonia) throughout Latium and Campania to support the Roman war effort in the Second Samnite War. With these efforts and reforms, Appius Claudius Caecus was able to hold the censorship for a whole lustrum (five-year period); and the office of censor, subsequently entrusted with various important duties, eventually attained one of the highest political statuses in the Roman Republic, second only to that of the consuls.\nElection.\nThe censors were elected in the Centuriate Assembly, which met under the presidency of a consul. Barthold Niebuhr suggests that the censors were at first elected by the Curiate Assembly, and that the Assembly's selections were confirmed by the Centuriate, but William Smith believes that \"there is no authority for this supposition, and the truth of it depends entirely upon the correctness of [Niebuhr's] views respecting the election of the consuls\". Both censors had to be elected on the same day, and accordingly if the voting for the second was not finished in the same day, the election of the first was invalidated, and a new assembly had to be held.\nThe assembly for the election of the censors was held under different auspices from those at the election of the consuls and praetors, so the censors were not regarded as their colleagues, although they likewise possessed the \"maxima auspicia\". The assembly was held by the new consuls shortly after they began their term of office; and the censors, as soon as they were elected and the censorial power had been granted to them by a decree of the Centuriate Assembly (\"lex centuriata\"), were fully installed in their office.\nAs a general principle, the only ones eligible for the office of censor were those who had previously been consuls, but there were a few exceptions. At first, there was no law to prevent a person being censor twice, but the only person who was elected to the office twice was Gaius Marcius Rutilus in 265 BC. In that year, he originated a law stating that no one could be elected censor twice. In consequence of this, he received the cognomen of \"Censorinus\".\nAttributes.\nThe censorship differed from all other Roman magistracies in the length of office. The censors were originally chosen for a whole \"lustrum\" (the period of five years), but as early as ten years after its institution (433 BC) their office was limited to eighteen months by a law of the dictator Mamercus Aemilius Mamercinus. The censors were also unique with respect to rank and dignity. They had no \"imperium\", and accordingly no lictors. Their rank was granted to them by the Centuriate Assembly, and not by the \"curiae\", and in that respect they were inferior in power to the consuls and praetors.\nNotwithstanding this, the censorship was regarded as the highest dignity in the state, with the exception of the dictatorship; it was a \"sacred magistracy\" (\"sanctus magistratus\"), to which the deepest reverence was due. The high rank and dignity which the censorship obtained was due to the various important duties gradually entrusted to it, and especially to its possessing the \"regimen morum\", or general control over the conduct and the morals of the citizens. In the exercise of this power, they were regulated solely by their own views of duty, and were not responsible to any other power in the state.\nThe censors possessed the official stool called a \"curule chair\" (\"sella curulis\"), but some doubt exists with respect to their official dress. A well-known passage of Polybius describes the use of the \"imagines\" at funerals; we may conclude that a consul or praetor wore the purple-bordered \"toga praetexta\", one who triumphed the embroidered \"toga picta\", and the censor a purple toga peculiar to him, but other writers speak of their official dress as being the same as that of the other higher magistrates. The funeral of a censor was always conducted with great pomp and splendour, and hence a \"censorial funeral\" (\"funus censorium\") was voted even to the emperors.\nAbolition.\nThe censorship continued in existence for 421 years, from 443 BC to 22 BC, but during this period, many \"lustra\" passed by without any censor being chosen at all. According to one statement, the office was abolished by Lucius Cornelius Sulla. Although the authority on which this statement rests is not of much weight, the fact itself is probable, since there was no census during the two \"lustra\" which elapsed from Sulla's dictatorship to Gnaeus Pompeius Magnus (Pompey)'s first consulship (82\u201370 BC), and any strict \"imposition of morals\" would have been found inconvenient to the aristocracy that supported Sulla.\nIf the censorship had been done away with by Sulla, it was at any rate restored in the consulship of Pompey and Marcus Licinius Crassus. Its power was limited by one of the laws of the tribune Publius Clodius Pulcher (58 BC), which prescribed certain regular forms of proceeding before the censors in expelling a person from the Roman Senate, and required that the censors be in agreement to exact this punishment. This law, however, was repealed in the third consulship of Pompey in 52 BC, on the urging of his colleague Q. Caecilius Metellus Scipio, but the office of the censorship never recovered its former power and influence.\nDuring the civil wars which followed soon afterwards, no censors were elected; it was only after a long interval that they were again appointed, namely in 22 BC, when Augustus caused Lucius Munatius Plancus and Aemilius Lepidus Paullus to fill the office. This was the last time that such magistrates were appointed; the emperors in future discharged the duties of their office under the name of Praefectura Morum (\"prefect of the morals\").\nSome of the emperors sometimes took the name of censor when they held a census of the Roman people; this was the case with Claudius, who appointed the elder Lucius Vitellius as his colleague, and with Vespasian, who likewise had a colleague in his son Titus. Domitian assumed the title of \"perpetual censor\" (\"censor perpetuus\"), but this example was not imitated by succeeding emperors. In the reign of Decius, we find the elder Valerian nominated to the censorship, but Valerian was never actually elected censor.\nDuties.\nThe duties of the censors may be divided into three classes, all of which were closely connected with one another:\nThe original business of the censorship was at first of a much more limited kind, and was restricted almost entirely to taking the census, but the possession of this power gradually brought with it fresh power and new duties, as is shown below. A general view of these duties is briefly expressed in the following passage of Cicero: \"Censores populi aevitates, soboles, familias pecuniasque censento: urbis templa, vias, aquas, aerarium, vectigalia tuento: populique partes in tribus distribunto: exin pecunias, aevitates, ordines patiunto: equitum, peditumque prolem describunto: caelibes esse prohibento: mores populi regunto: probrum in senatu ne relinquunto.\" This can be translated as: \"The Censors are to determine the generations, origins, families, and properties of the people; they are to (watch over/protect) the city's temples, roads, waters, treasury, and taxes; they are to divide the people into three parts; next, they are to (allow/approve) the properties, generations, and ranks [of the people]; they are to describe the offspring of knights and footsoldiers; they are to forbid being unmarried; they are to guide the behavior of the people; they are not to overlook abuse in the Senate.\" \nCensus.\nThe Census, the first and principal duty of the censors, was always held in the Campus Martius, and from the year 435 BC onwards, in a special building called Villa Publica, which was erected for that purpose by the second pair of censors, Gaius Furius Pacilus Fusus and Marcus Geganius Macerinus.\nAn account of the formalities with which the census was opened is given in a fragment of the \"Tabulae Censoriae\", preserved by Varro. After the auspices had been taken, the citizens were summoned by a public crier to appear before the censors. Each tribe was called up separately, and the names in each tribe were probably taken according to the lists previously made out by the tribunes of the tribes. Every paterfamilias had to appear in person before the censors, who were seated in their curule chairs, and those names were taken first which were considered to be of good omen, such as Valerius, Salvius, Statorius, etc.\nThe census was conducted according to the judgment of the censor (\"ad arbitrium censoris\"), but the censors laid down certain rules, sometimes called \"leges censui censendo\", in which mention was made of the different kinds of property subject to the census, and in what way their value was to be estimated. According to these laws, each citizen had to give an account of himself, of his family, and of his property upon oath, \"declared from the heart\".\nFirst he had to give his full name (praenomen, nomen, and cognomen) and that of his father, or if he were a \"Libertus\" (\"freedman\") that of his patron, and he was likewise obliged to state his age. He was then asked, \"You, declaring from your heart, do you have a wife?\" and if married he had to give the name of his wife, and likewise the number, names, and ages of his children, if any. Single women and orphans were represented by their guardians; their names were entered in separate lists, and they were not included in the sum total of heads.\nAfter a citizen had stated his name, age, family, etc., he then had to give an account of all his property, so far as it was subject to the census. Only such things were liable to the census (\"censui censendo\") as were property according to the Quiritarian law. At first, each citizen appears to have merely given the value of his whole property in general without entering into details; but it soon became the practice to give a minute specification of each article, as well as the general value of the whole.\nLand formed the most important article of the census, but public land, the possession of which only belonged to a citizen, was excluded as not being Quiritarian property. If we may judge from the practice of the imperial period, it was the custom to give a most minute specification of all such land as a citizen held according to the Quiritarian law. He had to state the name and location of the land, and to specify what portion of it was arable, what meadow, what vineyard, and what olive-ground: and of the land thus described, he had to give his assessment of its value.\nSlaves and cattle formed the next most important item. The censors also possessed the right of calling for a return of such objects as had not usually been given in, such as clothing, jewels, and carriages. It has been doubted by some modern writers whether the censors possessed the power of setting a higher valuation on the property than the citizens themselves gave, but when we recollect the discretionary nature of the censors' powers, and the necessity almost that existed, in order to prevent fraud, that the right of making a surcharge should be vested in somebody's hands, we can hardly doubt that the censors had this power. It is moreover expressly stated that on one occasion they made an extravagant surcharge on articles of luxury; and even if they did not enter in their books the property of a person at a higher value than he returned it, they accomplished the same end by compelling him to pay a tax upon the property at a higher rate than others. The tax was usually one per thousand upon the property entered in the books of the censors, but on one occasion the censors compelled a person to pay eight per thousand as a punishment.\nA person who voluntarily absented himself from the census was considered \"incensus\" and subject to the severest punishment. Servius Tullius is said to have threatened such individuals with imprisonment and death, and in the Republican period he might be sold by the state as a slave. In the later period of the Republic, a person who was absent from the census might be represented by another, and be thus registered by the censors. Whether the soldiers who were absent on service had to appoint a representative is uncertain. In ancient times, the sudden outbreaks of war prevented the census from being taken, because a large number of the citizens would necessarily be absent. It is supposed from a passage in Livy that in later times the censors sent commissioners into the provinces with full powers to take the census of the Roman soldiers there, but this seems to have been a special case. It is, on the contrary, probable from the way in which Cicero pleads the absence of Archias from Rome with the army under Lucullus, as a sufficient reason for his not having been enrolled in the census, that service in the army was a valid excuse for absence.\nAfter the censors had received the names of all the citizens with the amount of their property, they then had to make out the lists of the tribes, and also of the classes and centuries; for by the legislation of Servius Tullius the position of each citizen in the state was determined by the amount of his property (Comitia Centuriata). These lists formed a most important part of the \"Tabulae Censoriae\", under which name were included all the documents connected in any way with the discharge of the censors' duties. These lists, insofar as they were connected with the finances of the state, were deposited in the \"aerarium\", which was the temple of Saturn; but the regular depository for all the archives of the censors was in earlier times the Atrium Libertatis, near the Villa Publica, and in later times the temple of the Nymphs.\nBesides the division of the citizens into tribes, centuries, and classes, the censors had also to make out the lists of the senators for the ensuing five years, or until new censors were appointed; striking out the names of such as they considered unworthy, and making additions to the body from those who were qualified. In the same manner they held a review of the Equestrians who received a horse from public funds (\"equites equo publico\"), and added and removed names as they judged proper. They also confirmed the \"princeps senatus\", or appointed a new one. The princeps himself had to be a former censor.\nAfter the lists had been completed, the number of citizens was counted up, and the sum total announced. Accordingly, we find that in the account of a census, the number of citizens is likewise usually given. They are in such cases spoken of as \"capita\" (\"heads\"), sometimes with the addition of the word \"civium\" (\"of the citizens\"), and sometimes not. Hence, to be registered in the census was the same thing as \"having a head\" (\"caput habere\").\nCensus beyond Rome.\nA census was sometimes taken in the provinces, even under the Republic. The Emperor sent into the provinces special officers called \"Censitores\" to take the census; but the duty was sometimes discharged by the Imperial legati. The Censitores were assisted by subordinate officers, called Censuales, who made out the lists, etc. In Rome, the census was still taken under the empire, but the old ceremonies connected with it were no longer performed, and the ceremony of the lustration was not performed after the time of Vespasian. The jurists Paulus and Ulpian each wrote works on the census in the imperial period; and several extracts from these works are given in a chapter in the \"Digest\" (50 15). \nOther uses of census.\nThe word \"census\", besides the conventional meaning of \"valuation\" of a person's estate, has other meaning in Rome; it could refer to: \n\"Regimen morum\".\nKeeping the public morals (\"regimen morum\", or in the empire \"cura morum\" or \"praefectura morum\") was the second most important branch of the censors' duties, and the one which caused their office to be one of the most revered and the most dreaded in the Roman state; hence they were also known as \"Castigatores\" (\"chastisers\"). It naturally grew out of the right which they possessed of excluding persons from the lists of citizens; for, as has been well remarked, \"they would, in the first place, be the sole judges of many questions of fact, such as whether a citizen had the qualifications required by law or custom for the rank which he claimed, or whether he had ever incurred any judicial sentence, which rendered him infamous: but from thence the transition was easy, according to Roman notions, to the decisions of questions of right; such as whether a citizen was really worthy of retaining his rank, whether he had not committed some act as justly degrading as those which incurred the sentence of the law.\" \nIn this manner, the censors gradually assumed at least nominal complete superintendence over the whole public and private life of every citizen. They were constituted as the conservators of public morality; they were not simply to prevent crime or particular acts of immorality, but rather to maintain the traditional Roman character, ethics, and habits (\"mos majorum\")\u2014\"regimen morum\" also encompassed this protection of traditional ways, which was called in the times of the empire \"cura\" (\"supervision\") or \"praefectura\" (\"command\"). The punishment inflicted by the censors in the exercise of this branch of their duties was called \"nota\" (\"mark, letter\") or \"notatio\", or \"animadversio censoria\" (\"censorial reproach\"). In inflicting it, they were guided only by their conscientious convictions of duty; they had to take an oath that they would act biased by neither partiality nor favour; and, in addition to this, they were bound in every case to state in their lists, opposite the name of the guilty citizen, the cause of the punishment inflicted on him, \"Subscriptio censoria\".\nThis part of the censors' office invested them with a peculiar kind of jurisdiction, which in many respects resembled the exercise of public opinion in modern times; for there are innumerable actions which, though acknowledged by everyone to be prejudicial and immoral, still do not come within the reach of the positive laws of a country; as often said, \"immorality does not equal illegality\". Even in cases of real crimes, the positive laws frequently punish only the particular offence, while in public opinion the offender, even after he has undergone punishment, is still incapacitated for certain honours and distinctions which are granted only to persons of unblemished character.\nHence the Roman censors might brand a man with their \"censorial mark\" (\"nota censoria\") in case he had been convicted of a crime in an ordinary court of justice, and had already suffered punishment for it. The consequence of such a \"nota\" was only \"ignominia\" and not \"infamia\". \"Infamia\" and the censorial verdict was not a \"judicium\" or \"res judicata\", for its effects were not lasting, but might be removed by the following censors, or by a \"lex\" (roughly \"law\"). A censorial mark was moreover not valid unless both censors agreed. The \"ignominia\" was thus only a transitory reduction of status, which does not even appear to have deprived a magistrate of his office, and certainly did not disqualify persons labouring under it for obtaining a magistracy, for being appointed as \"judices\" by the praetor, or for serving in the Roman armies. Mamercus Aemilius Mamercinus was thus, notwithstanding the reproach of the censors (\"animadversio censoria\"), made dictator.\nA person might be branded with a censorial mark in a variety of cases, which it would be impossible to specify, as in a great many instances it depended upon the discretion of the censors and the view they took of a case; and sometimes even one set of censors would overlook an offence which was severely chastised by their successors. But the offences which are recorded to have been punished by the censors are of a threefold nature.\nA person who had been branded with a \"nota censoria\", might, if he considered himself wronged, endeavour to prove his innocence to the censors, and if he did not succeed, he might try to gain the protection of one of the censors, that he might intercede on his behalf.\nPunishments.\nThe punishments inflicted by the censors generally differed according to the station which a man occupied, though sometimes a person of the highest rank might suffer all the punishments at once, by being degraded to the lowest class of citizens. But they are generally divided into four classes:\nIt was this authority of the Roman censors which eventually developed into the modern meaning of \"censor\" and \"censorship\"\u2014i.e., officials who review published material and forbid the publication of material judged to be contrary to \"public morality\" as the term is interpreted in a given political and social environment.\nAdministration of the finances of the state.\nThe administration of the state's finances was another part of the censors' office. In the first place the \"tributum\", or property-tax, had to be paid by each citizen according to the amount of his property registered in the census, and, accordingly, the regulation of this tax naturally fell under the jurisdiction of the censors. They also had the superintendence of all the other revenues of the state, the vectigalia, such as the tithes paid for the public lands, the salt works, the mines, the customs, etc.\nThe censors typically auctioned off to the highest bidder for the space of a \"lustrum\" the collection of the tithes and taxes (tax farming). This auctioning was called \"venditio\" or \"locatio\", and seems to have taken place in the month of March, in a public place in Rome The terms on which they were let, together with the rights and duties of the purchasers, were all specified in the \"leges censoriae\", which the censors published in every case before the bidding commenced. For further particulars see Publicani.\nThe censors also possessed the right, though probably not without the assent of the Senate, of imposing new \"vectigalia\", and even of selling the land belonging to the state. It would thus appear that it was the duty of the censors to bring forward a budget for a five-year period, and to take care that the income of the state was sufficient for its expenditure during that time. In part, their duties resembled those of a modern minister of finance. The censors, however, did not receive the revenues of the state. All the public money was paid into the \"aerarium\", which was entirely under the jurisdiction of the senate; and all disbursements were made by order of this body, which employed the quaestors as its officers.\nOverseeing public works.\nIn one important department, the public works, the censors were entrusted with the expenditure of the public money (though the actual payments were no doubt made by the quaestors).\nThe censors had the general superintendence of all the public buildings and works (\"opera publica\"), and to meet the expenses connected with this part of their duties, the senate voted them a certain sum of money or certain revenues, to which they were restricted, but which they might at the same time employ according to their discretion. They had to see that the temples and all other public buildings were in a good state of repair, that no public places were encroached upon by the occupation of private persons, and that the aqueduct, roads, drains, etc. were properly attended to.\nThe repairs of the public works and the keeping of them in proper condition were let out by the censors by public auction to the lowest bidder, just as the \"vectigalia\" were let out to the highest bidder. These expenses were called \"ultrotributa\", and hence we frequently find \"vectigalia\" and \"ultrotributa\" contrasted with one another. The persons who undertook the contract were called \"conductores\", \"mancipes\", \"redemptores\", \"susceptores\", etc.; and the duties they had to discharge were specified in the Leges Censoriae. The censors had also to superintend the expenses connected with the worship of the gods, even for instance the feeding of the sacred geese in the Capitol; these various tasks were also let out on contract. It was ordinary for censors to expend large amounts of money (\u201cby far the largest and most extensive\u201d of the state) in their public works.\nBesides keeping existing public buildings and facilities in a proper state of repair, the censors were also in charge of constructing new ones, either for ornament or utility, both in Rome and in other parts of Italy, such as temples, basilicae, theatres, porticoes, fora, walls of towns, aqueducts, harbours, bridges, cloacae, roads, etc. These works were either performed by them jointly, or they divided between them the money, which had been granted to them by the senate. They were let out to contractors, like the other works mentioned above, and when they were completed, the censors had to see that the work was performed in accordance with the contract: this was called \"opus probare\" or \"in acceptum referre\".\nThe first ever Roman road, the Via Appia, and the first Roman aqueduct, the Aqua Appia, were all constructed under the censorship of Appius Claudius Caecus, one of the most influential censors.\nThe aediles had likewise a superintendence over the public buildings, and it is not easy to define with accuracy the respective duties of the censors and aediles, but it may be remarked in general that the superintendence of the aediles had more of a police character, while that of the censors were more financial in subject matter.\nLustrum.\nAfter the censors had performed their various duties and taken the five-yearly census, the \"lustrum\", a solemn purification of the people, followed. When the censors entered upon their office, they drew lots to see which of them should perform this purification; but both censors were of course obliged to be present at the ceremony.\nLong after the Roman census was no longer taken, the Latin word \"lustrum\" has survived, and been adopted in some modern languages, in the derived sense of a period of five years, i.e. half a decennium."}
{"id": "6292", "revid": "20530117", "url": "https://en.wikipedia.org/wiki?curid=6292", "title": "Convex set", "text": "In geometry, a subset of a Euclidean space, or more generally an affine space over the reals, is convex if, given any two points, it contains the whole line segment that joins them. Equivalently, a convex set or a convex region is a subset that intersect every line into a single line segment (possibly empty).\nFor example, a solid cube is a convex set, but anything that is hollow or has an indent, for example, a crescent shape, is not convex.\nThe boundary of a convex set is always a convex curve. The intersection of all the convex sets that contain a given subset of Euclidean space is called the convex hull of . It is the smallest convex set containing .\nA convex function is a real-valued function defined on an interval with the property that its epigraph (the set of points on or above the graph of the function) is a convex set. Convex minimization is a subfield of optimization that studies the problem of minimizing convex functions over convex sets. The branch of mathematics devoted to the study of properties of convex sets and convex functions is called convex analysis.\nThe notion of a convex set can be generalized as described below.\nDefinitions.\nLet be a vector space or an affine space over the real numbers, or, more generally, over some ordered field. This includes Euclidean spaces, which are affine spaces. A subset of is convex if, for all and in , the line segment connecting and is included in . This means that the affine combination belongs to , for all and in , and in the interval . This implies that convexity (the property of being convex) is invariant under affine transformations. This implies also that a convex set in a real or complex topological vector space is path-connected, thus connected.\nA set is \"\" if every point on the line segment connecting and other than the endpoints is inside the interior of .\nA set is \"absolutely convex\" if it is convex and balanced.\nThe convex subsets of (the set of real numbers) are the intervals and the points of . Some examples of convex subsets of the Euclidean plane are solid regular polygons, solid triangles, and intersections of solid triangles. Some examples of convex subsets of a Euclidean 3-dimensional space are the Archimedean solids and the Platonic solids. The Kepler-Poinsot polyhedra are examples of non-convex sets.\nNon-convex set.\nA set that is not convex is called a \"non-convex set\". A polygon that is not a convex polygon is sometimes called a concave polygon, and some sources more generally use the term \"concave set\" to mean a non-convex set, but most authorities prohibit this usage.\nThe complement of a convex set, such as the epigraph of a concave function, is sometimes called a \"reverse convex set\", especially in the context of mathematical optimization.\nProperties.\nGiven points in a convex set , and \nnonnegative numbers such that , the affine combination \nbelongs to . As the definition of a convex set is the case , this property characterizes convex sets.\nSuch an affine combination is called a convex combination of .\nIntersections and unions.\nThe collection of convex subsets of a vector space, an affine space, or a Euclidean space has the following properties:\nClosed convex sets.\nClosed convex sets are convex sets that contain all their limit points. They can be characterised as the intersections of \"closed half-spaces\" (sets of point in space that lie on and to one side of a hyperplane).\nFrom what has just been said, it is clear that such intersections are convex, and they will also be closed sets. To prove the converse, i.e., every closed convex set may be represented as such intersection, one needs the supporting hyperplane theorem in the form that for a given closed convex set and point outside it, there is a closed half-space that contains and not . The supporting hyperplane theorem is a special case of the Hahn\u2013Banach theorem of functional analysis.\nConvex sets and rectangles.\nLet \"C\" be a convex body in the plane (a convex set whose interior is non-empty). We can inscribe a rectangle \"r\" in \"C\" such that a homothetic copy \"R\" of \"r\" is circumscribed about \"C\". The positive homothety ratio is at most 2 and:\nBlaschke-Santal\u00f3 diagrams.\nThe set formula_3 of all planar convex bodies can be parameterized in terms of the convex body diameter \"D\", its inradius \"r\" (the biggest circle contained in the convex body) and its circumradius \"R\" (the smallest circle containing the convex body). In fact, this set can be described by the set of inequalities given byformula_4\nformula_5\nformula_6\nformula_7and can be visualized as the image of the function \"g\" that maps a convex body to the point given by (\"r\"/\"R\", \"D\"/2\"R\"). The image of this function is known a (\"r\", \"D\", \"R\") Blachke-Santal\u00f3 diagram.\nAlternatively, the set formula_3 can also be parametrized by its width (the smallest distance between any two different parallel support hyperplanes), perimeter and area.\nOther properties.\nLet \"X\" be a topological vector space and formula_9 be convex. \nConvex hulls and Minkowski sums.\nConvex hulls.\nEvery subset of the vector space is contained within a smallest convex set (called the convex hull of ), namely the intersection of all convex sets containing . The convex-hull operator Conv() has the characteristic properties of a hull operator:\nThe convex-hull operation is needed for the set of convex sets to form a lattice, in which the \"join\" operation is the convex hull of the union of two convex sets\nThe intersection of any collection of convex sets is itself convex, so the convex subsets of a (real or complex) vector space form a complete lattice.\nMinkowski addition.\nIn a real vector-space, the \"Minkowski sum\" of two (non-empty) sets, and , is defined to be the set formed by the addition of vectors element-wise from the summand-sets\nMore generally, the \"Minkowski sum\" of a finite family of (non-empty) sets is the set formed by element-wise addition of vectors\nFor Minkowski\u00a0addition, the \"zero set\"\u00a0 containing only the zero\u00a0vector\u00a0 has special importance: For every non-empty subset\u00a0S of a vector space\nin algebraic terminology, is the identity element of Minkowski addition (on the collection of non-empty sets).\nConvex hulls of Minkowski sums.\nMinkowski addition behaves well with respect to the operation of taking convex hulls, as shown by the following proposition:\nLet be subsets of a real vector-space, the convex hull of their Minkowski sum is the Minkowski sum of their convex hulls\nThis result holds more generally for each finite collection of non-empty sets:\nIn mathematical terminology, the operations of Minkowski summation and of forming convex hulls are commuting operations.\nMinkowski sums of convex sets.\nThe Minkowski sum of two compact convex sets is compact. The sum of a compact convex set and a closed convex set is closed.\nThe following famous theorem, proved by Dieudonn\u00e9 in 1966, gives a sufficient condition for the difference of two closed convex subsets to be closed. It uses the concept of a recession cone of a non-empty convex subset \"S\", defined as:\nwhere this set is a convex cone containing formula_23 and satisfying formula_24. Note that if \"S\" is closed and convex then formula_25 is closed and for all formula_26, formula_27.\nTheorem (Dieudonn\u00e9). Let \"A\" and \"B\" be non-empty, closed, and convex subsets of a locally convex topological vector space such that formula_28 is a linear subspace. If \"A\" or \"B\" is locally compact then \"A\"\u00a0\u2212\u00a0\"B\" is closed.\nGeneralizations and extensions for convexity.\nThe notion of convexity in the Euclidean space may be generalized by modifying the definition in some or other aspects. The common name \"generalized convexity\" is used, because the resulting objects retain certain properties of convex sets.\nStar-convex (star-shaped) sets.\nLet be a set in a real or complex vector space. is star convex (star-shaped) if there exists an in such that the line segment from to any point in is contained in . Hence a non-empty convex set is always star-convex but a star-convex set is not always convex.\nOrthogonal convexity.\nAn example of generalized convexity is orthogonal convexity.\nA set in the Euclidean space is called orthogonally convex or ortho-convex, if any segment parallel to any of the coordinate axes connecting two points of lies totally within . It is easy to prove that an intersection of any collection of orthoconvex sets is orthoconvex. Some other properties of convex sets are valid as well.\nNon-Euclidean geometry.\nThe definition of a convex set and a convex hull extends naturally to geometries which are not Euclidean by defining a geodesically convex set to be one that contains the geodesics joining any two points in the set.\nOrder topology.\nConvexity can be extended for a totally ordered set endowed with the order topology.\nLet . The subspace is a convex set if for each pair of points in such that , the interval is contained in . That is, is convex if and only if for all in , implies .\nA convex set is not connected in general: a counter-example is given by the subspace {1,2,3} in , which is both convex and not connected.\nConvexity spaces.\nThe notion of convexity may be generalised to other objects, if certain properties of convexity are selected as axioms.\nGiven a set , a convexity over is a collection of subsets of satisfying the following axioms:\nThe elements of are called convex sets and the pair is called a convexity space. For the ordinary convexity, the first two axioms hold, and the third one is trivial.\nFor an alternative definition of abstract convexity, more suited to discrete geometry, see the \"convex geometries\" associated with antimatroids."}
{"id": "6293", "revid": "34452882", "url": "https://en.wikipedia.org/wiki?curid=6293", "title": "Cairo", "text": "Cairo ( ; , , Coptic: \u2c95\u2c81\u03e9\u2c93\u2ca3\u2c8f) is the capital and largest-city of Egypt. The Cairo metropolitan area, with a population of 21.3 million, is the largest in Africa, in the Arab world, and the 6th-largest in the world. Cairo is associated with ancient Egypt, as the famous Giza pyramid complex and the ancient city of Memphis are located in its geographical area. Located near the Nile Delta, Cairo was founded in 969\u00a0AD by the Fatimid dynasty, but the land composing the present-day city was the site of ancient national capitals whose remnants remain visible in parts of Old Cairo. Cairo has long been a centre of the region's political and cultural life, and is titled \"the city of a thousand minarets\" for its preponderance of Islamic architecture. Cairo is considered a World City with a \"Beta +\" classification according to GaWC.\nCairo has the oldest and largest film and music industries in the Arab world, as well as the world's second-oldest institution of higher learning, Al-Azhar University. Many international media, businesses, and organizations have regional headquarters in the city; the Arab League has had its headquarters in Cairo for most of its existence.\nWith a population of over 9 million spread over , Cairo is by far the largest city in Egypt. An additional 9.5 million inhabitants live in close proximity to the city. Cairo, like many other megacities, suffers from high levels of pollution and traffic. The Cairo Metro is one of the only two metro systems in Africa (the other being in Algiers, Algeria), and ranks amongst the fifteen busiest in the world, with over 1 billion annual passenger rides. The economy of Cairo was ranked first in the Middle East in 2005, and 43rd globally on \"Foreign Policy\" 2010 Global Cities Index.\nEtymology.\nEgyptians often refer to Cairo as ' (; ), the Egyptian Arabic name for Egypt itself, emphasizing the city's importance for the country. Its official name ' () means \"the Vanquisher\" or \"the Conqueror\", supposedly due to the fact that the planet Mars, \"an-Najm al-Q\u0101hir\" (, \"the Conquering Star\"), was rising at the time when the city was founded, possibly also in reference to the much awaited arrival of the Fatimid Caliph Al-Mu'izz who reached Cairo in 973 from Mahdia, the old Fatimid capital. The location of the ancient city of Heliopolis is the suburb of Ain Shams (, \"Eye of the Sun\").\nThere are a few Coptic names of the city. (\"di\")\"Kashromi\" () is attested as early as 1211 and is a calque which means \"man breaker\" (\"\u2c95\u2c81\u03e3-\" \u2013 to break, \"\u2ca3\u2cb1\u2c99\u2c93\" \u2013 man) which is akin to Arabic \"\". \"Lioui\" () or \"Elioui\" () is another name which is a corruption of Greek name of Heliopolis (). Some argue that \"Mistram\" () or \"Nistram\" () is another Coptic name for Cairo, although others think that it's rather a name of an Abbasid capital Al-Askar. \u2c95\u2c81\u03e9\u2c93\u2ca3\u2c8f is a popular modern rendering of an Arabic name (others being \u2cad\u2c81\u2c93\u2ca3\u2c9f\u2c9b and \u2c95\u2c81\u03e9\u2c93\u2ca3\u2c81) which has a folk etymology \"land of sun\". Some argue that it was a name of an Egyptian settlement upon which Cairo was built, but it's rather doubtful as this name is not attested in any Hieroglyphic or Demotic source, although some researchers, like Paul Casanova, view it as a legitimate theory. Cairo is also referred to as \u2cad\u2c8f\u2c99\u2c93, which means Egypt in Coptic, the same way it's referred to in Egyptian Arabic.\nSometimes the city is informally referred to as ' by people from Alexandria (; ).\nHistory.\nInitial settlements.\nThe area around present-day Cairo, especially Memphis, which was the old capital of Egypt, had long been a focal point of Ancient Egypt due to its strategic location just upstream from the Nile Delta. However, the origins of the modern city are generally traced back to a series of settlements in the first millennium. Around the turn of the 4th century, as Memphis was continuing to decline in importance, the Romans established a fortress town along the east bank of the Nile. This fortress, known as Babylon, was the nucleus of the Roman and then the Byzantine city and is the oldest structure in the city today. It is also situated at the nucleus of the Coptic Orthodox community, which separated from the Roman and Byzantine churches in the late 4th century. Many of Cairo's oldest Coptic churches, including the Hanging Church, are located along the fortress walls in a section of the city known as Coptic Cairo.\nFollowing the Muslim conquest in AD 640, the conqueror Amr ibn As settled to the north of the Babylon in an area that became known as al-Fustat. Originally a tented camp (\"Fustat\" signifies \"City of Tents\") Fustat became a permanent settlement and the first capital of Islamic Egypt.\nIn 750, following the overthrow of the Umayyad caliphate by the Abbasids, the new rulers created their own settlement to the northeast of Fustat which became their capital. This was known as al-Askar (the city of sections, or cantonments) as it was laid out like a military camp.\nA rebellion in 869 by Ahmad ibn Tulun led to the abandonment of Al Askar and the building of another settlement, which became the seat of government. This was al-Qatta'i (\"the Quarters\"), to the north of Fustat and closer to the river. Al Qatta'i was centred around a palace and ceremonial mosque, now known as the Mosque of ibn Tulun.\nIn 905, the Abbasids re-asserted control of the country and their governor returned to Fustat, razing al-Qatta'i to the ground.\nFoundation and expansion.\nIn 969, the Fatimid empire ruled over Egypt, and under the rule of Jawhar Al Saqili, a new fortified city northeast of Fustat was established. It took four years to build the city, initially known as al-Man\u1e63\u016briyyah, which was to serve as the new capital of the caliphate. During that time, the construction of the al-Azhar Mosque was commissioned by order of the Caliph, which developed into the third-oldest university in the world. Cairo would eventually become a centre of learning, with the library of Cairo containing hundreds of thousands of books. When Caliph al-Mu'izz li Din Allah arrived from the old Fatimid capital of Mahdia in Tunisia in 973, he gave the city its present name, \"Q\u0101hirat al-Mu'izz\" (\"The Vanquisher of al-Mu'izz\").\nFor nearly 200 years after Cairo was established, the administrative centre of Egypt remained in Fustat. However, in 1168 the Fatimid vizier Shawar set fire to Fustat to prevent its capture by Amalric, the Crusader king of Jerusalem. Egypt's capital was permanently moved to Cairo, which was eventually expanded to include the ruins of Fustat and the previous capitals of al-Askar and al-Qatta'i. As al Qahira expanded these earlier settlements were encompassed, and have since become part of the city of Cairo as it expanded and spread; they are now collectively known as \"Old Cairo\".\nWhile the Fustat fire successfully protected the city of Cairo, a continuing power struggle between Shawar, King Amalric I of Jerusalem, and the Zengid general Shirkuh led to the downfall of the Fatimid establishment.\nIn 1169, Saladin was appointed as the new vizier of Egypt by the Fatimids and two years later he seized power from the family of the last Fatimid caliph, al-'\u0100\u1e0did. As the first Sultan of Egypt, Saladin established the Ayyubid dynasty, based in Cairo, and aligned Egypt with the Abbasids, who were based in Baghdad. During his reign, Saladin constructed the Cairo Citadel, which served as the seat of the Egyptian government until the mid-19th century.\nIn 1250, slave soldiers, known as the Mamluks, seized control of Egypt and like many of their predecessors established Cairo as the capital of their new dynasty. Continuing a practice started by the Ayyubids, much of the land occupied by former Fatimid palaces was sold and replaced by newer buildings. Construction projects initiated by the Mamluks pushed the city outward while also bringing new infrastructure to the centre of the city. Meanwhile, Cairo flourished as a centre of Islamic scholarship and a crossroads on the spice trade route among the civilisations in Afro-Eurasia. By 1340, Cairo had a population of close to half a million, making it the largest city west of China.\nThe historic traveller Ibn Battuta travelled thousands of miles during the course of his trek. One city he stopped in was Cairo, Egypt. One significant note Ibn Battuta made was that Cairo was the principal district of Egypt, meaning Cairo was Egypt's most important and most influential city (Ibn Battuta, 2009). Ibn Battuta also acknowledges the importance of the Nile river to all of Egypt, including Cairo, as he often travelled via boat to arrive at Cairo and to leave to continue his journey. The Nile was not just a means for transportation, it was the source of a plethora of other tangibles as well. The Nile's most influential attribute was its ability to sustain rich soil for agriculture. Part of the Agricultural Revolution thrived in Egypt, predominantly off the back of the Nile. The Nile also served as a source of food and a pathway for trade. Without it, the Egypt we know today wouldn't have been the same. One of Ibn Battuta's most detailed accounts in Cairo involves a plague that was devastating the city. Today, this plague is known as the Bubonic Plague, or the Black Death. It is believed to have arrived in Egypt in 1347, and as Ibn Battuta recalls, the Bubonic plague was responsible for the deaths of between 1 and 20,000 people a day in Cairo(Berkeley ORIAS, 2018) (Ibn Battuta, 2009). The plague originated in Asia and spread via fleas on rodents, such as rats (Berkeley ORIAS, 2018). The plague would end up spreading to all of Eurasia and wiped out any civilizations that were in its path. It is estimated that somewhere between 75 and 200 million people total died from the plague.\nOttoman rule.\nAlthough Cairo avoided Europe's stagnation during the Late Middle Ages, it could not escape the Black Death, which struck the city more than fifty times between 1348 and 1517. During its initial, and most deadly waves, approximately 200,000 people were killed by the plague, and, by the 15th century, Cairo's population had been reduced to between 150,000 and 300,000. The city's status was further diminished after Vasco da Gama discovered a sea route around the Cape of Good Hope between 1497 and 1499, thereby allowing spice traders to avoid Cairo.\nCairo's political influence diminished significantly after the Ottomans supplanted Mamluk power over Egypt in 1517. Ruling from Constantinople, Sultan Selim I relegated Egypt to a province, with Cairo as its capital. For this reason, the history of Cairo during Ottoman times is often described as inconsequential, especially in comparison to other time periods. However, during the 16th and 17th centuries, Cairo remained an important economic and cultural centre. Although no longer on the spice route, the city facilitated the transportation of Yemeni coffee and Indian textiles, primarily to Anatolia, North Africa, and the Balkans. Cairene merchants were instrumental in bringing goods to the barren Hejaz, especially during the annual hajj to Mecca. It was during this same period that al-Azhar University reached the predominance among Islamic schools that it continues to hold today; pilgrims on their way to hajj often attested to the superiority of the institution, which had become associated with Egypt's body of Islamic scholars. By the 16th century, Cairo also had high-rise apartment buildings where the two lower floors were for commercial and storage purposes and the multiple stories above them were rented out to tenants.\nUnder the Ottomans, Cairo expanded south and west from its nucleus around the Citadel. The city was the second-largest in the empire, behind Constantinople, and, although migration was not the primary source of Cairo's growth, twenty percent of its population at the end of the 18th century consisted of religious minorities and foreigners from around the Mediterranean. Still, when Napoleon arrived in Cairo in 1798, the city's population was less than 300,000, forty percent lower than it was at the height of Mamluk\u2014and Cairene\u2014influence in the mid-14th century.\nThe French occupation was short-lived as British and Ottoman forces, including a sizeable Albanian contingent, recaptured the country in 1801. Cairo itself was besieged by a British and Ottoman force culminating with the French surrender on 22 June 1801. The British vacated Egypt two years later, leaving the Ottomans, the Albanians, and the long-weakened Mamluks jostling for control of the country. Continued civil war allowed an Albanian named Muhammad Ali Pasha to ascend to the role of commander and eventually, with the approval of the religious establishment, viceroy of Egypt in 1805.\nModern era.\nUntil his death in 1848, Muhammad Ali Pasha instituted a number of social and economic reforms that earned him the title of founder of modern Egypt. However, while Muhammad Ali initiated the construction of public buildings in the city, those reforms had minimal effect on Cairo's landscape. Bigger changes came to Cairo under Isma'il Pasha (r. 1863\u20131879), who continued the modernisation processes started by his grandfather. Drawing inspiration from Paris, Isma'il envisioned a city of maidans and wide avenues; due to financial constraints, only some of them, in the area now composing Downtown Cairo, came to fruition. Isma'il also sought to modernize the city, which was merging with neighbouring settlements, by establishing a public works ministry, bringing gas and lighting to the city, and opening a theatre and opera house.\nThe immense debt resulting from Isma'il's projects provided a pretext for increasing European control, which culminated with the British invasion in 1882. The city's economic centre quickly moved west toward the Nile, away from the historic Islamic Cairo section and toward the contemporary, European-style areas built by Isma'il. Europeans accounted for five percent of Cairo's population at the end of the 19th century, by which point they held most top governmental positions.\nIn 1905 the Heliopolis Oasis Company headed by the Belgian industrialist \u00c9douard Empain and by Boghos Nubar, son of the Egyptian Prime Minister Nubar Pasha built a suburb called Heliopolis ten kilometers from the center of Cairo. It represented the first large-scale attempt to promote its own architecture, known now as the Heliopolis style.\nThe British occupation was intended to be temporary, but it lasted well into the 20th century. Nationalists staged large-scale demonstrations in Cairo in 1919, five years after Egypt had been declared a British protectorate. Nevertheless, this led to Egypt's independence in 1922.\n1924 Cairo Quran.\nThe King Fuad I Edition of the Qur\u2019an was first published on 10 July 1924 in Cairo under the patronage of King Fuad. The goal of the government of the newly formed Kingdom of Egypt was not to delegitimize the other variant Quranic texts (\"qira'at\"), but to eliminate errors found in Qur\u2019anic texts used in state schools. A committee of teachers chose to preserve a single one of the canonical qira\u2019at \"readings\", namely that of the \"\u1e24af\u1e63\" version, an 8th-century Kufic recitation. This edition has become the standard for modern printings of the Quran for much of the Islamic world. The publication has been called a \"terrific success\", and the edition has been described as one \"now widely seen as the official text of the Qur\u2019an\", so popular among both Sunni and Shi'a that the common belief among less well-informed Muslims is \"that the Qur\u2019an has a single, unambiguous reading\". Minor amendments were made later in 1924 and in 1936 - the \"Faruq edition\" in honour of then ruler, King Faruq.\nBritish occupation until 1956.\nBritish troops remained in the country until 1956. During this time, urban Cairo, spurred by new bridges and transport links, continued to expand to include the upscale neighbourhoods of Garden City, Zamalek, and Heliopolis. Between 1882 and 1937, the population of Cairo more than tripled\u2014from 347,000 to 1.3 million\u2014and its area increased from .\nThe city was devastated during the 1952 riots known as the Cairo Fire or Black Saturday, which saw the destruction of nearly 700 shops, movie theatres, casinos and hotels in downtown Cairo. The British departed Cairo following the Egyptian Revolution of 1952, but the city's rapid growth showed no signs of abating. Seeking to accommodate the increasing population, President Gamal Abdel Nasser redeveloped Maidan Tahrir and the Nile Corniche, and improved the city's network of bridges and highways. Meanwhile, additional controls of the Nile fostered development within Gezira Island and along the city's waterfront. The metropolis began to encroach on the fertile Nile Delta, prompting the government to build desert satellite towns and devise incentives for city-dwellers to move to them.\n1960s.\nCairo's population has doubled since the 1960s, reaching close to seven million (with an additional ten million in its urban area). Concurrently, Cairo has established itself as a political and economic hub for North Africa and the Arab world, with many multinational businesses and organisations, including the Arab League, operating out of the city.\nIn 1992, Cairo was hit by an earthquake causing 545 deaths, injuring 6,512 and leaving around 50,000 people homeless.\n2011 Egyptian revolution.\nCairo's Tahrir Square was the focal point of the 2011 Egyptian Revolution against former president Hosni Mubarak. Over 2 million protesters were at Cairo's Tahrir square. More than 50,000 protesters first occupied the square on 25 January, during which the area's wireless services were reported to be impaired. In the following days Tahrir Square continued to be the primary destination for protests in Cairo as it took place following a popular uprising that began on Tuesday, 25 January 2011 and continued until June 2013. The uprising was mainly a campaign of non-violent civil resistance, which featured a series of demonstrations, marches, acts of civil disobedience, and labour strikes. Millions of protesters from a variety of socio-economic and religious backgrounds demanded the overthrow of the regime of Egyptian President Hosni Mubarak. Despite being predominantly peaceful in nature, the revolution was not without violent clashes between security forces and protesters, with at least 846 people killed and 6,000 injured. The uprising took place in Cairo, Alexandria, and in other cities in Egypt, following the Tunisian revolution that resulted in the overthrow of the long-time Tunisian president Zine El Abidine Ben Ali. On 11 February, following weeks of determined popular protest and pressure, Hosni Mubarak resigned from office.\nPost-revolutionary Cairo.\nUnder the rule of President el-Sisi, in March 2015 plans were announced for another yet-unnamed planned city to be built further east of the existing satellite city of New Cairo, intended to serve as the new capital of Egypt.\nGeography.\nCairo is located in northern Egypt, known as Lower Egypt, south of the Mediterranean Sea and west of the Gulf of Suez and Suez Canal. The city lies along the Nile River, immediately south of the point where the river leaves its desert-bound valley and branches into the low-lying Nile Delta region. Although the Cairo metropolis extends away from the Nile in all directions, the city of Cairo resides only on the east bank of the river and two islands within it on a total area of . Geologically, Cairo lies on alluvium and sand dunes which date from the quaternary period.\nUntil the mid-19th century, when the river was tamed by dams, levees, and other controls, the Nile in the vicinity of Cairo was highly susceptible to changes in course and surface level. Over the years, the Nile gradually shifted westward, providing the site between the eastern edge of the river and the Mokattam highlands on which the city now stands. The land on which Cairo was established in 969 (present-day Islamic Cairo) was located underwater just over three hundred years earlier, when Fustat was first built.\nLow periods of the Nile during the 11th century continued to add to the landscape of Cairo; a new island, known as \"Geziret al-Fil\", first appeared in 1174, but eventually became connected to the mainland. Today, the site of \"Geziret al-Fil\" is occupied by the Shubra district. The low periods created another island at the turn of the 14th century that now composes Zamalek and Gezira. Land reclamation efforts by the Mamluks and Ottomans further contributed to expansion on the east bank of the river.\nBecause of the Nile's movement, the newer parts of the city\u2014Garden City, Downtown Cairo, and Zamalek\u2014are located closest to the riverbank. The areas, which are home to most of Cairo's embassies, are surrounded on the north, east, and south by the older parts of the city. Old Cairo, located south of the centre, holds the remnants of Fustat and the heart of Egypt's Coptic Christian community, Coptic Cairo. The Boulaq district, which lies in the northern part of the city, was born out of a major 16th-century port and is now a major industrial centre. The Citadel is located east of the city centre around Islamic Cairo, which dates back to the Fatimid era and the foundation of Cairo. While western Cairo is dominated by wide boulevards, open spaces, and modern architecture of European influence, the eastern half, having grown haphazardly over the centuries, is dominated by small lanes, crowded tenements, and Islamic architecture.\nNorthern and extreme eastern parts of Cairo, which include satellite towns, are among the most recent additions to the city, as they developed in the late-20th and early-21st centuries to accommodate the city's rapid growth. The western bank of the Nile is commonly included within the urban area of Cairo, but it composes the city of Giza and the Giza Governorate. Giza has also undergone significant expansion over recent years, and today the city, although still a suburb of Cairo, has a population of 2.7 million. The Cairo Governorate was just north of the Helwan Governorate from 2008 when some Cairo's southern districts, including Maadi and New Cairo, were split off and annexed into the new governorate, to 2011 when the Helwan Governorate was reincorporated into the Cairo Governorate.\nAccording to the World Health Organization, the level of air pollution in Cairo is nearly 12 times higher than the recommended safety level\nClimate.\nIn Cairo, and along the Nile River Valley, the climate is a hot desert climate (\"BWh\" according to the K\u00f6ppen climate classification system). Wind storms can be frequent, bringing Saharan dust into the city, from March to May and the air often becomes uncomfortably dry. High temperatures in winter range from , while night-time lows drop to below , often to . In summer, the highs rarely surpass , and lows drop to about . Rainfall is sparse and only happens in the colder months, but sudden showers can cause severe flooding. The summer months have high humidity due to its coastal location. Snowfall is extremely rare; a small amount of graupel, widely believed to be snow, fell on Cairo's easternmost suburbs on 13 December 2013, the first time Cairo's area received this kind of precipitation in many decades. Dew points in the hottest months range from in June to in August.\nMetropolitan area.\nThe Greater Cairo is the largest metropolitan area in Africa. It consists of Cairo Governorate, parts of Giza Governorate, and parts of Qalyubia Governorate.\nSatellite cities.\n6th of October City, west of Cairo, and New Cairo, east of Cairo, are major urban developments which have been built to accommodate additional growth and development of the Cairo area. New development includes several high-end residential developments.\nPlanned new capital.\nIn March 2015, plans were announced for a yet-unnamed planned city to be built east of Cairo, in an undeveloped area of the Cairo Governorate, which would serve as the administrative and financial capital of Egypt.\nInfrastructure.\nHealth.\nCairo, as well as neighbouring Giza, has been established as Egypt's main centre for medical treatment, and despite some exceptions, has the most advanced level of medical care in the country. Cairo's hospitals include the JCI-accredited As-Salaam International Hospital\u2014Corniche El Nile, Maadi (Egypt's largest private hospital with 350 beds), Ain Shams University Hospital, Dar Al Fouad, Nile Badrawi Hospital, 57357 Hospital, as well as Qasr El Eyni Hospital.\nEducation.\nGreater Cairo has long been the hub of education and educational services for Egypt and the region.\nToday, Greater Cairo is the centre for many government offices governing the Egyptian educational system, has the largest number of educational schools, and higher education institutes among other cities and governorates of Egypt.\nSome of the International Schools found in Cairo:\nUniversities in Greater Cairo:\nTransportation.\nCairo has an extensive road network, rail system, subway system and maritime services. Road transport is facilitated by personal vehicles, taxi cabs, privately owned public buses and Cairo microbuses. Cairo, specifically Ramses Station, is the centre of almost the entire Egyptian transportation network.\nThe subway system, officially called \"Metro (\u0645\u062a\u0631\u0648)\", is a fast and efficient way of getting around Cairo. Metro network covers Helwan and other suburbs. It can get very crowded during rush hour. Two train cars (the fourth and fifth ones) are reserved for women only, although women may ride in any car they want.\nTrams in Greater Cairo and Cairo trolleybus are former modes of transportation but were closed.\nAn extensive road network connects Cairo with other Egyptian cities and villages. There is a new Ring Road that surrounds the outskirts of the city, with exits that reach outer Cairo districts. There are flyovers and bridges, such as the 6th October Bridge that, when the traffic is not heavy, allow fast means of transportation from one side of the city to the other.\nCairo traffic is known to be overwhelming and overcrowded. Traffic moves at a relatively fluid pace. Drivers tend to be aggressive, but are more courteous at junctions, taking turns going, with police aiding in traffic control of some congested areas.\nIn 2017 plans to construct two monorail systems were announced, one linking 6th of October to suburban Giza, a distance of , and the other linking Nasr City to New Cairo, a distance of .\nSports.\nFootball is the most popular sport in Egypt, and Cairo has a number of sporting teams that compete in national and regional leagues. The best known teams are Al Ahly, El Zamalek and Al-Ismaily. The annual match between Al Ahly and El Zamalek is one of the most watched sports events in Egypt as well as the African-Arab region. The teams form the major rivalry of Egyptian football, and are the first and the second champions in Africa and the Arab world. They play their home games at Cairo International Stadium or Naser Stadium, which is the second largest stadium in Egypt, as well as the largest in Cairo and one of the largest stadiums in the world.\nThe Cairo International Stadium was built in 1960 and its multi-purpose sports complex that houses the main football stadium, an indoor stadium, several satellite fields that held several regional, continental and global games, including the African Games, U17 Football World Championship and was one of the stadiums scheduled that hosted the 2006 Africa Cup of Nations which was played in January 2006. Egypt later won the competition and went on to win the next edition in Ghana (2008) making the Egyptian and Ghanaian national teams the only teams to win the African Nations Cup Back to back which resulted in Egypt winning the title for a record number of six times in the history of African Continental Competition. This was followed by a third consecutive win in Angola 2010, making Egypt the only country with a record 3-consecutive and 7-total Continental Football Competition winner. This achievement had also placed the Egyptian football team as the #9 best team in the world's FIFA rankings.\nCairo failed at the applicant stage when bidding for the 2008 Summer Olympics, which was hosted in Beijing, China. However, Cairo did host the 2007 Pan Arab Games.\nThere are several other sports teams in the city that participate in several sports including el Gezira Sporting Club, el Shams Club, el Seid Club, Heliopolis Club and several smaller clubs, but the biggest clubs in Egypt (not in area but in sports) are Al Ahly and Al Zamalek. They have the two biggest football teams in Egypt. There are new sports clubs in the area of New Cairo (one hour far from Cairo's down town), these are Al Zohour sporting club, Wadi Degla sporting club and Platinum Club.\nMost of the sports federations of the country are also located in the city suburbs, including the Egyptian Football Association. The headquarters of the Confederation of African Football (CAF) was previously located in Cairo, before relocating to its new headquarters in 6 October City, a small city away from Cairo's crowded districts.\nIn October 2008, the Egyptian Rugby Federation was officially formed and granted membership into the International Rugby Board.\nEgypt is internationally known for the excellence of its squash players who excel in both professional and junior divisions. Egypt has seven players in the top ten of the PSA men's world rankings, and three in the women's top ten. Mohamed El Shorbagy held the world number one position for more than a year before being overtaken by compatriot Karim Abdel Gawad, who is number two behind Gregory Gaultier of France. Ramy Ashour and Amr Shabana are regarded as two of the most talented squash players in history. Shabana won the World Open title four times and Ashour twice, although his recent form has been hampered by injury. Egypt's Nour El Sherbini has won the Women's World Championship twice and has been women's world number one for 16 consecutive months. On 30 April 2016, she became the youngest woman to win the Women's World Championship which was held in Malaysia. In April 2017 she retained her title by winning the Women's World Championship which was held in the Egyptian resort of El Gouna.\nCulture.\nCairo Opera House.\nPresident Mubarak inaugurated the new Cairo Opera House of the Egyptian National Cultural Centres on 10 October 1988, 17 years after the Royal Opera House had been destroyed by fire. The National Cultural Centre was built with the help of JICA, the Japan International Co-operation Agency and stands as a prominent feature for the Japanese-Egyptian co-operation and the friendship between the two nations.\nKhedivial Opera House.\nThe Khedivial Opera House, or Royal Opera House, was the original opera house in Cairo. It was dedicated on 1 November 1869 and burned down on 28 October 1971. After the original opera house was destroyed, Cairo was without an opera house for nearly two decades until the opening of the new Cairo Opera House in 1988.\nCairo International Film Festival.\nCairo held its first international film festival 16 August 1976, when the first Cairo International Film Festival was launched by the Egyptian Association of Film Writers and Critics, headed by Kamal El-Mallakh. The Association ran the festival for seven years until 1983.\nThis achievement lead to the President of the Festival again contacting the FIAPF with the request that a competition should be included at the 1991 Festival. The request was granted.\nIn 1998, the Festival took place under the presidency of one of Egypt's leading actors, Hussein Fahmy, who was appointed by the Minister of Culture, Farouk Hosni, after the death of Saad El-Din Wahba. Four years later, the journalist and writer Cherif El-Shoubashy became president.\nCairo Geniza.\nThe Cairo Geniza is an accumulation of almost 200,000 Jewish manuscripts that were found in the genizah of the Ben Ezra synagogue (built 882) of Fustat, Egypt (now Old Cairo), the Basatin cemetery east of Old Cairo, and a number of old documents that were bought in Cairo in the later 19th century. These documents were written from about 870 to 1880 AD and have been archived in various American and European libraries. The Taylor-Schechter collection in the University of Cambridge runs to 140,000 manuscripts, a further 40,000 manuscripts are at the Jewish Theological Seminary of America.\nFood.\nThe majority of Cairenes make food for themselves and make use of local produce markets. The restaurant scene includes traditional Middle Eastern cuisine as well as local staples such as \"kushari\". The city's most exclusive restaurants are typically concentrated in Zamalek and around the luxury hotels lining the shore of the Nile near the Garden City district. Influence from modern western society is also evident, with American chains such as McDonald's, Arby's, Pizza Hut, Subway, and Kentucky Fried Chicken being easy to find in central areas.\nPlaces of worship.\nAmong the places of worship, they are predominantly Muslim mosques. There are also Christian churches and temples: Coptic Orthodox Church, Coptic Catholic Church (Catholic Church), Evangelical Church of Egypt (Synod of the Nile) (World Communion of Reformed Churches).\nEconomy.\nCairo accounts for 11% of Egypt's population and 22% of its economy (PPP). The majority of the nation's commerce is generated there, or passes through the city. The great majority of publishing houses and media outlets and nearly all film studios are there, as are half of the nation's hospital beds and universities. This has fuelled rapid construction in the city\u2014one building in five is less than 15 years old.\nThis growth until recently surged well ahead of city services. Homes, roads, electricity, telephone and sewer services were all in short supply. Analysts trying to grasp the magnitude of the change coined terms like \"hyper-urbanization\".\nCityscape and landmarks.\nTahrir Square.\nTahrir Square was founded during the mid 19th century with the establishment of modern downtown Cairo. It was first named Ismailia Square, after the 19th-century ruler Khedive Ismail, who commissioned the new downtown district's 'Paris on the Nile' design. After the Egyptian Revolution of 1919 the square became widely known as Tahrir (Liberation) Square, though it was not officially renamed as such until after the 1952 Revolution which eliminated the monarchy. Several notable buildings surround the square including, the American University in Cairo's downtown campus, the Mogamma governmental administrative Building, the headquarters of the Arab League, the Nile Ritz Carlton Hotel, and the Egyptian Museum. Being at the heart of Cairo, the square witnessed several major protests over the years. However, the most notable event in the square was being the focal point of the 2011 Egyptian Revolution against former president Hosni Mubarak.\nEgyptian Museum.\nThe Museum of Egyptian Antiquities, known commonly as the Egyptian Museum, is home to the most extensive collection of ancient Egyptian antiquities in the world. It has 136,000 items on display, with many more hundreds of thousands in its basement storerooms. Among its most famous collections on display are the finds from the tomb of Tutankhamun.\nGrand Egyptian Museum.\nMuch of the collection of the Museum of Egyptian Antiquities, including the Tutankhamun collection, are slated to be moved to the new Grand Egyptian Museum, under construction in Giza and due to open by the end of 2020.\nCairo Tower.\nThe Cairo Tower is a free-standing tower with a revolving restaurant at the top. It provides a bird's eye view of Cairo to the restaurant patrons. It stands in the Zamalek district on Gezira Island in the Nile River, in the city centre. At , it is higher than the Great Pyramid of Giza, which stands some to the southwest.\nOld Cairo.\nThis area of Cairo is so-named as it contains the remains of the ancient Roman fortress of Babylon and also overlaps the original site of Fustat, the first Arab settlement in Egypt (7th century AD) and the predecessor of later Cairo. The area includes the Coptic Cairo, which holds a high concentration of old Christian churches such as the Hanging Church, the Greek Orthodox Church of St. George, and other Christian or Coptic buildings, most of which are located over the site of the ancient Roman fortress. It is also the location of the Coptic Museum, which showcases the history of Coptic art from Greco-Roman to Islamic times, and of the Ben Ezra Synagogue, the oldest and best-known synagogue in Cairo, where the important collection of Geniza documents were discovered in the 19th century. To the north of this Coptic enclave is the Amr ibn al-'As Mosque, the first mosque in Egypt and the most important religious centre of what was formerly Fustat, founded in 642 AD right after the Arab conquest but rebuilt many times since.\nIslamic Cairo.\nCairo holds one of the greatest concentrations of historical monuments of Islamic architecture in the world. The areas around the old walled city and around the Citadel are characterized by hundreds of mosques, tombs, madrasas, mansions, caravanserais, and fortifications dating from the Islamic era and are often referred to as \"Islamic Cairo\", especially in English travel literature. It is also the location of several important religious shrines such as the al-Hussein Mosque (whose shrine is believed to hold the head of Husayn ibn Ali), the Mausoleum of Imam al-Shafi'i (founder of the Shafi'i madhhab, one of the primary schools of thought in Sunni Islamic jurisprudence), the Tomb of Sayyida Ruqayya, the Mosque of Sayyida Nafisa, and others.\nThe first mosque in Egypt was the Mosque of Amr ibn al-As in what was formerly Fustat, the first Arab-Muslim settlement in the area. However, the Mosque of Ibn Tulun is the oldest mosque that still retains its original form and is a rare example of Abbasid architecture from the classical period of Islamic civilization. It was built in 876\u2013879 AD in a style inspired by the Abbasid capital of Samarra in Iraq. It is one of the largest mosques in Cairo and is often cited as one of the most beautiful. Another Abbasid construction, the Nilometer on Rhoda Island, is the oldest original structure in Cairo, built in 862 AD. It was designed to measure the level of the Nile, which was important for agricultural and administrative purposes.\nThe settlement that was formally named Cairo (Arabic: \"al-Qahira\") was founded to the northeast of Fustat in 959 AD by the victorious Fatimid army. The Fatimids built it as a separate palatial city which contained their palaces and institutions of government. It was enclosed by a circuit of walls, which were rebuilt in stone in the late 11th century AD by the vizir Badr al-Gamali, parts of which survive today at Bab Zuwayla in the south and Bab al-Futuh and Bab al-Nasr in the north.\nOne of the most important and lasting institutions founded in the Fatimid period was the Mosque of al-Azhar, founded in 970 AD, which competes with the Qarawiyyin in Fes for the title of oldest university in the world. Today, al-Azhar University is the foremost Center of Islamic learning in the world and one of Egypt's largest universities with campuses across the country. The mosque itself retains significant Fatimid elements but has been added to and expanded in subsequent centuries, notably by the Mamluk sultans Qaitbay and al-Ghuri and by Abd al-Rahman Katkhuda in the 18th century.\nOther extant monuments from the Fatimid era include the large Mosque of al-Hakim, the Aqmar Mosque, Juyushi Mosque, Lulua Mosque, and the Mosque of Al-Salih Tala'i.\nThe most prominent architectural heritage of medieval Cairo, however, dates from the Mamluk period, from 1250 to 1517 AD. The Mamluk sultans and elites were eager patrons of religious and scholarly life, commonly building religious or funerary complexes whose functions could include a mosque, madrasa, khanqah (for Sufis), a sabil (water dispensary), and a mausoleum for themselves and their families.\nAmong the best-known examples of Mamluk monuments in Cairo are the huge Mosque-Madrasa of Sultan Hasan, the Mosque of Amir al-Maridani, the Mosque of Sultan al-Mu'ayyad (whose twin minarets were built above the gate of Bab Zuwayla), the Sultan Al-Ghuri complex, the funerary complex of Sultan Qaytbay in the Northern Cemetery, and the trio of monuments in the Bayn al-Qasrayn area comprising the complex of Sultan al-Mansur Qalawun, the Madrasa of al-Nasir Muhammad, and the Madrasa of Sultan Barquq. Some mosques include spolia (often columns or capitals) from earlier buildings built by the Romans, Byzantines, or Copts.\nThe Mamluks, and the later Ottomans, also built \"wikala\"s or caravanserais to house merchants and goods due to the important role of trade and commerce in Cairo's economy. The most famous example still intact today is the Wikala al-Ghuri, which nowadays also hosts regular performances by the Al-Tannoura Egyptian Heritage Dance Troupe. The famous Khan al-Khalili is a commercial hub which also integrated caravanserais (also known as \"khan\"s).\nCitadel of Cairo.\nThe Citadel is a fortified enclosure begun by Salah al-Din in 1176 AD on an outcrop of the Muqattam Hills as part of a large defensive system to protect both Cairo to the north and Fustat to the southwest. It was the centre of Egyptian government and residence of its rulers until 1874, when Khedive Isma'il moved to 'Abdin Palace. It is still occupied by the military today, but is now open as a tourist attraction comprising, notably, the National Military Museum, the 14th century Mosque of al-Nasir Muhammad, and the 19th century Mosque of Muhammad Ali which commands a dominant position on Cairo's skyline.\nKhan el-Khalili.\nKhan el-Khalili is an ancient bazaar, or marketplace adjacent to the Al-Hussein Mosque. It dates back to 1385, when Amir Jarkas el-Khalili built a large caravanserai, or khan. (A caravanserai is a hotel for traders, and usually the focal point for any surrounding area.) This original carvanserai building was demolished by Sultan al-Ghuri, who rebuilt it as a new commercial complex in the early 16th century, forming the basis for the network of souqs existing today. Many medieval elements remain today, including the ornate Mamluk-style gateways. Today, the Khan el-Khalili is a major tourist attraction and popular stop for tour groups.\nSociety.\nToday, Cairo is heavily urbanized and most Cairenes now live in apartment buildings. Because of the influx of people into the city, lone standing houses are rare, and apartment buildings accommodate for the limited space and abundance of people. Single detached houses are symbolic of the wealthy. Formal education has also become very important. There are twelve years of standard formal education. Cairenes can take a standardized test similar to the SAT to be accepted to an institution of higher learning but most children do not finish school and opt to pick up a trade to enter the work force. Egypt still struggles with poverty, with almost half the population living on $2 or less a day. \nWomen's rights.\nThe civil rights movement for women in Cairo and Egypt has been a long battle for years. Women are reported to face constant discrimination, sexual harassment, and abuse throughout Cairo. A 2013 UN study found that over 99% of Egyptian women reported experiencing sexual harassment at some point in their lives. The problem has persisted in spite of new national laws since 2014 defining and criminalizing sexual harassment. The situation is so severe that in 2017 Cairo was named by one poll as the most dangerous megacity for women in the world. In 2020, the social media account \"Assault Police\" began to name and shame perpetrators of violence against women. The account was founded by student Nadeen Ashraf, who is credited for instigating an iteration of the #MeToo movement in Egypt.\nPollution.\nThe air pollution in Cairo is a matter of serious concern. Greater Cairo's volatile aromatic hydrocarbon levels are higher than many other similar cities. Air quality measurements in Cairo have also been recording dangerous levels of lead, carbon dioxide, sulphur dioxide, and suspended particulate matter concentrations due to decades of unregulated vehicle emissions, urban industrial operations, and chaff and trash burning. There are over 4,500,000 cars on the streets of Cairo, 60% of which are over 10 years old, and therefore lack modern emission cutting features. Cairo has a very poor dispersion factor because of its lack of rain and its layout of tall buildings and narrow streets, which create a bowl effect.\nIn recent years, a black cloud (as Egyptians refer to it) of smog has appeared over Cairo every autumn due to temperature inversion. Smog causes serious respiratory diseases and eye irritations for the city's citizens. Tourists who are not familiar with such high levels of pollution must take extra care.\nCairo also has many unregistered lead and copper smelters which heavily pollute the city. The results of this has been a permanent haze over the city with particulate matter in the air reaching over three times normal levels. It is estimated that 10,000 to 25,000 people a year in Cairo die due to air pollution-related diseases. Lead has been shown to cause harm to the central nervous system and neurotoxicity particularly in children. In 1995, the first environmental acts were introduced and the situation has seen some improvement with 36 air monitoring stations and emissions tests on cars. Twenty thousand buses have also been commissioned to the city to improve congestion levels, which are very high.\nThe city also suffers from a high level of land pollution. Cairo produces 10,000 tons of waste material each day, 4,000 tons of which is not collected or managed. This is a huge health hazard, and the Egyptian Government is looking for ways to combat this. The Cairo Cleaning and Beautification Agency was founded to collect and recycle the waste; they work with the Zabbaleen community that has been collecting and recycling Cairo's waste since the turn of the 20th century and live in an area known locally as Manshiyat naser. Both are working together to pick up as much waste as possible within the city limits, though it remains a pressing problem.\nWater pollution is also a serious problem in the city as the sewer system tends to fail and overflow. On occasion, sewage has escaped onto the streets to create a health hazard. This problem is hoped to be solved by a new sewer system funded by the European Union, which could cope with the demand of the city. The dangerously high levels of mercury in the city's water system has global health officials concerned over related health risks.\nInternational relations.\nThe Headquarters of the Arab League is located in Tahrir Square, near the downtown business district of Cairo.\nTwin towns \u2013 sister cities.\nCairo is twinned with:"}
{"id": "6295", "revid": "33839581", "url": "https://en.wikipedia.org/wiki?curid=6295", "title": "Chaos theory", "text": "Chaos theory is a branch of mathematics focusing on the study of \"chaos\" \u2014 dynamical systems whose apparently random states of disorder and irregularities are actually governed by underlying patterns and deterministic laws that are highly sensitive to initial conditions. Chaos theory is an interdisciplinary theory stating that, within the apparent randomness of chaotic complex systems, there are underlying patterns, interconnectedness, constant feedback loops, repetition, self-similarity, fractals, and self-organization. The butterfly effect, an underlying principle of chaos, describes how a small change in one state of a deterministic nonlinear system can result in large differences in a later state (meaning that there is sensitive dependence on initial conditions). A metaphor for this behavior is that a butterfly flapping its wings in Texas can cause a hurricane in China.\nSmall differences in initial conditions, such as those due to errors in measurements or due to rounding errors in numerical computation, can yield widely diverging outcomes for such dynamical systems, rendering long-term prediction of their behavior impossible in general. This can happen even though these systems are deterministic, meaning that their future behavior follows a unique evolution and is fully determined by their initial conditions, with no random elements involved. In other words, the deterministic nature of these systems does not make them predictable. This behavior is known as deterministic chaos, or simply chaos. The theory was summarized by Edward Lorenz as:\nChaotic behavior exists in many natural systems, including fluid flow, heartbeat irregularities, weather and climate. It also occurs spontaneously in some systems with artificial components, such as the stock market and road traffic. This behavior can be studied through the analysis of a chaotic mathematical model, or through analytical techniques such as recurrence plots and Poincar\u00e9 maps. Chaos theory has applications in a variety of disciplines, including meteorology, anthropology, sociology, physics, environmental science, computer science, engineering, economics, biology, ecology, pandemic crisis management, and philosophy. The theory formed the basis for such fields of study as complex dynamical systems, edge of chaos theory, and self-assembly processes.\nIntroduction.\nChaos theory concerns deterministic systems whose behavior can in principle be predicted. Chaotic systems are predictable for a while and then 'appear' to become random. The amount of time that the behavior of a chaotic system can be effectively predicted depends on three things: how much uncertainty can be tolerated in the forecast, how accurately its current state can be measured, and a time scale depending on the dynamics of the system, called the Lyapunov time. Some examples of Lyapunov times are: chaotic electrical circuits, about 1 millisecond; weather systems, a few days (unproven); the inner solar system, 4 to 5 million years. In chaotic systems, the uncertainty in a forecast increases exponentially with elapsed time. Hence, mathematically, doubling the forecast time more than squares the proportional uncertainty in the forecast. This means, in practice, a meaningful prediction cannot be made over an interval of more than two or three times the Lyapunov time. When meaningful predictions cannot be made, the system appears random.\nChaotic dynamics.\nIn common usage, \"chaos\" means \"a state of disorder\". However, in chaos theory, the term is defined more precisely. Although no universally accepted mathematical definition of chaos exists, a commonly used definition, originally formulated by Robert L. Devaney, says that to classify a dynamical system as chaotic, it must have these properties:\nIn some cases, the last two properties above have been shown to actually imply sensitivity to initial conditions. In the discrete-time case, this is true for all continuous maps on metric spaces. In these cases, while it is often the most practically significant property, \"sensitivity to initial conditions\" need not be stated in the definition.\nIf attention is restricted to intervals, the second property implies the other two. An alternative and a generally weaker definition of chaos uses only the first two properties in the above list.\nChaos as a spontaneous breakdown of topological supersymmetry.\nIn continuous time dynamical systems, chaos is the phenomenon of the spontaneous breakdown of topological supersymmetry, which is an intrinsic property of evolution operators of all stochastic and deterministic (partial) differential equations. This picture of dynamical chaos works not only for deterministic models, but also for models with external noise which is an important generalization from the physical point of view, since in reality, all dynamical systems experience influence from their stochastic environments. Within this picture, the long-range dynamical behavior associated with chaotic dynamics (e.g., the butterfly effect) is a consequence of the Goldstone's theorem\u2014in the application to the spontaneous topological supersymmetry breaking.\nSensitivity to initial conditions.\nSensitivity to initial conditions means that each point in a chaotic system is arbitrarily closely approximated by other points that have significantly different future paths or trajectories. Thus, an arbitrarily small change or perturbation of the current trajectory may lead to significantly different future behavior.\nSensitivity to initial conditions is popularly known as the \"butterfly effect\", so-called because of the title of a paper given by Edward Lorenz in 1972 to the American Association for the Advancement of Science in Washington, D.C., entitled \"Predictability: Does the Flap of a Butterfly's Wings in Brazil set off a Tornado in Texas?\". The flapping wing represents a small change in the initial condition of the system, which causes a chain of events that prevents the predictability of large-scale phenomena. Had the butterfly not flapped its wings, the trajectory of the overall system could have been vastly different.\nA consequence of sensitivity to initial conditions is that if we start with a limited amount of information about the system (as is usually the case in practice), then beyond a certain time, the system would no longer be predictable. This is most prevalent in the case of weather, which is generally predictable only about a week ahead. This does not mean that one cannot assert anything about events far in the future\u2014only that some restrictions on the system are present. For example, we do know with weather that the temperature will not naturally reach 100\u00a0\u00b0C or fall to \u2212130\u00a0\u00b0C on earth (during the current geologic era), but that does not mean that we can predict exactly which day will have the hottest temperature of the year.\nIn more mathematical terms, the Lyapunov exponent measures the sensitivity to initial conditions, in the form of rate of exponential divergence from the perturbed initial conditions. More specifically, given two starting trajectories in the phase space that are infinitesimally close, with initial separation formula_1, the two trajectories end up diverging at a rate given by\nwhere formula_3 is the time and formula_4 is the Lyapunov exponent. The rate of separation depends on the orientation of the initial separation vector, so a whole spectrum of Lyapunov exponents can exist. The number of Lyapunov exponents is equal to the number of dimensions of the phase space, though it is common to just refer to the largest one. For example, the maximal Lyapunov exponent (MLE) is most often used, because it determines the overall predictability of the system. A positive MLE is usually taken as an indication that the system is chaotic.\nIn addition to the above property, other properties related to sensitivity of initial conditions also exist. These include, for example, measure-theoretical mixing (as discussed in ergodic theory) and properties of a K-system.\nNon-periodicity.\nA chaotic system may have sequences of values for the evolving variable that exactly repeat themselves, giving periodic behavior starting from any point in that sequence. However, such periodic sequences are repelling rather than attracting, meaning that if the evolving variable is outside the sequence, however close, it will not enter the sequence and in fact, will diverge from it. Thus for almost all initial conditions, the variable evolves chaotically with non-periodic behavior.\nTopological mixing.\nTopological mixing (or the weaker condition of topological transitivity) means that the system evolves over time so that any given region or open set of its phase space eventually overlaps with any other given region. This mathematical concept of \"mixing\" corresponds to the standard intuition, and the mixing of colored dyes or fluids is an example of a chaotic system.\nTopological mixing is often omitted from popular accounts of chaos, which equate chaos with only sensitivity to initial conditions. However, sensitive dependence on initial conditions alone does not give chaos. For example, consider the simple dynamical system produced by repeatedly doubling an initial value. This system has sensitive dependence on initial conditions everywhere, since any pair of nearby points eventually becomes widely separated. However, this example has no topological mixing, and therefore has no chaos. Indeed, it has extremely simple behavior: all points except 0 tend to positive or negative infinity.\nTopological transitivity.\nA map formula_5 is said to be topologically transitive if for any pair of open sets formula_6, there exists formula_7 such that formula_8. Topological transitivity is a weaker version of topological mixing. Intuitively, if a map is topologically transitive then given a point \"x\" and a region \"V\", there exists a point \"y\" near \"x\" whose orbit passes through \"V\". This implies that is impossible to decompose the system into two open sets.\nAn important related theorem is the Birkhoff Transitivity Theorem. It is easy to see that the existence of a dense orbit implies in topological transitivity. The Birkhoff Transitivity Theorem states that if \"X\" is a second countable, complete metric space, then topological transitivity implies the existence of a dense set of points in \"X\" that have dense orbits.\nDensity of periodic orbits.\nFor a chaotic system to have dense periodic orbits means that every point in the space is approached arbitrarily closely by periodic orbits. The one-dimensional logistic map defined by \"x\" \u2192 4 \"x\" (1 \u2013 \"x\") is one of the simplest systems with density of periodic orbits. For example, formula_9\u00a0\u2192 formula_10\u00a0\u2192 formula_9 (or approximately 0.3454915\u00a0\u2192 0.9045085\u00a0\u2192 0.3454915) is an (unstable) orbit of period 2, and similar orbits exist for periods 4, 8, 16, etc. (indeed, for all the periods specified by Sharkovskii's theorem).\nSharkovskii's theorem is the basis of the Li and Yorke (1975) proof that any continuous one-dimensional system that exhibits a regular cycle of period three will also display regular cycles of every other length, as well as completely chaotic orbits.\nStrange attractors.\nSome dynamical systems, like the one-dimensional logistic map defined by \"x\" \u2192 4 \"x\" (1 \u2013 \"x\"), are chaotic everywhere, but in many cases chaotic behavior is found only in a subset of phase space. The cases of most interest arise when the chaotic behavior takes place on an attractor, since then a large set of initial conditions leads to orbits that converge to this chaotic region.\nAn easy way to visualize a chaotic attractor is to start with a point in the basin of attraction of the attractor, and then simply plot its subsequent orbit. Because of the topological transitivity condition, this is likely to produce a picture of the entire final attractor, and indeed both orbits shown in the figure on the right give a picture of the general shape of the Lorenz attractor. This attractor results from a simple three-dimensional model of the Lorenz weather system. The Lorenz attractor is perhaps one of the best-known chaotic system diagrams, probably because it is not only one of the first, but it is also one of the most complex, and as such gives rise to a very interesting pattern that, with a little imagination, looks like the wings of a butterfly.\nUnlike fixed-point attractors and limit cycles, the attractors that arise from chaotic systems, known as strange attractors, have great detail and complexity. Strange attractors occur in both continuous dynamical systems (such as the Lorenz system) and in some discrete systems (such as the H\u00e9non map). Other discrete dynamical systems have a repelling structure called a Julia set, which forms at the boundary between basins of attraction of fixed points. Julia sets can be thought of as strange repellers. Both strange attractors and Julia sets typically have a fractal structure, and the fractal dimension can be calculated for them.\nMinimum complexity of a chaotic system.\nDiscrete chaotic systems, such as the logistic map, can exhibit strange attractors whatever their dimensionality. Universality of one-dimensional maps with parabolic maxima and Feigenbaum constants formula_12,formula_13 is well visible with map proposed as a toy \nmodel for discrete laser dynamics: \nformula_14,\nwhere formula_15 stands for electric field amplitude, formula_16 is laser gain as bifurcation parameter. The gradual increase of formula_16 at interval formula_18 changes dynamics from regular to chaotic one with qualitatively the same bifurcation diagram as those for logistic map.\nIn contrast, for continuous dynamical systems, the Poincar\u00e9\u2013Bendixson theorem shows that a strange attractor can only arise in three or more dimensions. Finite-dimensional linear systems are never chaotic; for a dynamical system to display chaotic behavior, it must be either nonlinear or infinite-dimensional.\nThe Poincar\u00e9\u2013Bendixson theorem states that a two-dimensional differential equation has very regular behavior. The Lorenz attractor discussed below is generated by a system of three differential equations such as:\nwhere formula_15, formula_21, and formula_22 make up the system state, formula_3 is time, and formula_24, formula_25, formula_26 are the system parameters. Five of the terms on the right hand side are linear, while two are quadratic; a total of seven terms. Another well-known chaotic attractor is generated by the R\u00f6ssler equations, which have only one nonlinear term out of seven. Sprott found a three-dimensional system with just five terms, that had only one nonlinear term, which exhibits chaos for certain parameter values. Zhang and Heidel showed that, at least for dissipative and conservative quadratic systems, three-dimensional quadratic systems with only three or four terms on the right-hand side cannot exhibit chaotic behavior. The reason is, simply put, that solutions to such systems are asymptotic to a two-dimensional surface and therefore solutions are well behaved.\nWhile the Poincar\u00e9\u2013Bendixson theorem shows that a continuous dynamical system on the Euclidean plane cannot be chaotic, two-dimensional continuous systems with non-Euclidean geometry can exhibit chaotic behavior. Perhaps surprisingly, chaos may occur also in linear systems, provided they are infinite dimensional. A theory of linear chaos is being developed in a branch of mathematical analysis known as functional analysis.\nInfinite dimensional maps.\nThe straightforward generalization of coupled discrete maps is based upon convolution integral which mediates interaction between spatially distributed maps:\nformula_27,\nwhere kernel formula_28 is propagator derived as Green function of a relevant physical system, \nformula_29 might be logistic map alike formula_30 or complex map. For examples of complex maps the Julia set formula_31 or Ikeda map \nformula_32 may serve. When wave propagation problems at distance formula_33 with wavelength formula_34 are considered the kernel formula_35 may have a form of Green function for Schr\u00f6dinger equation:.\nformula_36.\nJerk systems.\nIn physics, jerk is the third derivative of position, with respect to time. As such, differential equations of the form\nare sometimes called \"Jerk equations\". It has been shown that a jerk equation, which is equivalent to a system of three first order, ordinary, non-linear differential equations, is in a certain sense the minimal setting for solutions showing chaotic behaviour. This motivates mathematical interest in jerk systems. Systems involving a fourth or higher derivative are called accordingly hyperjerk systems.\nA jerk system's behavior is described by a jerk equation, and for certain jerk equations, simple electronic circuits can model solutions. These circuits are known as jerk circuits.\nOne of the most interesting properties of jerk circuits is the possibility of chaotic behavior. In fact, certain well-known chaotic systems, such as the Lorenz attractor and the R\u00f6ssler map, are conventionally described as a system of three first-order differential equations that can combine into a single (although rather complicated) jerk equation. Nonlinear jerk systems are in a sense minimally complex systems to show chaotic behaviour; there is no chaotic system involving only two first-order, ordinary differential equations (the system resulting in an equation of second order only).\nAn example of a jerk equation with nonlinearity in the magnitude of formula_15 is:\nHere, \"A\" is an adjustable parameter. This equation has a chaotic solution for \"A\"=3/5 and can be implemented with the following jerk circuit; the required nonlinearity is brought about by the two diodes:\nIn the above circuit, all resistors are of equal value, except formula_40, and all capacitors are of equal size. The dominant frequency is formula_41. The output of op amp 0 will correspond to the x variable, the output of 1 corresponds to the first derivative of x and the output of 2 corresponds to the second derivative.\nSimilar circuits only require one diode or no diodes at all.\nSee also the well-known Chua's circuit, one basis for chaotic true random number generators. The ease of construction of the circuit has made it a ubiquitous real-world example of a chaotic system.\nSpontaneous order.\nUnder the right conditions, chaos spontaneously evolves into a lockstep pattern. In the Kuramoto model, four conditions suffice to produce synchronization in a chaotic system.\nExamples include the coupled oscillation of Christiaan Huygens' pendulums, fireflies, neurons, the London Millennium Bridge resonance, and large arrays of Josephson junctions.\nHistory.\nAn early proponent of chaos theory was Henri Poincar\u00e9. In the 1880s, while studying the three-body problem, he found that there can be orbits that are nonperiodic, and yet not forever increasing nor approaching a fixed point. In 1898, Jacques Hadamard published an influential study of the chaotic motion of a free particle gliding frictionlessly on a surface of constant negative curvature, called \"Hadamard's billiards\". Hadamard was able to show that all trajectories are unstable, in that all particle trajectories diverge exponentially from one another, with a positive Lyapunov exponent.\nChaos theory began in the field of ergodic theory. Later studies, also on the topic of nonlinear differential equations, were carried out by George David Birkhoff, Andrey Nikolaevich Kolmogorov, Mary Lucy Cartwright and John Edensor Littlewood, and Stephen Smale. Except for Smale, these studies were all directly inspired by physics: the three-body problem in the case of Birkhoff, turbulence and astronomical problems in the case of Kolmogorov, and radio engineering in the case of Cartwright and Littlewood. Although chaotic planetary motion had not been observed, experimentalists had encountered turbulence in fluid motion and nonperiodic oscillation in radio circuits without the benefit of a theory to explain what they were seeing.\nDespite initial insights in the first half of the twentieth century, chaos theory became formalized as such only after mid-century, when it first became evident to some scientists that linear theory, the prevailing system theory at that time, simply could not explain the observed behavior of certain experiments like that of the logistic map. What had been attributed to measure imprecision and simple \"noise\" was considered by chaos theorists as a full component of the studied systems.\nThe main catalyst for the development of chaos theory was the electronic computer. Much of the mathematics of chaos theory involves the repeated iteration of simple mathematical formulas, which would be impractical to do by hand. Electronic computers made these repeated calculations practical, while figures and images made it possible to visualize these systems. As a graduate student in Chihiro Hayashi's laboratory at Kyoto University, Yoshisuke Ueda was experimenting with analog computers and noticed, on November 27, 1961, what he called \"randomly transitional phenomena\". Yet his advisor did not agree with his conclusions at the time, and did not allow him to report his findings until 1970.\nEdward Lorenz was an early pioneer of the theory. His interest in chaos came about accidentally through his work on weather prediction in 1961. Lorenz was using a simple digital computer, a Royal McBee LGP-30, to run his weather simulation. He wanted to see a sequence of data again, and to save time he started the simulation in the middle of its course. He did this by entering a printout of the data that corresponded to conditions in the middle of the original simulation. To his surprise, the weather the machine began to predict was completely different from the previous calculation. Lorenz tracked this down to the computer printout. The computer worked with 6-digit precision, but the printout rounded variables off to a 3-digit number, so a value like 0.506127 printed as 0.506. This difference is tiny, and the consensus at the time would have been that it should have no practical effect. However, Lorenz discovered that small changes in initial conditions produced large changes in long-term outcome. Lorenz's discovery, which gave its name to Lorenz attractors, showed that even detailed atmospheric modelling cannot, in general, make precise long-term weather predictions.\nIn 1963, Benoit Mandelbrot found recurring patterns at every scale in data on cotton prices. Beforehand he had studied information theory and concluded noise was patterned like a Cantor set: on any scale the proportion of noise-containing periods to error-free periods was a constant \u2013 thus errors were inevitable and must be planned for by incorporating redundancy. Mandelbrot described both the \"Noah effect\" (in which sudden discontinuous changes can occur) and the \"Joseph effect\" (in which persistence of a value can occur for a while, yet suddenly change afterwards). This challenged the idea that changes in price were normally distributed. In 1967, he published \"How long is the coast of Britain? Statistical self-similarity and fractional dimension\", showing that a coastline's length varies with the scale of the measuring instrument, resembles itself at all scales, and is infinite in length for an infinitesimally small measuring device. Arguing that a ball of twine appears as a point when viewed from far away (0-dimensional), a ball when viewed from fairly near (3-dimensional), or a curved strand (1-dimensional), he argued that the dimensions of an object are relative to the observer and may be fractional. An object whose irregularity is constant over different scales (\"self-similarity\") is a fractal (examples include the Menger sponge, the Sierpi\u0144ski gasket, and the Koch curve or \"snowflake\", which is infinitely long yet encloses a finite space and has a fractal dimension of circa 1.2619). In 1982, Mandelbrot published \"The Fractal Geometry of Nature\", which became a classic of chaos theory. Biological systems such as the branching of the circulatory and bronchial systems proved to fit a fractal model.\nIn December 1977, the New York Academy of Sciences organized the first symposium on chaos, attended by David Ruelle, Robert May, James A. Yorke (coiner of the term \"chaos\" as used in mathematics), Robert Shaw, and the meteorologist Edward Lorenz. The following year Pierre Coullet and Charles Tresser published \"Iterations d'endomorphismes et groupe de renormalisation\", and Mitchell Feigenbaum's article \"Quantitative Universality for a Class of Nonlinear Transformations\" finally appeared in a journal, after 3 years of referee rejections. Thus Feigenbaum (1975) and Coullet &amp; Tresser (1978) discovered the universality in chaos, permitting the application of chaos theory to many different phenomena.\nIn 1979, Albert J. Libchaber, during a symposium organized in Aspen by Pierre Hohenberg, presented his experimental observation of the bifurcation cascade that leads to chaos and turbulence in Rayleigh\u2013B\u00e9nard convection systems. He was awarded the Wolf Prize in Physics in 1986 along with Mitchell J. Feigenbaum for their inspiring achievements.\nIn 1986, the New York Academy of Sciences co-organized with the National Institute of Mental Health and the Office of Naval Research the first important conference on chaos in biology and medicine. There, Bernardo Huberman presented a mathematical model of the eye tracking disorder among schizophrenics. This led to a renewal of physiology in the 1980s through the application of chaos theory, for example, in the study of pathological cardiac cycles.\nIn 1987, Per Bak, Chao Tang and Kurt Wiesenfeld published a paper in \"Physical Review Letters\" describing for the first time self-organized criticality (SOC), considered one of the mechanisms by which complexity arises in nature.\nAlongside largely lab-based approaches such as the Bak\u2013Tang\u2013Wiesenfeld sandpile, many other investigations have focused on large-scale natural or social systems that are known (or suspected) to display scale-invariant behavior. Although these approaches were not always welcomed (at least initially) by specialists in the subjects examined, SOC has nevertheless become established as a strong candidate for explaining a number of natural phenomena, including earthquakes, (which, long before SOC was discovered, were known as a source of scale-invariant behavior such as the Gutenberg\u2013Richter law describing the statistical distribution of earthquake sizes, and the Omori law describing the frequency of aftershocks), solar flares, fluctuations in economic systems such as financial markets (references to SOC are common in econophysics), landscape formation, forest fires, landslides, epidemics, and biological evolution (where SOC has been invoked, for example, as the dynamical mechanism behind the theory of \"punctuated equilibria\" put forward by Niles Eldredge and Stephen Jay Gould). Given the implications of a scale-free distribution of event sizes, some researchers have suggested that another phenomenon that should be considered an example of SOC is the occurrence of wars. These investigations of SOC have included both attempts at modelling (either developing new models or adapting existing ones to the specifics of a given natural system), and extensive data analysis to determine the existence and/or characteristics of natural scaling laws.\nIn the same year, James Gleick published \"\", which became a best-seller and introduced the general principles of chaos theory as well as its history to the broad public, though his history under-emphasized important Soviet contributions. Initially the domain of a few, isolated individuals, chaos theory progressively emerged as a transdisciplinary and institutional discipline, mainly under the name of nonlinear systems analysis. Alluding to Thomas Kuhn's concept of a paradigm shift exposed in \"The Structure of Scientific Revolutions\" (1962), many \"chaologists\" (as some described themselves) claimed that this new theory was an example of such a shift, a thesis upheld by Gleick.\nThe availability of cheaper, more powerful computers broadens the applicability of chaos theory. Currently, chaos theory remains an active area of research, involving many different disciplines such as mathematics, topology, physics, social systems, population modeling, biology, meteorology, astrophysics, information theory, computational neuroscience, pandemic crisis management, etc.\nApplications.\nAlthough chaos theory was born from observing weather patterns, it has become applicable to a variety of other situations. Some areas benefiting from chaos theory today are geology, mathematics, microbiology, biology, computer science, economics, engineering, finance, algorithmic trading, meteorology, philosophy, anthropology, physics, politics, population dynamics, psychology, and robotics. A few categories are listed below with examples, but this is by no means a comprehensive list as new applications are appearing.\nCryptography.\nChaos theory has been used for many years in cryptography. In the past few decades, chaos and nonlinear dynamics have been used in the design of hundreds of cryptographic primitives. These algorithms include image encryption algorithms, hash functions, secure pseudo-random number generators, stream ciphers, watermarking and steganography. The majority of these algorithms are based on uni-modal chaotic maps and a big portion of these algorithms use the control parameters and the initial condition of the chaotic maps as their keys. From a wider perspective, without loss of generality, the similarities between the chaotic maps and the cryptographic systems is the main motivation for the design of chaos based cryptographic algorithms. One type of encryption, secret key or symmetric key, relies on diffusion and confusion, which is modeled well by chaos theory. Another type of computing, DNA computing, when paired with chaos theory, offers a way to encrypt images and other information. Many of the DNA-Chaos cryptographic algorithms are proven to be either not secure, or the technique applied is suggested to be not efficient.\nRobotics.\nRobotics is another area that has recently benefited from chaos theory. Instead of robots acting in a trial-and-error type of refinement to interact with their environment, chaos theory has been used to build a predictive model.\nChaotic dynamics have been exhibited by passive walking biped robots.\nBiology.\nFor over a hundred years, biologists have been keeping track of populations of different species with population models. Most models are continuous, but recently scientists have been able to implement chaotic models in certain populations. For example, a study on models of Canadian lynx showed there was chaotic behavior in the population growth. Chaos can also be found in ecological systems, such as hydrology. While a chaotic model for hydrology has its shortcomings, there is still much to learn from looking at the data through the lens of chaos theory. Another biological application is found in cardiotocography. Fetal surveillance is a delicate balance of obtaining accurate information while being as noninvasive as possible. Better models of warning signs of fetal hypoxia can be obtained through chaotic modeling.\nEconomics.\nIt is possible that economic models can also be improved through an application of chaos theory, but predicting the health of an economic system and what factors influence it most is an extremely complex task. Economic and financial systems are fundamentally different from those in the classical natural sciences since the former are inherently stochastic in nature, as they result from the interactions of people, and thus pure deterministic models are unlikely to provide accurate representations of the data. The empirical literature that tests for chaos in economics and finance presents very mixed results, in part due to confusion between specific tests for chaos and more general tests for non-linear relationships.\nChaos could be found in economics by the means of recurrence quantification analysis. In fact, Orlando et al. by the means of the so-called recurrence quantification correlation index were able detect hidden changes in time series. Then, the same technique was employed to detect transitions from laminar (i.e. regular) to turbulent (i.e. chaotic) phases as well as differences between macroeconomic variables and highlight hidden features of economic dynamics. Finally, chaos could help in modeling how economy operate as well as in embedding shocks due to external events such as COVID-19.\nOther areas.\nIn chemistry, predicting gas solubility is essential to manufacturing polymers, but models using particle swarm optimization (PSO) tend to converge to the wrong points. An improved version of PSO has been created by introducing chaos, which keeps the simulations from getting stuck. In celestial mechanics, especially when observing asteroids, applying chaos theory leads to better predictions about when these objects will approach Earth and other planets. Four of the five moons of Pluto rotate chaotically. In quantum physics and electrical engineering, the study of large arrays of Josephson junctions benefitted greatly from chaos theory. Closer to home, coal mines have always been dangerous places where frequent natural gas leaks cause many deaths. Until recently, there was no reliable way to predict when they would occur. But these gas leaks have chaotic tendencies that, when properly modeled, can be predicted fairly accurately.\nChaos theory can be applied outside of the natural sciences, but historically nearly all such studies have suffered from lack of reproducibility; poor external validity; and/or inattention to cross-validation, resulting in poor predictive accuracy (if out-of-sample prediction has even been attempted). Glass and Mandell and Selz have found that no EEG study has as yet indicated the presence of strange attractors or other signs of chaotic behavior.\nResearchers have continued to apply chaos theory to psychology. For example, in modeling group behavior in which heterogeneous members may behave as if sharing to different degrees what in Wilfred Bion's theory is a basic assumption, researchers have found that the group dynamic is the result of the individual dynamics of the members: each individual reproduces the group dynamics in a different scale, and the chaotic behavior of the group is reflected in each member.\nRedington and Reidbord (1992) attempted to demonstrate that the human heart could display chaotic traits. They monitored the changes in between-heartbeat intervals for a single psychotherapy patient as she moved through periods of varying emotional intensity during a therapy session. Results were admittedly inconclusive. Not only were there ambiguities in the various plots the authors produced to purportedly show evidence of chaotic dynamics (spectral analysis, phase trajectory, and autocorrelation plots), but also when they attempted to compute a Lyapunov exponent as more definitive confirmation of chaotic behavior, the authors found they could not reliably do so.\nIn their 1995 paper, Metcalf and Allen maintained that they uncovered in animal behavior a pattern of period doubling leading to chaos. The authors examined a well-known response called schedule-induced polydipsia, by which an animal deprived of food for certain lengths of time will drink unusual amounts of water when the food is at last presented. The control parameter (r) operating here was the length of the interval between feedings, once resumed. The authors were careful to test a large number of animals and to include many replications, and they designed their experiment so as to rule out the likelihood that changes in response patterns were caused by different starting places for r.\nTime series and first delay plots provide the best support for the claims made, showing a fairly clear march from periodicity to irregularity as the feeding times were increased. The various phase trajectory plots and spectral analyses, on the other hand, do not match up well enough with the other graphs or with the overall theory to lead inexorably to a chaotic diagnosis. For example, the phase trajectories do not show a definite progression towards greater and greater complexity (and away from periodicity); the process seems quite muddied. Also, where Metcalf and Allen saw periods of two and six in their spectral plots, there is room for alternative interpretations. All of this ambiguity necessitate some serpentine, post-hoc explanation to show that results fit a chaotic model.\nBy adapting a model of career counseling to include a chaotic interpretation of the relationship between employees and the job market, Aniundson and Bright found that better suggestions can be made to people struggling with career decisions. Modern organizations are increasingly seen as open complex adaptive systems with fundamental natural nonlinear structures, subject to internal and external forces that may contribute chaos. For instance, team building and group development is increasingly being researched as an inherently unpredictable system, as the uncertainty of different individuals meeting for the first time makes the trajectory of the team unknowable.\nSome say the chaos metaphor\u2014used in verbal theories\u2014grounded on mathematical models and psychological aspects of human behavior\nprovides helpful insights to describing the complexity of small work groups, that go beyond the metaphor itself.\nTraffic forecasting may benefit from applications of chaos theory. Better predictions of when traffic will occur would allow measures to be taken to disperse it before it would have occurred. Combining chaos theory principles with a few other methods has led to a more accurate short-term prediction model (see the plot of the BML traffic model at right).\nChaos theory has been applied to environmental water cycle data (aka hydrological data), such as rainfall and streamflow. These studies have yielded controversial results, because the methods for detecting a chaotic signature are often relatively subjective. Early studies tended to \"succeed\" in finding chaos, whereas subsequent studies and meta-analyses called those studies into question and provided explanations for why these datasets are not likely to have low-dimension chaotic dynamics."}
{"id": "6298", "revid": "1013130449", "url": "https://en.wikipedia.org/wiki?curid=6298", "title": "Cupola", "text": "In architecture, a cupola is a relatively small, most often dome-like, tall structure on top of a building. Often used to provide a lookout or to admit light and air, it usually crowns a larger roof or dome.\nThe word derives, via Italian, from the lower Latin \"cupula\" (classical Latin \"cupella\" from the Greek \u03ba\u03cd\u03c0\u03b5\u03bb\u03bb\u03bf\u03bd \"kupellon\") \"small cup\" (Latin \"cupa\") indicating a vault resembling an upside down cup.\nBackground.\nThe cupola evolved during the Renaissance from the older oculus. Being weatherproof, the cupola was better suited to the wetter climates of northern Europe. The chhatri, seen in Indian architecture, fits the definition of a cupola when it is used atop a larger structure.\nCupolas often serve as a belfry, belvedere, or roof lantern above a main roof. In other cases they may crown a spire, tower, or turret. Barns often have cupolas for ventilation.\nCupolas can also appear as small buildings in their own right.\nThe square, dome-like segment of a North American railroad train caboose that contains the second-level or \"angel\" seats is also called a cupola."}
{"id": "6299", "revid": "953796", "url": "https://en.wikipedia.org/wiki?curid=6299", "title": "Chupacabra", "text": "The chupacabra or chupacabras (, literally 'goat-sucker'; from , 'to suck', and , 'goats') is a legendary creature in the folklore of parts of the Americas, with its first purported sightings reported in Puerto Rico in 1995. The name comes from the animal's reported vampirism\u2014the chupacabra is said to attack and drink the blood of livestock, including goats.\nPhysical descriptions of the creature vary. It is purportedly a heavy creature the size of a small bear, with a row of spines reaching from the neck to the base of the tail.\nEyewitness sightings have been claimed in Puerto Rico, and have since been reported as far north as Maine, as far south as Chile, and even outside the Americas in countries like Russia and the Philippines. Many of the reports have been disregarded as uncorroborated or lacking evidence. Sightings in northern Mexico and the southern United States have been verified as canids afflicted by mange. According to biologists and wildlife management officials, the chupacabra is an urban legend.\nName.\n can be literally translated as 'goat-sucker', from ('to suck') and ('goats'). It is known as both and throughout the Americas, with the former being the original word, and the latter a regularization of it. The name is attributed to Puerto Rican comedian Silverio P\u00e9rez, who coined the label in 1995 while commenting on the attacks as a San Juan radio deejay.\nHistory.\nThe first reported attack eventually attributed to the creatures occurred in March 1995 in Puerto Rico. Eight sheep were discovered dead, each with three puncture wounds in the chest area and reportedly completely drained of blood. A few months later, in August, an eyewitness named Madelyne Tolentino reported seeing the creature in the Puerto Rican town of Can\u00f3vanas, when as many as 150 farm animals and pets were reportedly killed. In 1975, similar killings in the small town of Moca were attributed to ('the vampire of Moca'). Initially, it was suspected that the killings were committed by a Satanic cult; later more killings were reported around the island, and many farms reported loss of animal life. Each of the animals was reported to have had its body bled dry through a series of small circular incisions.\nPuerto Rican comedian and entrepreneur Silverio P\u00e9rez is credited with coining the term soon after the first incidents were reported in the press. Shortly after the first reported incidents in Puerto Rico, other animal deaths were reported in other countries, such as the Dominican Republic, Argentina, Bolivia, Chile, Colombia, Honduras, El Salvador, Nicaragua, Panama, Peru, Brazil, the United States, and Mexico.\nIn October and December 2018, there came many reports of suspected chupacabras in Manipur, India. Many domestic animals and poultry were killed in a suspicious manner similar to other chupacabra attacks, and several people reported that they had seen chupacabras. However, forensic experts opined that street dogs were responsible for mass killing of domestic animals and poultry after studying the remnants of a corpse.\nIn October 2019, a video recorded by showed a supposed attack on chickens in the Seburuquillo sector of Lares, Puerto Rico.\nReputed origin.\nA five-year investigation by Benjamin Radford, documented in his 2011 book \"Tracking the Chupacabra\", concluded that the description given by the original eyewitness in Puerto Rico, Madelyne Tolentino, was based on the creature Sil in the 1995 science-fiction horror film \"Species\". The alien creature Sil is nearly identical to Tolentino's chupacabra eyewitness account and she had seen the movie before her report: \"It was a creature that looked like the chupacabra, with spines on its back and all... The resemblance to the chupacabra was really impressive\", Tolentino reported. Radford revealed that Tolentino \"believed that the creatures and events she saw in \"Species\" were happening in reality in Puerto Rico at the time\", and therefore concludes that \"the most important chupacabra description cannot be trusted\". This, Radford believes, seriously undermines the credibility of the chupacabra as a real animal.\nIn addition, the reports of blood-sucking by the chupacabra were never confirmed by a necropsy, the only way to conclude that the animal was drained of blood. An analysis by a veterinarian of 300 reported victims of the chupacabra found that they had not been bled dry.\nRadford divided the chupacabra reports into two categories: the reports from Puerto Rico and Latin America, where animals were attacked and it is supposed their blood was extracted; and the reports in the United States of mammals, mostly dogs and coyotes with mange, that people call \"chupacabra\" due to their unusual appearance.\nIn late October 2010, University of Michigan biologist Barry O'Connor concluded that all the chupacabra reports in the United States were simply coyotes infected with the parasite \"Sarcoptes scabiei\", whose symptoms would explain most of the features of the chupacabra: they would be left with little fur, thickened skin, and a rank odor. O'Connor theorized that the attacks on goats occurred \"because these animals are greatly weakened, [so] they're going to have a hard time hunting. So they may be forced into attacking livestock because it's easier than running down a rabbit or a deer.\"\nAlthough several witnesses came to the conclusion that the attacks could not be the work of dogs or coyotes because they had not eaten the victim, this conclusion is incorrect. Both dogs and coyotes can kill and not consume the prey, either because they are inexperienced, or due to injury or difficulty in killing the prey. The prey can survive the attack and die afterwards from internal bleeding or circulatory shock. The presence of two holes in the neck, corresponding with the canine teeth, are to be expected since this is the only way that most land carnivores have to catch their prey.\nThere are reports of stray Mexican hairless dogs being mistaken for chupacabras.\nAppearance.\nThe most common description of the chupacabra is that of a reptile-like creature, said to have leathery or scaly greenish-gray skin and sharp spines or quills running down its back. It is said to be approximately high, and stands and hops in a fashion similar to that of a kangaroo.\nAnother common description of the chupacabra is of a strange breed of wild dog. This form is mostly hairless and has a pronounced spinal ridge, unusually pronounced eye sockets, fangs, and claws. Unlike conventional predators, the chupacabra is said to drain all of the animal's blood (and sometimes organs) usually through three holes in the shape of a downwards-pointing triangle, but sometimes through only one or two holes.\nRelated legends.\nThe \"Ozark Howler\", a large bear-like animal, is the subject of a similar urban legend.\nThe Peuchens of Chile also share similarities in their supposed habits, but instead of being dog-like they are described as winged snakes. This legend may have originated from the vampire bat, an animal endemic to the region.\nIn the Philippines, another legendary creature called the Sigbin shares many of the chupacabra's descriptions.\nIn popular culture.\nThe popularity of the chupacabra has resulted in it being featured in many types of media."}
{"id": "6302", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6302", "title": "Classical Element", "text": ""}
{"id": "6307", "revid": "491706", "url": "https://en.wikipedia.org/wiki?curid=6307", "title": "Classical Element/Ether", "text": ""}
{"id": "6309", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=6309", "title": "Cayuga Lake", "text": "Cayuga Lake ()\u00a0 is the longest of central New York's glacial Finger Lakes, and is the second largest in surface area (marginally smaller than Seneca Lake) and second largest in volume. It is just under long. Its average width is 1.7 miles (2.7\u00a0km), and it is at its widest point near Aurora. It is approximately at its deepest point.\nThe lake is named after the native Cayuga people.\nLocation.\nThe city of Ithaca, site of Ithaca College and Cornell University, is located at the southern end of Cayuga Lake.\nVillages and settlements along the east shore of Cayuga Lake include Myers, King Ferry, Aurora, Levanna, Union Springs, and Cayuga. Settlements along the west shore of the lake include Sheldrake, Poplar Beach, and Canoga.\nThe lake has two small islands. One is near Union Springs; Frontenac Island( North East). This island is not inhabited. The other island, Canoga Island (North West) is located near the town of Canoga. This island has several camps and is inhabited during the summer months. The only other island in any of the Finger Lakes is Squaw Island in Canandaigua Lake.\nGeographical characteristics.\nCayuga Lake is located at ; above sea level. Its depth, steep east and west sides with shallow north and south ends is typical of the Finger Lakes, as they were carved by glaciers during the last ice age.\nThe water level is regulated by the Mud Lock at the north end of the lake. It is connected to Lake Ontario by the Erie Canal and Seneca Lake by the Seneca River. The lake is drawn down as winter approaches, to minimize ice damage and to maximize its capacity to store heavy spring runoff.\nThe north end is dominated by shallow mudflats. An important stopover for migratory birds, the mudflats and marsh are the location of the Montezuma National Wildlife Refuge. The southern end is also shallow and often freezes during the winter.\nHuman impact.\nCayuga Lake is very popular among recreational boaters. The Allan H. Treman State Marine Park, a large state marina and boat launch, is located at the southern end of the lake in Ithaca. There are two yacht clubs on the western shore: Ithaca Yacht Club a few miles north of Ithaca, and Red Jacket Yacht Club just south of Canoga. There are several other marinas and boat launches scattered along the lake shore.\nCayuga Lake is the source of drinking water for several communities, including Lansing near the southern end of the lake along the east side, which draws water through the Bolton Point Municipal Water system. There are also several lake source cooling systems that are in operation on the lake, whereby cooler water is pumped from the depths of the lake, warmed, and circulated in a closed system back to the surface. One of these systems, which is operated by Cornell University and began operation in 2000, was controversial during the planning and building states for potential negative environmental impact. All the environmental impact reports and scientific studies have shown that the Cornell lake source cooling system has not yet had and will not likely have any measurably significant environmental impact. Furthermore, Cornell's system pumps significantly less warm water back into the lake than others further north which have been operating for decades, including the coal-fired power plant on the eastern shore.\nThe AES Coal Power plant was shut down in August 2019 and there are plans to convert it into a data center in the near future. The plant used to use Cayuga Lake as a cooling source. In the late 1960s, citizens successfully opposed the construction of an 830-MW nuclear power plant on the shore of Cayuga Lake.\nRod Serling named his production company Cayuga Productions during the years of his TV series, \"The Twilight Zone\". Serling and his family had a summer home at Cayuga Lake.\nFishing.\nThe fish population is managed and substantial sport fishing is practiced, with anglers targeting smelt, lake trout and smallmouth bass. Fish species present in the lake include lake trout, landlocked salmon, brown trout, rainbow trout, smallmouth bass, smelt, alewife, atlantic salmon, black crappie, bluegill, pickerel, largemouth bass, northern pike, pumpkinseed sunfish, rock bass, and yellow perch. There are state owned hard surface ramps in Mudlock Canal Park, Long Point State Park, Cayuga Lake State Park, Dean's Cove State Marine Park, Taughannock Falls State Park, and Allen H. Treman Marine Park.\nTributaries.\nInflow is represented by Cayuga Inlet, Fall Creek, Taughannock Creek, and Salmon Creek, while it outflows into Seneca River and other tributaries. \nFolklore.\nThe lake is the subject of local folklore. \nAn \"Ithaca Journal\" article of January 5, 1897 reported that a sea serpent, nicknamed \"Old Greeny,\" had been sighted in Cayuga Lake annually for 69 years. A sighting in that month described the animal, 200 feet from shore, as \"large and its body long,\" though a \"tramp\" suggested it was a muskrat. In 1929, two creatures, about 12 to 15 feet in length, were reportedly spotted along the eastern shore of the lake. Further sightings were reported in 1974 and 1979.\nCornell's alma mater makes reference to its position \"Far Above Cayuga's Waters\", while that of Ithaca College references \"Cayuga's shore\".\nA tradition at Wells College in Aurora holds that if the lake completely freezes over, classes are canceled (though for only one day). According to Wells College records, this most recently happened in 1979 and 2015. However, other sources suggest that the only time the entire lake froze over solid end to end in the 20th century was in 1912.\nCayuga Lake, like nearby Seneca Lake, is also the site of a phenomenon known as the Guns of the Seneca, mysterious cannon-like booms heard in the surrounding area. Many of these booms may be attributable to bird-scarers, automated cannon-like devices used by farmers to scare birds away from the many vineyards, orchards and crops. There is however no proof of this.\nWine.\nCayuga Lake is included in the American Viticultural Area with which it shares its name. Established in 1988, the AVA now boasts over a dozen wineries, four distilleries, a cidery, and a meadery."}
{"id": "6310", "revid": "39535342", "url": "https://en.wikipedia.org/wiki?curid=6310", "title": "Columbia University", "text": "Columbia University (also known as Columbia, and officially as Columbia University in the City of New York) is a private Ivy League research university in New York City. Established in 1754 on the grounds of Trinity Church in Manhattan, Columbia is the oldest institution of higher education in New York and the fifth-oldest institution of higher learning in the United States. It is one of nine colonial colleges founded prior to the Declaration of Independence, seven of which belong to the Ivy League. Columbia is ranked among the top universities in the world by major education publications.\nColumbia was established as King's College by royal charter from King George II of Great Britain in reaction to the founding of Princeton College. It was renamed Columbia College in 1784 following the American Revolution, and in 1787 was placed under a private board of trustees headed by former students Alexander Hamilton and John Jay. In 1896, the campus was moved to its current location in Morningside Heights and renamed Columbia University.\nColumbia scientists and scholars have played an important role in scientific breakthroughs including brain-computer interface; the laser and maser; nuclear magnetic resonance; the first nuclear pile; the first nuclear fission reaction in the Americas; the first evidence for plate tectonics and continental drift; and much of the initial research and planning for the Manhattan Project during World War II. Columbia is organized into twenty schools, including four undergraduate schools and 15 graduate schools. The university's research efforts include the Lamont\u2013Doherty Earth Observatory, the Goddard Institute for Space Studies, and accelerator laboratories with major technology firms such as IBM. Columbia is a founding member of the Association of American Universities and was the first school in the United States to grant the M.D. degree. With over 14 million volumes, Columbia University Library is the third largest private research library in the United States.\nThe university's endowment stands at $11.26 billion in 2020, among the largest of any academic institution. , Columbia's alumni, faculty, and staff have included: five Founding Fathers of the United States\u2014among them a co-author of the United States Constitution and a co-author of the Declaration of Independence; three U.S. presidents; 29 foreign heads of state; ten justices of the United States Supreme Court, one of whom currently serves; 96 Nobel laureates; five Fields Medalists; 122 National Academy of Sciences members; 53 living billionaires; eleven Olympic medalists; 33 Academy Award winners; and 125 Pulitzer Prize recipients.\nHistory.\nColonial period.\nDiscussions regarding the founding of a college in the Province of New York began as early as 1704, at which time Colonel Lewis Morris wrote to the Society for the Propagation of the Gospel in Foreign Parts, the missionary arm of the Church of England, persuading the society that New York City was an ideal community in which to establish a college. However, it was not until the founding of the College of New Jersey (renamed Princeton) across the Hudson River in New Jersey that the City of New York seriously considered founding a college. In 1746, an act was passed by the general assembly of New York to raise funds for the foundation of a new college. In 1751, the assembly appointed a commission of ten New York residents, seven of whom were members of the Church of England, to direct the funds accrued by the state lottery towards the foundation of a college.\nClasses were initially held in July 1754 and were presided over by the college's first president, Dr. Samuel Johnson. Dr. Johnson was the only instructor of the college's first class, which consisted of a mere eight students. Instruction was held in a new schoolhouse adjoining Trinity Church, located on what is now lower Broadway in Manhattan. The college was officially founded on October 31, 1754, as King's College by royal charter of King George II, making it the oldest institution of higher learning in the State of New York and the fifth oldest in the United States.\nIn 1763, Dr. Johnson was succeeded in the presidency by Myles Cooper, a graduate of The Queen's College, Oxford, and an ardent Tory. In the charged political climate of the American Revolution, his chief opponent in discussions at the college was an undergraduate of the class of 1777, Alexander Hamilton. The Irish anatomist, Samuel Clossy, was appointed professor of natural philosophy in October 1765 and later the college's first professor of anatomy in 1767. The American Revolutionary War broke out in 1776, and was catastrophic for the operation of King's College, which suspended instruction for eight years beginning in 1776 with the arrival of the Continental Army. The suspension continued through the military occupation of New York City by British troops until their departure in 1783. The college's library was looted and its sole building requisitioned for use as a military hospital first by American and then British forces. Loyalists were forced to abandon their King's College in New York, but some led by Bishop Charles Inglis fled to Windsor, Nova Scotia, where they founded King's Collegiate School.\n18th century.\nAfter the Revolution, the college turned to the State of New York in order to restore its vitality, promising to make whatever changes to the school's charter the state might demand. The legislature agreed to assist the college, and on May 1, 1784, it passed \"an Act for granting certain privileges to the College heretofore called King's College\". The Act created a Board of Regents to oversee the resuscitation of King's College, and, in an effort to demonstrate its support for the new Republic, the legislature stipulated that \"the College within the City of New York heretofore called King's College be forever hereafter called and known by the name of Columbia College\", a reference to Columbia, an alternative name for America. The Regents finally became aware of the college's defective constitution in February 1787 and appointed a revision committee, which was headed by John Jay and Alexander Hamilton. In April of that same year, a new charter was adopted for the college granted the power to a separate board of 24 trustees.\nOn May 21, 1787, William Samuel Johnson, the son of Dr. Samuel Johnson, was unanimously elected president of Columbia College. Prior to serving at the university, Johnson had participated in the First Continental Congress and been chosen as a delegate to the Constitutional Convention. For a period in the 1790s, with New York City as the federal and state capital and the country under successive Federalist governments, a revived Columbia thrived under the auspices of Federalists such as Hamilton and Jay. Both President George Washington and Vice President John Adams attended the college's commencement on May 6, 1789, as a tribute of honor to the many alumni of the school who had been involved in the American Revolution.\n19th century to present.\nIn November 1813, the college agreed to incorporate its medical school with The College of Physicians and Surgeons, a new school created by the Regents of New York, forming Columbia University College of Physicians and Surgeons. The college's enrollment, structure, and academics stagnated for the majority of the 19th century, with many of the college presidents doing little to change the way that the college functioned. In 1857, the college moved from the King's College campus at Park Place to a primarily Gothic Revival campus on 49th\u00a0Street and Madison Avenue, where it remained for the next forty years. During the last half of the 19th century, under the leadership of President F.A.P. Barnard, the president that Barnard College is named after, the institution rapidly assumed the shape of a modern university. Barnard College was created in 1889 as a response to the university's refusal to accept women. By this time, the college's investments in New York real estate became a primary source of steady income for the school, mainly owing to the city's expanding population. University president Seth Low moved the campus from 49th\u00a0Street to its present location, a more spacious campus in the developing neighborhood of Morningside Heights. Under the leadership of Low's successor, Nicholas Murray Butler, who served for over four decades, Columbia rapidly became the nation's major institution for research, setting the \"multiversity\" model that later universities would adopt. Prior to becoming the president of Columbia University, Butler founded Teachers College, as a school to prepare home economists and manual art teachers for the children of the poor, with philanthropist Grace Hoadley Dodge. Teachers College is currently affiliated as the university's Graduate School of Education.\nResearch into the atom by faculty members John R. Dunning, I. I. Rabi, Enrico Fermi and Polykarp Kusch placed Columbia's physics department in the international spotlight in the 1940s after the first nuclear pile was built to start what became the Manhattan Project. In 1928, Seth Low Junior College was established by Columbia University in order to mitigate the number of Jewish applicants to Columbia College. The college was closed in 1936 due to the adverse effects of the Great Depression and its students were subsequently taught at Morningside Heights, although they did not belong to any college but to the university at large.\nThere was an evening school called University Extension, which taught night classes, for a fee, to anyone willing to attend. In 1947, the program was reorganized as an undergraduate college and designated the School of General Studies in response to the return of GIs after World War II. In 1995, the School of General Studies was again reorganized as a full-fledged liberal arts college for non-traditional students (those who have had an academic break of one year or more, or are pursuing dual-degrees) and was fully integrated into Columbia's traditional undergraduate curriculum. Within the same year, the Division of Special Programs\u2014later the School of Continuing Education, and now the School of Professional Studies\u2014was established to reprise the former role of University Extension. While the School of Professional Studies only offered non-degree programs for lifelong learners and high school students in its earliest stages, it now offers degree programs in a diverse range of professional and inter-disciplinary fields.\nIn the aftermath of World War II, the discipline of international relations became a major scholarly focus of the university, and in response, the School of International and Public Affairs was founded in 1946, drawing upon the resources of the faculties of political science, economics, and history.\nDuring the 1960s Columbia experienced large-scale student activism, which reached a climax in the spring of 1968 when hundreds of students occupied buildings on campus. The incident forced the resignation of Columbia's president, Grayson Kirk and the establishment of the University Senate.\nThough several schools within the university had admitted women for years, Columbia College first admitted women in the fall of 1983, after a decade of failed negotiations with Barnard College, the all-female institution affiliated with the university, to merge the two schools. Barnard College still remains affiliated with Columbia, and all Barnard graduates are issued diplomas signed by the Presidents of Columbia University and Barnard College.\nDuring the late 20th century, the university underwent significant academic, structural, and administrative changes as it developed into a major research university. For much of the 19th century, the university consisted of decentralized and separate faculties specializing in Political Science, Philosophy, and Pure Science. In 1979, these faculties were merged into the Graduate School of Arts and Sciences. In 1991, the faculties of Columbia College, the School of General Studies, the Graduate School of Arts and Sciences, the School of the Arts, and the School of Professional Studies were merged into the Faculty of Arts and Sciences, leading to the academic integration and centralized governance of these schools. In 2010, the School of International and Public Affairs, which was previously a part of the Faculty of Arts and Sciences, became an independent faculty.\nCampus.\nAccording to \"New York Magazine\", Columbia University is the second largest landowner in New York City, after the Catholic Church.\nMorningside Heights.\nThe majority of Columbia's graduate and undergraduate studies are conducted in Morningside Heights on Seth Low's late-19th century vision of a university campus where all disciplines could be taught at one location. The campus was designed along Beaux-Arts planning principles by the architects McKim, Mead &amp; White. Columbia's main campus occupies more than six city blocks, or , in Morningside Heights, New York City, a neighborhood that contains a number of academic institutions. The university owns over 7,800 apartments in Morningside Heights, housing faculty, graduate students, and staff. Almost two dozen undergraduate dormitories (purpose-built or converted) are located on campus or in Morningside Heights. Columbia University has an extensive tunnel system more than a century old, with the oldest portions predating the present campus. Some of these remain accessible to the public, while others have been cordoned off.\nThe Nicholas Murray Butler Library, known simply as Butler Library, is the largest single library in the Columbia University Library System, and is one of the largest buildings on the campus. Proposed as \"South Hall\" by the university's former president Nicholas Murray Butler as expansion plans for Low Memorial Library stalled, the new library was funded by Edward Harkness, benefactor of Yale's residential college system, and designed by his favorite architect, James Gamble Rogers. It was completed in 1934 and renamed for Butler in 1946. The library design is neo-classical in style. Its facade features a row of columns in the Ionic order above which are inscribed the names of great writers, philosophers, and thinkers, most of whom are read by students engaged in the Core Curriculum of Columbia College. , Columbia's library system includes over 11.9 \u00a0million volumes, making it the eighth largest library system and fifth largest collegiate library system in the United States.\nSeveral buildings on the Morningside Heights campus are listed on the National Register of Historic Places. Low Memorial Library, a National Historic Landmark and the centerpiece of the campus, is listed for its architectural significance. Philosophy Hall is listed as the site of the invention of FM radio. Also listed is Pupin Hall, another National Historic Landmark, which houses the physics and astronomy departments. Here the first experiments on the fission of uranium were conducted by Enrico Fermi. The uranium atom was split there ten days after the world's first atom-splitting in Copenhagen, Denmark.\nA statue by sculptor Daniel Chester French called \"Alma Mater\" is centered on the front steps of Low Memorial Library. McKim, Mead &amp; White invited French to build the sculpture in order to harmonize with the larger composition of the court and library in the center of the campus. Draped in an academic gown, the female figure of Alma Mater wears a crown of laurels and sits on a throne. The scroll-like arms of the throne end in lamps, representing sapientia and doctrina. A book signifying knowledge, balances on her lap, and an owl, the attribute of wisdom, is hidden in the folds of her gown. Her right hand holds a scepter composed of four sprays of wheat, terminating with a crown of King's College which refers to Columbia's origin as a royal charter institution in 1754. A local actress named Mary Lawton was said to have posed for parts of the sculpture. The statue was dedicated on September 23, 1903, as a gift of Mr. &amp; Mrs. Robert Goelet, and was originally covered in golden leaf. During the Columbia University protests of 1968 a bomb damaged the sculpture, but it has since been repaired. The small hidden owl on the sculpture is also the subject of many Columbia legends, the main legend being that the first student in the freshmen class to find the hidden owl on the statue will be valedictorian, and that any subsequent Columbia male who finds it will marry a Barnard student, given that Barnard is a women's college.\n\"The Steps\", alternatively known as \"Low Steps\" or the \"Urban Beach\", are a popular meeting area for Columbia students. The term refers to the long series of granite steps leading from the lower part of campus (South Field) to its upper terrace. With a design inspired by the City Beautiful movement, the steps of Low Library provides Columbia University and Barnard College students, faculty, and staff with a comfortable outdoor platform and space for informal gatherings, events, and ceremonies. McKim's classical facade epitomizes late 19th-century new-classical designs, with its columns and portico marking the entrance to an important structure. On warm days when the weather is favorable, the Low Steps often become a popular gathering place for students to sunbathe, eat lunch, or play frisbee.\nOther campuses.\nIn April 2007, the university purchased more than two-thirds of a site for a new campus in Manhattanville, an industrial neighborhood to the north of the Morningside Heights campus. Stretching from 125th Street to 133rd\u00a0Street, Columbia Manhattanville houses buildings for Columbia's Business School, School of International and Public Affairs, Columbia School of the Arts, and the Jerome L. Greene Center for Mind, Brain, and Behavior, where research will occur on neurodegenerative diseases such as Parkinson's and Alzheimer's. The $7\u00a0billion expansion plan included demolishing all buildings, except three that are historically significant, eliminating the existing light industry and storage warehouses, and relocating tenants in 132\u00a0apartments. Replacing these buildings created of space for the university. Community activist groups in West Harlem fought the expansion for reasons ranging from property protection and fair exchange for land, to residents' rights. Subsequent public hearings drew neighborhood opposition. , the State of New York's Empire State Development Corporation approved use of eminent domain, which, through declaration of Manhattanville's \"blighted\" status, gives governmental bodies the right to appropriate private property for public use. On May 20, 2009, the New York State Public Authorities Control Board approved the Manhanttanville expansion plan and the first buildings are under construction. Columbia Transportation is the shuttle bus service of the university, it operates between all campuses.\nNewYork-Presbyterian Hospital is affiliated with the medical schools of both Columbia University and Cornell University. According to \"U.S. News &amp; World Report\"s \"2019\u201320 Best Hospitals Honor Roll and Medical Specialties Rankings\", it is ranked fifth overall and third among university hospitals. Columbia's medical school has a strategic partnership with New York State Psychiatric Institute, and is affiliated with 19 other hospitals in the U.S. and four hospitals overseas. Health-related schools are located at the Columbia University Medical Center, a campus located in the neighborhood of Washington Heights, fifty blocks uptown. Other teaching hospitals affiliated with Columbia through the NewYork-Presbyterian network include the Payne Whitney Clinic in Manhattan, and the Payne Whitney Westchester, a psychiatric institute located in White Plains, New York. On the northern tip of Manhattan island (in the neighborhood of Inwood), Columbia owns Baker Field, which includes the Lawrence A. Wien Stadium as well as facilities for field sports, outdoor track, and tennis. There is a third campus on the west bank of the Hudson River, the Lamont-Doherty Earth Observatory and Earth Institute in Palisades, New York. A fourth is the Nevis Laboratories in Irvington, New York for the study of particle and motion physics. A satellite site in Paris, France holds classes at Reid Hall.\nSustainability.\nIn 2006, the university established the Office of Environmental Stewardship to initiate, coordinate and implement programs to reduce the university's environmental footprint. The U.S. Green Building Council selected the university's Manhattanville plan for the Leadership in Energy and Environmental Design (LEED) Neighborhood Design pilot program. The plan commits to incorporating smart growth, new urbanism and \"green\" building design principles. Columbia is one of the 2030 Challenge Partners, a group of nine universities in the city of New York that have pledged to reduce their greenhouse emissions by 30% within the next ten years. Columbia University adopts LEED standards for all new construction and major renovations. The university requires a minimum of Silver, but through its design and review process seeks to achieve higher levels. This is especially challenging for lab and research buildings with their intensive energy use; however, the university also uses lab design guidelines that seek to maximize energy efficiency while protecting the safety of researchers.\nEvery Thursday and Sunday of the month, Columbia hosts a greenmarket where local farmers can sell their produce to residents of the city. In addition, from April to November Hodgson's farm, a local New York gardening center, joins the market bringing a large selection of plants and blooming flowers. The market is one of the many operated at different points throughout the city by the non-profit group GrowNYC. Dining services at Columbia spends 36 percent of its food budget on local products, in addition to serving sustainably harvested seafood and fair trade coffee on campus. Columbia has been rated \"B+\" by the 2011 College Sustainability Report Card for its environmental and sustainability initiatives.\nAccording to the A. W. Kuchler U.S. potential natural vegetation types, Columbia University would have a dominant vegetation type of Appalachian Oak (\"104\") with a dominant vegetation form of Eastern Hardwood Forest (\"25\").\nTransportation.\nColumbia Transportation is the bus service of the university, operated by Academy Bus Lines. The buses are open to all Columbia faculty, students, Dodge Fitness Center members, and anyone else who holds a Columbia ID card. In addition, all TSC students can ride the buses.\nAcademics.\nUndergraduate admissions and financial aid.\nColumbia University received nearly 40,100 applications for the class of 2024 (entering 2020) and a total of around 2,450 were admitted to the two schools for an overall acceptance rate of 6.1%, making Columbia the third most selective college in the United States behind Stanford and Harvard as well as the second most selective college in the Ivy League. Columbia is a racially diverse school, with approximately 52% of all students identifying themselves as persons of color. Additionally, 50% of all undergraduates received grants from Columbia. The average grant size awarded to these students is $46,516. In 2015\u20132016, annual undergraduate tuition at Columbia was $50,526 with a total cost of attendance of $65,860 (including room and board).\nOn April 11, 2007, Columbia University announced a $400 million to $600 million donation from media billionaire alumnus John Kluge to be used exclusively for undergraduate financial aid. The donation is among the largest single gifts to higher education. Its exact value will depend on the eventual value of Kluge's estate at the time of his death; however, the generous donation has helped change financial aid policy at Columbia. Annual gifts, fund-raising, and an increase in spending from the university's endowment have allowed Columbia to extend generous financial aid packages to qualifying students. , undergraduates from families with incomes as high as $60,000 a year will have the projected cost of attending the university, including room, board, and academic fees, fully paid for by the university. That same year, the university ended loans for incoming and then-current students who were on financial aid, replacing loans that were traditionally part of aid packages with grants from the university. However, this does not apply to international students, transfer students, visiting students, or students in the School of General Studies. In the fall of 2010, admission to Columbia's undergraduate colleges Columbia College and the Fu Foundation School of Engineering and Applied Science (also known as SEAS or Columbia Engineering) began accepting the Common Application. The policy change made Columbia one of the last major academic institutions and the last Ivy League university to switch to the Common Application.\nScholarships are also given to undergraduate students by the admissions committee. Designations include John W. Kluge Scholars, John Jay Scholars, C. Prescott Davis Scholars, Global Scholars, Egleston Scholars, and Science Research Fellows. Named scholars are selected by the admission committee from first-year applicants. According to Columbia, the first four designated scholars \"distinguish themselves for their remarkable academic and personal achievements, dynamism, intellectual curiosity, the originality and independence of their thinking, and the diversity that stems from their different cultures and their varied educational experiences.\"\nIn 1919, Columbia established a student application process characterized by The New York Times as \"the first modern college application.\" The application required a photograph of the applicant, the maiden name of the applicant's mother, and the applicant's religious background.\nColumbia University received $1 million in Hanban funds over five years to begin a Confucius Institute. Professor Robert Barnett, the director of the Modern Tibetan Studies Program, described a \"strange silence about Tibet and other sensitive issues when it comes to Columbia, academics, and talks of China.\"\nOrganization.\nColumbia University is an independent, privately supported, nonsectarian institution of higher education. Its official corporate name is \"The Trustees of Columbia University in the City of New York.\" The university's first charter was granted in 1754 by King George II; however, its modern charter was first enacted in 1787 and last amended in 1810 by the New York State Legislature. The university is governed by 24 trustees, customarily including the president, who serves \"ex officio\". The trustees themselves are responsible for choosing their successors. Six of the 24 are nominated from a pool of candidates recommended by the Columbia Alumni Association. Another six are nominated by the board in consultation with the executive committee of the University Senate. The remaining 12, including the president, are nominated by the trustees themselves through their internal processes. The term of office for trustees is six years. Generally, they serve for no more than two consecutive terms. The trustees appoint the president and other senior administrative officers of the university, and review and confirm faculty appointments as required. They determine the university's financial and investment policies, authorize the budget, supervise the endowment, direct the management of the university's real estate and other assets, and otherwise oversee the administration and management of the university.\nThe University Senate was established by the trustees after a university-wide referendum in 1969. It succeeded to the powers of the University Council, which was created in 1890 as a body of faculty, deans, and other administrators to regulate inter-Faculty affairs and consider issues of university-wide concern. The University Senate is a unicameral body consisting of 107 members drawn from all constituencies of the university. These include the president of the university, the provost, the deans of Columbia College and the Graduate School of Arts and Sciences, all who serve ex officio, and five additional representatives, appointed by the president, from the university's administration. The president serves as the Senate's presiding officer. The Senate is charged with reviewing the educational policies, physical development, budget, and external relations of the university. It oversees the welfare and academic freedom of the faculty and the welfare of students.\nThe president of Columbia University, who is selected by the trustees in consultation with the executive committee of the University Senate and who serves at the trustees' pleasure, is the chief executive officer of the university. Assisting the president in administering the university are the provost, the senior executive vice president, the executive vice president for health and biomedical sciences, several other vice presidents, the general counsel, the secretary of the university, and the deans of the faculties, all of whom are appointed by the trustees on the nomination of the president and serve at their pleasure. Lee C. Bollinger became the 19th president of Columbia University on June 1, 2002. A prominent advocate of affirmative action, he played a leading role in the twin Supreme Court cases\u2014Grutter v Bollinger and Gratz v Bollinger\u2014that upheld and clarified the importance of diversity as a compelling justification for affirmative action in higher education. A leading First Amendment scholar, he is widely published on freedom of speech and press, and serves on the faculty of Columbia Law School.\nColumbia has three official undergraduate colleges: Columbia College (CC), the liberal arts college offering the Bachelor of Arts degree; the Fu Foundation School of Engineering and Applied Science (also known as SEAS or Columbia Engineering), the engineering and applied science school offering the Bachelor of Science degree; and The School of General Studies (GS), the liberal arts college offering the Bachelor of Arts degree to non-traditional students undertaking full- or part-time study. Barnard College is a women's liberal arts college and an academic affiliate in which students receive a Bachelor of Arts degree from Columbia University. Their degrees are signed by the Presidents of Columbia University and Barnard College. Barnard students are also eligible to cross-register classes that are available through the Barnard Catalogue and alumnae can join the Columbia Alumni Association.\nJoint degree programs are available through Union Theological Seminary, the Jewish Theological Seminary of America, as well as through the Juilliard School. Teachers College and Barnard College are faculties of the university; both colleges' presidents are deans under the university governance structure. The Columbia University Senate includes faculty and student representatives from Teachers College and Barnard College who serve two-year terms; all senators are accorded full voting privileges regarding matters impacting the entire university. Teachers College is an affiliated, financially independent graduate school with their own Board of Trustees. Pursuant to an affiliation agreement, Columbia is given the authority to confer \"appropriate degrees and diplomas\" to the graduates of Teachers College. The degrees are signed by Presidents of Teachers College and Columbia University.\nColumbia's General Studies school also has joint undergraduate programs available through University College London, Sciences Po, City University of Hong Kong, Trinity College Dublin, and the Juilliard School.\nThe university also has several Columbia Global Centers, in Amman, Beijing, Istanbul, Paris, Mumbai, Rio de Janeiro, Santiago, Asunci\u00f3n and Nairobi. According to \"The Nation\", some American universities \"restrict discussions of Chinese human-rights abuses for fear of losing access to the country. Columbia University, for instance, canceled several talks on topics sensitive to the Communist Party because it was worried about offending Beijing.\"\nInternational partnerships.\nColumbia students can study abroad for a semester or a year at partner institutions such as Sciences Po, \u00c9cole des hautes \u00e9tudes en sciences sociales (EHESS), \u00c9cole normale sup\u00e9rieure (ENS), Panth\u00e9on-Sorbonne University, King's College London, London School of Economics, and the University of Warwick. Select students can study at either the University of Oxford or the University of Cambridge for a year if approved by both Columbia and either Oxford or Cambridge.\nRankings.\nColumbia University is ranked 3rd overall among U.S. national universities and 7th globally for 2020 by \"U.S. News &amp; World Report\". QS University Rankings listed Columbia as 5th in the United States. Ranked 15th among U.S. colleges for 2020 by \"The Wall Street Journal\" and \"Times Higher Education\", in recent years it has been ranked as high as 2nd. Individual colleges and schools were also nationally ranked by \"U.S. News &amp; World Report\" for its 2021 edition. Columbia Law School was ranked for 4th, the Mailman School of Public Health 4th, the School of Social Work tied for 3rd, Columbia Business School 8th, the College of Physicians and Surgeons tied for 6th for research (and tied for 31st for primary care), the School of Nursing tied for 11th in the master's program and tied for 1st in the doctorate nursing program, and the Fu Foundation School of Engineering and Applied Science (graduate) was ranked tied for 14th.\nIn 2019, Columbia was ranked 8th in the world by \"Academic Ranking of World Universities\", 7th in the world by \"U.S. News &amp; World Report\" 18th in the world by \"QS World University Rankings\", and 16th globally by \"Times Higher Education World University Rankings\".\nRankings by other organizations include the Graduate School of Architecture, Planning and Preservation #2, and its Graduate School of Journalism #1.\nBetween 1996 and 2008, 18 Columbia affiliates have won Nobel Prizes, of whom nine are faculty members while one is an adjunct senior research scientist (Daniel Tsui) and the other a Global Fellow (Kofi Annan). Columbia faculty awarded the Nobel Prize include Richard Axel, Martin Chalfie, Eric Kandel, Tsung-Dao Lee, Robert Mundell, Orhan Pamuk, Edmund S. Phelps, Joseph Stiglitz, and Horst L. Stormer. Other awards and honors won by faculty include 30 MacArthur Foundation Award winners, 4 National Medal of Science recipients, 43 National Academy of Sciences Award winners, 20 National Academy of Engineering Award winners, 38 Institute of Medicine of the National Academies Award recipients and 143 American Academy of Arts and Sciences Award winners.\nIn 2015, Columbia University was ranked the first in the state by average professor salaries. In 2011, the ranked Columbia 3rd best university for forming CEOs in the US and 12th worldwide.\nResearch.\nColumbia is classified among \"R1: Doctoral Universities \u2013 Very high research activity\". Columbia was the first North American site where the uranium atom was split. The College of Physicians and Surgeons played a central role in developing the modern understanding of neuroscience with the publication of \"Principles of Neural Science\", described by historian of science Katja Huenther as the \"neuroscience 'bible'\". The book was written by a team of Columbia researchers that included Nobel Prize winner Eric Kandel, James H. Schwartz, and Thomas Jessell. Columbia was the birthplace of FM radio and the laser. The first brain-computer interface capable of translating brain signals into speech was developed by neuroengineers at Columbia. The MPEG-2 algorithm of transmitting high quality audio and video over limited bandwidth was developed by Dimitris Anastassiou, a Columbia professor of electrical engineering. Biologist Martin Chalfie was the first to introduce the use of Green Fluorescent Protein (GFP) in labeling cells in intact organisms. Other inventions and products related to Columbia include Sequential Lateral Solidification (SLS) technology for making LCDs, System Management Arts (SMARTS), Session Initiation Protocol (SIP) (which is used for audio, video, chat, instant messaging and whiteboarding), pharmacopeia, Macromodel (software for computational chemistry), a new and better recipe for glass concrete, Blue LEDs, and Beamprop (used in photonics).\nColumbia scientists have been credited with about 175 new inventions in the health sciences each year. More than 30 pharmaceutical products based on discoveries and inventions made at Columbia reached the market. These include Remicade (for arthritis), Reopro (for blood clot complications), Xalatan (for glaucoma), Benefix, Latanoprost (a glaucoma treatment), shoulder prosthesis, homocysteine (testing for cardiovascular disease), and Zolinza (for cancer therapy). Columbia Technology Ventures (formerly Science and Technology Ventures), , manages some 600 patents and more than 250 active license agreements. Patent-related deals earned Columbia more than $230\u00a0million in the 2006 fiscal year, according to the university, more than any university in the world. Columbia owns many unique research facilities, such as the Columbia Institute for Tele-Information dedicated to telecommunications and the Goddard Institute for Space Studies, which is an astronomical observatory affiliated with NASA.\nMilitary and veteran enrollment.\nColumbia is a long-standing participant of the United States Department of Veterans Affairs Yellow Ribbon Program, allowing eligible veterans to pursue a Columbia undergraduate degree regardless of socioeconomic status for over 70 years. As a part of the Eisenhower Leader Development Program (ELDP) in partnership with the U.S. Military Academy at West Point, Columbia is the only school in the Ivy League to offer a graduate degree program in organizational psychology to aid military officers in tactical decision making and strategic management.\nStudent life.\nStudents.\nIn 2017, Columbia University's student population was 32,429 (8,868 students in undergraduate programs and 23,561 in postgraduate programs), with 42% of the student population identifying themselves as a minority and 28% born outside of the United States. Twenty-six percent of students at Columbia have family incomes below $60,000, making it one of the most socioeconomically diverse top-tier colleges. Sixteen percent of students at Columbia receive Federal Pell Grants, which mostly go to students whose family incomes are below $40,000. Seventeen percent of students are the first member of their family to attend a four-year college.\nOn-campus housing is guaranteed for all four years as an undergraduate. Columbia College and the Fu Foundation School of Engineering and Applied Science (also known as SEAS or Columbia Engineering) share housing in the on-campus residence halls. First-year students usually live in one of the large residence halls situated around South Lawn: Hartley Hall, Wallach Hall (originally Livingston Hall), John Jay Hall, Furnald Hall or Carman Hall. Upperclassmen participate in a room selection process, wherein students can pick to live in a mix of either corridor- or apartment-style housing with their friends. The Columbia University School of General Studies, Barnard College and graduate schools have their own apartment-style housing in the surrounding neighborhood.\nColumbia University is home to many fraternities, sororities, and co-educational Greek organizations. Approximately 10\u201315% of undergraduate students are associated with Greek life. Many Barnard women also join Columbia sororities. There has been a Greek presence on campus since the establishment in 1836 of the Delta chapter of Alpha Delta Phi. The InterGreek Council is the self-governing student organization that provides guidelines and support to its member organizations within each of the three councils at Columbia, the Interfraternity Council, Panhellenic Council, and Multicultural Greek Council. The three council presidents bring their affiliated chapters together once a month to meet as one Greek community. The InterGreek Council meetings provide opportunity for member organizations to learn from each other, work together and advocate for community needs.\nPublications.\nThe \"Columbia Daily Spectator\" is the nation's second-oldest student newspaper; and \"The Blue and White\", a monthly literary magazine established in 1890, discusses campus life and local politics in print and on its daily blog, dubbed the \"Bwog\". \"The Morningside Post\" is a student-run multimedia news publication. Its content: student-written investigative news, international affairs analysis, opinion, and satire.\nPolitical publications include \"The Current\", a journal of politics, culture and Jewish Affairs; the \"Columbia Political Review\", the multi-partisan political magazine of the Columbia Political Union; and \"AdHoc\", which denotes itself as the \"progressive\" campus magazine and deals largely with local political issues and arts events.\n\"Columbia Magazine\" is the alumni magazine of Columbia, serving all 340,000+ of the university's alumni. Arts and literary publications include \"The Columbia Review\", the nation's oldest college literary magazine; \"Columbia\", a nationally regarded literary journal; the \"Columbia Journal of Literary Criticism\"; and \"The Mobius Strip\", an online arts and literary magazine. \"Inside New York\" is an annual guidebook to New York City, written, edited, and published by Columbia undergraduates. Through a distribution agreement with Columbia University Press, the book is sold at major retailers and independent bookstores.\nColumbia is home to numerous undergraduate academic publications. The \"Columbia Undergraduate Science Journal\" prints original science research in its two annual publications. The \"Journal of Politics &amp; Society\" is a journal of undergraduate research in the social sciences, published and distributed nationally by the Helvidius Group; \"Publius\" is an undergraduate journal of politics established in 2008 and published biannually; the \"Columbia East Asia Review\" allows undergraduates throughout the world to publish original work on China, Japan, Korea, Tibet, and Vietnam and is supported by the Weatherhead East Asian Institute; and \"The Birch\", is an undergraduate journal of Eastern European and Eurasian culture that is the first national student-run journal of its kind; the \"Columbia Political Review\", the undergraduate magazine on politics operated by the Columbia Political Union; the \"Columbia Economics Review\", the undergraduate economic journal on research and policy supported by the Columbia Economics Department; and the \"Columbia Science Review\" is a science magazine that prints general interest articles and faculty profiles.\n\"The Fed\" a triweekly satire and investigative newspaper, and the \"Jester of Columbia\", the newly (and frequently) revived campus humor magazine both inject humor into local life. Other publications include \"The Columbian\", the undergraduate colleges' annually published yearbook the \"Gadfly\", a biannual journal of popular philosophy produced by undergraduates; and \"Rhapsody in Blue\", an undergraduate urban studies magazine. Professional journals published by academic departments at Columbia University include \"Current Musicology\" and \"The Journal of Philosophy\". During the spring semester, graduate students in the Journalism School publish \"The Bronx Beat\", a bi-weekly newspaper covering the South Bronx.\nFounded in 1961 under the auspices of Columbia University's Graduate School of Journalism, the \"Columbia Journalism Review\" (CJR) examines day-to-day press performance as well as the forces that affect that performance. The magazine is published six times a year, and offers a reporting, analysis, criticism, and commentary. CJR.org, its web site, delivers real-time criticism and reporting, giving CJR a presence in the ongoing conversation about the media.\nBroadcasting.\nColumbia is home to two pioneers in undergraduate campus radio broadcasting, WKCR-FM and CTV. Many undergraduates are also involved with Barnard's radio station, WBAR. WKCR, the student run radio station that broadcasts to the Tri-State area, claims to be the oldest FM radio station in the world, owing to the university's affiliation with Major Edwin Armstrong. The station went operational on July 18, 1939, from a 400-foot antenna tower in Alpine, New Jersey, broadcasting the first FM transmission in the world. Initially, WKCR wasn't a radio station, but an organization concerned with the technology of radio communications. As membership grew, however, the nascent club turned its efforts to broadcasting. Armstrong helped the students in their early efforts, donating a microphone and turntables when they designed their first makeshift studio in a dorm room. The station has its studios on the second floor of Alfred Lerner Hall on the Morningside campus with its main transmitter tower at 4 Times Square in Midtown Manhattan. Columbia Television (CTV) is the nation's second oldest Student television station and home of CTV News, a weekly live news program produced by undergraduate students.\nDebate and Model UN.\nThe Philolexian Society is a literary and debating club founded in 1802, making it the oldest student group at Columbia, as well as the third oldest collegiate literary society in the country. The society annually administers the Joyce Kilmer Bad Poetry Contest. The Columbia Parliamentary Debate Team competes in tournaments around the country as part of the American Parliamentary Debate Association, and hosts both high school and college tournaments on Columbia's campus, as well as public debates on issues affecting the university.\nThe Columbia International Relations Council and Association (CIRCA), oversees Columbia's Model United Nations activities. CIRCA hosts college and high school Model UN conferences, hosts speakers influential in international politics to speak on campus, trains students from underprivileged schools in New York in Model\u00a0UN and oversees a competitive team, which travels to colleges around the country and to an international conference every year. The competitive team consistently wins best and outstanding delegation awards and is considered one of the top teams in the country.\nTechnology and entrepreneurship.\nThe Columbia University Organization of Rising Entrepreneurs (CORE) was founded in 1999. The student-run group aims to foster entrepreneurship on campus. Each year CORE hosts dozens of events, including talks, #StartupColumbia, a conference and venture competition for $250,000, and Ignite@CU, a weekend for undergrads interested in design, engineering, and entrepreneurship. Notable speakers include Peter Thiel, Jack Dorsey, Alexis Ohanian, Drew Houston, and Mark Cuban. By 2006, CORE had awarded graduate and undergraduate students over $100,000 in seed capital.\nCampusNetwork, an on-campus social networking site called Campus Network that preceded Facebook, was created and popularized by Columbia engineering student Adam Goldberg in 2003. Mark Zuckerberg later asked Goldberg to join him in Palo Alto to work on Facebook, but Goldberg declined the offer. The Fu Foundation School of Engineering and Applied Science offers a minor in Technical Entrepreneurship through its Center for Technology, Innovation, and Community Engagement. SEAS' entrepreneurship activities focus on community building initiatives in New York and worldwide, made possible through partners such as Microsoft Corporation.\nColumbia is a top supplier of young engineering entrepreneurs for New York City. Over the past 20 years, graduates of Columbia established over 100 technology companies. Mayor Bloomberg has provided over $6.7\u00a0million towards entrepreneurial programs that partner with Columbia and other universities in New York. Professor Chris Wiggins of the Fu Foundation School of Engineering and Applied Science is working in conjunction with Professors Evan Korth of New York University and Hilary Mason, chief scientist at bit.ly to facilitate the growth of student tech-startups in an effort to transform a traditionally financially centered New York City into the next Silicon Valley. Their website, hackny.org, is a gathering ground of ideas and discussions for New York's young entrepreneurial community, the Silicon Alley.\nOn June 14, 2010, Mayor Michael R. Bloomberg launched the NYC Media Lab to promote innovations in New York's media industry. Situated at the New York University Tandon School of Engineering, the lab is a consortium of Columbia University, New York University, and New York City Economic Development Corporation acting to connect companies with universities in new technology research. The Lab is modeled after similar ones at MIT and Stanford. A $250,000 grant from the New York City Economic Development Corporation was used to establish the NYC Media Lab. Each year, the lab will host a range of roundtable discussions between the private sector and academic institutions. It will support research projects on topics of content format, next-generation search technologies, computer animation for film and gaming, emerging marketing techniques, and new devices development. The lab will also create a media research and development database. Columbia University will coordinate the long-term direction of the media lab as well as the involvement of its faculty and those of other universities.\nAthletics.\nA member institution of the National Collegiate Athletic Association (NCAA) in Division I FCS, Columbia fields varsity teams in 29 sports and is a member of the Ivy League. The football Lions play home games at the 17,000-seat Robert K. Kraft Field at Lawrence A. Wien Stadium. The Baker Athletics Complex also includes facilities for baseball, softball, soccer, lacrosse, field hockey, tennis, track, and rowing, as well as the new Campbell Sports Center, opened in January 2013. The basketball, fencing, swimming &amp; diving, volleyball, and wrestling programs are based at the Dodge Physical Fitness Center on the main campus.\nFormer students include Baseball Hall of Famers Lou Gehrig and Eddie Collins, football Hall of Famer Sid Luckman, Marcellus Wiley, and world champion women's weightlifter Karyn Marshall. On May 17, 1939, fledgling NBC broadcast a doubleheader between the Columbia Lions and the Princeton Tigers at Columbia's Baker Field, making it the first televised regular athletic event in history.\nColumbia University athletics has a long history, with many accomplishments in athletic fields. In 1870, Columbia played against Rutgers University in the second intercollegiate rugby football game in the history of the sport. Eight years later, Columbia crew won the famed Henley Royal Regatta in the first-ever defeat for an English crew rowing in English waters. In 1900, Olympian and Columbia College student Maxie Long set the first official world record in the 400 meters with a time of 47.8 seconds. In 1983, Columbia men's soccer went 18\u20130 and was ranked first in the nation, but lost to Indiana 1\u20130 in double overtime in the NCAA championship game; nevertheless, the team went further toward the NCAA title than any Ivy League soccer team in history. The football program unfortunately is best known for its record of futility set during the 1980s: between 1983 and 1988, the team lost 44 games in a row, which is still the record for the NCAA Football Championship Subdivision. The streak was broken on October 8, 1988, with a 16\u201313 victory over archrival Princeton University. That was the Lions' first victory at Wien Stadium, which had been opened during the losing streak and was already four years old. A new tradition has developed with the Liberty Cup. The Liberty Cup is awarded annually to the winner of the football game between Fordham and Columbia Universities, two of the only three NCAA Division I football teams in New York City. The tradition began in 2002, a year after the Fordham-Columbia game was postponed due to the September 11 attacks.\nWorld Leaders Forum.\nEstablished in 2003 by university president Lee C. Bollinger, the World Leaders Forum at Columbia University provides the opportunity for undergraduate and graduate students alike to listen to world leaders in government, religion, industry, finance, and academia. The World Leaders Forum is a year-around event series that strives to provide a platform for uninhibited speech among nations and cultures, while educating students about problems and progress around the globe.\nAll Columbia undergraduates and graduates, as well as students of Barnard College and other Columbia affiliated schools, can register to participate in the World Leaders Forum using their student IDs. Even for individuals who do not have the privilege to attend the event live, they can watch the forum via online videos on Columbia University's website.\nPast forum speakers include former president of the United States Bill Clinton, the prime minister of India Atal Bihari Vajpayee, former president of Ghana John Agyekum Kufuor, president of Afghanistan Hamid Karzai, prime minister of Russia Vladimir Putin, president of the Republic of Mozambique Joaquim Alberto Chissano, president of the Republic of Bolivia Carlos Diego Mesa Gisbert, president of the Republic of Romania Ion Iliescu, president of the Republic of Latvia Vaira V\u012b\u0137e-Freiberga, the first female president of Finland Tarja Halonen, President Yudhoyono of Indonesia, President Pervez Musharraf of the Islamic Republic of Pakistan, Iraq President Jalal Talabani, the 14th Dalai Lama, president of the Islamic Republic of Iran Mahmoud Ahmadinejad, financier George Soros, Mayor of New York City Michael R. Bloomberg, President V\u00e1clav Klaus of the Czech Republic, President Cristina Fern\u00e1ndez de Kirchner of Argentina, former Secretary-General of the United Nations Kofi Annan, and Al Gore.\nOther.\nThe Columbia University Orchestra was founded by composer Edward MacDowell in 1896, and is the oldest continually operating university orchestra in the United States. Undergraduate student composers at Columbia may choose to become involved with Columbia New Music, which sponsors concerts of music written by undergraduate students from all of Columbia's schools.\nThere are a number of performing arts groups at Columbia dedicated to producing student theater, including the Columbia Players, King's Crown Shakespeare Troupe (KCST), Columbia Musical Theater Society (CMTS), NOMADS (New and Original Material Authored and Directed by Students), LateNite Theatre, Columbia University Performing Arts League (CUPAL), Black Theatre Ensemble (BTE), sketch comedy group Chowdah, and improvisational troupes Alfred and Fruit Paunch. The Columbia University Marching Band tells jokes during the campus tradition of Orgo Night.\nThe Columbia Queer Alliance is the central Columbia student organization that represents the bisexual, lesbian, gay, transgender, and questioning student population. It is the oldest gay student organization in the world, founded as the Student Homophile League in 1967 by students including lifelong activist Stephen Donaldson. Columbia University campus military groups include the U.S. Military Veterans of Columbia University and Advocates for Columbia ROTC. In the 2005\u201306 academic year, the Columbia Military Society, Columbia's student group for ROTC cadets and Marine officer candidates, was renamed the Hamilton Society for \"students who aspire to serve their nation through the military in the tradition of Alexander Hamilton\".\nThe university also houses an independent nonprofit organization, Community Impact, which strives to serve disadvantaged people in the Harlem, Washington Heights, and Morningside Heights communities. From its earliest inception as a single service initiative formed in 1981 by Columbia University undergraduates, Community Impact has grown into Columbia University's largest student service organization. CI provides food, clothing, shelter, education, job training, and companionship for residents in its surrounding communities. CI consists of a dedicated corps of about 950 Columbia University student volunteers participating in 25 community service programs, which serve more than 8,000 people each year.\nStudent activism.\n1936 protest against Nazis.\nIn 1936, Robert Burke, CC '38 led a rally outside President Butler's mansion to protest Columbia's friendly relationship with the Nazis. Burke was expelled, and was never readmitted. The university has never apologized for expelling him.\nProtests of 1968.\nStudents initiated a major demonstration in 1968 over two main issues. The first was Columbia's proposed gymnasium in neighboring Morningside Park, perceived as a segregated facility, with limited access by the black residents of neighboring Harlem. A second issue was the Columbia administration's failure to resign its institutional membership in the Pentagon's weapons research think-tank, the Institute for Defense Analyses (IDA). Students barricaded themselves inside Low Library, Hamilton Hall, and several other university buildings during the protests, and New York City police were called onto the campus to arrest or forcibly remove the students.\nThe protests achieved two of their stated goals. Columbia disaffiliated from the IDA and scrapped the plans for the controversial gym, building a subterranean physical fitness center under the north end of campus instead. A popular myth states that the gym's plans were eventually used by Princeton University for the expansion of its athletic facilities, but as Jadwin Gymnasium was already 50% complete by 1966 (when the Columbia gym was announced) this was clearly not correct. At least 30 Columbia students were suspended by the administration as a result of the protests. Many of the Class of '68 walked out of their graduation and held a countercommencement on Low Plaza with a picnic following at Morningside Park, the place where the protests began. The protests hurt Columbia financially as many potential students chose to attend other universities and some alumni refused to donate money to the school. Allan Bloom, a professor of philosophy at the University of Chicago,\nbelieved that the protest efforts at Columbia were responsible for pushing higher education further toward the liberal left. As a result of the protests, Bloom stated, \"American universities were no longer places of intellectual and academic debate, but rather places of 'political correctness' and liberalism.\" \nProtests against racism and apartheid.\nFurther student protests, including hunger strike and more barricades of Hamilton Hall and the Business School during the late 1970s and early 1980s, were aimed at convincing the university trustees to divest all of the university's investments in companies that were seen as active or tacit supporters of the apartheid regime in South Africa. A notable upsurge in the protests occurred in 1978, when following a celebration of the tenth anniversary of the student uprising in 1968, students marched and rallied in protest of university investments in South Africa. The Committee Against Investment in South Africa (CAISA) and numerous student groups including the Socialist Action Committee, the Black Student Organization and the Gay Students group joined together and succeeded in pressing for the first partial divestment of a U.S. university.\nThe initial (and partial) Columbia divestment,\nfocused largely on bonds and financial institutions directly involved with the South African regime. It followed a year-long campaign first initiated by students who had worked together to block the appointment of former United States Secretary of State Henry Kissinger to an endowed chair at the university in 1977.\nBroadly backed by student groups and many faculty members the Committee Against Investment in South Africa held teach-ins and demonstrations through the year focused on the trustees ties to the corporations doing business with South Africa. Trustee meetings were picketed and interrupted by demonstrations culminating in May 1978 in the takeover of the Graduate School of Business.\n\"Columbia Unbecoming\".\nIn the early 2000s, professor Joseph Massad, held an elective course called Palestinian and Israeli Politics and Societies at Columbia. Students felt the views he espoused in the course were anti-Israel and some of them tried to disrupt his class and get him fired. In 2004, students got together with the pro-Israel campus group the David Project and produced a film called \"Columbia Unbecoming\", accusing Massad and two other professors of intimidating or treating unfairly students with pro-Israel views. The film led to a committee being appointed by Bollinger which exonerated the professors in the spring of 2005. However, the committee's report criticized Columbia's inadequate grievance procedures.\nAhmadinejad speech controversy.\nThe School of International and Public Affairs extends invitations to heads of state and heads of government who come to New York City for the opening of the fall session of the United Nations General Assembly. In 2007, Iranian President Mahmoud Ahmadinejad was one of those invited to speak on campus. Ahmadinejad accepted his invitation and spoke on September 24, 2007, as part of Columbia University's World Leaders Forum. The invitation proved to be highly controversial. Hundreds of demonstrators swarmed the campus on September 24 and the speech itself was televised worldwide. University President Lee C. Bollinger tried to allay the controversy by letting Ahmadenijad speak, but with a negative introduction (given personally by Bollinger). This did not mollify those who were displeased with the fact that the Iranian leader had been invited onto the campus. Columbia students, though, turned out en masse to listen to the speech on the South Lawn. An estimated 2,500 undergraduates and graduates came out for the historic occasion.\nDuring his speech, Ahmadinejad criticized Israel's policies towards the Palestinians; called for research on the historical accuracy of the Holocaust; raised questions as to who initiated the 9/11 attacks; defended Iran's nuclear power program, criticizing the UN's policy of sanctions on his country; and attacked U.S. foreign policy in the Middle East. In response to a question about Iran's treatment of women and homosexuals, he asserted that women are respected in Iran and that \"In Iran, we don't have homosexuals like in your country\u2026In Iran, we do not have this phenomenon. I don't know who told you this.\" The latter statement drew laughter from the audience. The Manhattan District Attorney's Office accused Columbia of accepting grant money from the Alavi Foundation to support faculty \"sympathetic\" to Iran's Islamic republic.\nROTC controversy.\nBeginning in 1969, during the Vietnam War, the university did not allow the U.S. military to have Reserve Officers' Training Corps (ROTC) programs on campus, though Columbia students could participate in ROTC programs at other local colleges and universities. At a forum at the university during the 2008 presidential election campaign, both John McCain and Barack Obama said that the university should consider reinstating ROTC on campus. After the debate, the president of the university, Lee C. Bollinger, stated that he did not favor reinstating Columbia's ROTC program, because of the military's anti-gay policies. In November 2008, Columbia's undergraduate student body held a referendum on the question of whether or not to invite ROTC back to campus, and the students who voted were almost evenly divided on the issue. ROTC lost the vote (which would not have been binding on the administration, and did not include graduate students, faculty, or alumni) by a fraction of a percentage point.\nIn April 2010 during Admiral Mike Mullen's address at Columbia, President Lee C. Bollinger stated that the ROTC would be readmitted to campus if the admiral's plans for revoking the don't ask, don't tell policy were successful. In February 2011 during one of three town-hall meetings on the ROTC ban, former Army staff sergeant Anthony Maschek, a Purple Heart recipient for injuries sustained during his service in Iraq, was booed and hissed at by some students during his speech promoting the idea of allowing the ROTC on campus. In April 2011 the Columbia University Senate voted to welcome the ROTC program back on campus. Secretary of the Navy Ray Mabus and Columbia University President Lee C. Bollinger signed an agreement to reinstate Naval Reserve Officers Training Corps (NROTC) program at Columbia for the first time in more than 40 years on May 26, 2011. The agreement was signed at a ceremony on board the , docked in New York for the Navy's annual Fleet Week.\nDivestment from private prisons.\nIn February 2014, after learning that the university had over $10 million invested in the private prison industry, a group of students delivered a letter President Bollinger's office requesting a meeting and officially launching the Columbia Prison Divest (CPD) campaign. , Columbia held investments in Corrections Corporation of America, the largest private prison company in the United States, as well as G4S, the largest multinational security firm in the world. Students demanded that the university divest these holdings from the industry and instate a ban on future investments in the private prison industry. Aligning themselves with the growing Black Lives Matter movement and in conversation with the heightened attention on race and the system of mass incarceration, CPD student activists hosted events to raise awareness of the issue and worked to involve large numbers of members of the Columbia and West Harlem community in campaign activities. After eighteen months of student driven organizing, the Board of Trustees of Columbia University voted to support the petition for divestment from private prison companies, which was confirmed to student leaders on June 22, 2015. The Columbia Prison Divest campaign was the first campaign to successfully get a U.S. university to divest from the private prison industry.\nTuition strike.\nIn January 2021, more than 1000 Columbia University students initiated a tuition strike, demanding that the university lower its tuition rates by 10% amid financial burdens and the move to online classes prompted by the COVID-19 pandemic. Tuition for undergraduates is $58,920 for an academic year, and the total costs eclipse $80,000 when expenses including fees, room and board, books and travel are factored in. It is the largest tuition strike at the university in nearly 50 years. Students have stated they have won a number of concessions, as the university announced it would freeze tuition, suspend fees on late payments, increase spring financial aid and provide a limited amount of summer grants. a university spokesperson, however, stated that the decisions occurred several months prior to the strike. Students have also asked the university to end its expansion into and gentrification of West Harlem, defund its university police force, to divest from its investments in oil and gas companies, and bargain in good faith with campus unions. The university in February 2021 announced that the Board of Trustees had finally formalized its commitment to divest from publicly traded oil and gas companies. The strike had been largely organized by the campus chapter of Young Democratic Socialists of America, which had partnered with other student groups to support the action. \nTraditions.\nOrgo Night.\nIn one of the school's longest-lasting traditions, begun in 1975, at midnight before the Organic Chemistry exam\u2014often the first day of final exams\u2014the Columbia University Marching Band invaded and briefly occupied the main undergraduate reading room in Butler Library to distract and entertain studying students with some forty-five minutes of raucous jokes and music, beginning and ending with the singing of the school's fight song, \"Roar, Lion, Roar\". After the main show before a crowd that routinely began filling the room well before the announced midnight start time, the Band led a procession to several campus locations, including the residential quadrangle of Barnard College for more music and temporary relief from the stress of last-minute studying.\nIn December 2016, following several years of complaints from students who said that some Orgo Night scripts and advertising posters were offensive to minority groups, as well as a \"The New York Times\" article on the Band's crass treatment of sexual assault on campus,\nUniversity administrators banned the Marching Band from performing its Orgo Night show in the traditional Butler Library location. Protests and allegations of censorship followed, but University President Lee Bollinger said that complaints and publicity about the shows had \"nothing to do with\" the prohibition. The Band instead performed\u2014at midnight, as usual\u2014outside the main entrance of Butler Library.\nThe Band's official alumni organization, the Columbia University Band Alumni Association, registered protests with the administration, and an ad hoc group of alumni writing under the name \"A. Hamiltonius\" published a series of pamphlets addressing their dissatisfaction with the ban, but at the end of the spring 2017 semester the university administration held firm, prompting the Marching Band to again stage its show outside the building. For Orgo Night December 2017, Band members quietly infiltrated the library with their musical instruments during the evening and popped up at midnight to perform the show inside despite the ban. Prior to the spring 2018 exam period, the administration warned the group's leaders against a repeat and restated the injunction, warning of sanctions; the Band again staged its Orgo Night show in front of the library.\nTree-Lighting and Yule Log ceremonies.\nThe campus Tree-Lighting Ceremony was inaugurated in 1998. It celebrates the illumination of the medium-sized trees lining College Walk in front of Kent and Hamilton Halls on the east end and Dodge and Journalism Halls on the west, just before finals week in early December. The lights remain on until February 28. Students meet at the sun-dial for free hot chocolate, performances by \"a cappella\" groups, and speeches by the university president and a guest.\nImmediately following the College Walk festivities is one of Columbia's older holiday traditions, the lighting of the Yule Log. The Christmas ceremony dates to a period prior to the American Revolutionary War, but lapsed before being revived by University President Nicholas Murray Butler in the early 20th century. A troop of students dressed as Continental Army soldiers carry the eponymous log from the sun-dial to the lounge of John Jay Hall, where it is lit amid the singing of seasonal carols. The Christmas ceremony is accompanied by a reading of \"A Visit From St. Nicholas\" by Clement Clarke Moore and \"Yes, Virginia, There is a Santa Claus\" by Francis Pharcellus Church.\nThe Varsity Show.\nThe Varsity Show is an annual musical written by and for students and was established in 1894, making it one of Columbia's oldest traditions. Past writers and directors have included Columbians Richard Rodgers and Oscar Hammerstein, Lorenz Hart, I.A.L. Diamond, Herman Wouk and Eric Garcetti. The show has one of the largest operating budgets of all university events.\nNotable people.\nThe university has graduated many notable alumni, including five Founding Fathers of the United States, an author of the United States Constitution and a member of the Committee of Five; , there were 125 Pulitzer Prize winners and 39 Oscar winners, as well as three United States presidents. , there were 101 National Academy members who were alumni.\nIn a 2016 ranking of universities worldwide with respect to living graduates who are billionaires, Columbia ranked second, after Harvard.\nFormer U.S. Presidents Theodore Roosevelt and Franklin Delano Roosevelt attended the law school. Other political figures educated at Columbia include former U.S President Barack Obama, Associate Justice of the U.S. Supreme Court Ruth Bader Ginsburg, former U.S. Secretary of State Madeleine Albright, former chairman of the U.S. Federal Reserve Bank Alan Greenspan, U.S. Attorney General Eric Holder, and U.S. Solicitor General Donald Verrilli Jr. Dwight D. Eisenhower served as the thirteenth president of Columbia University from 1948 to 1953. The university has also educated 26 foreign heads of state, including president of Georgia Mikheil Saakashvili, president of East Timor Jose Ramos Horta, president of Estonia Toomas Hendrik Ilves and other historical figures such as Wellington Koo, Radovan Karad\u017ei\u0107, Gaston Eyskens, and T. V. Soong. The author of India's constitution Dr. B. R. Ambedkar was also an alumnus of Columbia.\nAlumni of Columbia have occupied top positions in Wall Street and the rest of the business world. Notable members of the Astor family attended Columbia, while other business graduates include investor Warren Buffett, former CEO of PBS and NBC Larry Grossman, chairman of Wal-Mart S. Robson Walton and Bain Capital Co-Managing Partner, Jonathan Lavine. CEO's of top Fortune 500 companies include James P. Gorman of Morgan Stanley, Robert J. Stevens of Lockheed Martin, Philippe Dauman of Viacom, Ursula Burns of Xerox, and Vikram Pandit of Citigroup. Notable labor organizer and women's educator Louise Leonard McLaren received her degree of Master of Arts from Columbia.\nIn science and technology, Columbia alumni include: founder of IBM Herman Hollerith; inventor of FM radio Edwin Armstrong; Francis Mechner; integral in development of the nuclear submarine Hyman Rickover; founder of Google China Kai-Fu Lee; scientists Stephen Jay Gould, Robert Millikan, Helium\u2013neon laser inventor Ali Javan and Mihajlo Pupin; chief-engineer of the New York City Subway, William Barclay Parsons; philosophers Irwin Edman and Robert Nozick; economist Milton Friedman; psychologist Harriet Babcock; and sociologists Lewis A. Coser and Rose Laub Coser.\nMany Columbia alumni have gone on to renowned careers in the arts, including composers Richard Rodgers, Oscar Hammerstein II, Lorenz Hart, and Art Garfunkel. Four United States Poet Laureates received their degrees from Columbia. Columbia alumni have made an indelible mark in the field of American poetry and literature, with such people as Jack Kerouac and Allen Ginsberg, pioneers of the Beat Generation, and Langston Hughes, a seminal figure in the Harlem Renaissance, all having attended the university. Other notable writers who attended Columbia include authors Isaac Asimov, J.D. Salinger, Upton Sinclair, Danielle Valore Evans, and Hunter S. Thompson.\nUniversity alumni have also been very prominent in the film industry, with 33 alumni and former students winning a combined 43 Academy Awards (). Some notable Columbia alumni that have gone on to work in film include directors Sidney Lumet (\"12 Angry Men\") and Kathryn Bigelow (\"The Hurt Locker\"), screenwriters Howard Koch (\"Casablanca\") and Joseph L. Mankiewicz (\"All About Eve\"), and actors James Cagney and Ed Harris."}
{"id": "6311", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6311", "title": "College Football", "text": ""}
{"id": "6312", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6312", "title": "Cell wall", "text": "A cell wall is a structural layer surrounding some types of cells, just outside the cell membrane. It can be tough, flexible, and sometimes rigid. It provides the cell with both structural support and protection, and also acts as a filtering mechanism. Cell walls are present in most prokaryotes (except mollicute bacteria), in algae, fungi and eukaryotes including plants but are absent in animals. A major function is to act as pressure vessels, preventing over-expansion of the cell when water enters.\nThe composition of cell walls varies between species and may depend on cell type and developmental stage. The primary cell wall of land plants is composed of the polysaccharides cellulose, hemicelluloses and pectin. Often, other polymers such as lignin, suberin or cutin are anchored to or embedded in plant cell walls. Algae possess cell walls made of glycoproteins and polysaccharides such as carrageenan and agar that are absent from land plants. In bacteria, the cell wall is composed of peptidoglycan. The cell walls of archaea have various compositions, and may be formed of glycoprotein S-layers, pseudopeptidoglycan, or polysaccharides. Fungi possess cell walls made of the N-acetylglucosamine polymer chitin. Unusually, diatoms have a cell wall composed of biogenic silica.\nHistory.\nA plant cell wall was first observed and named (simply as a \"wall\") by Robert Hooke in 1665. However, \"the dead excrusion product of the living protoplast\" was forgotten, for almost three centuries, being the subject of scientific interest mainly as a resource for industrial processing or in relation to animal or human health.\nIn 1804, Karl Rudolphi and J.H.F. Link proved that cells had independent cell walls. Before, it had been thought that cells shared walls and that fluid passed between them this way.\nThe mode of formation of the cell wall was controversial in the 19th century. Hugo von Mohl (1853, 1858) advocated the idea that the cell wall grows by apposition. Carl N\u00e4geli (1858, 1862, 1863) believed that the growth of the wall in thickness and in area was due to a process termed intussusception. Each theory was improved in the following decades: the apposition (or lamination) theory by Eduard Strasburger (1882, 1889), and the intussusception theory by Julius Wiesner (1886).\nIn 1930, Ernst M\u00fcnch coined the term \"apoplast\" in order to separate the \"living\" symplast from the \"dead\" plant region, the latter of which included the cell wall.\nBy the 1980s, some authors suggested replacing the term \"cell wall\", particularly as it was used for plants, with the more precise term \"extracellular matrix\", as used for animal cells, but others preferred the older term.\nProperties.\nCell walls serve similar purposes in those organisms that possess them. They may give cells rigidity and strength, offering protection against mechanical stress. The chemical composition and mechanical properties of the cell wall are linked with plant cell growth and morphogenesis. In multicellular organisms, they permit the organism to build and hold a definite shape. Cell walls also limit the entry of large molecules that may be toxic to the cell. They further permit the creation of stable osmotic environments by preventing osmotic lysis and helping to retain water. Their composition, properties, and form may change during the cell cycle and depend on growth conditions.\nRigidity of cell walls.\nIn most cells, the cell wall is flexible, meaning that it will bend rather than holding a fixed shape, but has considerable tensile strength. The apparent rigidity of primary plant tissues is enabled by cell walls, but is not due to the walls' stiffness. Hydraulic turgor pressure creates this rigidity, along with the wall structure. The flexibility of the cell walls is seen when plants wilt, so that the stems and leaves begin to droop, or in seaweeds that bend in water currents. As John Howland explains\nThe apparent rigidity of the cell wall thus results from inflation of the cell contained within. This inflation is a result of the passive uptake of water.\nIn plants, a secondary cell wall is a thicker additional layer of cellulose which increases wall rigidity. Additional layers may be formed by lignin in xylem cell walls, or suberin in cork cell walls. These compounds are rigid and waterproof, making the secondary wall stiff. Both wood and bark cells of trees have secondary walls. Other parts of plants such as the leaf stalk may acquire similar reinforcement to resist the strain of physical forces.\nPermeability.\nThe primary cell wall of most plant cells is freely permeable to small molecules including small proteins, with size exclusion estimated to be 30-60 kDa. The pH is an important factor governing the transport of molecules through cell walls.\nEvolution.\nCell walls evolved independently in many groups.\nThe photosynthetic eukaryotes (so-called plant and algae) is one group with cellulose cell walls, where the cell wall is closely related to the evolution of multicellularity, terrestrialization and vascularization. The CesA cellulose synthase evolved in \"Cyanobacteria\" and was part of Archaeplastida since endosymbiosis; secondary endosymbiosis events transferred it (with the arabinogalactan proteins) further into brown algae and oomycetes. Plants later evolved various genes from CesA, including the Csl (cellulose synthase-like) family of proteins and additional Ces proteins. Combined with the various glycosyltransferases (GT), they enable more complex chemical structures to be built.\nFungi use a chitin-glucan-protein cell wall. They share the 1,3-\u03b2-glucan synthesis pathway with plants, using homologous GT48 family 1,3-Beta-glucan synthases to perform the task, suggesting that such an enzyme is very ancient within the eukaryotes. Their glycoproteins are rich in mannose. The cell wall might have evolved to deter viral infections. Proteins embedded in cell walls are variable, contained in tandem repeats subject to homologous recombination. An alternative scenario is that fungi started with a chitin-based cell wall and later acquired the GT-48 enzymes for the 1,3-\u03b2-glucans via horizontal gene transfer. The pathway leading to 1,6-\u03b2-glucan synthesis is not sufficiently known in either case.\nPlant cell walls.\nThe walls of plant cells must have sufficient tensile strength to withstand internal osmotic pressures of several times atmospheric pressure that result from the difference in solute concentration between the cell interior and external solutions. Plant cell walls vary from 0.1 to several \u00b5m in thickness.\nLayers.\nUp to three strata or layers may be found in plant cell walls:\nComposition.\nIn the primary (growing) plant cell wall, the major carbohydrates are cellulose, hemicellulose and pectin. The cellulose microfibrils are linked via hemicellulosic tethers to form the cellulose-hemicellulose network, which is embedded in the pectin matrix. The most common hemicellulose in the primary cell wall is xyloglucan. In grass cell walls, xyloglucan and pectin are reduced in abundance and partially replaced by glucuronarabinoxylan, another type of hemicellulose. Primary cell walls characteristically extend (grow) by a mechanism called acid growth, mediated by expansins, extracellular proteins activated by acidic conditions that modify the hydrogen bonds between pectin and cellulose. This functions to increase cell wall extensibility. The outer part of the primary cell wall of the plant epidermis is usually impregnated with cutin and wax, forming a permeability barrier known as the plant cuticle.\nSecondary cell walls contain a wide range of additional compounds that modify their mechanical properties and permeability. The major polymers that make up wood (largely secondary cell walls) include:\nAdditionally, structural proteins (1-5%) are found in most plant cell walls; they are classified as hydroxyproline-rich glycoproteins (HRGP), arabinogalactan proteins (AGP), glycine-rich proteins (GRPs), and proline-rich proteins (PRPs). Each class of glycoprotein is defined by a characteristic, highly repetitive protein sequence. Most are glycosylated, contain hydroxyproline (Hyp) and become cross-linked in the cell wall. These proteins are often concentrated in specialized cells and in cell corners. Cell walls of the epidermis may contain cutin. The Casparian strip in the endodermis roots and cork cells of plant bark contain suberin. Both cutin and suberin are polyesters that function as permeability barriers to the movement of water. The relative composition of carbohydrates, secondary compounds and proteins varies between plants and between the cell type and age. Plant cells walls also contain numerous enzymes, such as hydrolases, esterases, peroxidases, and transglycosylases, that cut, trim and cross-link wall polymers.\nSecondary walls - especially in grasses - may also contain microscopic silica crystals, which may strengthen the wall and protect it from herbivores.\nCell walls in some plant tissues also function as storage deposits for carbohydrates that can be broken down and resorbed to supply the metabolic and growth needs of the plant. For example, endosperm cell walls in the seeds of cereal grasses, nasturtium\nand other species, are rich in glucans and other polysaccharides that are readily digested by enzymes during seed germination to form simple sugars that nourish the growing embryo.\nFormation.\nThe middle lamella is laid down first, formed from the cell plate during cytokinesis, and the primary cell wall is then deposited inside the middle lamella. The actual structure of the cell wall is not clearly defined and several models exist - the covalently linked cross model, the tether model, the diffuse layer model and the stratified layer model. However, the primary cell wall, can be defined as composed of cellulose microfibrils aligned at all angles. Cellulose microfibrils are produced at the plasma membrane by the cellulose synthase complex, which is proposed to be made of a hexameric rosette that contains three cellulose synthase catalytic subunits for each of the six units. Microfibrils are held together by hydrogen bonds to provide a high tensile strength. The cells are held together and share the gelatinous membrane called the \"middle lamella\", which contains magnesium and calcium pectates (salts of pectic acid). Cells interact though plasmodesmata, which are inter-connecting channels of cytoplasm that connect to the protoplasts of adjacent cells across the cell wall.\nIn some plants and cell types, after a maximum size or point in development has been reached, a \"secondary wall\" is constructed between the plasma membrane and primary wall. Unlike the primary wall, the cellulose microfibrils are aligned parallel in layers, the orientation changing slightly with each additional layer so that the structure becomes helicoidal. Cells with secondary cell walls can be rigid, as in the gritty sclereid cells in pear and quince fruit. Cell to cell communication is possible through pits in the secondary cell wall that allow plasmodesmata to connect cells through the secondary cell walls.\nFungal cell walls.\nThere are several groups of organisms that have been called \"fungi\". Some of these groups (Oomycete and Myxogastria) have been transferred out of the Kingdom Fungi, in part because of fundamental biochemical differences in the composition of the cell wall. Most true fungi have a cell wall consisting largely of chitin and other polysaccharides. True fungi do not have cellulose in their cell walls.\nTrue fungi.\nIn fungi, the cell wall is the outer-most layer, external to the plasma membrane. The fungal cell wall is a matrix of three main components:\nOther eukaryotic cell walls.\nAlgae.\nLike plants, algae have cell walls. Algal cell walls contain either polysaccharides (such as cellulose (a glucan)) or a variety of glycoproteins (Volvocales) or both. The inclusion of additional polysaccharides in algal cells walls is used as a feature for algal taxonomy.\nOther compounds that may accumulate in algal cell walls include sporopollenin and calcium ions.\nThe group of algae known as the diatoms synthesize their cell walls (also known as frustules or valves) from silicic acid. Significantly, relative to the organic cell walls produced by other groups, silica frustules require less energy to synthesize (approximately 8%), potentially a major saving on the overall cell energy budget and possibly an explanation for higher growth rates in diatoms.\nIn brown algae, phlorotannins may be a constituent of the cell walls.\nWater molds.\nThe group Oomycetes, also known as water molds, are saprotrophic plant pathogens like fungi. Until recently they were widely believed to be fungi, but structural and molecular evidence has led to their reclassification as heterokonts, related to autotrophic brown algae and diatoms. Unlike fungi, oomycetes typically possess cell walls of cellulose and glucans rather than chitin, although some genera (such as \"Achlya\" and \"Saprolegnia\") do have chitin in their walls. The fraction of cellulose in the walls is no more than 4 to 20%, far less than the fraction of glucans. Oomycete cell walls also contain the amino acid hydroxyproline, which is not found in fungal cell walls.\nSlime molds.\nThe dictyostelids are another group formerly classified among the fungi. They are slime molds that feed as unicellular amoebae, but aggregate into a reproductive stalk and sporangium under certain conditions. Cells of the reproductive stalk, as well as the spores formed at the apex, possess a cellulose wall. The spore wall has three layers, the middle one composed primarily of cellulose, while the innermost is sensitive to cellulase and pronase.\nProkaryotic cell walls.\nBacterial cell walls.\nAround the outside of the cell membrane is the bacterial cell wall. Bacterial cell walls are made of peptidoglycan (also called murein), which is made from polysaccharide chains cross-linked by unusual peptides containing D-amino acids. Bacterial cell walls are different from the cell walls of plants and fungi which are made of cellulose and chitin, respectively. The cell wall of bacteria is also distinct from that of Archaea, which do not contain peptidoglycan. The cell wall is essential to the survival of many bacteria, although L-form bacteria can be produced in the laboratory that lack a cell wall. The antibiotic penicillin is able to kill bacteria by preventing the cross-linking of peptidoglycan and this causes the cell wall to weaken and lyse. The lysozyme enzyme can also damage bacterial cell walls.\nThere are broadly speaking two different types of cell wall in bacteria, called gram-positive and gram-negative. The names originate from the reaction of cells to the Gram stain, a test long-employed for the classification of bacterial species.\nGram-positive bacteria possess a thick cell wall containing many layers of peptidoglycan and teichoic acids. In contrast, gram-negative bacteria have a relatively thin cell wall consisting of a few layers of peptidoglycan surrounded by a second lipid membrane containing lipopolysaccharides and lipoproteins. Most bacteria have the gram-negative cell wall and only the Firmicutes and Actinobacteria (previously known as the low G+C and high G+C gram-positive bacteria, respectively) have the alternative gram-positive arrangement. These differences in structure can produce differences in antibiotic susceptibility, for instance vancomycin can kill only gram-positive bacteria and is ineffective against gram-negative pathogens, such as \"Haemophilus influenzae\" or \"Pseudomonas aeruginosa\".\nArchaeal cell walls.\nAlthough not truly unique, the cell walls of Archaea are unusual. Whereas peptidoglycan is a standard component of all bacterial cell walls, all archaeal cell walls lack peptidoglycan, though some methanogens have a cell wall made of a similar polymer called pseudopeptidoglycan. There are four types of cell wall currently known among the Archaea.\nOne type of archaeal cell wall is that composed of pseudopeptidoglycan (also called pseudomurein). This type of wall is found in some methanogens, such as \"Methanobacterium\" and \"Methanothermus\". While the overall structure of archaeal \"pseudo\"peptidoglycan superficially resembles that of bacterial peptidoglycan, there are a number of significant chemical differences. Like the peptidoglycan found in bacterial cell walls, pseudopeptidoglycan consists of polymer chains of glycan cross-linked by short peptide connections. However, unlike peptidoglycan, the sugar N-acetylmuramic acid is replaced by N-acetyltalosaminuronic acid, and the two sugars are bonded with a \"\u03b2\",1-3 glycosidic linkage instead of \"\u03b2\",1-4. Additionally, the cross-linking peptides are L-amino acids rather than D-amino acids as they are in bacteria.\nA second type of archaeal cell wall is found in \"Methanosarcina\" and \"Halococcus\". This type of cell wall is composed entirely of a thick layer of polysaccharides, which may be sulfated in the case of \"Halococcus\". Structure in this type of wall is complex and not fully investigated.\nA third type of wall among the Archaea consists of glycoprotein, and occurs in the hyperthermophiles, \"Halobacterium\", and some methanogens. In \"Halobacterium\", the proteins in the wall have a high content of acidic amino acids, giving the wall an overall negative charge. The result is an unstable structure that is stabilized by the presence of large quantities of positive sodium ions that neutralize the charge. Consequently, \"Halobacterium\" thrives only under conditions with high salinity.\nIn other Archaea, such as \"Methanomicrobium\" and \"Desulfurococcus\", the wall may be composed only of surface-layer proteins, known as an \"S-layer\". S-layers are common in bacteria, where they serve as either the sole cell-wall component or an outer layer in conjunction with polysaccharides. Most Archaea are Gram-negative, though at least one Gram-positive member is known.\nOther cell coverings.\nMany protists and bacteria produce other cell surface structures apart from cell walls, external (extracellular matrix) or internal. Many algae have a sheath or envelope of mucilage outside the cell made of exopolysaccharides. Diatoms build a frustule from silica extracted from the surrounding water; radiolarians, foraminiferans, testate amoebae and silicoflagellates also produce a skeleton from minerals, called test in some groups. Many green algae, such as \"Halimeda\" and the Dasycladales, and some red algae, the Corallinales, encase their cells in a secreted skeleton of calcium carbonate. In each case, the wall is rigid and essentially inorganic. It is the non-living component of cell. Some golden algae, ciliates and choanoflagellates produces a shell-like protective outer covering called lorica. Some dinoflagellates have a theca of cellulose plates, and coccolithophorids have coccoliths.\nAn extracellular matrix (ECM) is also present in metazoans. Its composition varies between cells, but collagens are the most abundant protein in the ECM."}
{"id": "6313", "revid": "41441035", "url": "https://en.wikipedia.org/wiki?curid=6313", "title": "Classical element", "text": "Classical elements typically refer to water, earth, fire, air, and (later) aether, which were proposed to explain the nature and complexity of all matter in terms of simpler substances. Ancient cultures in Greece, Ancient Egypt, Persia, Babylonia, Japan, Tibet, and India had all similar lists, sometimes referring in local languages to \"air\" as \"wind\" and the fifth element as \"void\". The Chinese Wu Xing system lists Wood (\u6728 \"m\u00f9\"), Fire (\u706b \"hu\u01d2\"), Earth (\u571f \"t\u01d4\"), Metal (\u91d1 \"j\u012bn\"), and Water (\u6c34 \"shu\u01d0\"), though these are described more as energies or transitions rather than as types of material.\nThese different cultures and even individual philosophers had widely varying explanations concerning their attributes and how they related to observable phenomena as well as cosmology. Sometimes these theories overlapped with mythology and were personified in deities. Some of these interpretations included atomism (the idea of very small, indivisible portions of matter), but other interpretations considered the elements to be divisible into infinitely small pieces without changing their nature.\nWhile the classification of the material world in ancient Indian, Hellenistic Egypt, and ancient Greece into Air, Earth, Fire and Water was more philosophical, during the Islamic Golden Age medieval middle eastern scientists used practical, experimental observation to classify materials. In Europe, the Ancient Greek system of Aristotle evolved slightly into the medieval system, which for the first time in Europe became subject to experimental verification in the 1600s, during the Scientific Revolution.\nModern science does not support the classical elements as the material basis of the physical world. Atomic theory classifies atoms into more than a hundred chemical elements such as oxygen, iron, and mercury. These elements form chemical compounds and mixtures, and under different temperatures and pressures, these substances can adopt different states of matter. The most commonly observed states of solid, liquid, gas, and plasma share many attributes with the classical elements of earth, water, air, and fire, respectively, but these states are due to similar behavior of different types of atoms at similar energy levels, and not due to containing a certain type of atom or a certain type of substance.\nAncient history.\nAncient Greece.\nIn Western thought, the four elements earth, water, air, and fire as proposed by Empedocles (5th century BC) frequently occur. In ancient Greece, discussion of the elements in the context of searching for an \"arche\" (\"first principle\") predated Empedocles by several centuries. For instance, Thales suggested in the 7th century BCE that water was the ultimate underlying substance from which everything is derived; Anaximenes subsequently made a similar claim about air. However, none before Empedocles proposed that matter could ultimately be composed of \"all four\" elements in different combinations of one another. Later on, Aristotle added a fifth element to the system, which he called aether.\nPersia.\nThe Persian philosopher Zarathustra (600\u2013583 BCE), also known as Zoroaster, \u200adescribed the four elements of earth, water, air and fire as \u201csacred,\u201d i.e., \u201cessential for the survival of all living beings and therefore should be venerated and kept free from any contamination\u201d.\nCosmic elements in Babylonia.\nIn Babylonian mythology, the cosmogony called \"En\u00fbma Eli\u0161\", a text written between the 18th and 16th centuries BC, involves four gods that we might see as personified cosmic elements: sea, earth, sky, wind. In other Babylonian texts these phenomena are considered independent of their association with deities, though they are not treated as the component elements of the universe, as later in Empedocles.\nIndia.\nHinduism.\nThe system of five elements are found in Vedas, especially Ayurveda, the \"pancha mahabhuta\", or \u201cfive great elements\u201d, of Hinduism are:\nThey further suggest that all of creation, including the human body, is made up of these five essential elements and that upon death, the human body dissolves into these five elements of nature, thereby balancing the cycle of nature.\nThe five elements are associated with the five senses, and act as the gross medium for the experience of sensations. The basest element, earth, created using all the other elements, can be perceived by all five senses\u202f\u2014\u202f(i) hearing, (ii) touch, (iii) sight, (iv) taste, and (v) smell. The next higher element, water, has no odor but can be heard, felt, seen and tasted. Next comes fire, which can be heard, felt and seen. Air can be heard and felt. \u201cAkasha\u201d (aether) is beyond the senses of smell, taste, sight, and touch; it being accessible to the sense of hearing alone.\nBuddhism.\nIn the Pali literature, the \"mahabhuta\" (\u201cgreat elements\u201d) or \"catudhatu\" (\u201cfour elements\u201d) are earth, water, fire and air. In early Buddhism, the four elements are a basis for understanding suffering and for liberating oneself from suffering. The earliest Buddhist texts explain that the four primary material elements are solidity, fluidity, temperature, and mobility, characterized as earth, water, fire, and air, respectively.\nThe Buddha\u2019s teaching regarding the four elements is to be understood as the base of all observation of real sensations rather than as a philosophy. The four properties are cohesion (water), solidity or inertia (earth), expansion or vibration (air) and heat or energy content (fire). He promulgated a categorization of mind and matter as composed of eight types of \u201ckalapas\u201d of which the four elements are primary and a secondary group of four are color, smell, taste, and nutriment which are derivative from the four primaries.\nThanissaro Bhikkhu (1997) renders an extract of Shakyamuni Buddha\u2019s from Pali into English thus:\nTibetan Buddhist medical literature speaks of the Panch Mah\u0101bh\u016bta (five elements).\nChina.\nThe Chinese had a somewhat different series of elements, namely Fire, Earth, Metal (literally gold), Water and Wood, which were understood as different types of energy in a state of constant interaction and flux with one another, rather than the Western notion of different kinds of material. Historians of science have noted a fundamental difference between Greek element theories and Chinese matter theories.\nAlthough it is usually translated as \u201celement\u201d, the Chinese word \"xing\" literally means something like \u201cchanging states of being\u201d, \u201cpermutations\u201d or \u201cmetamorphoses of being\u201d. In fact Sinologists cannot agree on any single translation. The Chinese elements were seen as ever changing and movingone translation of \"wu xing\" is simply \u201cthe five changes\u201d.\nThe Wu Xing are chiefly an ancient mnemonic device for systems with five stages; hence the preferred translation of \u201cmovements\u201d, \u201cphases\u201d or \u201csteps\u201d over \u201celements.\u201d\nIn the bagua, metal is associated with the divination figure \u514c \"Du\u00ec\" (\u2631, the lake or marsh: \u6fa4/\u6cfd \"z\u00e9\") and with \u4e7e \"Qi\u00e1n\" (\u2630, the sky or heavens: \u5929 \"ti\u0101n\"). Wood is associated with \u5dfd \"X\u00f9n\" (\u2634, the wind: \u98a8/\u98ce \"f\u0113ng\") and with \u9707 \"Zh\u00e8n\" (\u2633, the arousing/thunder: \u96f7 \"l\u00e9i\"). In view of the durability of meteoric iron, metal came to be associated with the aether, which is sometimes conflated with Stoic pneuma, as both terms originally referred to air (the former being higher, brighter, more fiery or celestial and the latter being merely warmer, and thus vital or biogenetic). In Taoism, \"qi\" functions similarly to pneuma in a prime matter (a basic principle of energetic transformation) that accounts for both biological and inanimate phenomena.\nIn Chinese philosophy the universe consists of heaven and earth. The five major planets are associated with and even named after the elements: Jupiter \u6728\u661f is Wood (\u6728), Mars \u706b\u661f is Fire (\u706b), Saturn \u571f\u661f is Earth (\u571f), Venus \u91d1\u661f is Metal (\u91d1), and Mercury \u6c34\u661f is Water (\u6c34). Also, the Moon represents Yin (\u9670), and the Sun \u592a\u967d represents Yang (\u967d). Yin, Yang, and the five elements are associated with themes in the I Ching, the oldest of Chinese classical texts which describes an ancient system of cosmology and philosophy. The five elements also play an important part in Chinese astrology and the Chinese form of geomancy known as Feng shui.\nThe doctrine of five phases describes two cycles of balance, a generating or creation (\u751f, sh\u0113ng) cycle and an overcoming or destruction (\u514b/\u524b, k\u00e8) cycle of interactions between the phases.\n\"Generating\"\n\"Overcoming\"\nThere are also two cycles of imbalance, an overacting cycle (\u4e58\uff0ccheng) and an insulting cycle (\u4fae\uff0cwu).\nGreece.\nThe ancient Greek concept of four basic elements, these being earth (\u03b3\u1fc6 \"g\u00ea\"), water (\u1f55\u03b4\u03c9\u03c1 \"h\u00fdd\u014dr\"), air (\u1f00\u03ae\u03c1 \"a\u1e17r\"), and fire (\u03c0\u1fe6\u03c1 \"p\u0177r\"), dates from pre-Socratic times and persisted throughout the Middle Ages and into the Renaissance, deeply influencing European thought and culture.\nSicilian philosopher Empedocles (ca. 450 BC) proved (at least to his satisfaction) that air was a separate substance by observing that a bucket inverted in water did not become filled with water, a pocket of air remaining trapped inside. Prior to Empedocles, Greek philosophers had debated which substance was the primordial element from which everything else was made; Heraclitus championed fire, Thales supported water, and Anaximenes plumped for air. Anaximander argued that the primordial substance was not any of the known substances, but could be transformed into them, and they into each other. Empedocles was the first to propose four elements, fire, earth, air, and water. He called them the four \u201croots\u201d (\u1fe5\u03b9\u03b6\u03ce\u03bc\u03b1\u03c4\u03b1, rhiz\u014dmata).\nPlato seems to have been the first to use the term \u201celement (\u03c3\u03c4\u03bf\u03b9\u03c7\u03b5\u1fd6\u03bf\u03bd, \"stoiche\u00eeon\")\u201d in reference to air, fire, earth, and water. The ancient Greek word for element, \"stoicheion\" (from \"stoicheo\", \u201cto line up\u201d) meant \u201csmallest division (of a sun-dial), a syllable\u201d, as the composing unit of an alphabet it could denote a letter and the smallest unit from which a word is formed.\nIn \"On the Heavens\", Aristotle defines \"element\" in general:\nIn his \"On Generation and Corruption\", Aristotle related each of the four elements to two of the four sensible qualities:\nA classic diagram has one square inscribed in the other, with the corners of one being the classical elements, and the corners of the other being the properties. The opposite corner is the opposite of these properties, \u201chot\u202f\u2013\u202fcold\u201d and \u201cdry\u202f\u2013\u202fwet\u201d.\nAristotle added a fifth element, aether (\u03b1\u1f30\u03b8\u03ae\u03c1 \"aither\"), as the quintessence, reasoning that whereas fire, earth, air, and water were earthly and corruptible, since no changes had been perceived in the heavenly regions, the stars cannot be made out of any of the four elements but must be made of a different, unchangeable, heavenly substance. It had previously been believed by pre-Socratics such as Empedocles and Anaxagoras that aether, the name applied to the material of heavenly bodies, was a form of fire. Aristotle himself did not use the term \"aether\" for the fifth element, and strongly criticised the pre-Socratics for associating the term with fire. He preferred a number of other terms that indicated eternal movement, thus emphasising the evidence for his discovery of a new element. These five elements have been associated since Plato's \"Timaeus\" with the five platonic solids.\nA text written in Egypt in Hellenistic or Roman times called the \"Kore Kosmou\" (\u201cVirgin of the World\u201d) ascribed to Hermes Trismegistus (associated with the Egyptian god Thoth), names the four elements fire, water, air, and earth. As described in this book:\nAnd Isis answer made: Of living things, my son, some are made friends with \"fire\", and some with \"water\", some with \"air\", and some with \"earth\", and some with two or three of these, and some with all. And, on the contrary, again some are made enemies of fire, and some of water, some of earth, and some of air, and some of two of them, and some of three, and some of all. For instance, son, the locust and all flies flee fire; the eagle and the hawk and all high-flying birds flee water; fish, air and earth; the snake avoids the open air. Whereas snakes and all creeping things love earth; all swimming things love water; winged things, air, of which they are the citizens; while those that fly still higher love the fire and have the habitat near it. Not that some of the animals as well do not love fire; for instance salamanders, for they even have their homes in it. It is because one or another of the elements doth form their bodies\u2019 outer envelope. Each soul, accordingly, while it is in its body is weighted and constricted by these four.\nAccording to Galen, these elements were used by Hippocrates in describing the human body with an association with the four humours: yellow bile (fire), black bile (earth), blood (air), and phlegm (water). Medical care was primarily about helping the patient stay in or return to his/her own personal natural balanced state.\nThe Neoplatonic philosopher Proclus rejected Aristotle's theory relating the elements to the sensible qualities hot, cold, wet, and dry. He maintained that each of the elements has three properties. Fire is sharp, subtle, and mobile while its opposite, earth, is blunt, dense, and immobile; they are joined by the intermediate elements, air and water, in the following fashion:\nTibet.\nIn B\u00f6n or ancient Tibetan philosophy, the five elemental processes of earth, water, fire, air and space are the essential materials of all existent phenomena or aggregates. The elemental processes form the basis of the calendar, astrology, medicine, psychology and are the foundation of the spiritual traditions of shamanism, tantra and Dzogchen.\nTenzin Wangyal Rinpoche states that\nThe names of the elements are analogous to categorised experiential sensations of the natural world. The names are symbolic and key to their inherent qualities and/or modes of action by analogy. In B\u00f6n the elemental processes are fundamental metaphors for working with external, internal and secret energetic forces. All five elemental processes in their essential purity are inherent in the mindstream and link the trikaya and are aspects of primordial energy. As Herbert V. G\u00fcnther states:\nIn the above block quote the trikaya is encoded as: \"dharmakaya\" \u201cgod\u201d; \"sambhogakaya\" \u201ctemple\u201d and \"nirmanakaya\" \u201chouse\u201d.\nPost-classical history.\nAlchemy.\nThe elemental system used in Medieval alchemy was developed primarily by the Arab alchemist J\u0101bir ibn Hayy\u0101n (Geber). His system consisted of the four classical elements of air, earth, fire, and water, in addition to two philosophical elements: sulphur, characterizing the principle of combustibility, \"the stone which burns\"; and mercury, characterizing the principle of metallic properties. They were seen by early alchemists as idealized expressions of irreducible components of the universe and are of larger consideration within philosophical alchemy.\nThe three metallic principles\u2014sulphur to flammability or combustion, mercury to volatility and stability, and salt to solidity\u2014became the \"tria prima\" of the Swiss alchemist Paracelsus. He reasoned that Aristotle's four element theory appeared in bodies as three principles. Paracelsus saw these principles as fundamental and justified them by recourse to the description of how wood burns in fire. Mercury included the cohesive principle, so that when it left in smoke the wood fell apart. Smoke described the volatility (the mercurial principle), the heat-giving flames described flammability (sulphur), and the remnant ash described solidity (salt).\nIslamic.\nThe Islamic philosophers al-Kindi, Avicenna and Fakhr al-Din al-Razi connected the four elements with the four natures heat and cold (the active force), and dryness and moisture (the recipients).\nThe classical elements were also used by some Ismaili thinkers as symbols and metaphors hinting at deeper realities. For instance, Nasir Khusraw, an 11th century Isma\u2019ili luminary,\u00a0argued that similar to how the human body is sustained by the four elements, the human soul is nourished by four spiritual dignitaries: the Universal Intellect, the Universal Soul, the enunciator of divine revelation (\"n\u0101\u1e6diq\") and the foundation of esoteric interpretation (\"as\u0101s\"). He notes that two elements, air and fire, are subtle, while the other two, earth and water, are dense. Similarly, Hakim Nasir describes two dignitaries, the Universal Intellect and Universal Soul, as spiritual archangels, while the other two, the enunciator of divine revelation and foundation of spiritual interpretation, as physical and human in nature.\nJapan.\nJapanese traditions use a set of elements called the (\"godai\", literally \"five great\"). These five are earth, water, fire, wind/air, and void. These came from Indian Vastu shastra philosophy and Buddhist beliefs; in addition, the classical Chinese elements (, \"wu xing\") are also prominent in Japanese culture, especially to the influential Neo-Confucianists during the medieval Edo period.\nModern history.\nChemical element.\nThe Aristotelian tradition and medieval alchemy eventually gave rise to modern chemistry, scientific theories and new taxonomies. By the time of Antoine Lavoisier, for example, a list of elements would no longer refer to classical elements. Some modern scientists see a parallel between the classical elements and the four states of matter: solid, liquid, gas and weakly ionized plasma.\nModern science recognizes classes of elementary particles which have no substructure (or rather, particles that are not made of other particles) and composite particles having substructure (particles made of other particles).\nWestern astrology.\nWestern astrology uses the four classical elements in connection with astrological charts and horoscopes. The twelve signs of the zodiac are divided into the four elements: Fire signs are Aries, Leo and Sagittarius, Earth signs are Taurus, Virgo and Capricorn, Air signs are Gemini, Libra and Aquarius, and Water signs are Cancer, Scorpio, and Pisces.\nCriticism.\nThe Dutch historian of science Eduard Jan Dijksterhuis writes that the theory of the classical elements \"was bound to exercise a really harmful influence. As is now clear, Aristotle, by adopting this theory as the basis of his interpretation of nature and by never losing faith in it, took a course which promised few opportunities and many dangers for science.\" Bertrand Russell says that Aristotle's thinking became imbued with almost biblical authority in later centuries. So much so that \"Ever since the beginning of the seventeenth century, almost every serious intellectual advance has had to begin with an attack on some Aristotelian doctrine\"."}
{"id": "6314", "revid": "39923979", "url": "https://en.wikipedia.org/wiki?curid=6314", "title": "Fire (classical element)", "text": "Fire is one of the four classical elements along with earth, water and air in ancient Greek philosophy and science. Fire is considered to be both hot and dry and, according to Plato, is associated with the tetrahedron.\nGreek and Roman tradition.\nFire is one of the four classical elements in ancient Greek philosophy and science. It was commonly associated with the qualities of energy, assertiveness, and passion. In one Greek myth, Prometheus stole \"fire\" from the gods to protect the otherwise helpless humans, but was punished for this charity.\nFire was one of many \"archai\" proposed by the Pre-socratics, most of whom sought to reduce the cosmos, or its creation, to a single substance. Heraclitus considered \"fire\" to be the most fundamental of all elements. He believed fire gave rise to the other three elements: \"All things are an interchange for fire, and fire for all things, just like goods for gold and gold for goods.\" He had a reputation for obscure philosophical principles and for speaking in riddles. He described how fire gave rise to the other elements as the: \"upward-downward path\", (), a \"hidden harmony\"\u2009 or series of transformations he called the \"turnings of fire\", (), first into \"sea\", and half that \"sea\" into \"earth\", and half that \"earth\" into rarefied \"air\". This is a concept that anticipates both the four classical elements of Empedocles and Aristotle's transmutation of the four elements into one another.\nThis world, which is the same for all, no one of gods or men has made. But it always was and will be: an ever-living fire, with measures of it kindling, and measures going out. \nHeraclitus regarded the soul as being a mixture of fire and water, with fire being the more noble part and water the ignoble aspect. He believed the goal of the soul is to be rid of water and become pure fire: the dry soul is the best and it is worldly pleasures that make the soul \"moist\". He was known as the \"weeping philosopher\" and died of hydropsy, a swelling due to abnormal accumulation of fluid beneath the skin.\nHowever, Empedocles of Acragas , is best known for having selected all elements as his \"archai\" and by the time of Plato , the four Empedoclian elements were well established. In the \"Timaeus\", Plato's major cosmological dialogue, the Platonic solid he associated with fire was the tetrahedron which is formed from four triangles and contains the least volume with the greatest surface area. This also makes fire the element with the smallest number of sides, and Plato regarded it as appropriate for the heat of fire, which he felt is sharp and stabbing, (like one of the points of a tetrahedron).\nPlato's student Aristotle did not maintain his former teacher's geometric view of the elements, but rather preferred a somewhat more naturalistic explanation for the elements based on their traditional qualities. Fire the hot and dry element, like the other elements, was an abstract principle and not identical with the normal solids, liquids and combustion phenomena we experience:\n What we commonly call fire. It is not really fire, for fire is an excess of heat and a sort of ebullition; but in reality, of what we call air, the part surrounding the earth is moist and warm, because it contains both vapour and a dry exhalation from the earth.\nAccording to Aristotle, the four elements rise or fall toward their natural place in concentric layers surrounding the center of the earth and form the terrestrial or sublunary spheres.\nIn ancient Greek medicine, each of the four humours became associated with an element. Yellow bile was the humor identified with fire, since both were hot and dry. Other things associated with fire and yellow bile in ancient and medieval medicine included the season of summer, since it increased the qualities of heat and aridity; the choleric temperament (of a person dominated by the yellow bile humour); the masculine; and the eastern point of the compass.\nIn alchemy the chemical element of sulfur was often associated with fire and its alchemical symbol and its symbol was an upward-pointing triangle. In alchemic tradition, metals are incubated by fire in the womb of the Earth and alchemists only accelerate their development.\nIndian tradition.\nAgni is a Hindu and Vedic deity. The word \"agni\" is Sanskrit for fire (noun), cognate with Latin \"ignis\" (the root of English \"ignite\"), Russian \"\u043e\u0433\u043e\u043d\u044c\" (fire), pronounced \"agon\". Agni has three forms: fire, lightning and the sun.\nAgni is one of the most important of the Vedic gods. He is the god of fire and the acceptor of sacrifices. The sacrifices made to Agni go to the deities because Agni is a messenger from and to the other gods. He is ever-young, because the fire is re-lit every day, yet he is also immortal. In Indian tradition Fire is also linked to Surya or the Sun and Mangala or Mars, and with the south-east direction.\nCeremonial magic.\nFire and the other Greek classical elements were incorporated into the Golden Dawn system. Philosophus (4=7) is the elemental grade attributed to fire; this grade is also attributed to the Qabalistic Sephirah Netzach and the planet Venus. The elemental weapon of fire is the Wand. Each of the elements has several associated spiritual beings. The archangel of fire is Michael, the angel is Aral, the ruler is Seraph, the king is Djin, and the fire elementals (following Paracelsus) are called salamanders. Fire is considered to be active; it is represented by the symbol for Leo and it is referred to the lower right point of the pentacle in the Supreme Invoking Ritual of the Pentacle. Many of these associations have since spread throughout the occult community.\nTarot.\nFire in Tarot symbolizes conversion or passion. Many references to fire in tarot are related to the usage of fire in the practice of alchemy, in which the application of fire is a prime method of conversion, and everything that touches fire is changed, often beyond recognition. The symbol of fire was a cue pointing towards transformation, the chemical variant being the symbol delta, which is also the classical symbol for fire. Conversion symbolized can be good, for example, refining raw crudities to gold, as seen in The Devil. Conversion can also be bad, as in The Tower, symbolizing a downfall due to anger. Fire is associated with the suit of rods/wands, and as such, represents passion from inspiration. As an element, fire has mixed symbolism because it represents energy, which can be helpful when controlled, but volatile if left unchecked.\nModern witchcraft.\nFire is one of the five elements that appear in most Wiccan traditions influenced by the Golden Dawn system of magic, and Aleister Crowley's mysticism, which was in turn inspired by the Golden Dawn.\nFreemasonry.\nIn freemasonry, fire is present, for example, during the ceremony of winter solstice, a symbol also of renaissance and energy. Freemasonry takes the ancient symbolic meaning of fire and recognizes its double nature: creation, light, on the one hand, and destruction and purification, on the other."}
{"id": "6315", "revid": "39923979", "url": "https://en.wikipedia.org/wiki?curid=6315", "title": "Air (classical element)", "text": "Air is one of the four classical elements along with water, earth and fire in ancient Greek philosophy and in Western alchemy.\nGreek and Roman tradition.\nAccording to Plato, it is associated with the octahedron; air is considered to be both hot and wet. The ancient Greeks used two words for air: \"aer\" meant the dim lower atmosphere, and \"aether\" meant the bright upper atmosphere above the clouds. Plato, for instance writes that \"So it is with air: there is the brightest variety which we call \"aether\", the muddiest which we call mist and darkness, and other kinds for which we have no name...\" Among the early Greek Pre-Socratic philosophers, Anaximenes (mid-6th century BCE) named air as the \"arche\". A similar belief was attributed by some ancient sources to Diogenes Apolloniates (late 5th century BCE), who also linked air with intelligence and soul (\"psyche\"), but other sources claim that his \"arche\" was a substance between air and fire. Aristophanes parodied such teachings in his play \"The Clouds\" by putting a prayer to air in the mouth of Socrates.\nAir was one of many \"archai\" proposed by the Pre-socratics, most of whom tried to reduce all things to a single substance. However, Empedocles of Acragas (c. 495-c. 435 BCE) selected four \"archai\" for his four roots: Air, fire, water, and earth. Ancient and modern opinions differ as to whether he identified air by the divine name Hera, Aidoneus or even Zeus. Empedocles\u2019 roots became the four classical elements of Greek philosophy. Plato (427\u2013347 BCE) took over the four elements of Empedocles. In the \"Timaeus\", his major cosmological dialogue, the Platonic solid associated with air is the octahedron which is formed from eight equilateral triangles. This places air between fire and water which Plato regarded as appropriate because it is intermediate in its mobility, sharpness, and ability to penetrate. He also said of air that its minuscule components are so smooth that one can barely feel them.\nPlato's student Aristotle (384\u2013322 BCE) developed a different explanation for the elements based on pairs of qualities. The four elements were arranged concentrically around the center of the universe to form the sublunary sphere. According to Aristotle, air is both hot and wet and occupies a place between fire and water among the elemental spheres. Aristotle definitively separated air from aether. For him, aether was an unchanging, almost divine substance that was found only in the heavens, where it formed celestial spheres.\nHumorism and temperaments.\nIn ancient Greek medicine, each of the four humours became associated with an element. Blood was the humor identified with air, since both were hot and wet. Other things associated with air and blood in ancient and medieval medicine included the season of spring, since it increased the qualities of heat and moisture; the sanguine temperament (of a person dominated by the blood humour); hermaphrodite (combining the masculine quality of heat with the feminine quality of moisture); and the northern point of the compass.\nAlchemy.\nThe alchemical symbol for air is an upward-pointing triangle, bisected by a horizontal line.\nModern reception.\nThe Hermetic Order of the Golden Dawn, founded in 1888, incorporates air and the other Greek classical elements into its teachings. The elemental weapon of air is the dagger which must be painted yellow with magical names and sigils written upon it in violet. Each of the elements has several associated spiritual beings. The archangel of air is Raphael, the angel is Chassan, the ruler is Aral, the king is Paralda, and the air elementals (following Paracelsus) are called sylphs. Air is considerable and it is referred to the upper left point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\nIn the Golden Dawn and many other magical systems, each element is associated with one of the cardinal points and is placed under the care of guardian Watchtowers. The Watchtowers derive from the Enochian system of magic founded by Dee. In the Golden Dawn, they are represented by the Enochian elemental tablets. Air is associated with the east, which is guarded by the First Watchtower.\nAir is one of the five elements that appear in most Wiccan and Pagan traditions. Wicca in particular was influenced by the Golden Dawn system of magic and Aleister Crowley's mysticism.\nParallels in non-Western traditions.\nAir is not one of the traditional five Chinese classical elements. Nevertheless, the ancient Chinese concept of \"Qi\" or \"chi\" is believed to be close to that of air. \"Qi\" is believed to be part of every living thing that exists, as a kind of \"life force\" or \"spiritual energy\". It is frequently translated as \"energy flow\", or literally as \"air\" or \"breath\". (For example, \"ti\u0101nq\u00ec\", literally \"sky breath\", is the Chinese word for \"weather\"). The concept of qi is often reified, however no scientific evidence supports its existence.\nThe element air also appears as a concept in the Buddhist philosophy which has an ancient history in China.\nSome Western modern occultists equate the Chinese classical element of metal with \"air\", others with wood due to the elemental association of wind and wood in the bagua.\nEnlil was the god of air in ancient Sumer. Shu was the ancient Egyptian deity of air and the husband of Tefnut, goddess of moisture. He became an emblem of strength by virtue of his role in separating Nut from Geb. Shu played a primary role in the Coffin Texts, which were spells intended to help the deceased reach the realm of the afterlife safely. On the way to the sky, the spirit had to travel through the air as one spell indicates: \"I have gone up in Shu, I have climbed on the sunbeams.\""}
{"id": "6316", "revid": "39923979", "url": "https://en.wikipedia.org/wiki?curid=6316", "title": "Water (classical element)", "text": "Water is one of the classical elements in ancient Greek philosophy, in the Asian Indian system \"Panchamahabhuta\", and in the Chinese cosmological and physiological system \"Wu Xing\". In contemporary esoteric traditions, it is commonly associated with the qualities of emotion and intuition.\nGreek and Roman tradition.\nWater was one of many \"archai\" proposed by the Pre-socratics, most of whom tried to reduce all things to a single substance. However, Empedocles of Acragas (c. 495 \u2013 c. 435 BC) selected four archai for his four roots: air, fire, water and earth. Empedocles roots became the four classical elements of Greek philosophy. Plato (427\u2013347 BC) took over the four elements of Empedocles. In the Timaeus, his major cosmological dialogue, the Platonic solid associated with water is the icosahedron which is formed from twenty equilateral triangles. This makes water the element with the greatest number of sides, which Plato regarded as appropriate because water flows out of one's hand when picked up, as if it is made of tiny little balls.\nPlato's student Aristotle (384\u2013322 BC) developed a different explanation for the elements based on pairs of qualities. The four elements were arranged concentrically around the center of the Universe to form the sublunary sphere. According to Aristotle, water is both cold and wet and occupies a place between air and earth among the elemental spheres.\nIn ancient Greek medicine, each of the four humours became associated with an element. Phlegm was the humor identified with water, since both were cold and wet. Other things associated with water and phlegm in ancient and medieval medicine included the season of Winter, since it increased the qualities of cold and moisture, the phlegmatic temperament, the feminine and the western point of the compass.\nIn alchemy, the chemical element of mercury was often associated with water and its alchemical symbol was a downward-pointing triangle.\nIndian tradition.\nAp (') is the Vedic Sanskrit term for water, in Classical Sanskrit occurring only in the plural is not an element.v, ' (sometimes re-analysed as a thematic singular, '), whence Hindi '. The term is from PIE \"hxap\" water.\nIn Hindu philosophy, the term refers to \nwater as an element, one of the \"Panchamahabhuta,\" or \"five great elements\". In Hinduism, it is also the name of the deva, a personification of water, (one of the Vasus in most later Puranic lists). The element water is also associated with Chandra or the moon and Shukra, who represent feelings, intuition and imagination.\nCeremonial magic.\nWater and the other Greek classical elements were incorporated into the Golden Dawn system. The elemental weapon of water is the cup. Each of the elements has several associated spiritual beings. The archangel of water is Gabriel, the angel is Taliahad, the ruler is Tharsis, the king is Nichsa and the water elementals are called Ondines. It is referred to the upper right point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\nModern witchcraft.\nWater is one of the five elements that appear in most Wiccan traditions. Wicca in particular was influenced by the Golden Dawn system of magic and Aleister Crowley's mysticism, which was in turn inspired by the Golden Dawn."}
{"id": "6317", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=6317", "title": "Earth (classical element)", "text": "Earth is one of the classical elements, in some systems being one of the four along with air, fire, and water.\nEuropean tradition.\nEarth is one of the four classical elements in ancient Greek philosophy and science. It was commonly associated with qualities of heaviness, matter and the terrestrial world. Due to the hero cults, and chthonic underworld deities, the element of \"earth\" is also associated with the sensual aspects of both life and death in later occultism.\nEmpedocles of Acragas proposed four \"archai\" by which to understand the cosmos: \"fire\",\" air\", \"water\", and \"earth\". Plato believed the elements were geometric forms (the platonic solids) and he assigned the cube to the element of \"earth\" in his dialogue \"Timaeus\". Aristotle (384\u2013322 BCE) believed \"earth\" was the heaviest element, and his theory of \"natural place\" suggested that any \"earth\u2013laden\" substances, would fall quickly, straight down, towards the center of the \"cosmos\".\nIn Classical Greek and Roman myth, various goddesses \nrepresented the Earth, seasons, crops and fertility, including Demeter and Persephone; Ceres; the Horae (goddesses of the seasons), and Proserpina; and Hades (Pluto) who ruled the souls of dead in the Underworld.\nIn ancient Greek medicine, each of the four humours became associated with an element. Black bile was the humor identified with earth, since both were cold and dry. Other things associated with earth and black bile in ancient and medieval medicine included the season of fall, since it increased the qualities of cold and aridity; the melancholic temperament (of a person dominated by the black bile humour); the feminine; and the southern point of the compass.\nIn alchemy, earth was believed to be primarily dry, and secondarily cold, (as per Aristotle). Beyond those classical attributes, the chemical substance salt, was associated with earth and its alchemical symbol was a downward-pointing triangle, bisected by a horizontal line.\nIndian tradition.\nPrithvi (Sanskrit: ', also ') is the Hindu \"earth\" and mother goddess. According to one such tradition, she is the personification of the Earth itself; according to another, its actual mother, being \"Prithvi Tattwa\", the essence of the element earth.\nAs \"Prithvi Mata\", or \"Mother Earth\", she contrasts with \"Dyaus Pita\", \"father sky\". In the Rigveda, \"earth\" and sky are frequently addressed as a duality, often indicated by the idea of two complementary \"half-shells.\" In addition, the element Earth is associated with Budha or Mercury who represents communication, business, mathematics and other practical matters.\nCeremonial magic.\nEarth and the other Greek classical elements were incorporated into the Golden Dawn system. Zelator is the elemental grade attributed to earth; this grade is also attributed to the Qabbalistic sphere Malkuth. The elemental weapon of earth is the Pentacle. Each of the elements has several associated spiritual beings. The archangel of earth is Uriel, the angel is Phorlakh, the ruler is Kerub, the king is Ghob, and the earth elementals (following Paracelsus) are called gnomes. Earth is considered to be passive; it is represented by the symbol for Taurus, and it is referred to the lower left point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\nIt is sometimes represented by its Tattva or by a downward pointing triangle with a horizontal line through it.\nModern witchcraft.\nEarth is one of the five elements that appear in most Wiccan and Pagan traditions. Wicca in particular was influenced by the Golden Dawn system of magic, and Aleister Crowley's mysticism which was in turn inspired by the Golden Dawn.\nOther traditions.\n\"Earth\" is represented in the Aztec religion by a house; to the Hindus, a lotus; to the Scythians, a plough; to the Greeks, a wheel; and in Christian iconography; bulls and birds."}
{"id": "6319", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6319", "title": "Blue Jam", "text": "Blue Jam was an ambient, surreal dark comedy and horror radio programme created and directed by Chris Morris. It was broadcast on BBC Radio 1 in the early hours of the morning, for three series from 1997 to 1999.\nThe programme gained cult status due to its unique mix of surreal monologue, ambient soundtrack, synthesised voices, heavily edited broadcasts and recurring sketches. It featured vocal performances of Kevin Eldon, Julia Davis, Mark Heap, David Cann and Amelia Bullmore, with Morris himself delivering disturbing monologues, one of which was revamped and made into the BAFTA-winning short film \"My Wrongs #8245\u20138249 &amp; 117\". Writers who contributed to the programme included Graham Linehan, Arthur Mathews, Peter Baynham, David Quantick, Jane Bussmann, Robert Katz and the cast.\nThe programme was adapted into the TV series \"Jam\", which aired in 2000. All episodes of \"Blue Jam\" are currently available for streaming and download on the Internet Archive.\nProduction.\nOn his inspiration for making the show, Morris commented: \"It was so singular, and it came from a mood, quite a desolate mood. I had this misty, autumnal, boggy mood anyway, so I just went with that. But no doubt getting to the end of something like Brass Eye, where you've been forced to be a sort of surrogate lawyer, well, that's the most creatively stifling thing you could possibly do.\" Morris also described the show as being \"like the nightmares you have when you fall asleep listening to the BBC World Service\" (a reference to the World Service also appears in one of the monologues read by Morris).\nMorris originally requested that the show be broadcast at 3 a.m. on Radio 1 \"because at that hour, on insomniac radio, the amplitude of terrible things is enormously overblown\". As a compromise, the show was broadcast at midnight without much promotion. Morris reportedly included sketches too graphic or transgressive for radio that he knew would be cut so as to make his other material seem less transgressive in comparison. During the airing of episode 6 of series one, a re-editing of the Archbishop of Canterbury's speech at Princess Diana's funeral was deemed too offensive for broadcast, and was switched with a different episode as it aired.\nFormat and style.\nEach episode opened (and closed) with a short spoken monologue (delivered by Morris) describing, in surreal, broken language, various bizarre feelings and situations (for example: \"when you sick so sad you cry, and in crying cry a whole leopard from your eye\"), set to ambient music interspersed with short clips of other songs and sounds. The introduction would always end with \"welcome in Blue Jam\", inviting the listener, who is presumably experiencing such feelings, to get lost in the program. (This format was replicated in the television adaptation \"Jam\", often reusing opening monologues from series 3 of the radio series.) The sketches within dealt with heavy and taboo topics, such as murder, suicide, missing or dead children, and rape.\nCommon recurring sketches.\nThe sketches not listed are often in the style of a documentary; characters speak as if being interviewed about a recent event. In one sketch, a character voiced by Morris describes a man attempting to commit suicide by jumping off a second-story balcony repeatedly; in another, an angry man (Eldon) shouts about how his car, after being picked up from the garage, is only four feet long.\nRadio stings.\nMorris included a series of 'radio stings', bizarre sequences of sounds and prose as a parody of modern DJs' own soundbites and self-advertising pieces. Each one revolves around a contemporary DJ, such as Chris Moyles, Jo Whiley and Mark Goodier, typically involving each DJ dying in a graphic way or going mad in some form \u2013 for example, Chris Moyles covering himself in jam and hanging himself from the top of a building.\nEpisodes.\nThree series were produced, with a total of eighteen episodes. All episodes were originally broadcast weekly on BBC Radio 1. Series 1 was broadcast from 14 November to 19 December 1997; series 2 was broadcast from 27 March to 1 May 1998; and series 3 broadcast from 21 January to 25 February 1999.\nThe first five episodes of series 1 of \"Blue Jam\" were repeated by BBC Radio 4 Extra in February and March 2014, and series 2 was rebroadcast in December.\nMusic.\n\"Blue Jam\" features songs, generally of a downtempo nature, interspersed between (and sometimes during) sketches. Artists featured includes Massive Attack, Air, Morcheeba, The Chemical Brothers, Bj\u00f6rk, Aphex Twin, Everything But the Girl and Dimitri from Paris, as well as various non-electronic artists including Sly and the Family Stone, Serge Gainsbourg, The Cardigans and Eels.\nReception.\n\"Blue Jam\" was favourably reviewed on several occasions by \"The Guardian\" and also received a positive review by \"The Independent\".\nDigital Spy wrote in 2014: \"It's a heady cocktail that provokes an odd, unsettling reaction in the listener, yet \"Blue Jam\" is still thumpingly and frequently laugh-out-loud hilarious.\" \"Hot Press\" called it \"as odd as comedy gets\".\nCD release.\nA CD of a number of \"Blue Jam\" sketches was released on 23 October 2000 by record label Warp. Although the CD claims to have 22 tracks, the last one, \"www.bishopslips.com\", is not a track, but rather a reference to the \"Bishopslips\" sketch, which was cut in the middle of a broadcast. Most of the sketches on the CD were remade for \"Jam\".\nRelated shows.\n\"Blue Jam\" was later made for television and broadcast on Channel 4 as \"Jam\". It used unusual editing techniques to achieve an unnerving ambience in keeping with the radio show. Many of the sketches were lifted from the radio version, even to the extent of simply setting images to the radio soundtrack. A subsequent \"re-mixed\" airing, called \"Jaaaaam\" was even more extreme in its use of post-production gadgetry, often heavily distorting the footage.\n\"Blue Jam\" shares parallels with early editions of a US public radio show \"Joe Frank: Work in Progress\" from the mid-1980s, that Joe Frank did on the NPR affiliate station, KCRW, in Santa Monica, California."}
{"id": "6321", "revid": "1125420", "url": "https://en.wikipedia.org/wiki?curid=6321", "title": "Channel 4", "text": "Channel 4 is a British free-to-air public-service television network with a remit to produce \"high quality and distinctive programming\". Its headquarters are in London, a National HQ in Leeds and creative hubs in Glasgow and Bristol.\nThe channel was established to provide a fourth television service to the United Kingdom in addition to the licence-funded BBC One and BBC Two, and the single commercial broadcasting network ITV.\nIt began transmission on 2 November 1982, the day after Welsh language broadcaster S4C's launch. Although largely commercially self-funded, it is ultimately publicly owned; originally a subsidiary of the Independent Broadcasting Authority (IBA), the station is now owned and operated by Channel Four Television Corporation, a public corporation of the Department for Digital, Culture, Media and Sport, which was established in 1990 and came into operation in 1993. In 2010, Channel 4 extended service into Wales and became a UK-wide television channel.\nHistory.\nConception.\nBefore Channel 4 and S4C, Britain had three terrestrial television services: BBC1, BBC2, and ITV. The Broadcasting Act 1980 began the process of adding a fourth; Channel 4 was formally created, along with its Welsh counterpart, by an Act of Parliament in 1982. After some months of test broadcasts, it began scheduled transmissions on 2 November 1982.\nThe notion of a second commercial broadcaster in the United Kingdom had been around since the inception of ITV in 1954 and its subsequent launch in 1955; the idea of an \"ITV2\" was long expected and pushed for. Indeed, television sets sold throughout the 1970s and early 1980s had a spare tuning button labelled \"ITV/IBA 2\". Throughout ITV's history and until Channel 4 finally became a reality, a perennial dialogue existed between the GPO, the government, the ITV companies and other interested parties, concerning the form such an expansion of commercial broadcasting would take. Most likely, politics had the biggest impact in leading to a delay of almost three decades before the second commercial channel became a reality.\nOne clear benefit of the \"late arrival\" of the channel was that its frequency allocations at each transmitter had already been arranged in the early 1960s, when the launch of an ITV2 was highly anticipated. This led to very good coverage across most of the country and few problems of interference with other UK-based transmissions; a stark contrast to the problems associated with Channel 5's launch almost 15 years later.\"ITV2\" is not to be confused with ITV's digital television channel launched in 1998.\nWales.\nAt the time the fourth service was being considered, a movement in Wales lobbied for the creation of dedicated service that would air Welsh-language programmes, then only catered for at \"off peak\" times on BBC Wales and HTV. The campaign was taken so seriously by Gwynfor Evans, former president of Plaid Cymru, that he threatened the government with a hunger strike were it not to honour the plans.\nThe result was that Channel 4 as seen by the rest of the United Kingdom would be replaced in Wales by Sianel Pedwar Cymru (S4C) (\"Channel Four Wales\"). Operated by a specially created authority, S4C would air programmes in Welsh made by HTV, the BBC and independent companies. Initially limited frequency space meant that Channel 4 could not be broadcast alongside S4C, though some Channel 4 programmes would be aired at less popular times on the Welsh variant; this practice continued until the closure of S4C's analogue transmissions in 2010, at which time S4C became a fully Welsh channel.\nWith this conversion of the Wenvoe transmitter group in Wales to digital terrestrial broadcasting on 31 March 2010, Channel 4 became a UK-wide television channel for the first time.\nSince then, carriage on digital cable, satellite and digital terrestrial has introduced Channel 4 to Welsh homes where it is now universally available.\nLaunch and IBA control.\nThe first voice heard on Channel 4's opening day of Tuesday 2 November 1982 was that of continuity announcer Paul Coia who said:\nFollowing the announcement, the channel headed into a montage of clips from its programmes set to the station's signature tune, \"Fourscore\", written by David Dundas, which would form the basis of the station's jingles for its first decade. The first programme to air on the channel was the teatime game show \"Countdown\", at 16:45 produced by Yorkshire Television. The first person to be seen on Channel 4 was Richard Whiteley with Ted Moult being the second. The first woman on the channel, contrary to popular belief, was not Whiteley's \"Countdown\" co-host Carol Vorderman but a lexicographer only ever identified as Mary. Whiteley opened the show with the words:\nOn its first day, Channel 4 also broadcast soap opera \"Brookside\", which often ran storylines thought to be controversial; this ran until 2003.\nAt its launch, Channel 4 committed itself to providing an alternative to the existing channels, an agenda in part set out by its remit which required the provision of programming to minority groups.\nIn step with its remit, the channel became well received both by minority groups and the arts and cultural worlds during this period, especially under founding chief executive Jeremy Isaacs, where the channel gained a reputation for programmes on the contemporary arts. Channel 4 co-commissioned Robert Ashley's ground-breaking television opera \"Perfect Lives\", which it premiered over several episodes in 1984. The channel often did not receive mass audiences for much of this period, however, as might be expected for a station focusing on minority interest.\nChannel 4 also began the funding of independent films, such as the Merchant Ivory docudrama \"The Courtesans of Bombay\", during this time.\nIn 1992, Channel 4 also faced its first libel case by Jani Allan, a South African journalist, who objected to her representation in Nick Broomfield's documentary \"The Leader, His Driver and the Driver's Wife\".\nIn September 1993, the channel broadcast the direct-to-TV documentary film \"Beyond Citizen Kane\", in which it displayed the dominant position of the Rede Globo television network, and discussed its influence, power and political connections in Brazil.\nChannel Four Television Corporation.\nAfter control of the station passed from the Channel Four Television Company to the Channel Four Television Corporation in 1993, a shift in broadcasting style took place. Instead of aiming for the fringes of society, it began to focus on the edges of the mainstream, and the centre of the mass market itself. It began to show many US programmes in peak viewing time, far more than it had previously done. It gave such shows as \"Friends\" and \"ER\" their UK premi\u00e8res.\nIn the early 2000s, Channel 4 began broadcasting reality formats such as \"Big Brother\" and obtained the rights to broadcast mass appeal sporting events like cricket and horse racing. This new direction increased ratings and revenues.\nIn addition, the corporation launched a number of new television channels through its new 4Ventures offshoot, including Film4, At the Races, E4 and More4.\nPartially in reaction to its new \"populist\" direction, the Communications Act 2003 directed the channel to demonstrate innovation, experimentation and creativity, appeal to the tastes and interests of a culturally diverse society, and to include programmes of an educational nature which exhibit a distinctive character.\nOn 31 December 2004, Channel 4 launched a new look and new idents in which the logo is disguised as different objects and the 4 can be seen in an angle.\nUnder the leadership of Freeview founder Andy Duncan, 2005 saw a change of direction for Channel 4's digital channels. Channel 4 made E4 free-to-air on digital terrestrial television, and launched a new free-to-air digital channel called More4. By October, Channel 4 had joined the Freeview consortium. By July 2006, Film4 had likewise become free-to-air and restarted broadcasting on digital terrestrial.\nVenturing into radio broadcasting, 2005 saw Channel 4 purchase 51% of shares in the now defunct Oneword radio station with UBC Media holding on to the remaining shares. New programmes such as the weekly, half-hour \"The Morning Report\" news programme were among some of the new content Channel 4 provided for the station, with the name 4Radio being used. As of early 2009, however, Channel 4's future involvement in radio remained uncertain.\nOn 2 November 2007, the station celebrated its 25th birthday. It showed the first episode of \"Countdown\", an anniversary \"Countdown\" special, as well as a special edition of \"The Big Fat Quiz\" and using the original multicoloured 1982\u20131996 blocks logo on presentation and idents using the Fourscore jingle throughout the day.\nIn November 2009, Channel 4 launched a week of 3D television, broadcasting selected programmes each night using stereoscopic ColorCode 3D technology. The accompanying 3D glasses were distributed through Sainsbury's supermarkets.\nOn 29 September 2015, Channel 4 revamped its presentation for a fifth time; the new branding downplayed the \"4\" logo from most on-air usage, in favour of using the shapes from the logo in various forms. Four new idents were filmed by Jonathan Glazer, which featured the shapes in various real-world scenes depicting the \"discovery\" and \"origins\" of the shapes. The full logo was still occasionally used, but primarily for off-air marketing. Channel 4 also commissioned two new corporate typefaces, \"Chadwick\", and \"Horseferry\" (a variation of Chadwick with the aforementioned shapes incorporated into its letter forms), for use across promotional material and on-air. \nOn 31 October 2017, Channel 4 introduced a new series of idents continuing the theme, this time depicting the logo shapes as having formed an anthropomorphic \"giant\" character.\nRecent history.\nBefore the digital switch-over, Channel 4 raised concerns over how it might finance its public service obligations afterward. It was announced in April 2006 that Channel 4's digital switch-over costs would be paid for by licence fee revenues.\nOn 28 March 2007, Channel 4 announced plans to launch a music channel \"4Music\" as a joint venture with British media company EMAP, which would include carriage on the Freeview platform. On 15 August 2008, 4Music was launched across the UK. Channel 4 announced interest in launching a high-definition version of Film4 on Freeview, to coincide with the launch of Channel 4 HD, However, the fourth HD slot was given to Channel 5 instead. Channel 4 has since acquired a 50% stake in EMAP's TV business for a reported \u00a328\u00a0million.\nChannel 4 was considered for privatisation by the governments of Margaret Thatcher, John Major and Tony Blair. the future of the channel was again being looked into by the government, with analysts suggesting several options for the channel's future.\nIn June 2017, it was announced that Alex Mahon would be the next chief executive, and would take over from David Abraham, who left in November 2017.\nPublic service remit.\nChannel 4 was established with, and continues to hold, a remit of public service obligations which it must fulfil. The remit changes periodically, as dictated by various broadcasting and communications acts, and is regulated by the various authorities Channel 4 has been answerable to; originally the IBA, then the ITC and now Ofcom.\nThe preamble of the remit as per the Communications Act 2003 states that:\nThe remit also involves an obligation to provide programming for schools, and a substantial amount of programming produced outside of Greater London.\nCarriage.\nChannel 4 was carried from its beginning on analogue terrestrial, which was practically the only means of television broadcast in the United Kingdom at the time. It continued to be broadcast through these means until the changeover to digital terrestrial television in the United Kingdom was complete. Since 1998, it has been universally available on digital terrestrial, and the Sky platform (initially encrypted, though encryption was dropped on 14 April 2008 and is now free of charge and available on the Freesat platform) as well as having been available from various times in various areas, on analogue and digital cable networks.\nDue to its special status as a public service broadcaster with a specific remit, it is afforded free carriage on the terrestrial platforms, in contrast with other broadcasters such as ITV.\nChannel 4 is also seen outside the United Kingdom where it is widely available in Ireland, especially in border counties which have been able to receive terrestrial transmissions from Northern Ireland as well as on Irish cable networks, and Switzerland.\nSince 2019, it has been offered by British Forces Broadcasting Service (BFBS) to members of HM Forces and their families around the world, BFBS Extra having previously carried a selection of Channel 4 programmes.\nThe Channel 4 website allows Internet users in the United Kingdom to watch Channel 4 live on the Internet. In the past some programmes (mostly international imports) were not shown. Channel 4 is also provided by Virgin Mobile's DAB mobile TV service which has the same restrictions as the Internet live stream had. Channel 4 is also carried by the Internet TV service TVCatchup and was previously carried by Zattoo until the operator removed the channel from its platform.\nChannel 4 also makes some of its programming available \"on demand\" via cable and the Internet through All 4.\nFunding.\nDuring the station's formative years, funding came from the ITV companies in return for their right to sell advertisements in their region on the fourth channel.\nNowadays it pays for itself in much the same way as most privately run commercial stations, i.e. through the sale of on-air advertising, programme sponsorship, and the sale of any programme content and merchandising rights it owns, such as overseas sales and video sales. For example, its total revenues were \u00a3925\u00a0million with 91% derived from sale of advertising. It also has the ability to subsidise the main network through any profits made on the corporation's other endeavours, which have in the past included subscription fees from stations such as E4 and Film4 (now no longer subscription services) and its \"video-on-demand\" sales. In practice, however, these other activities are loss-making, and are subsidised by the main network. According to Channel 4's last published accounts, for 2005, the extent of this cross-subsidy was some \u00a330\u00a0million.\nThe change in funding came about under the Broadcasting Act 1990 when the new corporation was afforded the ability to fund itself. Originally this arrangement left a \"safety net\" guaranteed minimum income should the revenue fall too low, funded by large insurance payments made to the ITV companies. Such a subsidy was never required, however, and these premiums were phased out by the government in 1998. After the link with ITV was cut, the cross-promotion which had existed between ITV and Channel 4 also ended.\nIn 2007, owing to severe funding difficulties, the channel sought government help and was granted a payment of \u00a314\u00a0million over a six-year period. The money was to have come from the television licence fee, and would have been the first time that money from the licence fee had been given to any broadcaster other than the BBC. However, the plan was scrapped by the Secretary of State for Culture, Media and Sport, Andy Burnham, ahead of \"broader decisions about the future framework of public service broadcasting\". The broadcasting regulator Ofcom released its review in January 2009 in which it suggested that Channel 4 would preferably be funded by \"partnerships, joint ventures or mergers\".\nProgramming.\nChannel 4 is a \"publisher-broadcaster\", meaning that it commissions or \"buys\" all of its programming from companies independent of itself. It was the first broadcaster in the United Kingdom to do so on any significant scale; such commissioning is a stipulation which is included in its licence to broadcast. This had the consequence of starting an industry of production companies that did not have to rely on owning an ITV licence to see their programmes air, though since Channel 4, external commissioning has become regular practice on the numerous stations that have launched since, as well as on the BBC and in ITV (where a quota of 25% minimum of total output has been imposed since the Broadcasting Act 1990 came into force). Although it was the first British broadcaster to commission all of its programmes from third parties, Channel 4 was the last terrestrial broadcaster to outsource its transmission and playout operations (to Red Bee Media), after 25 years in-house.\nThe requirement to obtain all content externally is stipulated in its licence. Additionally, Channel 4 also began a trend of owning the copyright and distribution rights of the programmes it aired, in a manner that is similar to the major Hollywood studios' ownership of television programmes that they did not directly produce. Thus, although Channel 4 does not produce programmes, many are seen as belonging to it.\nIt was established with a specific intention of providing programming to groups of minority interests, not catered for by its competitors, which at the time were only the BBC and ITV.\nChannel 4 also pioneered the concept of 'stranded programming', where seasons of programmes following a common theme would be aired and promoted together. Some would be very specific, and run for a fixed period of time; the \"4 Mation\" season, for example, showed innovative animation. Other, less specific strands, were (and still are) run regularly, such as \"T4\", a strand of programming aimed at teenagers, on weekend mornings (and weekdays during school/college holidays); \"Friday Night Comedy\", a slot where the channel would pioneer its style of comedy commissions, \"4Music\" (now a separate channel) and \"4Later\", an eclectic collection of offbeat programmes transmitted in the early hours of the morning.\nIn its earlier years, certain risqu\u00e9 art-house films (dubbed by many of Channel 4's critics as being pornographic) would be screened with a \"red triangle\" digital on-screen graphic in the upper right of the screen. Other films were broadcast under the \"Film on Four\" banner, before the \"FilmFour\" brand was launched in the late 1990s.\nMost watched programmes.\nThe following is a list of the 10 most watched shows on Channel 4 since launch, based on Live +28 data supplied by BARB, and archival data published by Channel 4.\nComedy.\nDuring the station's early days, the screenings of innovative short one-off comedy films produced by a rotating line-up of alternative comedians went under the title of \"The Comic Strip Presents\". \"The Tube\" and \"Saturday Live/Friday Night Live\" also launched the careers of a number of comedians and writers. Channel 4 broadcast a number of popular American imports, including \"Roseanne\", \"Friends\", \"Sex and the City\", \"South Park\" and \"Will &amp; Grace\". Other significant US acquisitions include \"The Simpsons\", for which the station was reported to have paid \u00a3700,000 per episode for the terrestrial television rights.\nIn April 2010, Channel 4 became the first UK broadcaster to adapt the American comedy institution of roasting to British television, with \"A Comedy Roast\".\nIn 2010, Channel 4 organised \"Channel 4's Comedy Gala\", a comedy benefit show in aid of Great Ormond Street Children's Hospital. With over 25 comedians appearing, it billed it as \"the biggest live stand up show in United Kingdom history\". Filmed live on 30 March in front of 14,000 at The O2 Arena in London, it was broadcast on 5 April. This has continued to 2016.\nFactual and current affairs.\nChannel 4 has a strong reputation for history programmes and real-life documentaries. It has also courted controversy, for example by broadcasting live the first public autopsy in the UK for 170 years, carried out by Gunther von Hagens in 2002, or the 2003 one-off stunt \"Derren Brown Plays Russian Roulette Live\".\nIts news service, \"Channel 4 News\", is supplied by ITN whilst its long-standing investigative documentary series, \"Dispatches\", attracts perennial media attention.\nFourDocs.\nFourDocs is an online documentary site provided by Channel 4. It allows viewers to upload their own documentaries to the site for others to view. It focuses on documentaries of between 3 and 5\u00a0minutes. The website also includes an archive of classic documentaries, interviews with documentary filmmakers and short educational guides to documentary-making. It won a Peabody Award in 2006. The site also includes a strand for documentaries of under 59 seconds, called \"Microdocs\".\nSchools programming.\nChannel 4 is obliged to carry schools programming as part of its remit and licence.\nITV Schools on Channel 4.\nSince 1957 ITV had produced schools programming, which became an obligation. In 1987, five years after the station was launched, the IBA afforded ITV free carriage of these programmes during Channel 4's then-unused weekday morning hours. This arrangement allowed the ITV companies to fulfil their obligation to provide schools programming, whilst allowing ITV itself to broadcast regular programmes complete with advertisements. During the times in which schools programmes were aired Central Television provided most of the continuity with play-out originating from Birmingham.\nChannel 4 Schools/4Learning.\nAfter the restructuring of the station in 1993, ITV's obligations to provide such programming on Channel 4's airtime passed to Channel 4 itself, and the new service became Channel 4 Schools, with the new corporation administering the service and commissioning its programmes, some still from ITV, others from independent producers.\nIn March 2008, the 4Learning interactive new media commission slabovia.tv was launched. The Slabplayer online media player showing TV shows for teenagers was launched on 26 May 2008.\nThe schools programming has always had elements which differ from its normal presentational package. In 1993, the Channel 4 Schools idents featured famous people in one category, with light shining on them in front of an industrial looking setting supplemented by instrumental calming music. This changed in 1996 with the circles look to numerous children touching the screen, forming circles of information then picked up by other children. The last child would produce the channel 4 logo in the form of three vertical circles, with another in the middle and to the left containing the Channel 4 logo.\nA present feature of presentation was a countdown sequence featuring, in 1993 a slide with the programme name, and afterwards an extended sequence matching the channel branding. In 1996, this was an extended ident with timer in top left corner, and in 1999 following the adoption of the squares look, featured a square with timer slowly make its way across the right of the screen with people learning and having fun while doing so passing across the screen. It finished with the Channel 4 logo box on the right of the screen and the name 'Channel 4 Schools' being shown. This was adapted in 2000 when the service's name was changed to '4Learning'.\nIn 2001, this was altered to various scenes from classrooms around the world and different parts of school life. The countdown now flips over from the top, right, bottom and left with each second, and ends with four coloured squares, three of which are aligned vertically to the left of the Channel 4 logo, which is contained inside the fourth box. The tag 'Learning' is located directly beneath the logo. The final countdown sequence lasted between 2004 and 2005 and featured a background video of current controversial issues, overlaid with upcoming programming information. the video features people in the style of graffiti enacting the overuse of CCTV cameras, fox hunting, computer viruses and pirate videos, relationships, pollution of the seas and violent lifestyles. Following 2005, no branded section has been used for Schools programmes.\nReligious programmes.\nFrom the outset, Channel 4 did not conform to the expectations of conventional religious broadcasting in the UK. John Ranelagh, first Commissioning Editor for Religion, made his priority 'broadening the spectrum of religious programming' and more 'intellectual' concerns. He also ignored the religious programme advisory structure that had been put in place by the BBC, and subsequently adopted by ITV. Ranelagh's first major commission caused a furore, a three-part documentary series called \"\". The programmes, transmitted during the Easter period of 1984, seemed to advocate the idea that the Gospels were unreliable, Jesus may have indulged in witchcraft, and that he may not have even existed. The series triggered a public outcry, and marked a significant moment in the deterioration in the relationship between the UK's broadcasting and religious institutions.\nFilm.\nNumerous genres of film-making \u2013 such as comedy, drama, documentary, adventure/action, romance and horror/thriller \u2013 are represented in the channel's schedule. From the launch of Channel 4 until 1998, film presentations on C4 would often be broadcast under the \"Film on Four\" banner.\nIn March 2005, Channel 4 screened the uncut Lars von Trier film \"The Idiots\", which includes unsimulated sexual intercourse, making it the first UK terrestrial channel to do so. The channel had previously screened other films with similar material but censored and with warnings.\nSince 1 November 1998, Channel 4 has had a digital subsidiary channel dedicated to the screening of films. This channel launched as a paid subscription channel under the name \"FilmFour\", and was relaunched in July 2006 as a free-to-air channel under the current name of \"Film4\". The Film4 channel carries a wide range of film productions, including acquired and Film4-produced projects. Channel 4's general entertainment channels E4 and More4 also screen feature films at certain points in the schedule as part of their content mix.\nWank Week.\nA season of television programmes about masturbation, called \"Wank Week\", was to be broadcast in the United Kingdom by Channel 4 in March 2007. The first show was about a Masturbate-a-thon, a public mass masturbation event, organised to raise money for the sexual health charity Marie Stopes International. Another film would have focused on compulsive male masturbators and a third was to feature the sex educator Dr Betty Dodson.\nThe series came under public attack from senior television figures, and was pulled amid claims of declining editorial standards and controversy over the channel's public service broadcasting credentials.\nGlobal warming.\nOn 8 March 2007, Channel 4 screened a highly controversial documentary, \"The Great Global Warming Swindle\". The programme states that global warming is \"a lie\" and \"the biggest scam of modern times\". The programme's accuracy has been disputed on multiple points, and several commentators have criticised it for being one-sided, noting that the mainstream position on global warming is supported by the scientific academies of the major industrialised nations. There were 246 complaints to Ofcom as of 25 April 2007, including allegations that the programme falsified data. The programme has been criticised by scientists and scientific organisations, and various scientists who participated in the documentary claimed their views had been distorted.\n\"Against Nature\": An earlier controversial Channel 4 programme made by Martin Durkin which was also critical of the environmental movement and was charged by the Independent Television Commission of the UK for misrepresenting and distorting the views of interviewees by selective editing.\n\"The Greenhouse Conspiracy\": An earlier Channel 4 documentary broadcast on 12 August 1990, as part of the \"Equinox\" series, in which similar claims were made. Three of the people interviewed (Lindzen, Michaels and Spencer) were also interviewed in \"The Great Global Warming Swindle\".\nAhmadinejad's Christmas speech.\nIn the \"Alternative Christmas address\" of 2008, a Channel 4 tradition since 1993 with a different presenter each year, Iranian President Mahmoud Ahmadinejad made a thinly veiled attack on the United States by claiming that Christ would have been against \"bullying, ill-tempered and expansionist powers\".\nThe airing courted controversy and was rebuked by several human rights activists, politicians and religious figures, including Peter Tatchell, Louise Ellman, Ron Prosor and Rabbi Aaron Goldstein. A spokeswoman for the Foreign and Commonwealth Office said: \"President Ahmadinejad has, during his time in office, made a series of appalling anti-Semitic statements. The British media are rightly free to make their own editorial choices, but this invitation will cause offence and bemusement not just at home but among friendly countries abroad\".\nHowever, some defended Channel 4. Stonewall director Ben Summerskill stated: \"In spite of his ridiculous and often offensive views, it is an important way of reminding him that there are some countries where free speech is not repressed...If it serves that purpose, then Channel 4 will have done a significant public service\". Dorothy Byrne, Channel 4's head of news and current affairs, also defended the station, saying: \"As the leader of one of the most powerful states in the Middle East, President Ahmadinejad's views are enormously influential... As we approach a critical time in international relations, we are offering our viewers an insight into an alternative world view...Channel 4 has devoted more airtime to examining Iran than any other broadcaster and this message continues a long tradition of offering a different perspective on the world around us\".\n4Talent.\n4Talent is an editorial branch of Channel 4's commissioning wing, which co-ordinates Channel 4's various talent development schemes for film, television, radio, new media and other platforms and provides a showcasing platform for new talent.\nThere are bases in London, Birmingham, Glasgow and Belfast, serving editorial hubs known respectively as 4Talent National, 4Talent Central England, 4Talent Scotland and 4Talent Northern Ireland. These four sites include features, profiles and interviews in text, audio and video formats, divided into five zones: TV, Film, Radio, New Media and Extras, which covers other arts such as theatre, music and design. 4Talent also collates networking, showcasing and professional development opportunities, and runs workshops, masterclasses, seminars and showcasing events across the UK.\n\"4Talent Magazine\".\n\"4Talent magazine\" is the creative industries magazine from 4Talent, which launched in 2005 as TEN4 magazine under the editorship of Dan Jones. \"4Talent Magazine\" is currently edited by Nick Carson. Other staff include deputy editor Catherine Bray and production editor Helen Byrne. The magazine covers rising and established figures of interest in the creative industries, a remit including film, radio, TV, comedy, music, new media and design.\nSubjects are usually UK-based, with contributing editors based in Northern Ireland, Scotland, London and Birmingham, but the publication has been known to source international content from Australia, America, continental Europe and the Middle East. The magazine is frequently organised around a theme for the issue, for instance giving half of November 2007's pages over to profiling winners of the annual 4Talent Awards.\nAn unusual feature of the magazine's credits is the equal prominence given to the names of writers, photographers, designers and illustrators, contradicting standard industry practice of more prominent writer bylines. It is also recognisable for its 'wraparound' covers, which use the front and back as a continuous canvas \u2013 often produced by guest artists.\nAlthough \"4Talent Magazine\" is technically a newsstand title, a significant proportion of its readers are subscribers. It started life as a quarterly 100-page title, but has since doubled in size and is now published bi-annually.\nPresentation.\nSince its launch in 1982, Channel 4 has used the same logo which consists of a stylised numeral \"4\" made up of nine differently shaped blocks. The logo was designed by Martin Lambie-Nairn and his partner [Colin Robinson] and was the first channel in the UK to depict an ident made using advanced computer generation (the first electronically generated ident was on BBC2 in 1979, but this was two-dimensional). It was designed in conjunction with Bo Gehring Aviation of Los Angeles and originally depicted the \"4\" in red, yellow, green, blue and purple. The music accompanying the ident was called \"Fourscore\" and was composed by David Dundas; it was later released as a single alongside a B-side, \"Fourscore Two\", although neither reached the UK charts. In November 1992, \"Fourscore\" was replaced by new music.\nIn 1996, Channel 4 commissioned Tomato Films to revamp the \"4\", which resulted in the \"Circles\" idents showing four white circles forming up transparently over various scenes, with the \"4\" logo depicted in white in one of the circles.\nIn 1999, Spin redesigned the logo to feature in a single square which sat on the right-hand side of the screen, whilst various stripes would move along from left to right, often lighting the squared \"4\" up. Like previous \"Circles\" idents from 1996 (which was made by Tomato Films), the stripes would be interspersed with various scenes potentially related to the upcoming programme.\nThe logo was made three-dimensional again in 2004 when it was depicted in filmed scenes that show the blocks forming the \"4\" logo for less than a second before the action moves away again.\nIn 2015, the logo was disassembled completely to allow the blocks to appear as parts of a nature scene, sometimes featuring a strange dancing creature and sometimes being excavated for scientific study, one being studied under a microscope and showing a tardigrade. The second wave of these idents, launched in 2017, depict a giant creature made of the \"4\" blocks (made to look almost like a person) interacting with everyday life, sometimes shouting the \"Fourscore\" theme as a foghorn.\nOn-air identity.\nThe Lambie-Nairn logo was the first logo of Channel 4, used from its launch on 2 November 1982 until 1996, lasting for fourteen years. The logo was re-introduced for one day only on 22 January 2021, to promote Channel 4's new five-part drama, It's a Sin, which focused on the 1980s AIDS crisis.\nRegions/International.\nChannel 4 has, since its inception, broadcast identical programmes and continuity throughout the United Kingdom (excluding Wales where it did not operate on analogue transmitters). At launch this made it unique, as both the BBC and ITV had long established traditions of providing regional variations in their programming in different areas of the country. Since the launch of subsequent British television channels, Channel 4 has become typical in its lack of regional programming variations.\nA few exceptions exist to this rule for programming and continuity:\nSome of Channel 4's schools' programming (1980s/early '90s) was regionalised due to differences in curricula between different regions.\nPart of Channel 4's remit covers the commissioning of programmes from outside London. Channel 4 has a dedicated director of nations and regions, Stuart Cosgrove, who is based in a regional office in Glasgow. As his job title suggests, it is his responsibility to foster relations with independent producers based in areas of the United Kingdom (including Wales) outside London.\nAdvertising on Channel 4 does contain regular variation: prior to 1993, when ITV was responsible for selling Channel 4's advertising, each regional ITV company would provide the content of advertising breaks, covering the same transmitter area as themselves, and these breaks were often unique to that area. After Channel 4 became responsible for its own advertising, it continued to offer advertisers the ability to target particular audiences and divided its coverage area into six regions: London, South (including Wales), Midlands, North, Northern Ireland and Scotland.\nAt present, Wales does not have its own advertising region, instead its viewers receive the southern region on digital platforms intentionally broadcast to the area, or the neighbouring region where terrestrial transmissions spill over into Wales. The Republic of Ireland shares its advertising region with Northern Ireland (referred to by Channel 4 as the 'Ulster Macro') with many advertisers selling products for Ireland here. E4 has an advertising variant for Ireland, although Northern Ireland receives the UK version of E4. The six regions are also carried on satellite, cable and Digital Terrestrial.\nChannel 5 and ITV Breakfast use a similar model to Channel 4 for providing their own advertising regions, despite also having a single national output of programming.\nDespite the Republic of Ireland not being in the UK, Channel 4 has a dedicated variant broadcast on Sky Ireland which omits programmes for which broadcast rights are not held in Ireland. For example, the series \"Glee\" is not available on Channel 4 on Sky in Ireland. In recent years a Republic of Ireland advertising opt-out has been added to this version.\nFuture possibility of regional news.\nWith ITV plc pushing for much looser requirements on the amount of regional news and other programming it is obliged to broadcast in its ITV regions, the idea of Channel 4 taking on a regional news commitment has been considered, with the corporation in talks with Ofcom and ITV over the matter. Channel 4 believe that a scaling-back of such operations on ITV's part would be detrimental to Channel 4's national news operation, which shares much of its resources with ITV through their shared news contractor ITN. At the same time, Channel 4 also believe that such an additional public service commitment would bode well in on-going negotiations with Ofcom in securing additional funding for its other public service commitments.\nChannel 4 HD.\nIn mid-2006 Channel 4 ran a six-month closed trial of HDTV, as part of the wider Freeview HD experiment via the Crystal Palace transmitter to London and parts of the home counties, including the use of \"Lost\" and \"Desperate Housewives\" as part of the experiment, as US broadcasters such as ABC already have an HDTV back catalogue.\nOn 10 December 2007, Channel 4 launched a high definition television simulcast of Channel 4 on Sky's digital satellite platform, after Sky agreed to contribute toward the channel's satellite distribution costs. It was the first full-time high definition channel from a terrestrial UK broadcaster.\nOn 31 July 2009, Virgin Media added Channel 4 HD on channel 146 (later on channel 142, now on channel 141) as a part of the M pack. On 25 March 2010 Channel 4 HD appeared on Freeview channel 52 with a placeholding caption, ahead of a commercial launch on 30 March 2010, coinciding with the commercial launch of Freeview HD. On 19 April 2011, Channel 4 HD was added to Freesat on channel 126. As a consequence, the channel moved from being free-to-view to free-to-air on satellite during March 2011. With the closure of S4C Clirlun in Wales on 1 December 2012, on Freeview, Channel 4 HD launched in Wales on 2 December 2012.\nThe channel carries the same schedule as Channel 4, broadcasting programmes in HD when available, acting as a simulcast. Therefore, SD programming is broadcast upscaled to HD. The first true HD programme to be shown was the 1996 Adam Sandler film Happy Gilmore. From launch until 2016 the presence of the 4HD logo on screen denoted true HD content.\nOn 1 July 2014, Channel 4 +1 HD, a HD simulcast of Channel 4 +1, launched on Freeview channel 110. It closed on 22 June 2020 to help make room on COM7 following the closure of COM8 on Freeview.\nOn 20 February 2018, Channel 4 announced that Channel 4 HD and All 4 will no longer be supplied on Freesat from Thursday 22 February 2018.\nOn 22 June 2020 Channel4+1 HD and 4Seven HD were removed from Freeview.\nAll 4.\nAll 4 is a video on demand service from Channel 4, launched in November 2006 as 4oD. The service offers a variety of programmes recently shown on Channel 4, E4, More4 or from their archives, though some programmes and movies are not available due to rights issues.\nTeletext services.\n4-Tel/FourText.\nChannel 4 originally licensed an ancillary teletext service to provide schedules, programme information and features. The original service was called 4-Tel, and was produced by Intelfax, a company set up especially for the purpose. It was carried in the 400s on Oracle. In 1993, with Oracle losing its franchise to Teletext Ltd, 4-Tel found a new home in the 300s, and had its name shown in the header row. Intelfax continued to produce the service and in 2002 it was renamed FourText.\nTeletext on 4.\nIn 2003, Channel 4 awarded Teletext Ltd a ten-year contract to run the channel's ancillary teletext service, named Teletext on 4. The service closed in 2008, and Teletext is no longer available on Channel 4, ITV and Channel 5."}
{"id": "6322", "revid": "39895928", "url": "https://en.wikipedia.org/wiki?curid=6322", "title": "Carolina parakeet", "text": "The Carolina parakeet (\"Conuropsis carolinensis\") or Carolina conure is an extinct species of small green neotropical parrot with a bright yellow head, reddish orange face and pale beak native to the eastern, midwest and plains states of the United States. It was the only indigenous parrot within its range, as well as one of only three parrot species native to the United States (the others being the thick-billed parrot, now extirpated, and the green parakeet still present in Texas; a fourth parrot species, the red-crowned amazon, is debated). It was found from southern New York and Wisconsin to Kentucky, Tennessee and the Gulf of Mexico, from the Atlantic seaboard to as far west as eastern Colorado. It lived in old-growth forests along rivers and in swamps. It was called \"puzzi la n\u00e9e\" (\"head of yellow\") or \"pot pot chee\" by the Seminole and \"kelinky\" in Chickasaw. Though formerly prevalent within its range, the bird had become rare by the middle of the 19th century. The last confirmed sighting in the wild was of the \"ludovicianus\" subspecies in 1910. The last known specimen perished in captivity at the Cincinnati Zoo in 1918 and the species was declared extinct in 1939.\nThe earliest reference to these parrots was in 1583 in Florida reported by Sir George Peckham in \"A True Report of the Late Discoveries of the Newfound Lands\" of expeditions conducted by English explorer Sir Humphrey Gilbert who notes that explorers in North America \"doe testifie that they have found in those countryes;\u00a0... parrots.\" They were first scientifically described in English naturalist Mark Catesby's two volume \"Natural History of Carolina, Florida and the Bahama Islands\" published in London in 1731 and 1743.\nCarolina parakeets were probably poisonous\u2014American naturalist and painter John J. Audubon noted that cats apparently died from eating them, and they are known to have eaten the toxic seeds of cockleburs.\nTaxonomy.\n\"Carolinensis\" is a species of the genus \"Conuropsis\", one of numerous genera of New World Neotropical parrots in family Psittacidae of true parrots.\nThe specific name \"Psittacus carolinensis\" was assigned by Swedish zoologist Carl Linnaeus in the 10th edition of Systema Naturae published in 1758. The species was given its own genus \"Conuropsis\" by Italian zoologist and ornithologist Tommaso Salvadori in 1891 in his \"Catalogue of the Birds in the British Museum\", volume\u00a020. The name is derived from the Greek-ified \"conure\" (\"parrot of the genus \"Conurus\"\" an obsolete name of genus \"Aratinga\") + \"-opsis\" (\"likeness of\") and Latinized \"Carolina\" (from Carolana, an English colonial province) + \"-ensis\" (of or \"from a place\"), therefore a bird \"like a conure from Carolina\".\nThere are two recognized subspecies. The Louisiana subspecies of the Carolina parakeet, \"C. c. ludovicianus\", was slightly different in color than the nominate subspecies, being more bluish-green and generally of a somewhat subdued coloration, and became extinct in much the same way, but at a somewhat earlier date (early 1910s). The Appalachian Mountains separated these birds from the eastern \"C.\u00a0c.\u00a0carolinensis\".\nEvolution.\nAccording to a study of mitochondrial DNA recovered from museum specimens, their closest living relatives include some of the South American \"Aratinga\" parakeets: The Nanday parakeet, the sun parakeet, and the golden-capped parakeet. The authors note the bright yellow and orange plumage and blue wing feathers found in \"Conuropsis carolinensis\" are traits shared by another species, the jandaya parakeet (\"A.\u00a0jandaya\"), that was not sampled in the study but is generally thought to be closely related. To help resolve the divergence time a whole genome of a preserved specimen has now been sequenced. Carolinensis is in a sister clade to that of Spix's macaw. The Carolina parakeet colonized North America about 5.5\u00a0million years ago. This was well before North America and South America were joined together by the formation of the Panama land bridge about 3.5\u00a0mya. Since the Carolina parakeets' more distant relations are geographically closer to its own historic range while its closest relatives are more geographically distant to it, these data are consistent with the generally accepted hypothesis that Central and North America were colonized at different times by distinct lineages of parrots \u2013 parrots that originally invaded South America from Antarctica some time after the breakup of Gondwana, where Neotropical parrots originated approximately 50\u00a0mya.\nThe following cladogram shows the placement of the Carolina parakeet among its closest relatives, after a DNA study by Kirchman \"et al\". (2012):\nA fossil parrot, designated \"Conuropsis fratercula\", was described based on a single humerus from the Miocene Sheep Creek Formation (possibly late Hemingfordian, c.\u00a016\u00a0mya, possibly later) of Snake River, Nebraska. This was a smaller bird, three-quarters the size of the Carolina parakeet. \"The present \"species\" is of peculiar interest as it represents the first known parrot-like bird to be described as a fossil from North America.\" (Wetmore 1926; italics added) However, it is not altogether certain that this species is correctly assigned to \"Conuropsis\", but some authors consider it a paleosubspecies of the Carolina parakeet.\nDescription.\nThe Carolina parakeet was a small green parrot very similar in size and coloration to the extant jenday parakeet and sun conure. The majority of the plumage was green with lighter green underparts, a bright yellow head and orange forehead and face extending to behind the eyes and upper cheeks (lores). The shoulders were yellow, continuing down the outer edge of the wings. The primary feathers were mostly green, but with yellow edges on the outer primaries. Thighs were green towards the top and yellow towards the feet. Male and female adults were identical in plumage, however males were slightly larger than females (sexually dimorphic). The legs and feet were light brown. They share the zygodactyl feet of the parrot family. The skin around the eyes was white and the beak was pale flesh colored. These birds weigh about 3.5\u00a0oz., are 13\u00a0in. long, and have wingspans of 2123\u00a0in.\nYoung Carolina parakeets differed slightly in coloration from adults. The face and entire body was green, with paler underparts. They lacked yellow or orange plumage on the face, wings, and thighs. Hatchlings were covered in mouse-gray down, until about 39\u201340 days when green wings and tails appear. Fledglings had full adult plumage at around 1 year of age. (\"Nature Serve, Conuropsis carolinensis\", 2005; Fuller, 2001; Mauler, 2001; Rising, 2004; Snyder and Russell, 2002)\nThese birds were fairly long lived, at least in captivity - a pair was kept at the Cincinnati Zoo for over 35 years.\nDistribution and habitat.\nThe Carolina parakeet had the northernmost range of any known parrot. It was found from southern New England and New York and Wisconsin to Kentucky, Tennessee and the Gulf of Mexico. It has also had a wide distribution west of the Mississippi River, as far west as eastern Colorado. Its range was described by early explorers thus: the 43rd parallel as the northern limit, the 26th as the most southern, the 73rd and 106th meridians as the eastern and western boundaries respectively, the range included all or portions of at least 28 states. Its habitats were old-growth wetland forests along rivers and in swamps especially in the Mississippi-Missouri drainage basin with large hollow trees including cypress and sycamore to use as roosting and nesting sites.\nOnly very rough estimates of the birds' former prevalence can be made: with an estimated range of 20,000 to 2.5 million km2, and population density of 0.5 to 2.0 parrots per km2, population estimates range from tens of thousands to a few million birds (though the densest populations occurred in Florida covering 170,000\u00a0km2, so there may have been hundreds of thousands of the birds in that state alone).\nThe species may have appeared as a very rare vagrant in places as far north as Southern Ontario. A few bones, including a pygostyle found at the Calvert Site in Southern Ontario, came from the Carolina parakeet. The possibility remains open that this specimen was taken to Southern Ontario for ceremonial purposes.\nBehavior and diet.\nThe bird lived in huge, noisy flocks of as many as 200\u2013300 birds. It built its nest in a hollow tree, laying two to five (most accounts say two) round white eggs.\nIt mostly ate the seeds of forest trees and shrubs including those of cypress, hackberry, beech, sycamore, elm, pine, maple, oak, and other plants such as thistles and sandspurs (\"Cenchrus\" species). It also ate fruits, including apples, grapes and figs (often from orchards by the time of its decline). It was especially noted for its predilection for cockleburs (\"Xanthium strumarium\"), a plant which contains a toxic glucoside, and it was considered to be an agricultural pest of grain crops.\nExtinction.\nThe last captive Carolina parakeet, Incas, died at the Cincinnati Zoo on February 21, 1918, in the same cage as Martha, the last passenger pigeon, who died in 1914. There are no scientific studies or surveys of this bird by American naturalists; most information about it is from anecdotal accounts and museum specimens. Therefore, details of its prevalence and decline are unverified or speculative.\nThere are extensive accounts of the pre-colonial and early colonial prevalence of this bird. The existence of flocks of gregarious, very colorful and raucous parrots could hardly have gone unnoted by European explorers, as parrots were virtually unknown in seafaring European nations in the 16th and 17th centuries. Later accounts in the latter half of the 19th century onward noted the birds' sparseness and absence.\nThe birds' range collapsed from east to west with settlement and clearing of the eastern and southern deciduous forests. John J. Audubon commented as early as 1832 on the decline of the birds. The bird was rarely reported outside Florida after 1860. The last reported sighting east of the Mississippi River (except Florida) was in 1878 in Kentucky. By the turn of the century it was restricted to the swamps of central Florida. The last known wild specimen was killed in Okeechobee County, Florida, in 1904, and the last captive bird died at the Cincinnati Zoo on February 21, 1918. This was the male specimen, called \"Incas\", who died within a year of his mate, \"Lady Jane\". Additional reports of the bird were made in Okeechobee County, Florida, until the late 1920s, but these are not supported by specimens. It was not until 1939, however, that the American Ornithologists' Union declared that the Carolina parakeet had become extinct. The IUCN has listed the species as extinct since 1920.\nIn 1937, three parakeets resembling this species were sighted and filmed in the Okefenokee Swamp of Georgia. However, the American Ornithologists' Union analyzed the film and concluded that they had probably filmed feral parakeets. A year later, in 1938, a flock of parakeets was apparently sighted by a group of experienced ornithologists in the swamps of the Santee River basin in South Carolina. However, this sighting was doubted by most other ornithologists. The birds were never seen again after this sighting, and shortly after a portion of the area was destroyed to make way for power lines, making the species' continued existence unlikely.\nAbout 720 skins and 16 skeletons are housed in museums around the world and analyzable DNA has been extracted from them.\nReasons for extinction.\nThe evidence is indicative that humans had at least a contributory role in the extinction of the Carolina parakeet, through a variety of means. Chief was deforestation in the 18th and 19th centuries. Hunting played a significant role, both for decorative use of their colorful feathers, for example, adornment of women's hats, and for reduction of crop predation. This was partially offset by the recognition of their value in controlling invasive cockleburs. Minor roles were played by capture for the pet trade and, as noted in \"Pacific Standard\", \"One biologist has argued\", by the introduction for crop pollination of European honeybees that competed for nest sites.\nA factor that exacerbated their decline to extinction was the flocking behavior that led them to return to the vicinity of dead and dying birds (e.g., birds downed by hunting), enabling wholesale slaughter.\nThe final extinction of the species in the early years of the 20th century is somewhat of a mystery, as it happened so rapidly. Vigorous flocks with many juveniles and reproducing pairs were noted as late as 1896, and the birds were long-lived in captivity, but they had virtually disappeared by 1904. Sufficient nest sites remained intact, so deforestation was not the final cause. American ornithologist Noel F. Snyder speculates that the most likely cause seems to be that the birds succumbed to poultry disease, although no recent or historical records exist of New World parrot populations being afflicted by domestic poultry diseases. The modern poultry scourge Newcastle disease was not detected until 1926 in Indonesia, and only a subacute form of it was reported in the United States in 1938."}
{"id": "6324", "revid": "1012634696", "url": "https://en.wikipedia.org/wiki?curid=6324", "title": "Collective trauma", "text": "A collective trauma is a traumatic psychological effect shared by a group of people of any size, up to and including an entire society. Traumatic events witnessed by an entire society can stir up collective sentiment, often resulting in a shift in that society's culture and mass actions.\nWell known collective traumas include: The Holocaust, the Armenian Genocide, Slavery in the United States, the Atomic bombings of Hiroshima and Nagasaki, the Trail of Tears, the Great Irish Famine, Attack on Pearl Harbor, the MS Estonia in Sweden, the September 11, 2001 attacks in the United States, the Halabja chemical attack and various others.\nCollective traumas have been shown to play a key role in group identity formation (see: Law of Common Fate). During World War II, a US submarine, the USS \"Puffer\" (SS-268), came under several hours of depth charge attack by a Japanese surface vessel until the ship became convinced the submarine had somehow escaped. Psychological studies later showed that crewmen transferred to the submarine after the event were never accepted as part of the team. Later, US naval policy was changed so that after events of such psychological trauma, the crew would be dispersed to new assignments.\nRehabilitation of survivors becomes extremely difficult when an entire nation has experienced such severe traumas as war, genocide, torture, massacre, etc. Treatment is hardly effective when everybody is traumatized. Trauma remains chronic and would reproduce itself as long as social causes are not addressed and perpetrators continue to enjoy impunity. The whole society may suffer from an everlasting culture of pain. (1)\nDuring the Algerian War, Frantz Omar Fanon found his practice of treatment of native Algerians ineffective due to the continuation of the horror of a colonial war. He emphasized about the social origin of traumas, joined the liberation movement and urged oppressed people to purge themselves of their degrading traumas through their collective liberation struggle. He made the following remarks in his letter of resignation, as the Head of the Psychiatry Department at the Blida-Joinville Hospital in Algeria:\"If psychiatry is the medical technique that aims to enable man no longer to be a stranger to his environment, I owe it to myself to affirm that the Arab, permanently an alien in his own country, lives in a state of absolute depersonalization.\" (2) Inculcation of horror and anxiety, through widespread torture, massacre, genocide and similar coercive measures has happened frequently in human history. There are plenty of examples in our modern history. Tyrants have always used their technique of \"psychological artillery\" in an attempt to cause havoc and confusion in the minds of people and hypnotize them with intimidation and cynicism. The result is a collective trauma that will pass through generations. There is no magic formula of rehabilitation. Collective trauma can be alleviated through cohesive and collective efforts such as recognition, remembrance, solidarity, communal therapy and massive cooperation."}
{"id": "6325", "revid": "3174456", "url": "https://en.wikipedia.org/wiki?curid=6325", "title": "Church (building)", "text": "A church building, church house, or simply church, is a building used for Christian worship services and other Christian religious activities. The term is used to refer to the physical buildings where Christians worship and also to refer to the community of Christians. Sometimes it is used as an analogy for the buildings of other religions. In traditional Christian architecture the plan view of a church often forms a Christian cross; the center aisle and seating representing the vertical beam with the bema and altar forming the horizontal. Towers or domes may inspire contemplation of the heavens. Modern churches have a variety of architectural styles and layouts. Some buildings designed for other purposes have been converted to churches, while many original church buildings have been put to other uses.\nThe earliest identified Christian church building is a house church founded between 233 and 256. From the 11th through the 14th centuries there was a wave of church construction in western Europe. A cathedral is a church building housing a cathedra, the seat or throne of a presiding bishop.\nEtymology.\nIn Greek, the adjective \"kyriak-\u00f3s/-\u0113/-\u00f3n\" () means \"belonging, or pertaining, to a \"Kyrios\"\" (\"Lord\"), and the usage was adopted by early Christians of the Eastern Mediterranean with regard to anything pertaining to Jesus Christ: hence \"Kyriak\u00f3s o\u00edkos\" () (\"house of the Lord\", church), \"Kyriak\u0113\" () (\"[the day] of the Lord\", i.e. Sunday), or \"Kyriak\u0113 proseukh\u0113\" () (the \"Lord's Prayer\").\nIn standard Greek usage, the older word \"ecclesia\" (, \"ekkles\u00eda\", literally \"assembly\", \"congregation\", or the place where such a gathering occurs) was retained to signify both a specific edifice of Christian worship (a \"church\"), and the overall community of the faithful (the \"Church\"). This usage was also retained in Latin and the languages derived from Latin (e.g. French \"\u00e9glise\", Italian \"chiesa\", Spanish \"iglesia\", Portuguese \"igreja\", etc.), as well as in the Celtic languages (Welsh \"eglwys\", Irish \"eaglais\", Breton \"iliz\", etc.) and in Turkish (\"Kilise\").\nIn the Germanic and some Slavic languages, the word \"kyriak-\u00f3s/-\u0113/-\u00f3n\" was adopted instead and derivatives formed thereof. In Old English the sequence of derivation started as \"cirice\", then Middle English \"churche\", and eventually \"church\" in its current pronunciation. German \"Kirche\", Scots \"kirk\", Russian (\"tserkov\"), Serbo-Croatian \"crkva\", etc., are all similarly derived.\nHistory.\nAntiquity.\nAccording to the New Testament, the earliest Christians did not build church buildings. Instead, they gathered in homes (Acts 17:5, 20:20, 1 Corinthians 16:19) or in Jewish places of worship, like the Second Temple or synagogues (Acts 2:46, 19:8). The earliest archeologically identified Christian church is a house church (\"domus ecclesiae\"), the Dura-Europos church, founded between 233 and 256. In the second half of the 3rd century AD, the first purpose-built halls for Christian worship (\"aula ecclesiae\") began to be constructed. Although many of these were destroyed early in the next century during the Diocletianic Persecution, even larger and more elaborate church buildings began to appear during the reign of the Emperor Constantine the Great.\nMedieval times.\nFrom the 11th through the 14th centuries, a wave of cathedral-building and construction of smaller parish churches occurred across western Europe. Besides serving as a place of worship, the cathedral or parish church was frequently employed as a general gathering-place by the communities in which they were located, hosting such events as guild meetings, banquets, mystery plays, and fairs. Church grounds and buildings were also used for the threshing and storage of grain.\nRomanesque architecture.\nBetween 1000 and 1200 the romanesque style became popular across Europe. While the term \"Romanesque\" refers to the tradition of Roman architecture, the trend in fact appeared throughout western and central Europe. The romanesque style is defined by large and bulky edifices that are typically made up of simple, compact, sparsely decorated geometric structures. Frequent features of the Romanesque church include circular arches, round or octagonal towers and cushion capitals on pillars. In the early romanesque era, coffering on the ceiling was fashionable, while later in the same era, groined vault gained popularity. Interiors widened and the motifs of sculptures took on more epic traits and themes.\nGothic architecture.\nThe Gothic style emerged around 1140 in \u00cele-de-France and subsequently spread throughout Europe. Gothic churches lost the compact qualities of the romanesque era and decorations often contained symbolic and allegorical features. The first pointed arches, rib vaults and buttresses began to appear, all possessing geometric properties that reduced the need for large, rigid walls to ensure structural stability. This also permitted the size of windows to increase, producing brighter and lighter interiors. Nave ceilings became higher and pillars and steeples grew taller. Many architects used these developments to push the limits of structural possibility, an inclination which resulted in the collapse of several towers possessing designs that had unwittingly exceeded the boundaries of soundness. In Germany, the Netherlands, and Spain, it became popular to build hall churches, a style in which every vault would be built to the same height.\nGothic cathedrals were lavishly designed, as in the romanesque era, and many share romanesque traits. However, several also exhibit unprecedented degrees of detail and complexity in decoration. The Notre-Dame de Paris and Notre-Dame de Reims in France, as well as the San Francesco d\u2019Assisi in Palermo, and the Salisbury Cathedral and Wool Church in England demonstrate the elaborate stylings characteristic of Gothic cathedrals.\nSome of the most well-known gothic churches remained unfinished for centuries, after the gothic style fell out of popularity. The construction of the Cologne Cathedral, which was begun in 1248, halted in 1473, and not resumed until 1842 is one such example.\nRenaissance.\nIn the 15th and 16th century, the change in ethics and society due to the Renaissance and the Reformation also influenced the building of churches. The common style was much like the gothic style, but in a simplified way. The basilica was not the most popular type of church anymore, but instead hall churches were built. Typical features are columns and classical capitals.\nIn Protestant churches, where the proclamation of God's Word is of special importance, the visitor's line of view is directed towards the pulpit.\nBaroque architecture.\nThe baroque style was first used in Italy around 1575. From there it spread to the rest of Europe and to the European colonies. During the Baroque era, the building industry increased heavily. Buildings, even churches, were used as indicators for wealth, authority and influence. The use of forms known from the renaissance were extremely exaggerated. Domes and capitals were decorated with moulding and the former stucco sculptures were replaced by fresco paintings on the ceilings. For the first time, churches were seen as one connected work of art and consistent artistic concepts were developed. Instead of long buildings, more central-plan buildings were created. The sprawling decoration with floral ornamentation and mythological motives raised until about 1720 to the Rococo era.\nThe Protestant parishes preferred lateral churches, in which all the visitors could be as close as possible to the pulpit and the altar.\nArchitecture.\nA common architecture for churches is the shape of a cross (a long central rectangle, with side rectangles, and a rectangle in front for the altar space or sanctuary). These churches also often have a dome or other large vaulted space in the interior to represent or draw attention to the heavens. Other common shapes for churches include a circle, to represent eternity, or an octagon or similar star shape, to represent the church's bringing light to the world. Another common feature is the spire, a tall tower on the \"west\" end of the church or over the crossing.\nAnother common feature of many Christian churches is the eastwards orientation of the front altar. \nOften, the altar will not be oriented due east, but in the direction of sunrise. This tradition originated in Byzantium in the 4th century, and became prevalent in the West in the 8th to 9th century. \nThe old Roman custom of having the altar at the west end and the entrance at the east was sometimes followed as late as the 11th century even in areas of northern Europe under Frankish rule, as seen in Petershausen (Constance), Bamberg Cathedral, Augsburg Cathedral, Regensburg Cathedral, and Hildesheim Cathedral.\nTypes.\nBasilica.\nThe Latin word basilica (derived from Greek, \"Basilik\u00e9 Sto\u00e0\", Royal \"Stoa\") was originally used to describe a Roman public building (as in Greece, mainly a tribunal), usually located in the forum of a Roman town.\nAfter the Roman Empire became officially Christian, the term came by extension to refer to a large and important church that has been given special ceremonial rights by the Pope. Thus the word retains two senses today, one architectural and the other ecclesiastical.\nCathedral.\nA cathedral is a church, usually Catholic, Anglican, Oriental Orthodox or Eastern Orthodox, housing the seat of a bishop. The word cathedral takes its name from \"cathedra\", or Bishop's Throne (In ). The term is sometimes (improperly) used to refer to any church of great size.\nA church that has the function of cathedral is not necessarily a large building. It might be as small as Christ Church Cathedral in Oxford, England, Porvoo Cathedral in Porvoo, Finland, Sacred Heart Cathedral in Raleigh, United States, or Chur Cathedral in Switzerland. However, frequently, the cathedral along with some of the abbey churches, was the largest building in any region.\nPilgrimage church.\nA pilgrimage church is a church to which pilgrimages are regularly made, or a church along a pilgrimage route, often located at the tomb of a saints, or holding icons or relics to which miraculous properties are ascribed, the site of Marian apparitions, etc.\nConventual church.\nA conventual church (or monastery church, minster, \"katholikon\") is the main church building in a Christian monastery or abbey.\nCollegiate church.\nA collegiate church is a church where the daily office of worship is maintained by a college of canons, which may be presided over by a dean or provost.\nCollegiate churches were often supported by extensive lands held by the church, or by tithe income from appropriated benefices. They commonly provide distinct spaces for congregational worship and for the choir offices of their clerical community.\nEvangelical church structures.\nThe architecture of evangelical places of worship is mainly characterized by its sobriety. The Latin cross is one of the only spiritual symbols that can usually be seen on the building of an evangelical church and that identifies the place's belonging. Some services take place in theaters, schools or multipurpose rooms, rented for Sunday only. Because of their understanding of the second of the Ten Commandments, evangelicals do not have religious material representations such as statues, icons, or paintings in their places of worship. There is usually a baptistery on the stage of the auditorium (also called sanctuary) or in a separate room for baptisms by immersion.\nAlternative buildings.\nOld and disused church buildings can be seen as an interesting proposition for developers as the architecture and location often provide for attractive homes or city centre entertainment venues On the other hand, many newer churches have decided to host meetings in public buildings such as schools, universities, cinemas or theatres.\nThere is another trend to convert old buildings for worship rather than face the construction costs and planning difficulties of a new build. Unusual venues in the UK include a former tram power station, a former bus garage, a former cinema and bingo hall, a former Territorial Army drill hall, and a former synagogue. served as a floating church for mariners at Liverpool from 1827 until she sank in 1872. A windmill has also been converted into a church at Reigate Heath.\nThere has been an increase in partnerships between church management and private real estate companies to redevelop church properties into mixed uses. While it has garnered criticism from some, the partnership offers congregations the opportunity to increase revenue while preserving the property."}
{"id": "6326", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=6326", "title": "Childe's Tomb", "text": "Childe's Tomb is a granite cross on Dartmoor, Devon, England. Although not in its original form, it is more elaborate than most of the crosses on Dartmoor, being raised upon a constructed base, and it is known that a kistvaen is underneath.\nA well-known legend attached to the site, first recorded in 1630 by Tristram Risdon, concerns a wealthy hunter, Childe, who became lost in a snow storm and supposedly died there despite disembowelling his horse and climbing into its body for protection. The legend relates that Childe left a note of some sort saying that whoever found and buried his body would inherit his lands at Plymstock. After a race between the monks of Tavistock Abbey and the men of Plymstock, the Abbey won.\nThe tomb was virtually destroyed in 1812 by a man who stole most of the stones to build a house nearby, but it was partly reconstructed in 1890.\nDescription.\nChilde's Tomb is a reconstructed granite cross on the south-east edge of Foxtor Mires, about 500 metres north of Fox Tor on Dartmoor, Devon, England at . According to William Burt, in his notes to \"Dartmoor, a Descriptive Poem\" by N. T. Carrington (1826), the original tomb consisted of a pedestal of three steps, the lowest of which was built of four stones each six feet long and twelve inches square. The two upper steps were made of eight shorter but similarly shaped stones, and on top was an octagonal block about three feet high with a cross fixed upon it.\nThe tomb lies on the line of several cairns that marked the east-west route of the ancient Monks' Path between Buckfast Abbey and Tavistock Abbey and it was no doubt erected here as part of that route: it would have been particularly useful in this part of the moor with few landmarks where a traveller straying from the path could easily end up in Foxtor Mires. Tristram Risdon, writing in about 1630, said that Childe's Tomb was one of three remarkable things in the Forest of Dartmoor (the others being Crockern Tor and Wistman's Wood). Risdon also stated that the original tomb bore an inscription: \"They fyrste that fyndes and bringes mee to my grave, The priorie of Plimstoke they shall have\", but no sign of this has ever been found.\nToday the cross, which is a replacement, is about tall and across at the crosspiece, and it has its base in a socket stone which rests on a pedestal of granite blocks that raises the total height of the cross to . The original, now broken, socket stone for the cross lies nearby. The whole is surrounded by a circle of granite stones set on their edge which once surrounded the cairn\u2014the rocks of which are now scattered around\u2014that was originally built over a large kistvaen that still exists beneath the pedestal.\nDestruction.\nIn the early 19th century there was much interest in enclosing and \"improving\" the open moorland on Dartmoor, encouraged by Sir Thomas Tyrwhitt's early successes at Tor Royal near Princetown. Enclosure was aided by the greatly enhanced access provided by the construction of the first turnpike roads over the moor: the road between Ashburton and Two Bridges opened in around 1800, for instance. In February 1809 one Thomas Windeatt, from Bridgetown, Totnes, took over the lease of a plot of land (a \"newtake\") of about 582 acres in the valley of the River Swincombe. In 1812 Windeatt started to build a farmhouse, Fox Tor Farm, on his land and his workmen robbed the nearby Childe's Tomb of most of its stones for the building and its doorsteps.\nIn 1902 William Crossing wrote that he had been told by an old moorman that some of the granite blocks from the tomb's pedestal had also been used to make a clapper bridge across a stream flowing into the River Swincombe near the farm. The moorman also said that they had lettering on their undersides. This encouraged Crossing to arrange to lift the clapper bridge, but no inscription was found. However, he did locate nine out of the twelve stones that had made up the pedestal, as well as the broken socket stone for the cross.\nReconstruction.\nCrossing rediscovered the original site of the tomb in 1882 and said that all that remained was a small mound and some half buried stones. He cleared out the kistvaen, reporting that it was long by wide and that unlike most kistvaens found on the moor, the stones lining it had apparently been shaped by man, which led him to suggest that it was less old than most. Having located most of the stones of the original tomb, Crossing thought that it could be rebuilt in its original form with little effort, but it was not to be.\nJ. Brooking Rowe, writing in 1895, states that the tomb was re-erected in 1890 under the direction of Mr. E. Fearnley Tanner, who said that he was dissatisfied with the result because several stones were missing and it was difficult to recreate the original character of the monument. Tanner was the honourable secretary of the Dartmoor Preservation Association, and this reconstruction was one of the first acts of that organisation. The replacement base and cross were made in Holne in 1885.\nChilde the Hunter.\nAccording to legend, the cross was erected over the kistvaen ('chest-stone' i.e. burial chamber) of Childe the Hunter, who was Ordulf, son of Ordgar, an Anglo-Saxon Earl of Devon in the 11th century. The name \"Childe\" is probably derived from the Old English word \"cild\" which was used as a title of honour.\nLegend has it that Childe was in a party hunting on the moor when they were caught in some changeable weather. Childe became separated from the main party and was lost. In order to save himself from dying of exposure, he killed his horse, disembowelled it and crept inside the warm carcass for shelter. He nevertheless froze to death, but before he died, he wrote a note to the effect that whoever should find him and bury him in their church should inherit his Plymstock estate.\nHis body was found by the monks of Tavistock Abbey, who started to carry it back. However, they heard of a plot to ambush them by the people of Plymstock, at a bridge over the River Tavy. They took a detour and built a new bridge over the river, just outside Tavistock. They were successful in burying the body in the grounds of the Abbey and inherited the Plymstock estate.\nThe first account of this story is to be found in Risdon's \"Survey of Devon\" which was completed in around 1632:\nFinberg pointed out, however, that a document of 1651 refers to Tavistock's guildhall as \"Guilehall\", so \"Guilebridge\" is more likely to be \"guild bridge\", probably because it was built or maintained by one of the town guilds.\nIn popular culture.\nDevon folk singer Seth Lakeman sang about Childe the Hunter on his 2006 album \"Freedom Fields\"."}
{"id": "6328", "revid": "7269056", "url": "https://en.wikipedia.org/wiki?curid=6328", "title": "Cognate", "text": "In linguistics, cognates, also called lexical cognates, are words that have a common etymological origin. Cognates are often inherited from a shared parent language, but they may also involve borrowings from some other language. For example, the English words \"dish\", \"disk\" and \"desk\" and the German word \"Tisch\" (\"table\") are cognates because they all come from Latin \"discus\", which relates to their flat surfaces. Cognates may have evolved similar, different or even opposite meanings, and although there are usually some similar sounds or letters in the words, they may appear to be dissimilar. Some words sound similar, but do not come from the same root; these are called false cognates, while some are truly cognate but differ in meaning; these are called false friends.\nThe word \"cognate\" derives from the Latin noun \"cognatus\", which means \"blood relative\".\nCharacteristics.\nCognates do not need to have the same meaning, which may have changed as the languages developed separately. For example English \"starve\" and Dutch \"sterven\" or German \"sterben\" (\"to die\") all derive from the same Proto-Germanic root, \"*sterban\u0105\" (\"die\"). \"Discus\" is from Greek (from the verb \"to throw\"). A later and separate English reflex of \"discus\", probably through medieval Latin , is \"desk\" (see OED s.v. \"desk\").\nAlso, cognates do not need to have similar forms: English \"father\", French \"p\u00e8re\", and Armenian \u0570\u0561\u0575\u0580 (\"hayr\") all descend directly from Proto-Indo-European \"*ph\u2082t\u1e17r\". An extreme case is Armenian \u0565\u0580\u056f\u0578\u0582 (\"erku\") and English \"two\", which descend from Proto-Indo-European \"*dw\u00f3h\u2081\" (note that the sound change \"*dw\" &gt; \"erk\" in Armenian is regular).\nAcross languages.\nExamples of cognates in Indo-European languages are the words \"night\" (English), \"nicht\" (Scots), \"Nacht\" (German), \"nacht\" (Dutch, Frisian), \"nag\" (Afrikaans), \"Naach\" (Colognian), \"natt\" (Swedish, Norwegian), \"nat\" (Danish), \"n\u00e1tt\" (Faroese), \"n\u00f3tt\" (Icelandic), \"noc\" (Czech, Slovak, Polish), \u043d\u043e\u0447\u044c, \"noch\" (Russian), \u043d\u043e\u045c, \"no\u0107\" (Macedonian), \u043d\u043e\u0449, \"nosht\" (Bulgarian), \"nishi\" (Bengali), \"\u043d\u0456\u0447\", \"nich\" (Ukrainian), \"\u043d\u043e\u0447\", \"noch\"/\"no\u010d\" (Belarusian), \"no\u010d\" (Slovene), \"no\u0107\" (Bosnian, Serbian, Croatian), \"nakts\" (Latvian), \"naktis\" (Lithuanian), \u03bd\u03cd\u03be, \"nyx\" (Ancient Greek), \"\u03bd\u03cd\u03c7\u03c4\u03b1\" / \"nychta\" (Modern Greek), \"nakt-\" (Sanskrit), \"nat\u00eb\" (Albanian), \"nos\" (Welsh, Cornish), \"noz\" (Breton), \"nox/nocte\" (Latin), \"nuit\" (French), \"noche\" (Spanish), \"nueche\" (Asturian), \"noite\" (Portuguese and Galician), \"notte\" (Italian), \"nit\" (Catalan), \"nuet/nit/nueit\" (Aragonese), \"nu\u00e8ch\" / \"nu\u00e8it\" (Occitan) and \"noapte\" (Romanian), all meaning \"night\" and being derived from the Proto-Indo-European \"night\".\nAnother Indo-European example is \"star\" (English), \"starn\" (Scots), \"Stern\" (German), \"ster\" (Dutch and Afrikaans), \"stjer\" (Frisian) \"Scht\u00e4hn\" (Colognian), \"stj\u00e4rna\" (Swedish), \"stjerne\" (Norwegian and Danish), \"stjarna\" (Icelandic), \"stj\u00f8rna\" (Faroese), \"stairno\" (Gothic), \"str-\" (Sanskrit), \"tara\" (Hindustani and Bengali), \"tera\" (Sylheti), \"tora\" (Assamese), \"set\u0101re\" (Persian), \"stoorei\" (Pashto), \"est\u00eare\" or \"st\u00eark\" (Kurdish), \"astgh\" (Armenian), \"\u1f00\u03c3\u03c4\u03ae\u03c1 (ast\u0113r)\" (Greek or \"\u1f00\u03c3\u03c4\u03ad\u03c1\u03b9\"/\"\u1f04\u03c3\u03c4\u03c1\u03bf\", \"asteri\"/\"astro\" in Modern Greek), \"astrum\" / \"stell\u0103\" (Latin), \"astre\" / \"\u00e9toile\" (French), \"astro\" / \"stella\" (Italian), \"stea\" (Romanian and Venetian), \"estel\" (Catalan), \"astru\" / \"isteddu\" (Sardinian), \"estela\" (Occitan), \"estrella\" and \"astro\" (Spanish), \"estrella\" (Asturian and Leonese), \"estrela\" and \"astro\" (Portuguese and Galician), \"seren\" (Welsh), \"steren\" (Cornish) and \"sterenn\" (Breton), from the Proto-Indo-European \"star\".\nThe Arabic \"sal\u0101m\", the Hebrew \"shalom\", the Assyrian Neo-Aramaic \"shlama\" and the Amharic \"selam\" (\"peace\") are also cognates, derived from the Proto-Semitic *\u0161al\u0101m- \"peace\".\nCognates may often be less easily recognised than the above examples, and authorities sometimes differ in their interpretations of the evidence. The English word \"milk\" is clearly a cognate of German \"Milch\", Dutch and Afrikaans \"melk\", Russian \u043c\u043e\u043b\u043e\u043a\u043e (moloko), Serbian and Slovenian \"mleko\", and Montenegrin, Bosnian, Croatian, \"mlijeko\". On the other hand, French \"lait\", Catalan \"llet\", Italian \"latte\", Romanian \"lapte\", Spanish \"leche\" and \"leite\" (Portuguese and Galician) (all meaning \"milk\") are less-obvious cognates of Ancient Greek \"\" \"g\u00e1laktos\" (genitive singular of \"g\u00e1la\", \"milk\"), a relationship that is more evidently seen through the intermediate Latin \"lac\" \"milk\" as well as the English word \"lactic\" and other terms borrowed from Latin.\nSome cognates are semantic opposites. For instance, while the Hebrew word \"chutzpah\" means \"impudence\", its Classical Arabic cognate \"\u1e25a\u1e63\u0101fah\" means \"sound judgment.\" Another example is English \"empathy\" \"understanding of thoughts\" and Greek \"emp\u00e1theia\" \"malice\".\nWithin the same language.\nCognates within a single language, or \"doublets\", may have meanings that are slightly or even totally different. For example, English \"ward\" and \"guard\" (&lt;PIE \"*wer-\", \"to perceive, watch out for\") are cognates, as are \"shirt\" (garment on top) and \"skirt\" (garment on bottom) (&lt;PIE \"*sker-\", \"to cut\"). In some cases, including this one, one cognate (\"skirt\") has an ultimate source in another language related to English, but the other one (\"shirt\") is native. That happened with many loanwords, such as \"skirt\" in this example, which was borrowed from Old Norse during the Danelaw.\nSometimes both doublets come from other languages, often the same one but at different times. For example, the word \"chief\" (meaning the leader of any group) comes from the Middle French \"chef\" (\"head\"), and its modern pronunciation preserves the Middle French consonant sound; the word \"chef\" (the leader of the cooks) was borrowed from the same source centuries later, but by then, the consonant had changed to a \"sh\" sound in French. Such word sets can also be called etymological twins, and they may come in groups of higher numbers, as with, for example, the words \"wain\" (native), \"waggon/wagon\" (Dutch), and \"vehicle\" (Latin) in English.\nA word may also enter another language, develop a new form or meaning there, and be re-borrowed into the original language; that is called reborrowing. For example, the Greek word (\"k\u00ednima\", \"movement\") became French \"cin\u00e9ma\" (compare American English \"movie\") and then later returned to Greece as (\"sinem\u00e1\", \"the art of film\", \"movie theater\"). In Greek, (\"k\u00ednima\", \"movement\") and (\"sinem\u00e1\", \"filmmaking, cinema\") are now doublets.\nA less obvious English-language doublet pair is \"grammar\" and \"glamour\".\nFalse cognates.\nFalse cognates are words that people commonly believe are related (have a common origin), but that linguistic examination reveals are unrelated. For example, on the basis of superficial similarities, the Latin verb \"hab\u0113re\" and German \"haben\", both meaning 'to have', appear to be cognates. However, because the words evolved from different roots, in this case, different Proto-Indo-European (PIE) roots, they cannot be cognate (see for example Grimm's law). German \"haben\", like English \"have\", comes from PIE \"*kh\u2082py\u00e9-\" 'to grasp', and its real cognate in Latin is \"capere\", 'to seize, grasp, capture'. Latin \"hab\u0113re\", on the other hand, is from PIE \"*g\u02b0ab\u02b0\", 'to give, to receive', and hence cognate with English \"give\" and German \"geben\".\nLikewise, English \"much\" and Spanish \"mucho\" look similar and have a similar meaning but are not cognates, as they evolved from different roots: \"much\" from Proto-Germanic \"*mikilaz\" &lt; PIE \"*me\u01f5-\" and \"mucho\" from Latin \"multum\" &lt; PIE \"*mel-\". Instead, its real cognate is Spanish \"ma\u00f1o\"."}
{"id": "6329", "revid": "39534040", "url": "https://en.wikipedia.org/wiki?curid=6329", "title": "Chromatography", "text": "Chromatography is a laboratory technique for the separation of a mixture.\nThe mixture is dissolved in a fluid (gas, solvent, water, ...) called the \"mobile phase,\" which carries it through a system (a column, a capillary tube, a plate, or a sheet) on which is fixed a material called the \"stationary phase.\" The different constituents of the mixture have different affinities for the stationary phase. The different molecules stay longer or shorter on the stationary phase, depending on their interactions with its surface sites. So, they travel at different apparent velocities in the mobile fluid, causing them to separate. The separation is based on the differential partitioning between the mobile and the stationary phases. Subtle differences in a compound's partition coefficient result in differential retention on the stationary phase and thus affect the separation.\nChromatography may be preparative or analytical. The purpose of preparative chromatography is to separate the components of a mixture for later use, and is thus a form of purification. Analytical chromatography is done normally with smaller amounts of material and is for establishing the presence or measuring the relative proportions of analytes in a mixture. The two are not mutually exclusive.\nEtymology and pronunciation.\nChromatography, pronounced , is derived from Greek \u03c7\u03c1\u1ff6\u03bc\u03b1 \"chroma\", which means \"color\", and \u03b3\u03c1\u03ac\u03c6\u03b5\u03b9\u03bd \"graphein\", which means \"to write\". The combination of these two terms was directly inherited from the invention of the technique first used to separate pigments.\nHistory.\nChromatography was first devised in Russia by the Italian-born scientist Mikhail Tsvet in 1900. He developed the technique, he coined \"chromatography,\" in the first decade of the 20th century, primarily for the separation of plant pigments such as chlorophyll, carotenes, and xanthophylls. Since these components separate in bands of different colors (green, orange, and yellow, respectively) they directly inspired the name of the technique. New types of chromatography developed during the 1930s and 1940s made the technique useful for many separation processes.\nChromatography technique developed substantially as a result of the work of Archer John Porter Martin and Richard Laurence Millington Synge during the 1940s and 1950s, for which they won the 1952 Nobel Prize in Chemistry. They established the principles and basic techniques of partition chromatography, and their work encouraged the rapid development of several chromatographic methods: paper chromatography, gas chromatography, and what would become known as high-performance liquid chromatography. Since then, the technology has advanced rapidly. Researchers found that the main principles of Tsvet's chromatography could be applied in many different ways, resulting in the different varieties of chromatography described below. Advances are continually improving the technical performance of chromatography, allowing the separation of increasingly similar molecules.\nChromatography terms.\nChromatography is based on the concept of partition coefficient. Any solute partitions between two immiscible solvents. When we make one solvent immobile (by adsorption on a solid support matrix) and another mobile it results in most common applications of chromatography. If the matrix support, or stationary phase, is polar (e.g. paper, silica etc.) it is forward phase chromatography, and if it is non-polar (C-18) it is reverse phase.\nTechniques by chromatographic bed shape.\nColumn chromatography.\nColumn chromatography is a separation technique in which the stationary bed is within a tube. The particles of the solid stationary phase or the support coated with a liquid stationary phase may fill the whole inside volume of the tube (packed column) or be concentrated on or along the inside tube wall leaving an open, unrestricted path for the mobile phase in the middle part of the tube (open tubular column). Differences in rates of movement through the medium are calculated to different retention times of the sample.\nIn 1978, W. Clark Still introduced a modified version of column chromatography called \"flash column chromatography\" (flash). The technique is very similar to the traditional column chromatography, except that the solvent is driven through the column by applying positive pressure. This allowed most separations to be performed in less than 20 minutes, with improved separations compared to the old method. Modern flash chromatography systems are sold as pre-packed plastic cartridges, and the solvent is pumped through the cartridge. Systems may also be linked with detectors and fraction collectors providing automation. The introduction of gradient pumps resulted in quicker separations and less solvent usage.\nIn expanded bed adsorption, a fluidized bed is used, rather than a solid phase made by a packed bed. This allows omission of initial clearing steps such as centrifugation and filtration, for culture broths or slurries of broken cells.\nPhosphocellulose chromatography utilizes the binding affinity of many DNA-binding proteins for phosphocellulose. The stronger a protein's interaction with DNA, the higher the salt concentration needed to elute that protein.\nPlanar chromatography.\n\"Planar chromatography\" is a separation technique in which the stationary phase is present as or on a plane. The plane can be a paper, serving as such or impregnated by a substance as the stationary bed (paper chromatography) or a layer of solid particles spread on a support such as a glass plate (thin-layer chromatography). Different compounds in the sample mixture travel different distances according to how strongly they interact with the stationary phase as compared to the mobile phase. The specific Retention factor (Rf) of each chemical can be used to aid in the identification of an unknown substance.\nPaper chromatography.\nPaper chromatography is a technique that involves placing a small dot or line of sample solution onto a strip of \"chromatography paper\". The paper is placed in a container with a shallow layer of solvent and sealed. As the solvent rises through the paper, it meets the sample mixture, which starts to travel up the paper with the solvent. This paper is made of cellulose, a polar substance, and the compounds within the mixture travel further if they are less polar. More polar substances bond with the cellulose paper more quickly, and therefore do not travel as far.\nThin-layer chromatography (TLC).\nThin-layer chromatography (TLC) is a widely employed laboratory technique used to separate different biochemicals on the basis of their relative attractions to the stationary and mobile phases. It is similar to paper chromatography. However, instead of using a stationary phase of paper, it involves a stationary phase of a thin layer of adsorbent like silica gel, alumina, or cellulose on a flat, inert substrate. TLC is very versatile; multiple samples can be separated simultaneously on the same layer, making it very useful for screening applications such as testing drug levels and water purity. Possibility of cross-contamination is low since each separation is performed on a new layer. Compared to paper, it has the advantage of faster runs, better separations, better quantitative analysis, and the choice between different adsorbents. For even better resolution and faster separation that utilizes less solvent, high-performance TLC can be used. An older popular use had been to differentiate chromosomes by observing distance in gel (separation of was a separate step).\nDisplacement chromatography.\nThe basic principle of displacement chromatography is:\nA molecule with a high affinity for the chromatography matrix (the displacer) competes effectively for binding sites, and thus displaces all molecules with lesser affinities.\nThere are distinct differences between displacement and elution chromatography. In elution mode, substances typically emerge from a column in narrow, Gaussian peaks. Wide separation of peaks, preferably to baseline, is desired for maximum purification. The speed at which any component of a mixture travels down the column in elution mode depends on many factors. But for two substances to travel at different speeds, and thereby be resolved, there must be substantial differences in some interaction between the biomolecules and the chromatography matrix. Operating parameters are adjusted to maximize the effect of this difference. In many cases, baseline separation of the peaks can be achieved only with gradient elution and low column loadings. Thus, two drawbacks to elution mode chromatography, especially at the preparative scale, are operational complexity, due to gradient solvent pumping, and low throughput, due to low column loadings. Displacement chromatography has advantages over elution chromatography in that components are resolved into consecutive zones of pure substances rather than \"peaks\". Because the process takes advantage of the nonlinearity of the isotherms, a larger column feed can be separated on a given column with the purified components recovered at significantly higher concentrations.\nTechniques by physical state of mobile phase.\nGas chromatography.\nGas chromatography (GC), also sometimes known as gas-liquid chromatography, (GLC), is a separation technique in which the mobile phase is a gas. Gas chromatographic separation is always carried out in a column, which is typically \"packed\" or \"capillary\". Packed columns are the routine work horses of gas chromatography, being cheaper and easier to use and often giving adequate performance. Capillary columns generally give far superior resolution and although more expensive are becoming widely used, especially for complex mixtures. Both types of column are made from non-adsorbent and chemically inert materials. Stainless steel and glass are the usual materials for packed columns and quartz or fused silica for capillary columns.\nGas chromatography is based on a partition equilibrium of analyte between a solid or viscous liquid stationary phase (often a liquid silicone-based material) and a mobile gas (most often helium). The stationary phase is adhered to the inside of a small-diameter (commonly 0.53 \u2013 0.18mm inside diameter) glass or fused-silica tube (a capillary column) or a solid matrix inside a larger metal tube (a packed column). It is widely used in analytical chemistry; though the high temperatures used in GC make it unsuitable for high molecular weight biopolymers or proteins (heat denatures them), frequently encountered in biochemistry, it is well suited for use in the petrochemical, environmental monitoring and remediation, and industrial chemical fields. It is also used extensively in chemistry research.\nLiquid chromatography.\nLiquid chromatography (LC) is a separation technique in which the mobile phase is a liquid. It can be carried out either in a column or a plane. Present day liquid chromatography that generally utilizes very small packing particles and a relatively high pressure is referred to as high-performance liquid chromatography (HPLC).\nIn HPLC the sample is forced by a liquid at high pressure (the mobile phase) through a column that is packed with a stationary phase composed of irregularly or spherically shaped particles, a porous monolithic layer, or a porous membrane. HPLC is historically divided into two different sub-classes based on the polarity of the mobile and stationary phases. Methods in which the stationary phase is more polar than the mobile phase (e.g., toluene as the mobile phase, silica as the stationary phase) are termed normal phase liquid chromatography (NPLC) and the opposite (e.g., water-methanol mixture as the mobile phase and C18 (octadecylsilyl) as the stationary phase) is termed reversed phase liquid chromatography (RPLC).\nSpecific techniques under this broad heading are listed below.\nAffinity chromatography.\nAffinity chromatography is based on selective non-covalent interaction between an analyte and specific molecules. It is very specific, but not very robust. It is often used in biochemistry in the purification of proteins bound to tags. These fusion proteins are labeled with compounds such as His-tags, biotin or antigens, which bind to the stationary phase specifically. After purification, some of these tags are usually removed and the pure protein is obtained.\nAffinity chromatography often utilizes a biomolecule's affinity for a metal (Zn, Cu, Fe, etc.). Columns are often manually prepared. Traditional affinity columns are used as a preparative step to flush out unwanted biomolecules.\nHowever, HPLC techniques exist that do utilize affinity chromatography properties. Immobilized Metal Affinity Chromatography (IMAC) is useful to separate aforementioned molecules based on the relative affinity for the metal (i.e. Dionex IMAC). Often these columns can be loaded with different metals to create a column with a targeted affinity.\nSupercritical fluid chromatography.\nSupercritical fluid chromatography is a separation technique in which the mobile phase is a fluid above and relatively close to its critical temperature and pressure.\nTechniques by separation mechanism.\nIon exchange chromatography.\nIon exchange chromatography (usually referred to as ion chromatography) uses an ion exchange mechanism to separate analytes based on their respective charges. It is usually performed in columns but can also be useful in planar mode. Ion exchange chromatography uses a charged stationary phase to separate charged compounds including anions, cations, amino acids, peptides, and proteins. In conventional methods the stationary phase is an ion exchange resin that carries charged functional groups that interact with oppositely charged groups of the compound to retain. There are two types of ion exchange chromatography: Cation-Exchange and Anion-Exchange. In the Cation-Exchange Chromatography the stationary phase has negative charge and the exchangeable ion is a cation, whereas, in the Anion-Exchange Chromatography the stationary phase has positive charge and the exchangeable ion is an anion. Ion exchange chromatography is commonly used to purify proteins using FPLC.\nSize-exclusion chromatography.\nSize-exclusion chromatography (SEC) is also known as \"gel permeation chromatography\" (GPC) or \"gel filtration chromatography\" and separates molecules according to their size (or more accurately according to their hydrodynamic diameter or hydrodynamic volume).\nSmaller molecules are able to enter the pores of the media and, therefore, molecules are trapped and removed from the flow of the mobile phase. The average residence time in the pores depends upon the effective size of the analyte molecules. However, molecules that are larger than the average pore size of the packing are excluded and thus suffer essentially no retention; such species are the first to be eluted. It is generally a low-resolution chromatography technique and thus it is often reserved for the final, \"polishing\" step of a purification. It is also useful for determining the tertiary structure and quaternary structure of purified proteins, especially since it can be carried out under native solution conditions.\nExpanded bed adsorption chromatographic separation.\nAn expanded bed chromatographic adsorption (EBA) column for a biochemical separation process comprises a pressure equalization liquid distributor having a self-cleaning function below a porous blocking sieve plate at the bottom of the expanded bed, an upper part nozzle assembly having a backflush cleaning function at the top of the expanded bed, a better distribution of the feedstock liquor added into the expanded bed ensuring that the fluid passed through the expanded bed layer displays a state of piston flow. The expanded bed layer displays a state of piston flow. The expanded bed chromatographic separation column has advantages of increasing the separation efficiency of the expanded bed.\nExpanded-bed adsorption (EBA) chromatography is a convenient and effective technique for the capture of proteins directly from unclarified crude sample. In EBA chromatography, the settled bed is first expanded by upward flow of equilibration buffer. The crude feed, a mixture of soluble proteins, contaminants, cells, and cell debris, is then passed upward through the expanded bed. Target proteins are captured on the adsorbent, while particulates and contaminants pass through. A change to elution buffer while maintaining upward flow results in desorption of the target protein in expanded-bed mode. Alternatively, if the flow is reversed, the adsorbed particles will quickly settle and the proteins can be desorbed by an elution buffer. The mode used for elution (expanded-bed versus settled-bed) depends on the characteristics of the feed. After elution, the adsorbent is cleaned with a predefined cleaning-in-place (CIP) solution, with cleaning followed by either column regeneration (for further use) or storage.\nSpecial techniques.\nReversed-phase chromatography.\nReversed-phase chromatography (RPC) is any liquid chromatography procedure in which the mobile phase is significantly more polar than the stationary phase. It is so named because in normal-phase liquid chromatography, the mobile phase is significantly less polar than the stationary phase. Hydrophobic molecules in the mobile phase tend to adsorb to the relatively hydrophobic stationary phase. Hydrophilic molecules in the mobile phase will tend to elute first. Separating columns typically comprise a C8 or C18 carbon-chain bonded to a silica particle substrate.\nHydrophobic interaction chromatography.\nHydrophobic interactions between proteins and the chromatographic matrix can be exploited to purify proteins. In hydrophobic interaction chromatography the matrix material is lightly substituted with hydrophobic groups. These groups can range from methyl, ethyl, propyl, octyl, or phenyl groups. At high salt concentrations, non-polar sidechains on the surface on proteins \"interact\" with the hydrophobic groups; that is, both types of groups are excluded by the polar solvent (hydrophobic effects are augmented by increased ionic strength). Thus, the sample is applied to the column in a buffer which is highly polar. The eluant is typically an aqueous buffer with decreasing salt concentrations, increasing concentrations of detergent (which disrupts hydrophobic interactions), or changes in pH.\nIn general, Hydrophobic Interaction Chromatography (HIC) is advantageous if the sample is sensitive to pH change or harsh solvents typically used in other types of chromatography but not high salt concentrations. Commonly, it is the amount of salt in the buffer which is varied. In 2012, M\u00fcller and Franzreb described the effects of temperature on HIC using Bovine Serum Albumin (BSA) with four different types of hydrophobic resin. The study altered temperature as to effect the binding affinity of BSA onto the matrix. It was concluded that cycling temperature from 50 to 10 degrees would not be adequate to effectively wash all BSA from the matrix but could be very effective if the column would only be used a few times. Using temperature to effect change allows labs to cut costs on buying salt and saves money.\nIf high salt concentrations along with temperature fluctuations want to be avoided you can use a more hydrophobic to compete with your sample to elute it. [source] This so-called salt independent method of HIC showed a direct isolation of Human Immunoglobulin G (IgG) from serum with satisfactory yield and used Beta-cyclodextrin as a competitor to displace IgG from the matrix. This largely opens up the possibility of using HIC with samples which are salt sensitive as we know high salt concentrations precipitate proteins.\nHydrodynamic chromatography.\nHydrodynamic chromatography (HDC) is derived from the observed phenomenon that large droplets move faster than small ones. In a column, this happens because the center of mass of larger droplets is prevented from being as close to the sides of the column as smaller droplets because of their larger overall size. Larger droplets will elute first from the middle of the column while smaller droplets stick to the sides of the column and elute last. This form of chromatography is useful for separating analytes by molar mass, size, shape, and structure when used in conjunction with light scattering detectors, viscometers, and refractometers. The two main types of HDC are open tube and packed column. Open tube offers rapid separation times for small particles, whereas packed column HDC can increase resolution and is better suited for particles with an average molecular mass larger than formula_1 daltons. HDC differs from other types of chromatography because the separation only takes place in the interstitial volume, which is the volume surrounding and in between particles in a packed column.\nHDC shares the same order of elution as Size Exclusion Chromatography (SEC) but the two processes still vary in many ways. In a study comparing the two types of separation, Isenberg, Brewer, C\u00f4t\u00e9, and Striegel use both methods for polysaccharide characterization and conclude that HDC coupled with multiangle light scattering (MALS) achieves more accurate molar mass distribution when compared to off-line MALS than SEC in significantly less time. This is largely due to SEC being a more destructive technique because of the pores in the column degrading the analyte during separation, which tends to impact the mass distribution. However, the main disadvantage of HDC is low resolution of analyte peaks, which makes SEC a more viable option when used with chemicals that are not easily degradable and where rapid elution is not important.\nHDC plays an especially important role in the field of microfluidics. The first successful apparatus for HDC-on-a-chip system was proposed by Chmela, et al. in 2002. Their design was able to achieve separations using an 80\u00a0mm long channel on the timescale of 3 minutes for particles with diameters ranging from 26 to 110\u00a0nm, but the authors expressed a need to improve the retention and dispersion parameters. In a 2010 publication by Jellema, Markesteijn, Westerweel, and Verpoorte, implementing HDC with a recirculating bidirectional flow resulted in high resolution, size based separation with only a 3\u00a0mm long channel. Having such a short channel and high resolution was viewed as especially impressive considering that previous studies used channels that were 80\u00a0mm in length. For a biological application, in 2007, Huh, et al. proposed a microfluidic sorting device based on HDC and gravity, which was useful for preventing potentially dangerous particles with diameter larger than 6 microns from entering the bloodstream when injecting contrast agents in ultrasounds. This study also made advances for environmental sustainability in microfluidics due to the lack of outside electronics driving the flow, which came as an advantage of using a gravity based device.\nTwo-dimensional chromatography.\nIn some cases, the selectivity provided by the use of one column can be insufficient to provide resolution of analytes in complex samples. Two-dimensional chromatography aims to increase the resolution of these peaks by using a second column with different physico-chemical (chemical classification) properties. Since the mechanism of retention on this new solid support is different from the first dimensional separation, it can be possible to separate compounds by two-dimensional chromatography that are indistinguishable by one-dimensional chromatography. Furthermore, the separation on the second dimension occurs faster than the first dimension. An example of a two-dimensional TLC separation is where the sample is spotted at one corner of a square plate, developed, air-dried, then rotated by 90\u00b0 and usually redeveloped in a second solvent system. Two-dimensional chromatography can be applied to GC or LC separations. This separation method can also be used in a heart-cutting approach, where specific regions of interest on the first dimension are selected for separation by the second dimension, or in a comprehensive approach, where all the analytes from the first dimension undergo the second dimension separation.\nSimulated moving-bed chromatography.\nThe simulated moving bed (SMB) technique is a variant of high performance liquid chromatography; it is used to separate particles and/or chemical compounds that would be difficult or impossible to resolve otherwise. This increased separation is brought about by a valve-and-column arrangement that is used to lengthen the stationary phase indefinitely.\nIn the moving bed technique of preparative chromatography the feed entry and the analyte recovery are simultaneous and continuous, but because of practical difficulties with a continuously moving bed, simulated moving bed technique was proposed. In the simulated moving bed technique instead of moving the bed, the sample inlet and the analyte exit positions are moved continuously, giving the impression of a moving bed.\nTrue moving bed chromatography (TMBC) is only a theoretical concept. Its simulation, SMBC is achieved by the use of a multiplicity of columns in series and a complex valve arrangement, which provides for sample and solvent feed, and also analyte and waste takeoff at appropriate locations of any column, whereby it allows switching at regular intervals the sample entry in one direction, the solvent entry in the opposite direction, whilst changing the analyte and waste takeoff positions appropriately as well.\nPyrolysis gas chromatography.\nPyrolysis\u2013gas chromatography\u2013mass spectrometry is a method of chemical analysis in which the sample is heated to decomposition to produce smaller molecules that are separated by gas chromatography and detected using mass spectrometry.\nPyrolysis is the thermal decomposition of materials in an inert atmosphere or a vacuum. The sample is put into direct contact with a platinum wire, or placed in a quartz sample tube, and rapidly heated to 600\u20131000\u00a0\u00b0C. Depending on the application even higher temperatures are used. Three different heating techniques are used in actual pyrolyzers: Isothermal furnace, inductive heating (Curie Point filament), and resistive heating using platinum filaments. Large molecules cleave at their weakest points and produce smaller, more volatile fragments. These fragments can be separated by gas chromatography. Pyrolysis GC chromatograms are typically complex because a wide range of different decomposition products is formed. The data can either be used as fingerprint to prove material identity or the GC/MS data is used to identify individual fragments to obtain structural information. To increase the volatility of polar fragments, various methylating reagents can be added to a sample before pyrolysis.\nBesides the usage of dedicated pyrolyzers, pyrolysis GC of solid and liquid samples can be performed directly inside Programmable Temperature Vaporizer (PTV) injectors that provide quick heating (up to 30\u00a0\u00b0C/s) and high maximum temperatures of 600\u2013650\u00a0\u00b0C. This is sufficient for some pyrolysis applications. The main advantage is that no dedicated instrument has to be purchased and pyrolysis can be performed as part of routine GC analysis. In this case quartz GC inlet liners have to be used. Quantitative data can be acquired, and good results of derivatization inside the PTV injector are published as well.\nFast protein liquid chromatography.\nFast protein liquid chromatography (FPLC), is a form of liquid chromatography that is often used to analyze or purify mixtures of proteins. As in other forms of chromatography, separation is possible because the different components of a mixture have different affinities for two materials, a moving fluid (the \"mobile phase\") and a porous solid (the stationary phase). In FPLC the mobile phase is an aqueous solution, or \"buffer\". The buffer flow rate is controlled by a positive-displacement pump and is normally kept constant, while the composition of the buffer can be varied by drawing fluids in different proportions from two or more external reservoirs. The stationary phase is a resin composed of beads, usually of cross-linked agarose, packed into a cylindrical glass or plastic column. FPLC resins are available in a wide range of bead sizes and surface ligands depending on the application.\nCountercurrent chromatography.\nCountercurrent chromatography (CCC) is a type of liquid-liquid chromatography, where both the stationary and mobile phases are liquids and the liquid stationary phase is held stagnant by a strong centrifugal force.\nHydrodynamic countercurrent chromatography (CCC).\nThe operating principle of CCC instrument requires a column consisting of an open tube coiled around a bobbin. The bobbin is rotated in a double-axis gyratory motion (a cardioid), which causes a variable gravity (G) field to act on the column during each rotation. This motion causes the column to see one partitioning step per revolution and components of the sample separate in the column due to their partitioning coefficient between the two immiscible liquid phases used. There are many types of CCC available today. These include HSCCC (High Speed CCC) and HPCCC (High Performance CCC). HPCCC is the latest and best-performing version of the instrumentation available currently.\nHydrostatic countercurrent chromatography or centrifugal partition chromatography (CPC).\nIn the CPC instrument, the column consists of a series of cells interconnected by ducts attached to a rotor. This rotor rotates on its central axis creating the centrifugal field necessary to hold the stationary phase in place. The separation process in CPC is governed solely by the partitioning of solutes between the stationary and mobile phases, which mechanism can be easily described using the partition coefficients (\"KD\") of solutes. CPC instruments are commercially available for laboratory, pilot, and industrial-scale separations with different sizes of columns ranging from some 10 milliliters to 10 liters volume.\nPeriodic counter-current chromatography.\nIn contrast to Counter current chromatography (see above), periodic counter-current chromatography (PCC) uses a solid stationary phase and only a liquid mobile phase. It thus is much more similar to conventional affinity chromatography than to counter current chromatography. PCC uses multiple columns, which during the loading phase are connected in line. This mode allows for overloading the first column in this series without losing product, which already breaks through the column before the resin is fully saturated. The breakthrough product is captured on the subsequent column(s). In a next step the columns are disconnected from one another. The first column is washed and eluted, while the other column(s) are still being loaded. Once the (initially) first column is re-equilibrated, it is re-introduced to the loading stream, but as last column. The process then continues in a cyclic fashion.\nChiral chromatography.\nChiral chromatography involves the separation of stereoisomers. In the case of enantiomers, these have no chemical or physical differences apart from being three-dimensional mirror images. Conventional chromatography or other separation processes are incapable of separating them. To enable chiral separations to take place, either the mobile phase or the stationary phase must themselves be made chiral, giving differing affinities between the analytes. Chiral chromatography HPLC columns (with a chiral stationary phase) in both normal and reversed phase are commercially available.\nAqueous normal-phase chromatography.\nAqueous normal-phase (ANP) chromatography is characterized by the elution behavior of classical normal phase mode (i.e. where the mobile phase is significantly less polar than the stationary phase) in which water is one of the mobile phase solvent system components. It is distinguished from hydrophilic interaction liquid chromatography (HILIC) in that the retention mechanism is due to adsorption rather than partitioning."}
{"id": "6330", "revid": "753665", "url": "https://en.wikipedia.org/wiki?curid=6330", "title": "Clement Martyn Doke", "text": "Clement Martyn Doke (16 May 1893 in Bristol, United Kingdom \u2013 24 February 1980 in East London, South Africa) was a South African linguist working mainly on African languages. Realizing that the grammatical structures of Bantu languages are quite different from those of European languages, he was one of the first African linguists of his time to abandon the Euro-centric approach to language description for a more locally grounded one. A most prolific writer, he published a string of grammars, several dictionaries, comparative work, and a history of Bantu linguistics.\nMissionary in Lambaland.\nThe Doke family had been engaged in missionary activity for the Baptist Church for some generations. His father Reverend Joseph J. Doke left England and travelled to South Africa in 1882, where he met and married Agnes Biggs. They returned to England, where Clement was born as the third of four children. The family moved to New Zealand and eventually returned to South Africa in 1903, where they later on settled in Johannesburg.\nAt the age of 18, Clement received a bachelor's degree from Transvaal University College in Pretoria (now the University of Pretoria). He decided to devote his life to missionary activity. In 1913, he accompanied his father on a tour of north-western Rhodesia, to an area called Lambaland, now known as Ilamba. It is situated at the watershed of the Congo and Zambesi rivers, part of the district lay in Northern Rhodesia and part in the Belgian Congo State. The Cape-Cairo Railway threaded through its eastern portion; otherwise, travelling mostly had to be done on foot.\nThe Reverend William Arthur Phillips of the Nyasa Industrial Mission in Blantyre had established a Baptist mission there in 1905, serving an area of and 50,000 souls. The Dokes were supposed to investigate, whether the mission in Lambaland could be taken over by the Baptist Union of South Africa. It was on this trip that Doke's father contracted enteric fever and died soon afterwards (Gandhi attended the memorial service and addressed the congregation). Clement assumed his father's role.\nThe South African Baptists decided to take over Kafulafuta Mission, while its founder Reverend Phillips remained as superintendent. Clement Doke returned to Kafulafuta as missionary in 1914, followed by his sister Olive two years later.\nThe Lamba language.\nAt first, Clement Doke was frustrated by his inability to communicate with the Lamba. The only written material available at the time was a translation of Jonah and a collection of 47 hymns. Soon he mastered the language and published his first book \"Ifintu Fyakwe Lesa\" (The Things of God, a Primer of Scripture Knowledge) in 1917. He enrolled in Johannesburg as the extension of Transvaal University College for an MA degree. His thesis was published as \"The Grammar of the Lamba language\". The book is couched in traditional grammatical terms as Doke had not yet established his innovative method of analysis and description for the Bantu languages. His later \"Textbook of Lamba Grammar\" is far superior in this respect.\nClement Doke was also interested in ethnology. In 1931 he compiled \"The Lambas of Northern Rhodesia\", which remains one of the outstanding ethnographic descriptions of the peoples of Central Africa. For Doke, literacy was part of the evangelisation since people had to be able to read to appreciate the message of the Bible, but it was only after his retirement that he completed the translation of the Bible into Lamba. It was published under the title of \"Amasiwi AwaLesa\" (The Words of God) in 1959.\nUniversity of the Witwatersrand.\nIn 1919 Doke married Hilda Lehmann, who accompanied him back to Lambaland. They both contracted malaria during their work and she was forbidden to return to Lambaland. Clement Doke also realised that his field work couldn't continue much longer and left in 1921. He was recruited by the newly founded University of the Witwatersrand. In order to secure a qualification as a lecturer, the family moved to England, where he registered at the School of Oriental and African Studies. His major languages were Lamba and Luba, but as no suitable examiner was available, he eventually had to change his language to Zulu.\nDoke took up his appointment in the new Department of Bantu Studies at the University of Witwatersrand in 1923. In 1925 he received his D. Litt. for his doctoral thesis \"The Phonetics of the Zulu Language\" and was promoted to Senior Lecturer. In 1931 he was appointed to the Chair of Bantu Studies and thus headed the Department of Bantu Studies. The Department acted as a catalyst for the admission of Africans to the University: as early as 1925 a limited number were admitted to the vacation course in African Studies. Doke supported the appointment of Benedict Wallet Vilakazi as member of the staff, as he believed a native speaker was essential for acquiring a language. This provoked a storm of criticism and controversy from the public. They both collaborated on the \"Zulu-English Dictionary\", first published in 1948. It is still one of the best examples of lexicography for any of the Bantu languages.\nAt the request of the government of Southern Rhodesia, Doke investigated the range of dialect diversity among the languages of the country and made recommendations for \"Unified Shona\". This formed the basis for Standard Shona. He devised a unified orthography based on the Zezuru, Karanga and Manyika dialects. However, Doke's orthography was never fully accepted and the South African government introduced an alternative, leaving Shona with two competing orthographies between 1935 and 1955.\nDuring his tenure Doke developed and promoted a method of linguistic analysis and description of the Bantu languages that was based upon the structure of these languages. The \"Dokean model\" continues to be one of the dominant models of linguistic description in Southern and Central Africa. His classification of the Bantu languages was for many years the dominant view of the interrelations among the African languages. He was also an early describer of Khoisan and Bantu click consonants, devising phonetic symbols for a number of them.\nDoke served the University of the Witwatersrand until his retirement in 1953. He was awarded the honorary degree of Doctor of Letters by Rhodes University and the honorary degree of Doctor of Laws by the University of the Witwatersrand in 1972.\nThe former missionary always remained devoted to the Baptist Church. He was elected President of the South African Baptist Union in 1949 and spent a year visiting churches and mission stations. He used his presidential address in condemning the recently established apartheid policy: \"I solemnly warn the Government that the spirit behind their apartheid legislation, and the way in which they are introducing discriminatory measures of all types today, will bring disaster upon this fair land of ours.\""}
{"id": "6331", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=6331", "title": "Carl Meinhof", "text": "Carl Friedrich Michael Meinhof (July 23, 1857 \u2013 February 11, 1944) was a German linguist and one of the first linguists to study African languages.\nEarly years and career.\nMeinhof was born in Barzwitz near R\u00fcgenwalde in the Province of Pomerania. He studied at the University of T\u00fcbingen and at the University of Greifswald. In 1905 he became professor at the School of Oriental Studies in Berlin. On 5 May 1933 he became a member of the Nazi Party.\nWorks.\nHis most notable work was developing comparative grammar studies of the Bantu languages, building on the pioneering work of Wilhelm Bleek. In his work, Meinhof looked at the common Bantu languages such as Swahili and Zulu to determine similarities and differences.\nIn his work, Meinhof looked at noun classes with all Bantu languages having at least 10 classes and with 22 classes of nouns existing throughout the Bantu languages, though his definition of noun class differs slightly from the accepted one, considering the plural form of a word as belonging to a different class from the singular form (thus leading, for example, to consider a language like French as having four classes instead of two). While no language has all 22 (later: 23) classes active, Venda has 20, Lozi has 18, and Ganda has 16 or 17 (depending on whether the locative class 23 \"e-\" is included). All Bantu languages have a noun class specifically for humans (sometimes including other animate beings).\nMeinhof also examined other African languages, including groups classified at the time as Kordofanian, Bushman, Khoikhoi, and Hamitic.\nMeinhof developed a comprehensive classification scheme for African languages. His classification was the standard one for many years (Greenberg 1955:3). It was replaced by those of Joseph Greenberg in 1955 and in 1963.\nIn 1902, Meinhof made recordings of East African music. These are among the first recordings made of traditional African music.\nControversial views.\nIn 1912, Carl Meinhof published \"Die Sprachen der Hamiten\" (The Languages of the Hamites). He used the term Hamitic. Meinhof's system of classification of the Hamitic languages was based on a belief that \"speakers of Hamitic became largely coterminous with cattle herding peoples with essentially Caucasian origins, intrinsically different from and superior to the 'Negroes of Africa'.\" However, in the case of the so-called Nilo-Hamitic languages (a concept he introduced), it was based on the typological feature of gender and a \"fallacious theory of language mixture.\" Meinhof did this in spite of earlier work by scholars such as Lepsius and Johnston demonstrating that the languages which he would later dub \"Nilo-Hamitic\" were in fact Nilotic languages with numerous similarities in vocabulary with other Nilotic languages.\nFamily.\nCarl Meinhof was the great-uncle (the brother of the grandfather) of Ulrike Meinhof, a founding member of the German Red Army Faction (RAF), a left-wing militant group, which operated in West Germany in the 1970s and 1980s."}
{"id": "6335", "revid": "2153309", "url": "https://en.wikipedia.org/wiki?curid=6335", "title": "Cucurbitaceae", "text": "The Cucurbitaceae, also called cucurbits or the gourd family, are a plant family consisting of about 965 species in around 95 genera, of which the most important to humans are:\nThe plants in this family are grown around the tropics and in temperate areas, where those with edible fruits were among the earliest cultivated plants in both the Old and New Worlds. The family Cucurbitaceae ranks among the highest of plant families for number and percentage of species used as human food. The name \"Cucurbitaceae\" comes to international scientific vocabulary from New Latin, from \"Cucurbita\", the type genus, + \"-aceae\", a standardized suffix for plant family names in modern taxonomy. The genus name comes from the Classical Latin word \"cucurbita\", \"gourd\".\nDescription.\nMost of the plants in this family are annual vines, but some are woody lianas, thorny shrubs, or trees (\"Dendrosicyos\"). Many species have large, yellow or white flowers. The stems are hairy and pentangular. Tendrils are present at 90\u00b0 to the leaf petioles at nodes. Leaves are exstipulate alternate simple palmately lobed or palmately compound. The flowers are unisexual, with male and female flowers on different plants (dioecious) or on the same plant (monoecious). The female flowers have inferior ovaries. The fruit is often a kind of modified berry called a pepo.\nFossil history.\nOne of the oldest fossil cucurbits so far is \u2020\"Cucurbitaciphyllum lobatum\" from the Paleocene epoch, found at Shirley Canal, Montana. It was described for the first time in 1924 by the paleobotanist Frank Hall Knowlton. The fossil leaf is palmate, trilobed with rounded lobal sinuses and an entire or serrate margin. It has a leaf pattern similar to the members of the genera \"Kedrostis\", \"Melothria\" and \"Zehneria\".\nClassification.\nTribal classification.\nThe most recent classification of Cucurbitaceae delineates 15 tribes:\nSystematics.\nModern molecular phylogenetics suggest the following relationships:\n! style=\"background:#F0F2F5\" |Detailed Cladogram showing Cucurbitaceae phylogeny"}
{"id": "6336", "revid": "1005015866", "url": "https://en.wikipedia.org/wiki?curid=6336", "title": "Chorded keyboard", "text": "A keyset or chorded keyboard (also called a chorded keyset, \"chord keyboard\" or \"chording keyboard\") is a computer input device that allows the user to enter characters or commands formed by pressing several keys together, like playing a \"chord\" on a piano. The large number of combinations available from a small number of keys allows text or commands to be entered with one hand, leaving the other hand free. A secondary advantage is that it can be built into a device (such as a pocket-sized computer or a bicycle handlebar) that is too small to contain a normal-sized keyboard.\nA chorded keyboard minus the board, typically designed to be used while held in the hand, is called a keyer. Douglas Engelbart introduced the chorded keyset as a computer interface in 1968 at what is often called \"The Mother of All Demos\".\nPrinciples of operation.\nEach key is mapped to a number and then can be mapped to a corresponding letter or command. By pressing two or more keys together the user can generate many combinations. In Engelbart's original mapping, he used five keys: 1, 2, 4, 8, 16. The keys were mapped as follows: a = 1, b = 2, c = 3, d = 4, and so on. If the user pressed keys 1 + 2 = 3 simultaneously, and then released the keys, the letter \"c\" appeared. Unlike pressing a chord on a piano, the chord is recognized only after all the keys or mouse buttons are released. Since Engelbart introduced the keyset, several different designs have been developed based on similar concepts.\nAs a crude example, each finger might control one key which corresponds to one bit in a byte, so that using seven keys and seven fingers, one could enter any character in the ASCII set\u2014if the user could remember the binary codes. Due to the small number of keys required, chording is easily adapted from a desktop to mobile environment.\nPractical devices generally use simpler chords for common characters (\"e.g.,\" Baudot), or may have ways to make it easier to remember the chords (\"e.g.,\" Microwriter), but the same principles apply. These portable devices first became popular with the wearable computer movement in the 1980s.\nThad Starner from Georgia Institute of Technology and others published numerous studies showing that two-handed chorded text entry was faster and yielded fewer errors than on a QWERTY keyboard. Currently stenotype machines hold the record for fastest word entry. Many stenotype users can reach 300 words per minute. However, stenographers typically train for three years before reaching professional levels of speed and accuracy.\nHistory.\nThe earliest known chord keyboard was part of the \"five-needle\" telegraph operator station, designed by Wheatstone and Cooke in 1836, in which any two of the five needles could point left or right to indicate letters on a grid. It was designed to be used by untrained operators (who would determine which keys to press by looking at the grid), and was not used where trained telegraph operators were available.\nThe first widespread use of a chord keyboard was in the stenotype machine used by court reporters, which was invented in 1868 and is still in use. The output of the stenotype was originally a phonetic code that had to be transcribed later (usually by the same operator who produced the original output), rather than arbitrary text\u2014automatic conversion software is now commonplace.\nIn 1874, the five-bit Baudot telegraph code and a matching 5-key chord keyboard was designed to be used with the operator forming the codes manually. The code is optimized for speed and low wear: chords were chosen so that the most common characters used the simplest chords. But telegraph operators were already using typewriters with QWERTY keyboards to \"copy\" received messages, and at the time it made more sense to build a typewriter that could generate the codes automatically, rather than making them learn to use a new input device.\nSome early keypunch machines used a keyboard with 12 labeled keys to punch the correct holes in paper cards. The numbers 0 through 9 were represented by one punch; 26 letters were represented by combinations of two punches, and symbols were represented by combinations of two or three punches.\nBraille (a writing system for the blind) uses either 6 or 8 tactile 'points' from which all letters and numbers are formed. When Louis Braille invented it, it was produced with a needle holing successively all needed points in a cardboard sheet. In 1892, Frank Haven Hall, superintendent of the Illinois Institute for the Education of the Blind, created the Hall Braille Writer, which was like a typewriter with 6 keys, one for each dot in a braille cell. The Perkins Brailler, first manufactured in 1951, uses a 6-key chord keyboard (plus a spacebar) to produce braille output, and has been very successful as a mass market affordable product. Braille, like Baudot, uses a number symbol and a shift symbol, which may be repeated for shift lock, to fit numbers and upper case into the 63 codes that 6 bits offer.\nAfter World War II, with the arrival of electronics for reading chords and looking in tables of \"codes\", the postal sorting offices started to research chordic solutions to be able to employ people other than trained and expensive typists. In 1954, an important concept was discovered: chordic production is easier to master when the production is done at the release of the keys instead of when they are pressed.\nResearchers at IBM investigated chord keyboards for both typewriters and computer data entry as early as 1959, with the idea that it might be faster than touch-typing if some chords were used to enter whole words or parts of words. A 1975 design by IBM Fellow Nat Rochester had 14 keys that were dimpled on the edges as well as the top, so one finger could press two adjacent keys for additional combinations. Their results were inconclusive, but research continued until at least 1978.\nDoug Engelbart began experimenting with keysets to use with the mouse in the mid 1960s. In a famous 1968 demonstration, Engelbart introduced a computer human interface that included the QWERTY keyboard, a three button mouse, and a five key keyset. Engelbart used the keyset with his left hand and the mouse with his right to type text and enter commands. The mouse buttons marked selections and confirmed or aborted commands.\nUsers in Engelbart's Augmentation Research Center at SRI became proficient with the mouse and keyset. In the 1970s the funding Engelbart's group received from the Advanced Research Projects Agency (ARPA) was cut and many key members of Engelbart's team went to work for Xerox PARC where they continued to experiment with the mouse and keyset. Keychord sets were used at Xerox PARC in the early 1980s, along with mice, GUIs, on the Xerox Star and Alto workstations. A one button version of the mouse was incorporated into the Apple Macintosh but Steve Jobs decided against incorporating the chorded keyset.\nIn the early 1980s, Philips Research labs at Redhill, Surrey did a brief study into small, cheap keyboards for entering text on a telephone. One solution used a grid of hexagonal keys with symbols inscribed into dimples in the keys that were either in the center of a key, across the boundary of two keys, or at the joining of three keys. Pressing down on one of the dimples would cause either one, two or three of the hexagonal buttons to be depressed at the same time, forming a chord that would be unique to that symbol. With this arrangement, a nine button keyboard with three rows of three hexagonal buttons could be fitted onto a telephone and could produce up to 33 different symbols. By choosing widely separated keys, one could employ one dimple as a 'shift' key to allow both letters and numbers to be produced. With eleven keys in a 3/4/4 arrangement, 43 symbols could be arranged allowing for lowercase text, numbers and a modest number of punctuation symbols to be represented along with a 'shift' function for accessing uppercase letters. While this had the advantage of being usable by untrained users via 'hunt and peck' typing and requiring one less key switch than a conventional 12 button keypad, it had the disadvantage that some symbols required three times as much force to depress them as others which made it hard to achieve any speed with the device. That solution is still alive and proposed by Fastap and Unitap among others, and a commercial phone has been produced and promoted in Canada during 2006.\nStandards.\nHistorically, the baudot and braille keyboards were standardized to some extent, but they are unable to replicate the full character set of a modern keyboard. Braille comes closest, as it has been extended to eight bits.\nThe only proposed modern standard, GKOS (or Global Keyboard Open Standard) can support most characters and functions found on a computer keyboard but has had little commercial development. There is, however, a GKOS keyboard application available for iPhone since May 8, 2010, for Android since October 3, 2010 and for MeeGo Harmattan since October 27, 2011.\nOpen-source designs.\nFour open-source keyer/keyset designs are available: The pickey, a PS/2 device based on the PIC microcontroller; the spiffchorder, a USB device based on the Atmel AVR family of microcontrollers; the FeatherChorder, a BLE chorder based on the Adafruit Feather, an all-in-one board incorporating an Arduino-compatible microcontroller; and the GKOS keypad driver for Linux as well as the Gkos library for the Atmel/Arduino open-source board.\nPlover is a free, open-source, cross-platform program intended to bring real-time stenographic technology not just to stenographers, but also to hobbyists using anything from professional Stenotype machines to low-cost NKRO gaming keyboards. It is available for GNU/Linux, Microsoft Windows, and Apple Mac macOS.\nJoy2chord is a chorded keyboard driver for GNU/Linux. With a configuration file, any joystick or gamepad can be turned into a chorded keyboard. This design philosophy was decided on to lower the cost of building devices, and in turn lower the entry barrier to becoming familiar with chorded keyboards. Macro keys, and multiple modes are also easily implemented with a user space driver.\nCommercial devices.\nOne minimal chordic keyboard example is Edgar Matias' Half-Qwerty keyboard described in patent circa 1992 that produces the letters of the missing half when the user simultaneously presses the space bar along with the mirror key. INTERCHI '93 published a study by Matias, MacKenzie and Buxton showing that people who have already learned to touch-type can quickly recover 50 to 70% of their two-handed typing speed. The loss contributes to the speed discussion above. It is implemented on two popular mobile phones, each provided with software disambiguation, which allows users to avoid using the space-bar.\n\"Multiambic\" keyers for use with wearable computers were invented in Canada in the 1970s. Multiambic keyers are similar to chording keyboards but without the board, in that the keys are grouped in a cluster for being handheld, rather than for sitting on a flat surface.\nChording keyboards are also used as portable but two handed input devices for the visually impaired (either combined with a refreshable braille display or vocal synthesis). Such keyboards use a minimum of seven keys, where each key corresponds to an individual braille point, except one key which is used as a spacebar. In some applications, the spacebar is used to produce additional chords which enable the user to issue editing commands, such as moving the cursor, or deleting words. Note that the number of points used in braille computing is not 6, but 8, as this allows the user, among other things, to distinguish between small and capital letters, as well as identify the position of the cursor. As a result, most newer chorded keyboards for braille input include at least nine keys.\nTouch screen chordic keyboards are available to smartphone users as an optional way of entering text. As the number of keys is low the button areas can be made bigger and easier to hit on the small screen. The most common letters do not necessarily require chording as is the case with the GKOS keyboard optimised layouts (Android app) where the twelve most frequent characters only require single keys.\nHistorical.\nThe WriteHander, a 12-key chord keyboard from NewO Company, appeared in 1978 issues of ROM Magazine, an early microcomputer applications magazine.\nAnother early commercial model was the six-button Microwriter, designed by Cy Endfield and Chris Rainey, and first sold in 1980. Microwriting is the system of chord keying and is based on a set of mnemonics. It was designed only for right-handed use.\nIn 1982 the Octima 8 keys cord keyboard was presented by Ergoplic Kebords Ltd an Israeli Startup that was founded by Israeli researcher with intensive experience in Man Machine Interface design. The keyboard had 8 keys one for each finger and additional 3 keys that enabled the production of numbers, punctuations and control functions. The keyboard was fully compatible with the IBM PC &amp; AT keyboards and had an Apple IIe version as well. Its key combinations were based on a mnemonic system that enabled fast and easy touch type learning. Within a few hours the user could achieve a typing speed similar to hand writing speed. The unique design also gave a relief from hand stress (Carpal Tunnel Syndrome) and allowed longer typing sessions than traditional keyboards. It was multi-lingual supporting English, German, French and Hebrew.\nThe BAT is a 7-key hand-sized device from Infogrip, and has been sold since 1985. It provides one key for each finger and three for the thumb. It is proposed for the hand which does not hold the mouse, in an exact continuation of Engelbart's vision.\nModern.\nModern examples of chorded keyboards include TipTapSpeech (using Engelbart's original mapping), the GKOS keyboard, the FrogPad, the In10did method, the EkaPad, TextFaster and HotTyper. Some of them are intended for tiny tablet computers and wireless mobile terminals, many of them are additionally available as apps on Apple's iOS devices. See also the on-screen virtual keyset at Teague Labs.\nCyKey.\nChris Rainey, the co-inventor of Microwriter, re-introduced Microwriting for PC and Palm PDAs with a standalone miniature chording keyboard called CyKey which caters to both left and right-handed users, being 9-keys. CyKey (pronounced sai-ki) is named after the Microwriter chord system's co-inventor Cy Endfield, who died in 1995 but the name also reflects its intuitive nature.\nSiWriter.\nThe SiWriter is an app for the iPad and iPhone which uses a close variant of the microwriter chording system developed by Cy Enfield. It is available via the Apple app store. More information can be found at The system is let down by the lack of haptic feedback - you can't tell if your fingers are in the right place without looking. The finger pad positions are adjustable to fit your hand size. It also works for left handed users and has a live speech output facility that could be helpful for people with speech impairments.\nGKOS and ComboKey.\nThe GKOS is a 6-key keyboard with a different signs and commands allocation of the 63 different chords in order to provide all PC keyboard functions and to make entering letters and numbers lighter by having to press fewer keys simultaneously. The \"6 physical keys\" are intended to be on the back of the device and to be operated with the six free fingers of two hands holding the device. Another option is to have virtual GKOS keys positioned towards the sides of a touch sensitive screen. This GKOS for thumbs has additional keys to enable all combos by only one keypress per hand. GKOS iPhone, Android phone/tablet and MeeGo Harmattan applications use this principle.\nGKOS has been further developed under name ComboKey to better suit the touch screens of smartphones.\nEkaPad.\nThe EkaPad is a 12-key chorded keyboard operated with the four fingers of one hand. It is supported on the thumb. With the 9 main keys, (operated by the index, middle, and ring fingers), 2 prefix keys and one delete key, the EkaPad can produce all the inputs of a standard qwerty keyboard with one, two, and a few three finger chords. For some characters one or two prefix chords are required. 9 main keys (3\u00d73 matrix) can produce a total of 511 chords. With each of the three fingers limited to its own row, 229 chords are possible with 3 fingers. EkaPad uses 66 of these accessible chords. One and two finger chords produce about 85% of American English; with an additional prefix chord about 97%. In addition, the EkaPad can store 100 text strings and 100 keyboard shortcuts. Like many other chorded keyboards, it can be used with one hand.\nEkaPads are no longer manufactured at this writing.\nFrogPad.\nThe FrogPad is a 20-key chorded keyboard about the size of a numeric keypad that can be used with one hand, and is optimized by character frequency. 85% of average keystrokes in English text can be typed without chording, and chords are limited to 2 fingers.\nDecatxt.\nThe Decatxt keyboard uses the IN10DID 10 key chording method[29] (pronounced \"intended\"), and is currently on Amazon. It is a wireless one-handed chord keyboard that places two keys under each finger in order to utilize one hand for typing. Typically only two fingers are needed for any operations. Each key is essentially a shift key so that with ten keys, there are ten single keystrokes and dozens of two and three key combinations. The alphabet is produced with a single press for ten letters or by shifting with either thumb for sixteen more. Changing modes, such as number lock, can make other input such as numbers, provided with a single keystroke. This avoids complex chords while providing enough keystrokes for efficient typing and allows for some unique implementations such as typing with gloves or on a steering wheel. A video game controller called the X-SKIN, using this system, was expected to be commercially available by 2010 to help make Morphs popular on console systems and ease entry of common data such as a username and password, but the USB device was never made commercially available. The IN10DID chording system can be applied in single hand configurations, two handed or with one key at a time if desired. Claimed advantages of the IN10DID method are the diversity of devices, limited motion and simple chords.\nTwiddler.\nThe Twiddler is a fully featured 16-key keyboard (plus mouse) designed to fit in the palm of one hand. It was originally introduced in the early 1990s by Handykey and is currently being produced by Tek Gear (Tek Gear acquired Handykey on April 30, 2008). It is popular among wearable computer researchers and hobbyists due to its ease of use, large community of users, and active support by the manufacturer. Every single and multi-key chord on the Twiddler can be customized by the end user. The Twiddler comes standard with an \"A, B, C, D\" chord set, with TabSpace and other chord sets available. Chords are not limited to single keystrokes - multiple keystrokes can be sent with a single chord press. An example of this is an email address or address block can be typed by pressing just one chord. The efficiency gained by using multi-character chords have novice Twiddler users typing at 47 WPM while experts can burst up to 130 WPM.\nASETNIOP.\nASETNIOP is a virtual keyboard based on chords that appeared in 2012. The alphabet uses the 8 keys of the home row as ASET and NIOP (the most commonly typed key for each finger when touch-typing on a QWERTY keyboard in English), plus 18 chorded combinations. The layout also makes a less-cluttered 10-button keypad for tablet computers, touchscreens, touchpads, and can be used in wired gloves."}
{"id": "6337", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=6337", "title": "Carolyn Beug", "text": "Carolyn Ann Mayer-Beug (December 11, 1952 \u2013 September 11, 2001) was a filmmaker and video producer from Santa Monica, California. She died in the September 11 attacks.\nCareer.\nIn addition to her work as video producer, Beug also directed three music videos for country singer Dwight Yoakam: \"Ain't That Lonely Yet\", \"A Thousand Miles from Nowhere\" and \"Fast as You.\" Beug co-directed the former two videos with Yoakam and was the sole director of the latter video. She won an MTV Video Music award for the Van Halen music video of the song \"Right Now\", which she produced. She also served as senior vice president of Walt Disney Records.\nPersonal life.\nBeug lived in a Tudor-style home in the North 25th Street neighborhood. She hosted an annual backyard barbecue for the Santa Monica High School cross country and track team, which her daughters captained. Beug was a Latter-day Saint.\nDeath and legacy.\nBeug was killed at the age of 48 in the crash of American Airlines Flight 11 in the September 11, 2001 attacks. At the time of her death, Carolyn Beug was working on a children's book about Noah's Ark which was to be told from Noah's wife's point of view. On the plane with her was her mother, Mary Alice Wahlstrom. Beug was survived by her twin eighteen-year-old daughters Lauren and Lindsey Mayer-Beug, her 13-year-old son, Nick, and her husband, John Beug, a senior vice president in charge of filmed production for Warner Brothers' record division. She was returning home from taking her daughters to college at the Rhode Island School of Design.\nAt the National 9/11 Memorial, Beug is memorialized at the North Pool, on Panel N-1."}
{"id": "6339", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6339", "title": "Cell biology", "text": "Cell biology (also cellular biology or cytology) is a branch of biology studying the structure and function of the cell, also known as the basic unit of life. Cell biology encompasses both prokaryotic and eukaryotic cells and can be divided into many sub-topics which may include the study of cell metabolism, cell communication, cell cycle, biochemistry, and cell composition. The study of cells is performed using several techniques such as cell culture, various types of microscopy, and cell fractionation. These have allowed for and are currently being used for discoveries and research pertaining to how cells function, ultimately giving insight into understanding larger organisms. Knowing the components of cells and how cells work is fundamental to all biological sciences while also being essential for research in biomedical fields such as cancer, and other diseases. Research in cell biology is interconnected to other fields such as genetics, molecular genetics, biochemistry, molecular biology, medical microbiology, immunology, and cytochemistry.\nHistory.\nCells were first seen in 17th century Europe with the invention of the compound microscope. In 1665, Robert Hooke termed the building block of all living organisms as \"cells\" after looking at a piece of cork and observing a cell-like structure, however, the cells were dead and gave no indication to the actual overall components of a cell. A few years later, in 1674, Anton Van Leeuwenhoek was the first to analyze live cells in his examination of algae. All of this preceded the cell theory which states that all living things are made up of cells and that cells are the functional and structural unit of organisms. This was ultimately concluded by plant scientist, Matthias Schleiden and animal scientist, Theodor Schwann in 1838, who viewed live cells in plant and animal tissue, respectively. 19 years later, Rudolf Virchow further contributed to the cell theory, adding that all cells come from the division of pre-existing cells. Although widely accepted, there have been many studies that question the validity of the cell theory. Viruses, for example, lack common characteristics of a living cell, such as membranes, cell organelles, and the ability to reproduce by themselves. Scientists have struggled to decide whether viruses are alive or not and whether they are in agreement with the cell theory.\nTechniques.\nModern-day cell biology research looks at different ways to culture and manipulate cells outside of a living body to further research in human anatomy and physiology, and to derive medications. The techniques by which cells are studied have evolved. Due to advancements in microscopy, techniques and technology have allowed for scientists to hold a better understanding of the structure and function of cells. Many techniques commonly used to study cell biology are listed below:\nCell classification and composition.\nThere are two fundamental classifications of cells: prokaryotic and eukaryotic. Prokaryotic cells are distinguished from eukaryotic cells by the absence of a cell nucleus or other membrane bound organelle. Prokaryotic cells are much smaller than eukaryotic cells, making them the smallest form of life. The study of eukaryotic cells is typically the main focus of cytologists, whereas prokaryotic cells are the focus of microbiologists.\nProkaryotic cells.\nProkaryotic cells include Bacteria and Archaea, and lack an enclosed cell nucleus. They both reproduce through binary fission. Bacteria, the most prominent type, have several different shapes which include mainly spherical, and rod-shaped. Bacteria can be classed as either gram positive or gram negative depending on the cell wall composition. Bacterial structural features include:\nThere are many process that occur in prokaryotic cells that allow them to survive. For instance, in a process termed conjugation, fertility factor allows the bacteria to possess a pilus which allows it to transmit DNA to another bacteria which lacks the F factor, permitting the transmittance of resistance allowing it to survive in certain environments.\nEukaryotic cells.\nEukaryotic cells can either be unicellular or multicellular and include animal, plant, fungi, and protozoa cells which all contain organelles with various shapes and sizes. These cells are composed of the following organelles:\nEukaryotic cells may also be composed of the following molecular components:\nProcesses.\nCell metabolism.\nCell metabolism is necessary for the production of energy for the cell and therefore its survival and includes many pathways. For cellular respiration, once glucose is available, glycolysis occurs within the cytosol of the cell to produce pyruvate. Pyruvate undergoes decarboxylation using the multi-enzyme complex to form acetyl coA which can readily be used in the TCA cycle to produce NADH and FADH2. These products are involved in the electron transport chain to ultimately form a proton gradient across the inner mitochondrial membrane. This gradient can then drive the production of ATP and H2O during oxidative phosphorylation. Metabolism in plant cells includes photosynthesis which is simply the exact opposite of respiration as it ultimately produces molecules of glucose.\nCell communication and signaling.\nCell communication is important for cell regulation and for cells to process information from the environment and respond accordingly. Communication can occur through direct cell contact or endocrine, paracrine, and autocrine signaling. Direct cell-cell contact is when a receptor on a cell binds a molecule that is attached to the membrane of another cell. Endocrine signaling occurs through molecules secreted into the bloodstream. Paracrine signaling uses molecules diffusing between two cells to communicate. Autocrine is a cell sending a signal to itself by secreting a molecule that binds to a receptor on its surface. Forms of communication can be through:\nCell cycle.\nThe growth process of the cell does not refer to the size of the cell, but the density of the number of cells present in the organism at a given time. Cell growth pertains to the increase in the number of cells present in an organism as it grows and develops; as the organism gets larger so does the number of cells present. Cells are the foundation of all organisms and are the fundamental unit of life. The growth and development of cells are essential for the maintenance of the host and survival of the organism. For this process, the cell goes through the steps of the cell cycle and development which involves cell growth, DNA replication, cell division, regeneration, and cell death. The cell cycle is divided into four distinct phases: G1, S, G2, and M. The G phase \u2013 which is the cell growth phase \u2013 makes up approximately 95% of the cycle. The proliferation of cells is instigated by progenitors. All cells start out in an identical form and can essentially become any type of cells. Cell signaling such as induction can influence nearby cells to differentiate determinate the type of cell it will become. Moreover, this allows cells of the same type to aggregate and form tissues, then organs, and ultimately systems. The G1, G2, and S phase (DNA replication, damage and repair) are considered to be the interphase portion of the cycle, while the M phase (mitosis) is the cell division portion of the cycle. Mitosis is composed of many stages which include, prophase, metaphase, anaphase, telophase, and cytokinesis, respectively. The ultimate result of mitosis is the formation of two identical daughter cells.\nThe cell cycle is regulated by a series of signaling factors and complexes such as cyclins, cyclin-dependent kinase, and p53. When the cell has completed its growth process and if it is found to be damaged or altered, it undergoes cell death, either by apoptosis or necrosis, to eliminate the threat it can cause to the organism's survival.\nPathology.\nThe scientific branch that studies and diagnoses diseases on the cellular level is called cytopathology. Cytopathology is generally used on samples of free cells or tissue fragments, in contrast to the pathology branch of histopathology, which studies whole tissues. Cytopathology is commonly used to investigate diseases involving a wide range of body sites, often to aid in the diagnosis of cancer but also in the diagnosis of some infectious diseases and other inflammatory conditions. For example, a common application of cytopathology is the Pap smear, a screening test used to detect cervical cancer, and precancerous cervical lesions that may lead to cervical cancer."}
{"id": "6340", "revid": "32218334", "url": "https://en.wikipedia.org/wiki?curid=6340", "title": "Canadian English", "text": "Canadian English (CanE, CE, en-CA) is the set of varieties of the English language native to Canada. According to the 2016 census, English was the first language of more than 19.4 million Canadians or 58.1% of the total population; the remainder of the population were native speakers of Canadian French (20.8%) or other languages (21.1%). A larger number, 28 million people, reported using English as their dominant language. Of Canadians outside the province of Quebec, 82% reported speaking English natively, but within Quebec the figure was just 7.5% as most of its residents are native speakers of Quebec French.\nCanadian English contains major elements of both British and American English, as well as some uniquely Canadian characteristics. While Canadian English tends to be closer to American English in most regards, the precise influence of American English, British English and other sources on Canadian English varieties has been the ongoing focus of systematic studies since the 1950s.\nPhonologically, Canadian and American English are classified together as North American English, emphasizing the fact that the vast majority of outsiders, even other native English speakers, cannot distinguish the typical accents of the two countries by sound alone. Canadians and Americans themselves sometimes have trouble differentiating their own two accents, particularly when the Canadian accent in question is Standard Canadian English: the mainstream mainland variety. There is even evidence that Standard Canadian English and some Western American English (Pacific Northwest and California English, for example) are undergoing a very similar vowel shift, since the 1980s. Most Canadian accents outside of Standard Canadian English fall under Atlantic Canadian English.\nHistory.\nThe term \"Canadian English\" is first attested in a speech by the Reverend A. Constable Geikie in an address to the Canadian Institute in 1857 (see DCHP-1 Online, s.v. \"Canadian English\", Avis \"et al.,\" 1967). Geikie, a Scottish-born Canadian, reflected the Anglocentric attitude that would be prevalent in Canada for the next hundred years when he referred to the language as \"a corrupt dialect\", in comparison with what he considered the proper English spoken by immigrants from Britain.\nCanadian English is the product of five waves of immigration and settlement over a period of more than two centuries. The first large wave of permanent English-speaking settlement in Canada, and linguistically the most important, was the influx of Loyalists fleeing the American Revolution, chiefly from the Mid-Atlantic States\u2014as such, Canadian English is believed by some scholars to have derived from northern American English. Canadian English has been developing features of its own since the early 19th century. The second wave from Britain and Ireland was encouraged to settle in Canada after the War of 1812 by the governors of Canada, who were worried about American dominance and influence among its citizens. Further waves of immigration from around the globe peaked in 1910, 1960 and at the present time had a lesser influence, but they did make Canada a multicultural country, ready to accept linguistic change from around the world during the current period of globalization.\nThe languages of Aboriginal peoples in Canada started to influence European languages used in Canada even before widespread settlement took place, and the French of Lower Canada provided vocabulary, with words such as \"toque\" and \"portage\", to the English of Upper Canada.\nWhile the process of the making of Canadian English\u2014its documentation and codification\u2014goes back to the 1930s, the 1960s were the key period. Like other social developments in Canada, the general acceptance of Canadian English has taken its time. According to a recent study, a noticeable shift in public discourse can only be seen in the middle of the first decade of the 2000s, when Canadian English was seen as a \"given\", generally accepted default variety, while before such statements were usually \"balanced\" by doubts.\nHistorical linguistics.\nStudies on earlier forms of English in Canada are rare, yet connections with other work to historical linguistics can be forged. An overview of diachronic work on Canadian English, or diachronically relevant work, is Dollinger (2012, updated to 2017). Until the 2000s, basically all commentators on the history of CanE have argued from the \"language-external\" history, i.e. social and political history. An exception has been in the area of lexis, where Avis \"et al.\"'s 1967 \"Dictionary of Canadianisms on Historical Principles\" offered real-time historical data through its quotations. Recently, historical linguists have started to study earlier Canadian English with historical linguistic data. DCHP-1 is now available in open access. Most notably, Dollinger (2008) pioneered the historical corpus linguistic approach for English in Canada with CONTE (Corpus of Early Ontario English, 1776\u20131849) and offers a developmental scenario for 18th- and 19th-century Ontario. Recently, Reuter (2015), with a 19th-century newspaper corpus from Ontario, has confirmed the scenario laid out in Dollinger (2008).\n Historically, Canadian English included a class-based sociolect known as \"Canadian dainty\". Treated as a marker of upper-class prestige in the 19th and early 20th centuries, Canadian dainty was marked by the use of some features of British English pronunciation, resulting in an accent similar, but not identical, to the Mid-Atlantic accent known in the United States. This accent faded in prominence following World War II, when it became stigmatized as pretentious, and is now almost never heard in modern Canadian life outside of archival recordings used in film, television or radio documentaries.\nOrthography.\nCanadian spelling of the English language combines British and American conventions, the two dominant varieties, and adds some domestic idiosyncrasies. Spelling in Canadian English co-varies with regional and social variables, somewhat more so, perhaps, than in the two dominant varieties of English, yet general trends have emerged since the 1970s.\nCanadian spelling conventions can be partly explained by Canada's trade history. For instance, the British spelling of the word \"cheque\" probably relates to Canada's once-important ties to British financial institutions. Canada's automobile industry, on the other hand, has been dominated by American firms from its inception, explaining why Canadians use the American spelling of \"tire\" (hence, \"Canadian Tire\") and American terminology for automobiles and their parts (for example, \"truck\" instead of \"lorry\", \"gasoline\" instead of \"petrol\", \"trunk\" instead of \"boot\").\nCanada's political history has also had an influence on Canadian spelling. Canada's first prime minister, John A. Macdonald, once advised the Governor General of Canada to issue an order-in-council directing that government papers be written in the British style.\nA contemporary reference for formal Canadian spelling is the spelling used for Hansard transcripts of the Parliament of Canada . Many Canadian editors, though, use the \"Canadian Oxford Dictionary\", often along with the chapter on spelling in \"Editing Canadian English\", and, where necessary (depending on context), one or more other references. \nThroughout part of the 20th century, some Canadian newspapers adopted American spellings, for example, \"color\" as opposed to the British-based \"colour\". Some of the most substantial historical spelling data can be found in Dollinger (2010) and Grue (2013). The use of such spellings was the long-standing practice of the Canadian Press perhaps since that news agency's inception, but visibly the norm prior to World War II. The practice of dropping the letter \"u\" in such words was also considered a labour-saving technique during the early days of printing in which movable type was set manually. Canadian newspapers also received much of their international content from American press agencies, therefore it was much easier for editorial staff to leave the spellings from the wire services as provided.\nIn the 1990s, Canadian newspapers began to adopt the British spelling variants such as \"-our\" endings, notably with \"The Globe and Mail\" changing its spelling policy in October 1990. Other Canadian newspapers adopted similar changes later that decade, such as the Southam newspaper chain's conversion in September 1998. The \"Toronto Star\" adopted this new spelling policy in September 1997 after that publication's ombudsman discounted the issue earlier in 1997. The \"Star\" had always avoided using recognized Canadian spelling, citing the \"Gage Canadian Dictionary\" in their defence. Controversy around this issue was frequent. When the \"Gage Dictionary\" finally adopted standard Canadian spelling, the \"Star\" followed suit. Some publishers, e.g. \"Maclean's\", continue to prefer American spellings.\nDictionaries.\nThe first Canadian dictionaries of Canadian English were edited by Walter Spencer Avis and published by Gage Ltd. The \"Beginner's Dictionary\" (1962), the \"Intermediate Dictionary\" (1964) and, finally, the \"Senior Dictionary\" (1967) were milestones in Canadian English lexicography. In November 1967 A Dictionary of Canadianisms on Historical Principles (DCHP) was published and completed the first edition of Gage's Dictionary of Canadian English Series. The DCHP documents the historical development of Canadian English words that can be classified as \"Canadianisms\". It therefore includes words such as mukluk, Canuck, and bluff, but does not list common core words such as desk, table or car. Many secondary schools in Canada use the graded dictionaries. The dictionaries have regularly been updated since: the \"Senior Dictionary,\" edited by Robert John Gregg, was renamed \"Gage Canadian Dictionary\". Its fifth edition was printed beginning in 1997. Gage was acquired by Thomson Nelson around 2003. The latest editions were published in 2009 by HarperCollins. On 17 March 2017 a second edition of DCHP, the online Dictionary of Canadianisms on Historical Principles 2 (DCHP-2), was published. DCHP-2 incorporates the c. 10\u200a000 lexemes from DCHP-1 and adds c. 1\u200a300 novel meanings or 1\u200a002 lexemes to the documented lexicon of Canadian English.\nIn 1997, the \"ITP Nelson Dictionary of the Canadian English Language\" was another product, but has not been updated since.\nIn 1998, Oxford University Press produced a Canadian English dictionary, after five years of lexicographical research, entitled \"The Oxford Canadian Dictionary\". A second edition, retitled \"The Canadian Oxford Dictionary\", was published in 2004. Just as the older dictionaries it includes uniquely Canadian words and words borrowed from other languages, and surveyed spellings, such as whether \"colour\" or \"color\" was the more popular choice in common use. Paperback and concise versions (2005, 2006), with minor updates, are available.\nPhonology and phonetics.\nIn terms of the major sound systems (phonologies) of English around the world, Canadian English aligns most closely to American English, both being grouped together under a common North American English sound system; the mainstream Canadian accent (\"Standard Canadian\") is often compared to the very similar and largely overlapping \"General American\" accent, an accent widely spoken throughout the United States and perceived there as being relatively lacking in any noticeable regional features.\nThe provinces east of Ontario show the largest dialect diversity. Northern Canada is, according to William Labov, a dialect region in formation, and a homogeneous English dialect has not yet formed. A very homogeneous dialect exists in Western and Central Canada, a situation that is similar to that of the Western United States. Labov identifies an \"Inland Canada\" region that concentrates all of the defining features of the dialect centred on the Prairies, with periphery areas with more variable patterns including the metropolitan areas of Vancouver and Toronto. This dialect forms a dialect continuum with the far Western US English; however, it is sharply differentiated from the Inland Northern US English of the central and eastern Great Lakes region.\nCanadian English raises the diphthong onsets /\u0259, \u028c/ before voiceless segments; diphthongs /ai/ and /au/.\nStandard Canadian English.\nStandard Canadian English is socially defined. It is the variety spoken, in Chamber's (1998: 252) definition, by Anglophone or multilingual residents, who are second generation or later (i.e. born in Canada) and who live in urban settings. Applying this definition, c. 36% of the Canadian population speak Standard Canadian English in the 2006 population, with 38% in the 2011 census.\nRegional variation.\nThe literature has for a long time conflated the notions of Standard Canadian English (StCE) and regional variation. While some regional dialects are close with the StCE, they are not identical with it. To the untrained ear, for instance, a B.C. middle class speaker from a rural setting may sound like a StCE speaker, while, given Chambers' definition, such person, because of the rural provenance, would not be included in the accepted definition (see the previous section). The \"Atlas of North American English,\" while being the best source for US regional variation, is not a good source for Canadian regional variation, as its analysis is based on only 33 Canadian speakers. Boberg's (2005, 2008) studies offer the best data for the delimitation of dialect zones. The results for vocabulary and phonetics overlap to a great extent, which has allowed the proposal of dialect zones. Dollinger and Clarke distinguish between:\nBritish Columbia.\nBritish Columbia English shares dialect features with both Standard Canadian English and the American Pacific Northwest English. In Vancouver, speakers exhibit more vowel retraction of before nasals than people from Toronto, and this retraction may become a regional marker of West Coast English. raising (found words such as bag, vague and bagel), a prominent feature in western American speakers, is also found in Vancouver speakers. Younger speakers in the Greater Vancouver area do not raise , causing \"about\" to sound somewhat like \"a boat\". The \"o\" in such words as \"holy, goal, load, know,\" etc. is pronounced as a back and rounded , but not as rounded as in the Prairies where there are strong Scandinavian, Slavic and German influences.\nOntario.\nCanadian raising is quite strong throughout the province of Ontario, except within the Ottawa Valley. The Canadian Shift is also a common vowel shift found in Ontario. The retraction of was found to be more advanced for women in Ontario than for people from the Prairies or Atlantic Canada and men.\nIn Southwestern Ontario (roughly in the line south from Sarnia to St. Catharines), despite the existence of the many characteristics of West/Central Canadian English, many speakers, especially those under 30, speak a dialect which is influenced by the Inland Northern American English dialect, though there are minor differences such as Canadian raising (e.g. \"ice\" vs \"my\").\nThe subregion of Midwestern Ontario consists of the Counties of Huron, Bruce, Grey, and Perth. The \"Queen's Bush,\" as the area was called, did not experience communication with Southwestern and Central dialects until the early 20th century. Thus, a strong accent similar to Central Ontarian is heard, yet many different phrasings exist. It is typical in the area to drop phonetic sounds to make shorter contractions, such as: \"prolly\" (probably), \"goin\"' (going), and \"Wuts goin' on tonight? D'ya wanna do sumthin'?\" It is particularly strong in the County of Bruce, so much that it is commonly referred to as being the Bruce Cownian (Bruce Countian) accent. Also 'er' sounds are often pronounced 'air', with \"were\" sounding more like \"wear\".\nResidents of the Golden Horseshoe (including the Greater Toronto Area) are known to merge the second with the in \"Toronto\", pronouncing the name variously as , or even or . This, however, is not unique to Toronto; for example, Atlanta is often pronounced \"Atlanna\" by residents. In the Greater Toronto Area, the \"th\" sound is sometimes pronounced . Sometimes is elided altogether, resulting in \"Do you want this one er'iss one?\" The word \"southern\" is often pronounced with . In the area north of the Regional Municipality of York and south of Parry Sound, notably among those who were born in the surrounding communities, the cutting down of syllables and consonants often heard, e.g. \"probably\" is reduced to \"prolly\" or \"probly\" when used as a response. In Greater Toronto, the diphthong tends to be fronted (as a result the word \"about\" is pronounced as or 'a-beh-oot'). The Greater Toronto Area is diverse linguistically, with 43 percent of its people having a mother tongue other than English. As a result Toronto English has distinctly more variability than Inland Canada.\nIn Eastern Ontario, Canadian raising is not as strong as it is in the rest of the province. In Prescott and Russell, parts of Stormont-Dundas-Glengarry and Eastern Ottawa, French accents are often mixed with English ones due to the high Franco-Ontarian population there. In Lanark County, Western Ottawa and Leeds-Grenville and the rest of Stormont-Dundas-Glengarry, the accent spoken is nearly identical to that spoken in Central Ontario and the Quinte area. Phrases such as \"got it\" is often pronounced as . \"Okay\" is often pronounced as , while \"hello\" is often pronounced as .\nA linguistic enclave has also formed in the Ottawa Valley, heavily influenced by original Scottish, Irish, and German settlers, and existing along the Ontario-Quebec boundary, which has its own distinct accent known as the Ottawa Valley twang (or brogue). Phonetically, the Ottawa Valley twang is characterized by the lack of Canadian raising as well as the cot\u2013caught merger, two common elements of mainstream Canadian English. However, this accent is quite rare in the region today.\nQuebec.\nEnglish is a minority language in Quebec (with French the majority), but has many speakers in Montreal, the Eastern Townships and in the Gatineau-Ottawa region. A person whose mother tongue is English and who still speaks English is called an \"Anglophone\", versus a \"Francophone\", or French speaker.\nMany people in Montreal distinguish between words like \"marry\" versus \"merry\" and \"parish\" versus \"perish\", which are homophones to most other speakers of Canadian English. Quebec Anglophones generally pronounce French street names in Montreal as French words. \"Pie IX\" Boulevard is pronounced as in French: not as \"pie nine\" but as (compare French /pi.n\u0153f/). On the other hand, Anglophones do pronounce final \"d\" as in \"Bernard\" and \"Bouchard\"; the word \"Montreal\" is pronounced as an English word and \"Rue Lambert-Closse\" is known as \"Clossy Street\" (vs French /kl\u0254s/). In the city of Montreal, especially in some of the western suburbs like C\u00f4te-St-Luc and Hampstead, there is a strong Jewish influence in the English spoken in these areas. A large wave of Jewish immigration from Eastern Europe and the former Soviet Union before and after World War II is also evident today. Their English has a strong Yiddish influence; there are some similarities to English spoken in New York. Words used mainly in Quebec and especially in Montreal are: \"stage\" for \"apprenticeship\" or \"internship\", \"copybook\" for a notebook, \"d\u00e9panneur\" or \"dep\" for a convenience store, and \"guichet\" for an ABM/ATM. It is also common for Anglophones, particularly of Greek or Italian descent, to use translated French words instead of common English equivalents such as \"open\" and \"close\" for \"on\" and \"off\" or \"Open the lights, please\" for \"Turn on the lights, please\".\nMaritimes.\nMany in the Maritime provinces\u00a0\u2013 Nova Scotia, New Brunswick and Prince Edward Island\u00a0\u2013 have an accent that sounds more like Scottish English and, in some places, Irish English than General American. Outside of major communities, dialects can vary markedly from community to community, as well as from province to province, reflecting ethnic origin as well as a past in which there were few roads and many communities, with some villages very isolated. Into the 1980s, residents of villages in northern Nova Scotia could identify themselves by dialects and accents distinctive to their village. The dialects of Prince Edward Island are often considered the most distinct grouping.\nThe phonology of Maritimer English has some unique features:\nNewfoundland.\nThe dialect spoken in the province of Newfoundland and Labrador, an autonomous dominion until 31 March 1949, is often considered the most distinctive Canadian English dialect. Some Newfoundland English differs in vowel pronunciation, morphology, syntax, and preservation of archaic adverbial-intensifiers. The dialect can vary markedly from community to community, as well as from region to region, reflecting ethnic origin as well as a past in which there were few roads and many communities, and fishing villages in particular remained very isolated. A few speakers have a transitional pin\u2013pen merger.\nAboriginal North.\nFirst Nations and Inuit people from Northern Canada speak a version of Canadian English influenced by the phonology of their first languages. European Canadians in these regions are relatively recent arrivals, and have not produced a dialect that is distinct from southern Canadian English.\nGrammar.\nThere are a handful of syntactical practices unique to Canadian English. When writing, Canadians may start a sentence with \"As well\", in the sense of \"in addition\"; this construction is a Canadianism.\nUnlike British English, North American English strongly prefers \"have\" to \"have got\" to denote possession or obligation (as in \"I have a car\" vs. \"I've got a car\"); Canadian English, however, differs from American English in that it tends to eschew plain \"got\" (\"I got a car\"), which is a common third option in very informal US English.\nThe grammatical construction \"\"be done\" something\" means roughly \"\"have/has finished\" something\". For example, \"I am done my homework\" and \"The dog is done dinner\" are genuine sentences in this dialect, respectively meaning \"I have finished my homework\" and \"The dog has finished dinner\". Another example, \"Let's start after you're done all the coffee\", means \"Let's start after you've finished all the coffee\". This is not exactly the same as the standard construction \"\"to be done with\" something\", since \"She is done the computer\" can only mean \"She is done with the computer\" in one sense: \"She has finished (building) the computer\". \nDate and time notation.\nDate and time notation in Canadian English is a mixture of British and American practices. The date can be written in the form of either \"\" or \"1 July 2017\": the latter is common in more formal writing and bilingual contexts. The Government of Canada only recommends writing all-numeric dates in the form of YYYY-MM-DD (e.g. 2017-07-01), following ISO 8601. Nonetheless, the traditional DD/MM/YY and MM/DD/YY systems remain in everyday use, which can be interpreted in multiple ways: 01/07/17 can mean either 1 July 2017 or 7 January 2017. Private members' bills have repeatedly attempted to clarify the situation. In business communication and filing systems the YYMMDD is used to assist in automatic ordering of electronic files. \nThe government also recommends use of the 24-hour clock, which is widely used in contexts such as transportation schedules, parking meters, and data transmission. Many speakers of English use the 12-hour clock in everyday speech, even when reading from a 24-hour display, similar to the use of the 24-hour clock in the United Kingdom.\nVocabulary.\nWhere Canadian English shares vocabulary with other English dialects, it tends to share most with American English, but also has many non-American terms distinctively shared instead with Britain. British and American terms also can coexist in Canadian English to various extents, sometimes with new nuances in meaning; a classic example is \"holiday\" (British) often used interchangeably with \"vacation\" (American), though, in Canadian speech, the latter can more narrowly mean a trip elsewhere and the former can mean general time off work. In addition, the vocabulary of Canadian English also features some words that are seldom (if ever) found elsewhere. A good resource for these and other words is the Dictionary of Canadianisms on Historical Principles, which is currently being revised at the University of British Columbia in Vancouver, British Columbia. The Canadian public appears to take interest in unique \"Canadianisms\": words that are distinctively characteristic of Canadian English\u2014though perhaps not exclusive to Canada; there is some disagreement about the extent to which \"Canadianism\" means a term actually unique to Canada, with such an understanding possibly overstated by the popular media. As a member of the Commonwealth of Nations, Canada shares many items of institutional terminology and professional designations with the countries of the former British Empire\u2014for example, \"constable\", for a police officer of the lowest rank, and \"chartered accountant\".\nEducation.\nThe term \"college\", which refers to post-secondary education in general in the US, refers in Canada to either a post-secondary technical or vocational institution, or to one of the colleges that exist as federated schools within some Canadian universities. Most often, a \"college\" is a community college, not a university. It may also refer to a CEGEP in Quebec. In Canada, \"college student\" might denote someone obtaining a diploma in business management (this would be an associate degree in the United States); while \"university student\" is the term for someone earning a bachelor's degree. For that reason, \"going to college\" in Canada does not have the same meaning as \"going to university\", unless the speaker or context clarifies the specific level of post-secondary education that is meant.\nWithin the public school system the chief administrator of a school is generally \"the principal\", as in the United States, but the term is not used preceding his or her name, i.e. \"Principal Smith\". The assistant to the principal is not titled as \"assistant principal\", but rather as \"vice-principal\", although the former is not unknown. This usage is identical to that in Northern Ireland.\nCanadian universities publish \"calendars\" or \"schedules\", not \"catalogs\" as in the US. Canadian students \"write\" or \"take\" exams (in the US, students generally \"take\" exams while teachers \"write\" them); they rarely \"sit\" them (standard British usage). Those who supervise students during an exam are sometimes called \"invigilators\" as in Britain, or sometimes \"proctors\" as in the US; usage may depend on the region or even the individual institution.\nSuccessive years of school are usually referred to as \"grade one\", \"grade two\", and so on. In Quebec, the speaker (if Francophone) will often say \"primary one\", \"primary two\" (a direct translation from the French), and so on; while Anglophones will say \"grade one\", \"grade two\". (Compare American \"first grade, second grade\" (sporadically found in Canada), and English/Welsh \"Year 1, Year 2\", Scottish/Northern Irish \"Primary 1, Primary 2\" or \"P1, P2\", and Southern Irish \"First Class, Second Class\" and so on.). The year of school before grade 1 is usually called \"Kindergarten\", with the exception of Nova Scotia, where it is called \"grade primary\".\nIn the US, the four years of high school are termed the freshman, sophomore, junior, and senior years (terms also used for college years); in Canada, the specific levels are used instead (i.e., \"grade nine\"). As for higher education, only the term \"freshman\" (often reduced to \"frosh\") has some currency in Canada. The American usages \"sophomore\", \"junior\" and \"senior\" are not used in Canadian university terminology, or in speech. The specific high-school grades and university years are therefore stated and individualized; for example, \"the grade 12s failed to graduate\"; \"John is in his second year at McMaster\". The \"first year\", \"third year\" designation also applies to Canadian law school students, as opposed to the common American usage of \"1L\", \"2L\" and \"3L\".\nCanadian students use the term \"marks\" (more common in England) or \"grades\" (more common in the US) to refer to their results; usage is very mixed.\nUnits of measurement.\nUnlike in the United States, use of metric units within a majority of (but not all) industries is standard in Canada, as a result of the partial national adoption of the metric system during the mid-to-late 1970s that was eventually stalled; this has spawned some colloquial usages such as \"klick\" for kilometre (as also heard in the US military).\nNonetheless, US units are still used in many situations. Imperial volumes are also used, albeit very rarely\u2014although many Canadians and Americans mistakenly conflate the measurement systems despite their slight differences from each other.\nFor example, English Canadians state their weight and height in pounds and feet/inches, respectively. This is also the case for many Quebec Francophones. Distances while playing golf are always marked and discussed in yards, though official scorecards may also show metres. Temperatures for cooking are often given in Fahrenheit, while the weather is given in Celsius. Directions in the Prairie provinces are sometimes given using miles, because the country roads generally follow the mile-based grid of the Dominion Land Survey. Motor vehicle speed limits are measured in kilometres per hour.\nCanadians measure property, both residential and commercial, floor areas are in square feet or square meters, property is in square feet, square meters, acres or hectares. Fuel efficiency is less frequently discussed in miles per US gallon, more often the metric L/100\u00a0km despite gasoline being sold by the litre. The Letter paper size of 8.5\u00a0inches \u00d7 11\u00a0inches is used instead of the international and metric equivalent A4 size of 210\u00a0mm \u00d7 297\u00a0mm. Beer cans are 355 mL (12 US oz), while beer bottles are typically 341 mL (12 Imperial oz), and draft beer is sold by the pint.\nBuilding materials are used in soft conversions of imperial sizes, but often purchased in relation to the imperial sizes. Example 8\" concrete masonry unit can be referred to as a 8\" CMU or 190 CMU. The actual material used in the US and Canada is the same.\nTransportation.\nHowever, \"expressway\" may also refer to a limited-access road that has control of access but has at-grade junctions, railway crossings (for example, the Harbour Expressway in Thunder Bay.) Sometimes the term \"Parkway\" is also used (for example, the Hanlon Parkway in Guelph). In Saskatchewan, the term 'grid road' is used to refer to minor highways or rural roads, usually gravel, referring to the 'grid' upon which they were originally designed. In Quebec, freeways and expressways are called autoroutes.\nIn Alberta, the generic \"Trail\" is often used to describe a freeway, expressway or major urban street (for example, Deerfoot Trail, Macleod Trail or Crowchild Trail in Calgary, Yellowhead Trail, Victoria Trail or Mark Messier/St.Albert Trail in Edmonton). The British term \"motorway\" is not used. The American terms \"turnpike\" and \"tollway\" for a toll road are not common. The term \"throughway\" or \"thruway\" was used for first tolled limited-access highways (for example, the Deas Island Throughway, now Highway 99, from Vancouver, BC, to Blaine, Washington, USA or the Saint John Throughway (Highway 1) in Saint John, NB), but this term is not common anymore. In everyday speech, when a particular roadway is not being specified, the term \"highway\" is generally or exclusively used.\nLaw.\nLawyers in all parts of Canada, except Quebec, which has its own civil law system, are called \"barristers and solicitors\" because any lawyer licensed in any of the common law provinces and territories must pass bar exams for, and is permitted to engage in, both types of legal practice in contrast to other common-law jurisdictions such as England, Wales and Ireland where the two are traditionally separated (i.e., Canada has a fused legal profession). The words \"lawyer\" and \"counsel\" (not \"counsellor\") predominate in everyday contexts; the word \"attorney\" refers to any personal representative. Canadian lawyers generally do not refer to themselves as \"attorneys\", a term that is common in the United States.\nThe equivalent of an American \"district attorney\", meaning the barrister representing the state in criminal proceedings, is called a \"crown attorney\" (in Ontario), \"crown counsel\" (in British Columbia), \"crown prosecutor\" or \"the crown\", on account of Canada's status as a constitutional monarchy in which the Crown is the locus of state power.\nThe words \"advocate\" and \"notary\"\u00a0\u2013 two distinct professions in Quebec civil law\u00a0\u2013 are used to refer to that province's approximate equivalents of barrister and solicitor, respectively. It is not uncommon, however, for English-speaking advocates in Quebec to refer to themselves in English as \"barrister(s) and solicitor(s)\", as most advocates chiefly perform what would traditionally be known as \"solicitor's work\", while only a minority of advocates actually appear in court. In Canada's common law provinces and territories, the word \"notary\" means strictly a notary public.\nWithin the Canadian legal community itself, the word \"solicitor\" is often used to refer to any Canadian lawyer in general (much like the way the word \"attorney\" is used in the United States to refer to any American lawyer in general). Despite the conceptual distinction between \"barrister\" and \"solicitor\", Canadian court documents would contain a phrase such as \"\"John Smith, \"solicitor\" for the Plaintiff\"\" even though \"John Smith\" may well himself be the barrister who argues the case in court. In a letter introducing him/herself to an opposing lawyer, a Canadian lawyer normally writes something like \"\"I am the \"solicitor\" for Mr. Tom Jones.\"\nThe word \"litigator\" is also used by lawyers to refer to a fellow lawyer who specializes in lawsuits even though the more traditional word \"barrister\" is still employed to denote the same specialization.\nJudges of Canada's superior courts, which exist at the provincial and territorial levels, are traditionally addressed as \"My Lord\" or \"My Lady\", however there are some variances across certain jurisdictions, with some superior court judges preferring the titles \"Mister Justice\" or \"Madam Justice\" to \"Lordship\".\nMasters are addressed as \"Mr. Master\" or simply \"Sir.\" In British Columbia, masters are addressed as \"Your Honour.\"\nJudges of provincial or inferior courts are traditionally referred to in person as \"Your Honour\". Judges of the Supreme Court of Canada and of the federal-level courts prefer the use of \"Mister/Madam (Chief) Justice\". Justices of The Peace are addressed as \"Your Worship\". \"Your Honour\" is also the correct form of address for a Lieutenant Governor.\nA serious crime is called an indictable offence, while a less-serious crime is called a summary offence. The older words felony and misdemeanour, which are still used in the United States, are not used in Canada's current \"Criminal Code\" (R.S.C. 1985, c. C-46) or by today's Canadian legal system. As noted throughout the \"Criminal Code\", a person accused of a crime is called \"the accused\" and not \"the defendant\", a term used instead in civil lawsuits.\nIn Canada, \"visible minority\" refers to a non-aboriginal person or group visibly not one of the majority race in a given population. The term comes from the Canadian Employment Equity Act, which defines such people as \"persons, other than Aboriginal people, who are non-Caucasian in race or non-white in colour.\" The term is used as a demographic category by Statistics Canada. The qualifier \"visible\" is used to distinguish such minorities from the \"invisible\" minorities determined by language (English vs. French) and certain distinctions in religion (Catholics vs. Protestants).\nA county in British Columbia means only a regional jurisdiction of the courts and justice system and is not otherwise connected to governance as with counties in other provinces and in the United States. The rough equivalent to \"county\" as used elsewhere is a \"Regional District\".\nPlaces.\nDistinctive Canadianisms are:\nDaily life.\nTerms common in Canada, Britain and Ireland but less frequent or nonexistent in the United States are:\nThe following are more or less distinctively Canadian:\nApparel.\nThe following are common in Canada, but not in the United States or the United Kingdom.\nPrairies (Manitoba, Saskatchewan and Alberta).\nA strong Canadian raising exists in the prairie regions together with certain older usages such as \"chesterfield\" and \"front room\" also associated with the Maritimes. Aboriginal Canadians are a larger and more conspicuous population in prairie cities than elsewhere in the country and certain elements of aboriginal speech in English are sometimes to be heard. Similarly, the linguistic legacy, mostly intonation but also speech patterns and syntax, of the Scandinavian, Slavic and German settlers\u00a0\u2013 who are far more numerous and historically important in the Prairies than in Ontario or the Maritimes\u00a0\u2013 can be heard in the general milieu. Again, the large M\u00e9tis population in Saskatchewan and Manitoba also carries with it certain linguistic traits inherited from French, Aboriginal and Celtic forebears.\nSome terms are derived from immigrant groups or are just local inventions:\nIn farming communities with substantial Ukrainian, German or Mennonite populations, accents, sentence structure and vocabulary influenced by these languages is common. These communities are most common in the Saskatchewan Valley region of Saskatchewan and Red River Valley region of Manitoba.\nDescendants of marriages between Hudson's Bay Company workers of mainly Scottish descent and Cree women spoke Bungi, a creole that blends Cree and English. A few Bungi speakers can still be found in Manitoba. It is marked by no masculine, feminine or third-person pronouns.\nBritish Columbia.\nBritish Columbian English has several words still in current use borrowed from the Chinook Jargon although the use of such vocabulary is observably decreasing. The most famous and widely used of these terms are \"skookum\" and \"saltchuck\". However, among young British Columbians, almost no one uses this vocabulary, and only a small percentage is even familiar with the meaning of such words. In the Yukon, \"cheechako\" is used for newcomers or greenhorns.\nOntario.\nNorthern Ontario English has several distinct qualities stemming from its large Franco-Ontarian population. As a result several French and English words are used interchangeably. A number of phrases and expressions may also be found in Northern Ontario that are not present in the rest of the province, such as the use of \"camp\" for a summer home where Southern Ontario speakers would idiomatically use cottage.\nIn the early 2010s, certain words from London slang and Arabic were popularized among Toronto youth, especially in immigrant communities. These included words such as \"mandems\", \"styll\", \"wallahi\", \"wasteman\", and \"yute\".\nInformal speech.\nA \"rubber\" in the US and Canada is slang for a condom; however, in Canada it is sometimes (rarely except for Newfoundland and South Western Ontario) another term for an eraser (as it is in the United Kingdom and Ireland).\nThe word \"bum\" can refer either to the buttocks (as in Britain), or, derogatorily, to a homeless person (as in the US). However, the \"buttocks\" sense does not have the indecent character it retains in British use, as it and \"butt\" are commonly used as a polite or childish euphemism for ruder words such as \"arse\" (commonly used in Atlantic Canada and among older people in Ontario and to the west) or \"ass\", or \"mitiss\" (used in the Prairie Provinces, especially in northern and central Saskatchewan; probably originally a Cree loanword). Older Canadians may see \"bum\" as more polite than \"butt\", which before the 1980s was often considered rude.\nSimilarly the word \"pissed\" can refer either to being drunk (as in Britain), or being angry (as in the US), though anger is more often said as \"pissed off\", while \"piss drunk\" or \"pissed up\" is said to describe inebriation (though \"piss drunk\" is sometimes also used in the US, especially in the northern states).\nOne of the most distinctive Canadian phrases is the spoken interrogation or tag \"eh\". The only usage of \"eh\" exclusive to Canada, according to the \"Canadian Oxford Dictionary\", is for \"ascertaining the comprehension, continued interest, agreement, etc., of the person or persons addressed\" as in, \"It's four kilometres away, eh, so I have to go by bike.\" In that case, \"eh?\" is used to confirm the attention of the listener and to invite a supportive noise such as \"mm\" or \"oh\" or \"okay\". This usage is also common in Queensland, Australia and New Zealand. Other uses of \"eh\"\u00a0\u2013 for instance, in place of \"huh?\" or \"what?\" meaning \"please repeat or say again\"\u00a0\u2013 are also found in parts of the British Isles and Australia. It is common in Northern/Central Ontario, the Maritimes and the Prairie provinces. The word \"eh\" is used quite frequently in the North Central dialect, so a Canadian accent is often perceived in people from North Dakota, Michigan, Minnesota, and Wisconsin.\nThe term \"Canuck\" simply means \"Canadian\" in its demonymic form, and, as a term used even by Canadians themselves, it is not considered derogatory. In the 19th century and early 20th century it tended to refer to French-Canadians, while the only Canadian-built version of the popular World War I-era American Curtiss JN-4 \"Jenny\" training biplane aircraft, the JN-4C, got the \"Canuck\" nickname, 1,260 of which were built. The nickname Janey Canuck was used by Anglophone women's rights writer Emily Murphy in the 1920s and the \"Johnny Canuck\" comic book character of the 1940s. Throughout the 1970s, Canada's winning World Cup men's downhill ski team was called the \"Crazy Canucks\" for their fearlessness on the slopes. It is also the name of the Vancouver Canucks, the National Hockey League team of Vancouver, British Columbia.\nThe term \"hoser\", popularized by Bob &amp; Doug McKenzie, typically refers to an uncouth, beer-swilling male and is a euphemism for \"loser\" coming from the earlier days of hockey played on an outdoor rink and the losing team would have to hose down the ice after the game so it froze smooth. Bob &amp; Doug also popularized the use of \"Beauty, eh\", another western slang term which may be used to describe something as being of interest or note or deserving approval. \nA \"Newf\" or \"Newfie\" is someone from Newfoundland and Labrador; sometimes considered derogatory. In Newfoundland, the term \"Mainlander\" refers to any Canadian (sometimes American, occasionally Labradorian) not from the island of Newfoundland. \"Mainlander\" is also occasionally used derogatorily.\nIn the Maritimes, a \"Caper\" or \"Cape Bretoner\" is someone from Cape Breton Island, a \"Bluenoser\" is someone with a thick, usually southern Nova Scotia accent or as a general term for a Nova Scotian (including Cape Bretoners), while an \"Islander\" is someone from Prince Edward Island (the same term is used in British Columbia for people from Vancouver Island, or the numerous islands along it). A \"Haligonian\" refers to someone from the city of Halifax.\nCape Bretoners and Newfies (from Newfoundland and Labrador) often have similar slang. \"Barmp\" is often used as the sound a car horn makes, example: \"He cut me off so I barmped the horn at him\". When saying \"B'y\", while sounds like the traditional farewell, it is a syncopated shortening of the word \"boy\", referring to a person, example: \"How's it goin, b'y?\". Another slang that is commonly used is \"doohickey\" which means an object, example: \"Pass me that doohickey over there\". When an individual uses the word \"biffed\", they mean that they threw something. Example: \"I got frustrated so I biffed it across the room\".\nAttitudes.\nIn 2011, just under 21.5\u00a0million Canadians, representing 65% of the population, spoke English most of the time at home, while 58% declared it their mother language. English is the major language everywhere in Canada except Quebec, and most Canadians (85%) can speak English. While English is not the preferred language in Quebec, 36.1% of the Qu\u00e9b\u00e9cois can speak English. Nationally, Francophones are five times more likely to speak English than Anglophones are to speak French \u2013 44% and 9% respectively. Only 3.2% of Canada's English-speaking population resides in Quebec\u2014mostly in Montreal.\nAttitude studies on Canadian English are somewhat rare. A perceptual study on Albertan and Ontarians exists in combination with older literature from the 1970s\u201380s. Sporadic reports can be found in the literature, e.g. on Vancouver English, in which more than 80% believe in a \"Canadian way of speaking\", with those with a university education reporting higher than those without.\nJaan Lilles argues in an essay for \"English Today\" that there is no variety of \"Canadian English\". He acknowledges that no variety of English is more \"real\" or \"natural\" than any other, but that, in the words of American linguist John Algeo, \"All linguistic varieties are fictions.\" According to Lilles, Canadian English is simply not a \"useful fiction\". He goes on to argue that too often national identity is conflated with linguistic identity, and that in the case of \"Canadian English\", supposedly unique features of Canadian speakers, such as certain lexical terms such as \"muskeg\" are artificially exaggerated to distinguish Canadian speech primarily from that found in the United States.\nFurther reading.\nDollinger, Stefan (2015). The Written Questionnaire in Social Dialectology: History, Theory, Practice. Amsterdam/Philadelphia: Benjamins. The book's examples are exclusive taken from Canadian English and represent one of the more extensive collections of variables for Canadian English."}
{"id": "6343", "revid": "10175747", "url": "https://en.wikipedia.org/wiki?curid=6343", "title": "Czech language", "text": "Czech (; Czech ), historically also Bohemian (; \"lingua Bohemica\" in Latin), is a West Slavic language of the Czech\u2013Slovak group. Spoken by over 13 million people, it serves as the official language of the Czech Republic. Czech is closely related to Slovak, to the point of mutual intelligibility to a very high degree, as well as Polish. Like other Slavic languages, Czech is a fusional language with a rich system of morphology and relatively flexible word order. Its vocabulary has been extensively influenced by Latin and German.\nThe Czech\u2013Slovak group developed within West Slavic in the high medieval period, and the standardization of Czech and Slovak within the Czech\u2013Slovak dialect continuum emerged in the early modern period. In the later 18th to mid-19th century, the modern written standard became codified in the context of the Czech National Revival. The main non-standard variety, known as Common Czech, is based on the vernacular of Prague, but is now spoken as an interdialect throughout most of the Czech Republic. The Moravian dialects spoken in the eastern part of the country are also classified as Czech, although some of their eastern variants are closer to Slovak.\nCzech has a moderately-sized phoneme inventory, comprising ten monophthongs, three diphthongs and 25 consonants (divided into \"hard\", \"neutral\" and \"soft\" categories). Words may contain complicated consonant clusters or lack vowels altogether. Czech has a raised alveolar trill, which is known to occur as a phoneme in only a few other languages, represented by the grapheme \"\u0159\". Czech uses a simple orthography which phonologists have used as a model.\nClassification.\nCzech is a member of the West Slavic sub-branch of the Slavic branch of the Indo-European language family. This branch includes Polish, Kashubian, Upper and Lower Sorbian and Slovak. Slovak is the most closely related language to Czech, followed by Polish and Silesian.\nThe West Slavic languages are spoken in Central Europe. Czech is distinguished from other West Slavic languages by a more-restricted distinction between \"hard\" and \"soft\" consonants (see Phonology below).\nHistory.\nMedieval/Old Czech.\nThe term \"Old Czech\" is applied to the period predating the 16th century, with the earliest records of the high medieval period also classified as \"early Old Czech\", but the term \"Medieval Czech\" is also used. The function of the written language was initially performed by Old Slavonic written in Glagolitic, later by Latin written in Latin script. \nAround the 7th century, the Slavic expansion reached Central Europe, settling on the eastern fringes of the Frankish Empire. The West Slavic polity of Great Moravia formed by the 9th century. The Christianization of Bohemia took place during the 9th and 10th centuries. The diversification of the Czech-Slovak group within West Slavic began around that time, marked among other things by its use of the voiced velar fricative consonant (/\u0263/) and consistent stress on the first syllable.\nThe Bohemian (Czech) language is first recorded in writing in glosses and short notes during the 12th to 13th centuries. Literary works written in Czech appear in the late 13th and early 14th century and administrative documents first appear towards the late 14th century. The first complete Bible translation also dates to this period. Old Czech texts, including poetry and cookbooks, were produced outside the university as well.\nLiterary activity becomes widespread in the early 15th century in the context of the Bohemian Reformation. Jan Hus contributed significantly to the standardization of Czech orthography, advocated for widespread literacy among Czech commoners (particularly in religion) and made early efforts to model written Czech after the spoken language.\nEarly Modern Czech.\nThere was no standardization distinguishing between Czech and Slovak prior to the 15th century. In the 16th century, the division between Czech and Slovak becomes apparent, marking the confessional division between Lutheran Protestants in Slovakia using Czech orthography and Catholics, especially Slovak Jesuits, beginning to use a separate Slovak orthography based on the language of the Trnava region.\nThe publication of the Kralice Bible between 1579 and 1593 (the first complete Czech translation of the Bible from the original languages) became very important for standardization of the Czech language in the following centuries.\nIn 1615, the Bohemian diet tried to declare Czech to be the only official language of the kingdom. After the Bohemian Revolt (of predominantly Protestant aristocracy) which was defeated by the Habsburgs in 1620, the Protestant intellectuals had to leave the country. This emigration together with other consequences of the Thirty Years' War had a negative impact on the further use of the Czech language. In 1627, Czech and German became official languages of the Kingdom of Bohemia and in the 18th century German became dominant in Bohemia and Moravia, especially among the upper classes.\nModern Czech.\nThe modern standard Czech language originates in standardization efforts of the 18th century. By then the language had developed a literary tradition, and since then it has changed little; journals from that period have no substantial differences from modern standard Czech, and contemporary Czechs can understand them with little difficulty. Sometime before the 18th century, the Czech language abandoned a distinction between phonemic /l/ and /\u028e/ which survives in Slovak.\nWith the beginning of the national revival of the mid-18th century, Czech historians began to emphasize their people's accomplishments from the 15th through the 17th centuries, rebelling against the Counter-Reformation (the Habsburg re-catholization efforts which had denigrated Czech and other non-Latin languages). Czech philologists studied sixteenth-century texts, advocating the return of the language to high culture. This period is known as the Czech National Revival (or Renaissance).\nDuring the national revival, in 1809 linguist and historian Josef Dobrovsk\u00fd released a German-language grammar of Old Czech entitled \"Ausf\u00fchrliches Lehrgeb\u00e4ude der b\u00f6hmischen Sprache\" (\"Comprehensive Doctrine of the Bohemian Language\"). Dobrovsk\u00fd had intended his book to be descriptive, and did not think Czech had a realistic chance of returning as a major language. However, Josef Jungmann and other revivalists used Dobrovsk\u00fd's book to advocate for a Czech linguistic revival. Changes during this time included spelling reform (notably, \"\u00ed\" in place of the former \"j\" and \"j\" in place of \"g\"), the use of \"t\" (rather than \"ti\") to end infinitive verbs and the non-capitalization of nouns (which had been a late borrowing from German). These changes differentiated Czech from Slovak. Modern scholars disagree about whether the conservative revivalists were motivated by nationalism or considered contemporary spoken Czech unsuitable for formal, widespread use.\nAdherence to historical patterns was later relaxed and standard Czech adopted a number of features from Common Czech (a widespread, informally used interdialectal variety), such as leaving some proper nouns undeclined. This has resulted in a relatively high level of homogeneity among all varieties of the language.\nGeographic distribution.\nCzech is spoken by about 10 million residents of the Czech Republic. A Eurobarometer survey conducted from January to March 2012 found that the first language of 98 percent of Czech citizens was Czech, the third-highest proportion of a population in the European Union (behind Greece and Hungary).\nAs the official language of the Czech Republic (a member of the European Union since 2004), Czech is one of the EU's official languages and the 2012 Eurobarometer survey found that Czech was the foreign language most often used in Slovakia. Economist Jonathan van Parys collected data on language knowledge in Europe for the 2012 European Day of Languages. The five countries with the greatest use of Czech were the Czech Republic (98.77 percent), Slovakia (24.86 percent), Portugal (1.93 percent), Poland (0.98 percent) and Germany (0.47 percent).\nCzech speakers in Slovakia primarily live in cities. Since it is a recognised minority language in Slovakia, Slovak citizens who speak only Czech may communicate with the government in their language to the extent that Slovak speakers in the Czech Republic may do so.\nUnited States.\nImmigration of Czechs from Europe to the United States occurred primarily from 1848 to 1914. Czech is a Less Commonly Taught Language in U.S. schools, and is taught at Czech heritage centers. Large communities of Czech Americans live in the states of Texas, Nebraska and Wisconsin. In the 2000 United States Census, Czech was reported as the commonest language spoken at home (besides English) in Valley, Butler and Saunders Counties, Nebraska and Republic County, Kansas. With the exception of Spanish (the non-English language most commonly spoken at home nationwide), Czech was the commonest home language in more than a dozen additional counties in Nebraska, Kansas, Texas, North Dakota and Minnesota. As of 2009, 70,500 Americans spoke Czech as their first language (49th place nationwide, after Turkish and before Swedish).\nPhonology.\nStandard Czech contains ten basic vowel phonemes, and three diphthongs. The vowels are , and their long counterparts . The diphthongs are ; the last two are found only in loanwords such as \"car\" and \"euro\".\nIn Czech orthography, the vowels are spelled as follows:\nThe letter indicates that the previous consonant is palatalised (e.g. ). After a labial it represents (e.g. ); but is pronounced /m\u0272\u025b/, cf. ().\nEach word usually has primary stress on its first syllable, except for enclitics (minor, monosyllabic, unstressed syllables). In all words of more than two syllables, every odd-numbered syllable receives secondary stress. Stress is unrelated to vowel length; both long and short vowels can be stressed or unstressed. Vowels are never reduced in tone (e.g. to schwa sounds) when unstressed. When a noun is preceded by a monosyllabic preposition, the stress moves to the preposition, e.g. \"to Prague\".\nVoiced consonants with unvoiced counterparts are unvoiced at the end of a word before a pause, and in consonant clusters voicing assimilation occurs, which matches voicing to the following consonant. The unvoiced counterpart of /\u0266/ is /x/.\nCzech consonants are categorized as \"hard\", \"neutral\", or \"soft\":\nIn Czech orthography, the consonants are spelled as follows:\nHard consonants may not be followed by \"i\" or \"\u00ed\" in writing, or soft ones by \"y\" or \"\u00fd\" (except in loanwords such as \"kilogram\"). Neutral consonants may take either character. Hard consonants are sometimes known as \"strong\", and soft ones as \"weak\". This distinction is also found in the declension patterns of nouns, which vary according to whether the final consonant of the noun is hard or soft.\nThe phoneme represented by the letter \"\u0159\" (capital \"\u0158\") is often considered unique to Czech. It represents the raised alveolar non-sonorant trill (IPA: ), a sound somewhere between Czech's \"r\" and \"\u017e\" (example: ), and is present in \"Dvo\u0159\u00e1k\". In unvoiced environments, /r\u031d/ is realized as its voiceless allophone [r\u031d\u030a].\nThe consonants can be syllabic, acting as syllable nuclei in place of a vowel. \"Str\u010d prst skrz krk\" (\"Stick [your] finger through [your] throat\") is a well-known Czech tongue twister using only syllabic consonants.\nConsonants&lt;br&gt;\nVowels&lt;br&gt;\nGrammar.\nCzech grammar, like that of other Slavic languages, is fusional; its nouns, verbs, and adjectives are inflected by phonological processes to modify their meanings and grammatical functions, and the easily separable affixes characteristic of agglutinative languages are limited. \nCzech inflects for case, gender and number in nouns and tense, aspect, mood, person and subject number and gender in verbs.\nParts of speech include adjectives, adverbs, numbers, interrogative words, prepositions, conjunctions and interjections. Adverbs are primarily formed from adjectives by taking the final \"\u00fd\" or \"\u00ed\" of the base form and replacing it with \"e\", \"\u011b\", or \"o\". Negative statements are formed by adding the affix \"ne-\" to the main verb of a clause, with one exception: \"je\" (he, she or it is) becomes \"nen\u00ed\".\nSentence and clause structure.\nBecause Czech uses grammatical case to convey word function in a sentence (instead of relying on word order, as English does), its word order is flexible. As a pro-drop language, in Czech an intransitive sentence can consist of only a verb; information about its subject is encoded in the verb. Enclitics (primarily auxiliary verbs and pronouns) appear in the second syntactic slot of a sentence, after the first stressed unit. The first slot must contain a subject or object, a main form of a verb, an adverb, or a conjunction (except for the light conjunctions \"a\", \"and\", \"i\", \"and even\" or \"ale\", \"but\").\nCzech syntax has a subject\u2013verb\u2013object sentence structure. In practice, however, word order is flexible and used for topicalization and focus. Although Czech has a periphrastic passive construction (like English), in colloquial style, word-order changes frequently replace the passive voice. For example, to change \"Peter killed Paul\" to \"Paul was killed by Peter\" the order of subject and object is inverted: \"Petr zabil Pavla\" (\"Peter killed Paul\") becomes \"Paul, Peter killed\" (\"Pavla zabil Petr\"). \"Pavla\" is in the accusative case, the grammatical object of the verb.\nA word at the end of a clause is typically emphasized, unless an upward intonation indicates that the sentence is a question:\nIn parts of Bohemia (including Prague), questions such as \"J\u00ed pes bagetu?\" without an interrogative word (such as \"co\", \"what\" or \"kdo\", \"who\") are intoned in a slow rise from low to high, quickly dropping to low on the last word or phrase.\nIn modern Czech syntax, adjectives precede nouns, with few exceptions. Relative clauses are introduced by relativizers such as the adjective \"kter\u00fd\", analogous to the English relative pronouns \"which\", \"that\" and \"who\"/\"whom\". As with other adjectives, it agrees with its associated noun in gender, number and case. Relative clauses follow the noun they modify. The following is a glossed example:\nEnglish: I want to visit the university that John attends.\nDeclension.\nIn Czech, nouns and adjectives are declined into one of seven grammatical cases which indicate their function in a sentence, two numbers (singular and plural) and three genders (masculine, feminine and neuter). The masculine gender is further divided into animate and inanimate classes.\nCase.\nA nominative\u2013accusative language, Czech marks subject nouns of transitive and intransitive verbs in the nominative case, which is the form found in dictionaries, and direct objects of transitive verbs are declined in the accusative case. The vocative case is used to address people. The remaining cases (genitive, dative, locative and instrumental) indicate semantic relationships, such as noun adjuncts (genitive), indirect objects (dative), or agents in passive constructions (instrumental). Additionally prepositions and some verbs require their complements to be declined in a certain case. The locative case is only used after prepositions. An adjective's case agrees with that of the noun it modifies. When Czech children learn their language's declension patterns, the cases are referred to by number: \nSome Czech grammatical texts order the cases differently, grouping the nominative and accusative (and the dative and locative) together because those declension patterns are often identical; this order accommodates learners with experience in other inflected languages, such as Latin or Russian. This order is nominative, accusative, genitive, dative, locative, instrumental and vocative.\nSome prepositions require the nouns they modify to take a particular case. The cases assigned by each preposition are based on the physical (or metaphorical) direction, or location, conveyed by it. For example, \"od\" (from, away from) and \"z\" (out of, off) assign the genitive case. Other prepositions take one of several cases, with their meaning dependent on the case; \"na\" means \"onto\" or \"for\" with the accusative case, but \"on\" with the locative.\nThis is a glossed example of a sentence using several cases:\n\"English:\" I carried the box into the house with my friend.\nGender.\nCzech distinguishes three genders\u2014masculine, feminine, and neuter\u2014and the masculine gender is subdivided into animate and inanimate. With few exceptions, feminine nouns in the nominative case end in \"-a\", \"-e\", or a consonant; neuter nouns in \"-o\", \"-e\", or \"-\u00ed\", and masculine nouns in a consonant. Adjectives agree in gender and animacy with the nouns they modify. The main effect of gender in Czech morphology is the difference in noun and adjective declension, as well as in endings of verbal participles and past-tense verbs, which are also marked for gender, e.g. \"d\u011blal\" (he did, or made); \"d\u011blala\" (she did, or made) and \"d\u011blalo\" (it did, or made). Gender also plays a semantic role; most nouns that describe people and animals, including personal names, have separate masculine and feminine forms which are normally formed by adding a suffix to the stem, for example \"\u010cech\" (Czech man) has the feminine form \"\u010ce\u0161ka\" (Czech woman).\nExamples of declension patterns for noun phrases of various genders follow:\nNumber.\nNouns are also inflected for number, distinguishing between singular and plural. Typical of a Slavic language, Czech cardinal numbers one through four allow the nouns and adjectives they modify to take any case, but numbers over five require subject and direct object noun phrases to be declined in the genitive plural instead of the nominative or accusative, and when used as subjects these phrases take singular verbs. For example:\nNumbers decline for case, and the numbers one and two are also inflected for gender. Numbers one through five are shown below as examples. The number one has declension patterns identical to those of the demonstrative pronoun \"ten\".\nAlthough Czech's grammatical numbers are singular and plural, several residuals of dual forms remain, such as the words \"dva\" (\"two\") and \"oba\" (\"both\"), which decline the same way. Some nouns for paired body parts use a historical dual form to express plural in some cases: \"ruka\" (hand)\u2014\"ruce\" (nominative); \"noha\" (leg)\u2014\"nohama\" (instrumental), \"nohou\" (genitive/locative); \"oko\" (eye)\u2014\"o\u010di\", and \"ucho\" (ear)\u2014\"u\u0161i\". While two of these nouns are neuter in their singular forms, all plural forms are considered feminine; their gender is relevant to their associated adjectives and verbs. These forms are plural semantically, used for any non-singular count, as in \"mezi \u010dty\u0159ma o\u010dima\" (face to face, lit. \"among four eyes\"). The plural number paradigms of these nouns are a mixture of historical dual and plural forms. For example, \"nohy\" (legs; nominative/accusative) is a standard plural form of this type of noun.\nVerb conjugation.\nCzech verbs agree with their subjects in person (first, second or third), number (singular or plural), and in constructions involving participles also in gender. They are conjugated for tense (past, present or future) and mood (indicative, imperative or conditional). For example, the conjugated verb \"mluv\u00edme\" (we speak) is in the present tense and first-person plural; it is distinguished from other conjugations of the infinitive \"mluvit\" by its ending, \"-\u00edme\". The infinitive form of Czech verbs ends in \"-t\" (archaically, \"-ti\"). It is the form found in dictionaries and the form that follows auxiliary verbs (for example, \"m\u016f\u017eu t\u011b sly\u0161et\"\u2014\"I can \"hear\" you\").\nAspect.\nTypical of Slavic languages, Czech marks its verbs for one of two grammatical aspects: perfective and imperfective. Most verbs are part of inflected aspect pairs\u2014for example, \"koupit\" (perfective) and \"kupovat\" (imperfective). Although the verbs' meaning is similar, in perfective verbs the action is completed and in imperfective verbs it is ongoing or repeated. This is distinct from past and present tense. Any verb of either aspect can be conjugated into either the past or present tense, but the future tense is only used with imperfective verbs. Aspect describes the state of the action at the time specified by the tense.\nThe verbs of most aspect pairs differ in one of two ways: by prefix or by suffix. In prefix pairs, the perfective verb has an added prefix\u2014for example, the imperfective \"ps\u00e1t\" (to write, to be writing) compared with the perfective \"napsat\" (to write down). The most common prefixes are \"na-\", \"o-\", \"po-\", \"s-\", \"u-\", \"vy-\", \"z-\" and \"za-\". In suffix pairs, a different infinitive ending is added to the perfective stem; for example, the perfective verbs \"koupit\" (to buy) and \"prodat\" (to sell) have the imperfective forms \"kupovat\" and \"prod\u00e1vat\". Imperfective verbs may undergo further morphology to make other imperfective verbs (iterative and frequentative forms), denoting repeated or regular action. The verb \"j\u00edt\" (to go) has the iterative form \"chodit\" (to go repeatedly) and the frequentative form \"chod\u00edvat\" (to go occasionally).\nMany verbs have only one aspect, and verbs describing continual states of being\u2014\"b\u00fdt\" (to be), \"cht\u00edt\" (to want), \"moct\" (to be able to), \"le\u017eet\" (to lie down, to be lying down)\u2014have no perfective form. Conversely, verbs describing immediate states of change\u2014for example, \"ot\u011bhotn\u011bt\" (to become pregnant) and \"nadchnout se\" (to become enthusiastic)\u2014have no imperfective aspect.\nTense.\nThe present tense in Czech is formed by adding an ending which agrees with the person and number of the subject at the end of the verb stem. As Czech is a null-subject language, the subject pronoun can be omitted unless it is needed for clarity. The past tense is formed using a participle which ends in \"-l\" and a further ending which agrees with the gender and number of the subject. For the first and second persons, the auxiliary verb \"b\u00fdt\" conjugated in the present tense is added.\nIn some contexts, the present tense of perfective verbs (which differs from the English present perfect) implies future action; in others, it connotes habitual action. The perfective present is used to refer to completion of actions in the future and is distinguished from the imperfective future tense, which refers to actions that will be ongoing in the future. The future tense is regularly formed using the future conjugation of \"b\u00fdt\" (as shown in the table on the left) and the infinitive of an imperfective verb, for example, \"budu j\u00edst\"\u2014\"I will eat\" or \"I will be eating\". Where \"budu\" has a noun or adjective complement it means \"I will be\", for example, \"budu \u0161\u0165astn\u00fd\" (I will be happy). Some verbs of movement form their future tense by adding the prefix \"po-\" to the present tense forms instead, e.g. \"jedu\" (\"I go\") &gt; \"pojedu\" (\"I will go\").\nMood.\nCzech verbs have three grammatical moods: indicative, imperative and conditional. The imperative mood is formed by adding specific endings for each of three person\u2013number categories: \"-\u00d8/-i/-ej\" for second-person singular, \"-te/-ete/-ejte\" for second-person plural and \"-me/-eme/-ejme\" for first-person plural. Imperatives are usually expressed using perfective verbs if positive and imperfective verbs if negative. The conditional mood is formed with a particle after the participle ending in -l which is used to form the past tense. This mood indicates hypothetical events and can also be used to express wishes.\nVerb classes.\nMost Czech verbs fall into one of five classes, which determine their conjugation patterns. The future tense of \"b\u00fdt\" would be classified as a Class I verb because of its endings. Examples of the present tense of each class and some common irregular verbs follow in the tables below:\nOrthography.\nCzech has one of the most phonemic orthographies of all European languages. Its thirty-one graphemes represent thirty sounds (in most dialects, \"i\" and \"y\" have the same sound), and it contains only one digraph: \"ch\", which follows \"h\" in the alphabet. As a result, some of its characters have been used by phonologists to denote corresponding sounds in other languages. The characters \"q\", \"w\" and \"x\" appear only in foreign words. The h\u00e1\u010dek (\u02c7) is used with certain letters to form new characters: \"\u0161\", \"\u017e\", and \"\u010d\", as well as \"\u0148\", \"\u011b\", \"\u0159\", \"\u0165\", and \"\u010f\" (the latter five uncommon outside Czech). The last two letters are sometimes written with a comma above (\u02bc, an abbreviated h\u00e1\u010dek) because of their height.\nUnlike most European languages, Czech distinguishes vowel length; long vowels are indicated by an acute accent or, occasionally with \"\u016f\", a ring. Long \"u\" is usually written \"\u00fa\" at the beginning of a word or morpheme (\"\u00faroda\", \"ne\u00farodn\u00fd\") and \"\u016f\" elsewhere, except for loanwords (\"sk\u00fatr\") or onomatopoeia (\"b\u00fa\"). Long vowels and \"\u011b\" are not considered separate letters in the alphabetical order. The character \"\u00f3\" exists only in loanwords and onomatopoeia.\nCzech typographical features not associated with phonetics generally resemble those of most European languages that use the Latin script, including English. Proper nouns, honorifics, and the first letters of quotations are capitalized, and punctuation is typical of other Latin European languages. Writing of ordinal numerals is similar to most European languages. The Czech language uses a decimal comma instead of a decimal point. When writing a long number, spaces between every three digits, including those in decimal places, may be used for better orientation in handwritten texts. The number 1,234,567.89101 may be written as 1234567,89101 or 1 234 567,891 01. Ordinal numbers (1st) use a point as in German (1.). In proper noun phrases (except personal and settlement names), only the first word is capitalized (\"Pra\u017esk\u00fd hrad\", Prague Castle) (included proper nouns are also capitalized).\nVarieties.\nThe modern literary standard and prestige variety, known as \"Standard Czech\" () is based on the standardization during the Czech National Revival in the 1830s, significantly influenced by Josef Jungmann's Czech\u2013German dictionary published during 1834\u20131839. Jungmann used vocabulary of the Bible of Kralice (1579\u20131613) period and of the language used by his contemporaries. He borrowed words not present in Czech from other Slavic languages or created neologisms. Standard Czech is the formal register of the language which is used in official documents, formal literature, newspaper articles, education and occasionally public speeches. It is codified by the Czech Language Institute, who publish occasional reforms to the codification. The most recent reform took place in 1993. The term (lit. \"Colloquial Czech\") is sometimes used to refer to the spoken variety of standard Czech.\nThe most widely spoken vernacular form of the language is called \"Common Czech\" (), an interdialect influenced by spoken Standard Czech and the Central Bohemian dialects of the Prague region. Other Bohemian regional dialects have become marginalized, while Moravian dialects remain more widespread and diverse, with a political movement for Moravian linguistic revival active since the 1990s.\nThese varieties of the language (Standard Czech, spoken/colloquial Standard Czech, Common Czech, and regional dialects) form a stylistic continuum, in which contact between varieties of a similar prestige influences change within them.\nCommon Czech.\nThe main Czech vernacular, spoken primarily in and around Prague but also throughout the country, is known as Common Czech (\"obecn\u00e1 \u010de\u0161tina\"). This is an academic distinction; most Czechs are unaware of the term or associate it with deformed or \"incorrect\" Czech. Compared to Standard Czech, Common Czech is characterized by simpler inflection patterns and differences in sound distribution.\nCommon Czech is distinguished from spoken/colloquial Standard Czech (), which is a stylistic variety within standard Czech. Tomasz Kamusella defines the spoken variety of Standard Czech as a compromise between Common Czech and the written standard, while Miroslav Kom\u00e1rek calls Common Czech an intersection of spoken Standard Czech and regional dialects.\nCommon Czech has become ubiquitous in most parts of the Czech Republic since the later 20th century. It is usually defined as an interdialect used in common speech in Bohemia and western parts of Moravia (by about two thirds of all inhabitants of the Czech Republic). Common Czech is not codified, but some of its elements have become adopted in the written standard. Since the second half of the 20th century, Common Czech elements have also been spreading to regions previously unaffected, as a consequence of media influence. Standard Czech is still the norm for politicians, businesspeople and other Czechs in formal situations, but Common Czech is gaining ground in journalism and the mass media. The colloquial form of Standard Czech finds limited use in daily communication due to the expansion of the Common Czech interdialect. It is sometimes defined as a theoretical construct rather than an actual tool of colloquial communication, since in casual contexts, the non-standard interdialect is preferred.\nCommon Czech phonology is based on that of the Central Bohemian dialect group, which has a slightly different set of vowel phonemes to Standard Czech. The phoneme /\u025b\u02d0/ is peripheral and usually merges with /i\u02d0/, e.g. in \"mal\u00fd m\u011bsto\" (small town), \"plam\u00ednek\" (little flame) and \"l\u00edtat\" (to fly), and a second native diphthong /\u025b\u026a\u032f/ occurs, usually in places where Standard Czech has /i\u02d0/, e.g. \"malej d\u016fm\" (small house), \"mlejn\" (mill), \"plejtvat\" (to waste), \"bejt\" (to be). In addition, a prothetic \"v-\" is added to most words beginning \"o-\", such as \"votev\u0159\u00edt vokno\" (to open the window).\nNon-standard morphological features that are more or less common among all Common Czech speakers include:\nExamples of declension (Standard Czech is added in italics for comparison):\n\"mlad\u00fd \u010dlov\u011bk \u2013 young man/person, mlad\u00ed lid\u00e9 \u2013 young people, mlad\u00fd st\u00e1t \u2013 young state, mlad\u00e1 \u017eena \u2013 young woman, mlad\u00e9 zv\u00ed\u0159e \u2013 young animal\"\nBohemian dialects.\nApart from the Common Czech vernacular, there remain a variety of other Bohemian dialects, mostly in marginal rural areas. Dialect use began to weaken in the second half of the 20th century, and by the early 1990s regional dialect use was stigmatized, associated with the shrinking lower class and used in literature or other media for comedic effect. Increased travel and media availability to dialect-speaking populations has encouraged them to shift to (or add to their own dialect) Standard Czech.\nThe Czech Statistical Office in 2003 recognized the following Bohemian dialects:\nMoravian dialects.\nThe Czech dialects spoken in Moravia and Silesia are known as Moravian (\"morav\u0161tina\"). In the Austro-Hungarian Empire, \"Bohemian-Moravian-Slovak\" was a language citizens could register as speaking (with German, Polish and several others). Of the Czech dialects, only Moravian is distinguished in nationwide surveys by the Czech Statistical Office. As of 2011, 62,908 Czech citizens spoke Moravian as their first language and 45,561 were diglossic (speaking Moravian and standard Czech as first languages).\nBeginning in the sixteenth century, some varieties of Czech resembled Slovak; the southeastern Moravian dialects, in particular, are sometimes considered dialects of Slovak rather than Czech. These dialects form a continuum between the Czech and Slovak languages, using the same declension patterns for nouns and pronouns and the same verb conjugations as Slovak.\nThe Czech Statistical Office in 2003 recognized the following Moravian dialects:\nSample.\nIn a 1964 textbook on Czech dialectology, B\u0159etislav Koudela used the following sentence to highlight phonetic differences between dialects:\nMutual intelligibility.\nCzech and Slovak have been considered mutually intelligible; speakers of either language can communicate with greater ease than those of any other pair of West Slavic languages. Since the 1993 dissolution of Czechoslovakia, mutual intelligibility has declined for younger speakers, probably because Czech speakers now experience less exposure to Slovak and vice versa.\nIn phonetic differences, Czech is characterized by a glottal stop before initial vowels and Slovak by its less-frequent use of long vowels than Czech; however, Slovak has long forms of the consonants \"r\" and \"l\" when they function as vowels. Slovak phonotactics employs a \"rhythmic law\", which forbids two syllables with long vowels from following one another in a word, unlike in Czech. Grammatically, although Czech (unlike Slovak) has a fully productive vocative case, both languages share a common syntax.\nOne study showed that Czech and Slovak lexicons differed by 80 percent, but this high percentage was found to stem primarily from differing orthographies and slight inconsistencies in morphological formation; Slovak morphology is more regular (when changing from the nominative to the locative case, \"Praha\" becomes \"Praze\" in Czech and \"Prahe\" in Slovak). The two lexicons are generally considered similar, with most differences found in colloquial vocabulary and some scientific terminology. Slovak has slightly more borrowed words than Czech.\nThe similarities between Czech and Slovak led to the languages being considered a single language by a group of 19th-century scholars who called themselves \"Czechoslavs\" (\"\u010cechoslovan\u00e9\"), believing that the peoples were connected in a way which excluded German Bohemians and (to a lesser extent) Hungarians and other Slavs. During the First Czechoslovak Republic (1918\u20131938), although \"Czechoslovak\" was designated as the republic's official language, both Czech and Slovak written standards were used. Standard written Slovak was partially modeled on literary Czech, and Czech was preferred for some official functions in the Slovak half of the republic. Czech influence on Slovak was protested by Slovak scholars, and when Slovakia broke off from Czechoslovakia in 1938 as the Slovak State (which then aligned with Nazi Germany in World War II), literary Slovak was deliberately distanced from Czech. When the Axis powers lost the war and Czechoslovakia reformed, Slovak developed somewhat on its own (with Czech influence); during the Prague Spring of 1968, Slovak gained independence from (and equality with) Czech, due to the transformation of Czechoslovakia from a unitary state to a federation. Since the dissolution of Czechoslovakia in 1993, \"Czechoslovak\" has referred to improvised pidgins of the languages which have arisen from the decrease in mutual intelligibility.\nVocabulary.\nCzech vocabulary derives primarily from Slavic, Baltic and other Indo-European roots. Although most verbs have Balto-Slavic origins, pronouns, prepositions and some verbs have wider, Indo-European roots. Some loanwords have been restructured by folk etymology to resemble native Czech words (e.g. \"h\u0159bitov\", \"graveyard\" and \"listina\", \"list\").\nMost Czech loanwords originated in one of two time periods. Earlier loanwords, primarily from German, Greek and Latin, arrived before the Czech National Revival. More recent loanwords derive primarily from English and French, and also from Hebrew, Arabic and Persian. Many Russian loanwords, principally animal names and naval terms, also exist in Czech.\nAlthough older German loanwords were colloquial, recent borrowings from other languages are associated with high culture. During the nineteenth century, words with Greek and Latin roots were rejected in favor of those based on older Czech words and common Slavic roots; \"music\" is \"muzyka\" in Polish and \"\u043c\u0443\u0437\u044b\u043a\u0430\" (\"muzyka\") in Russian, but in Czech it is \"hudba\". Some Czech words have been borrowed as loanwords into English and other languages\u2014for example, \"robot\" (from \"robota\", \"labor\") and \"polka\" (from \"polka\", \"Polish woman\" or from \"p\u016flka\" \"half\").\nSample text.\nAccording to Article 1 of the United Nations Universal Declaration of Human Rights:\nCzech: \"V\u0161ichni lid\u00e9 se rod\u00ed svobodn\u00ed a sob\u011b rovn\u00ed co do d\u016fstojnosti a pr\u00e1v. Jsou nad\u00e1ni rozumem a sv\u011bdom\u00edm a maj\u00ed spolu jednat v duchu bratrstv\u00ed.\"\nEnglish: \"All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood.\""}
{"id": "6344", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=6344", "title": "Capsid", "text": "A capsid is the protein shell of a virus, enclosing its genetic material. It consists of several oligomeric (repeating) structural subunits made of protein called protomers. The observable 3-dimensional morphological subunits, which may or may not correspond to individual proteins, are called capsomeres. The proteins making up the capsid are called capsid proteins or viral coat proteins (VCP). The capsid and inner genome is called the nucleocapsid.\nCapsids are broadly classified according to their structure. The majority of the viruses have capsids with either helical or icosahedral structure. Some viruses, such as bacteriophages, have developed more complicated structures due to constraints of elasticity and electrostatics. The icosahedral shape, which has 20 equilateral triangular faces, approximates a sphere, while the helical shape resembles the shape of a spring, taking the space of a cylinder but not being a cylinder itself. The capsid faces may consist of one or more proteins. For example, the foot-and-mouth disease virus capsid has faces consisting of three proteins named VP1\u20133.\nSome viruses are \"enveloped\", meaning that the capsid is coated with a lipid membrane known as the \"viral envelope\". The envelope is acquired by the capsid from an intracellular membrane in the virus' host; examples include the inner nuclear membrane, the Golgi membrane, and the cell's outer membrane.\nOnce the virus has infected a cell and begins replicating itself, new capsid subunits are synthesized using the protein biosynthesis mechanism of the cell. In some viruses, including those with helical capsids and especially those with RNA genomes, the capsid proteins co-assemble with their genomes. In other viruses, especially more complex viruses with double-stranded DNA genomes, the capsid proteins assemble into empty precursor procapsids that includes a specialized portal structure at one vertex. Through this portal, viral DNA is translocated into the capsid.\nStructural analyses of major capsid protein (MCP) architectures have been used to categorise viruses into lineages. For example, the bacteriophage PRD1, the algal virus Paramecium bursaria Chlorella virus (PBCV-1), mimivirus and the mammalian adenovirus have been placed in the same lineage, whereas tailed, double-stranded DNA bacteriophages (Caudovirales) and herpesvirus belong to a second lineage.\nSpecific shapes.\nIcosahedral.\nThe icosahedral structure is extremely common among viruses. The icosahedron consists of 20 triangular faces delimited by 12 fivefold vertexes and consists of 60 asymmetric units. Thus, an icosahedral virus is made of 60N protein subunits. The number and arrangement of capsomeres in an icosahedral capsid can be classified using the \"quasi-equivalence principle\" proposed by Donald Caspar and Aaron Klug. Like the Goldberg polyhedra, an icosahedral structure can be regarded as being constructed from pentamers and hexamers. The structures can be indexed by two integers \"h\" and \"k\", with formula_1 and formula_2; the structure can be thought of as taking \"h\" steps from the edge of a pentamer, turning 60 degrees counterclockwise, then taking \"k\" steps to get to the next pentamer. The triangulation number \"T\" for the capsid is defined as:\nIn this scheme, icosahedral capsids contain 12 pentamers plus 10(\"T\"\u00a0\u2212\u00a01) hexamers. The \"T\"-number is representative of the size and complexity of the capsids. Geometric examples for many values of \"h\", \"k\", and \"T\" can be found at List of geodesic polyhedra and Goldberg polyhedra.\nMany exceptions to this rule exist: For example, the polyomaviruses and papillomaviruses have pentamers instead of hexamers in hexavalent positions on a quasi-T=7 lattice. Members of the double-stranded RNA virus lineage, including reovirus, rotavirus and bacteriophage \u03c66 have capsids built of 120 copies of capsid protein, corresponding to a \"T=2\" capsid, or arguably a T=1 capsid with a dimer in the asymmetric unit. Similarly, many small viruses have a pseudo-T=3 (or P=3) capsid, which is organized according to a T=3 lattice, but with distinct polypeptides occupying the three quasi-equivalent positions \nT-numbers can be represented in different ways, for example \"T\"\u00a0=\u00a01 can only be represented as an icosahedron or a dodecahedron and, depending on the type of quasi-symmetry, \"T\"\u00a0=\u00a03 can be presented as a truncated dodecahedron, an icosidodecahedron, or a truncated icosahedron and their respective duals a triakis icosahedron, a rhombic triacontahedron, or a pentakis dodecahedron.\nProlate.\nAn elongated icosahedron is a common shape for the heads of bacteriophages. Such a structure is composed of a cylinder with a cap at either end. The cylinder is composed of 10 elongated triangular faces. The Q number (or Tmid), which can be any positive integer, specifies the number of triangles, composed of asymmetric subunits, that make up the 10 triangles of the cylinder. The caps are classified by the T (or Tend) number.\nThe bacterium \"E. coli\" is the host for bacteriophage T4 that has a prolate head structure. The bacteriophage encoded gp31 protein appears to be functionally homologous to \"E. coli\" chaparone protein GroES and able to substitute for it in the assembly of bacteriophage T4 virions during infection. Like GroES, gp31 forms a stable complex with GroEL chaperonin that is absolutely necessary for the folding and assembly \"in vivo\" of the bacteriophage T4 major capsid protein gp23.\nHelical.\nMany rod-shaped and filamentous plant viruses have capsids with helical symmetry. The helical structure can be described as a set of \"n\" 1-D molecular helices related by an \"n\"-fold axial symmetry. The helical transformation are classified into two categories: one-dimensional and two-dimensional helical systems. Creating an entire helical structure relies on a set of translational and rotational matrices which are coded in the protein data bank. Helical symmetry is given by the formula \"P\"\u00a0=\u00a0\"\u03bc\"\u00a0x\u00a0\"\u03c1\", where \"\u03bc\" is the number of structural units per turn of the helix, \"\u03c1\" is the axial rise per unit and \"P\" is the pitch of the helix. The structure is said to be open due to the characteristic that any volume can be enclosed by varying the length of the helix. The most understood helical virus is the tobacco mosaic virus. The virus is a single molecule of (+) strand RNA. Each coat protein on the interior of the helix bind three nucleotides of the RNA genome. Influenza A viruses differ by comprising multiple ribonucleoproteins, the viral NP protein organizes the RNA into a helical structure. The size is also different; the tobacco mosaic virus has a 16.33 protein subunits per helical turn, while the influenza A virus has a 28 amino acid tail loop.\nFunctions.\nThe functions of the capsid are to:\nThe virus must assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents. These include forms of natural radiation, extremes of pH or temperature and proteolytic and nucleolytic enzymes. For non-enveloped viruses, the capsid itself may be involved in interaction with receptors on the host cell, leading to penetration of the host cell membrane and internalization of the capsid. Delivery of the genome occurs by subsequent uncoating or disassembly of the capsid and release of the genome into the cytoplasm, or by ejection of the genome through a specialized portal structure directly into the host cell nucleus.\nOrigin and evolution.\nIt has been suggested that many viral capsid proteins have evolved on multiple occasions from functionally diverse cellular proteins. The recruitment of cellular proteins appears to have occurred at different stages of evolution so that some cellular proteins were captured and refunctionalized prior to the divergence of cellular organisms into the three contemporary domains of life, whereas others were hijacked relatively recently. As a result, some capsid proteins are widespread in viruses infecting distantly related organisms (e.g., capsid proteins with the jelly-roll fold), whereas others are restricted to a particular group of viruses (e.g., capsid proteins of alphaviruses).\nA computational model (2015) has shown that virus capsids may have originated in the RNA world and that they served as a means of horizontal transfer between replicator communities since these communities could not survive if the number of gene parasites increased, with certain genes being responsible for the formation of these structures and those that favored the survival of self-replicating communities. The displacement of these ancestral genes between cellular organisms could favor the appearance of new viruses during evolution."}
{"id": "6345", "revid": "5364", "url": "https://en.wikipedia.org/wiki?curid=6345", "title": "Central Dogma Of Genetics", "text": ""}
{"id": "6346", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=6346", "title": "Chloramphenicol", "text": "Chloramphenicol is an antibiotic useful for the treatment of a number of bacterial infections. This includes use as an eye ointment to treat conjunctivitis. By mouth or by injection into a vein, it is used to treat meningitis, plague, cholera, and typhoid fever. Its use by mouth or by injection is only recommended when safer antibiotics cannot be used. Monitoring both blood levels of the medication and blood cell levels every two days is recommended during treatment.\nCommon side effects include bone marrow suppression, nausea, and diarrhea. The bone marrow suppression may result in death. To reduce the risk of side effects treatment duration should be as short as possible. People with liver or kidney problems may need lower doses. In young children a condition known as gray baby syndrome may occur which results in a swollen stomach and low blood pressure. Its use near the end of pregnancy and during breastfeeding is typically not recommended. Chloramphenicol is a broad-spectrum antibiotic that typically stops bacterial growth by stopping the production of proteins.\nChloramphenicol was discovered after being isolated from \"Streptomyces venezuelae\" in 1947. Its chemical structure was identified and it was first synthesized in 1949. It is on the World Health Organization's List of Essential Medicines. It is available as a generic medication.\nMedical uses.\nThe original indication of chloramphenicol was in the treatment of typhoid, but the now almost universal presence of multiple drug-resistant \"Salmonella typhi\" has meant it is seldom used for this indication except when the organism is known to be sensitive.\nIn low-income countries, the WHO no longer recommends only chloramphenicol as first-line to treat meningitis, but recognises it may be used with caution if there are no available alternatives.\nIn the context of preventing endophthalmitis, a complication of cataract surgery, a 2017 systematic review found moderate evidence that using chloramphenicol eye drops in addition to an antibiotic injection (cefuroxime or penicillin) will likely lower the risk of endophthalmitis, compared to eye drops or antibiotic injections alone.\nSpectrum.\nChloramphenicol has a broad spectrum of activity and has been effective in treating ocular infections such as conjunctivitis, blepharitis etc. caused by a number of bacteria including \"Staphylococcus aureus, Streptococcus pneumoniae\", and \"Escherichia coli\". It is not effective against \"Pseudomonas aeruginosa\". The following susceptibility data represent the minimum inhibitory concentration for a few medically significant organisms.\nEach of these concentrations is dependent upon the bacterial strain being targeted. Some strains of \"E. coli\", for example, show spontaneous emergence of chloramphenicol resistance.\nResistance.\nThree mechanisms of resistance to chloramphenicol are known: reduced membrane permeability, mutation of the 50S ribosomal subunit, and elaboration of chloramphenicol acetyltransferase. It is easy to select for reduced membrane permeability to chloramphenicol \"in vitro\" by serial passage of bacteria, and this is the most common mechanism of low-level chloramphenicol resistance. High-level resistance is conferred by the \"cat\"-gene; this gene codes for an enzyme called chloramphenicol acetyltransferase, which inactivates chloramphenicol by covalently linking one or two acetyl groups, derived from acetyl-\"S\"-coenzyme A, to the hydroxyl groups on the chloramphenicol molecule. The acetylation prevents chloramphenicol from binding to the ribosome. Resistance-conferring mutations of the 50S ribosomal subunit are rare.\nChloramphenicol resistance may be carried on a plasmid that also codes for resistance to other drugs. One example is the ACCoT plasmid (A=ampicillin, C=chloramphenicol, Co=co-trimoxazole, T=tetracycline), which mediates multiple drug resistance in typhoid (also called R factors).\nAs of 2014 some \"Enterococcus faecium\" and\" Pseudomonas aeruginosa\" strains are resistant to chloramphenicol. Some \"Veillonella\" spp. and \"Staphylococcus capitis\" strains have also developed resistance to chloramphenicol to varying degrees.\nAdverse effects.\nAplastic anemia.\nThe most serious side effect of chloramphenicol treatment is aplastic anaemia. This effect is rare and sometimes fatal. The risk of AA is high enough that alternatives should be strongly considered. Treatments are available but expensive. No way exists to predict who may or may not get this side effect. The effect usually occurs weeks or months after treatment has been stopped, and a genetic predisposition may be involved. It is not known whether monitoring the blood counts of patients can prevent the development of aplastic anaemia, but patients are recommended to have a baseline blood count with a repeat blood count every few days while on treatment. Chloramphenicol should be discontinued if the complete blood count drops. The highest risk is with oral chloramphenicol (affecting 1 in 24,000\u201340,000) and the lowest risk occurs with eye drops (affecting less than one in 224,716 prescriptions).\nThiamphenicol, a related compound with a similar spectrum of activity, is available in Italy and China for human use, and has never been associated with aplastic anaemia. Thiamphenicol is available in the U.S. and Europe as a veterinary antibiotic, but is not approved for use in humans.\nBone marrow suppression.\nChloramphenicol may cause bone marrow suppression during treatment; this is a direct toxic effect of the drug on human mitochondria. This effect manifests first as a fall in hemoglobin levels, which occurs quite predictably once a cumulative dose of 20\u00a0g has been given. The anaemia is fully reversible once the drug is stopped and does not predict future development of aplastic anaemia. Studies in mice have suggested existing marrow damage may compound any marrow damage resulting from the toxic effects of chloramphenicol.\nLeukemia.\nLeukemia, a cancer of the blood or bone marrow, is characterized by an abnormal increase of immature white blood cells. The risk of childhood leukemia is increased, as demonstrated in a Chinese case\u2013control study, and the risk increases with length of treatment.\nGray baby syndrome.\nIntravenous chloramphenicol use has been associated with the so-called gray baby syndrome.\nThis phenomenon occurs in newborn infants because they do not yet have fully functional liver enzymes (i.e. UDP-glucuronyl transferase), so chloramphenicol remains unmetabolized in the body.\nThis causes several adverse effects, including hypotension and cyanosis. The condition can be prevented by using the drug at the recommended doses, and monitoring blood levels.\nHypersensitivity reactions.\nFever, macular and vesicular rashes, angioedema, urticaria, and anaphylaxis may occur. Herxheimer's reactions have occurred during therapy for typhoid fever.\nNeurotoxic reactions.\nHeadache, mild depression, mental confusion, and delirium have been described in patients receiving chloramphenicol. Optic and peripheral neuritis have been reported, usually following long-term therapy. If this occurs, the drug should be promptly withdrawn.\nPharmacokinetics.\nChloramphenicol is extremely lipid-soluble; it remains relatively unbound to protein and is a small molecule. It has a large apparent volume of distribution and penetrates effectively into all tissues of the body, including the brain. Distribution is not uniform, with highest concentrations found in the liver and kidney, with lowest in the brain and cerebrospinal fluid. The concentration achieved in brain and cerebrospinal fluid is around 30 to 50% of the overall average body concentration, even when the meninges are not inflamed; this increases to as high as 89% when the meninges are inflamed.\nChloramphenicol increases the absorption of iron.\nUse in special populations.\nChloramphenicol is metabolized by the liver to chloramphenicol glucuronate (which is inactive). In liver impairment, the dose of chloramphenicol must therefore be reduced. No standard dose reduction exists for chloramphenicol in liver impairment, and the dose should be adjusted according to measured plasma concentrations.\nThe majority of the chloramphenicol dose is excreted by the kidneys as the inactive metabolite, chloramphenicol glucuronate. Only a tiny fraction of the chloramphenicol is excreted by the kidneys unchanged. Plasma levels should be monitored in patients with renal impairment, but this is not mandatory. Chloramphenicol succinate ester (an intravenous prodrug form) is readily excreted unchanged by the kidneys, more so than chloramphenicol base, and this is the major reason why levels of chloramphenicol in the blood are much lower when given intravenously than orally.\nChloramphenicol passes into breast milk, so should therefore be avoided during breast feeding, if possible.\nDose monitoring.\nPlasma levels of chloramphenicol must be monitored in neonates and patients with abnormal liver function. Plasma levels should be monitored in all children under the age of four, the elderly, and patients with kidney failure.\nBecause efficacy and toxicity of chloramphenicol are associated with a maximum serum concentration, peak levels (one hour after the intravenous dose is given) should be 10\u201320\u00a0\u00b5g/ml with toxicity ; trough levels (taken immediately before a dose) should be 5\u201310\u00a0\u00b5g/ml.\nDrug interactions.\nAdministration of chloramphenicol concomitantly with bone marrow depressant drugs is contraindicated, although concerns over aplastic anaemia associated with ocular chloramphenicol have largely been discounted.\nChloramphenicol is a potent inhibitor of the cytochrome P450 isoforms CYP2C19 and CYP3A4 in the liver. Inhibition of CYP2C19 causes decreased metabolism and therefore increased levels of, for example, antidepressants, antiepileptics, proton-pump inhibitors, and anticoagulants if they are given concomitantly. Inhibition of CYP3A4 causes increased levels of, for example, calcium channel blockers, immunosuppressants, chemotherapeutic drugs, benzodiazepines, azole antifungals, tricyclic antidepressants, macrolide antibiotics, SSRIs, statins, cardiac antiarrhythmics, antivirals, anticoagulants, and PDE5 inhibitors.\nDrug antagonistic.\nChloramphenicol is antagonistic with most cephalosporins and using both together should be avoided in the treatment of infections.\nMechanism of action.\nChloramphenicol is a bacteriostatic by inhibiting protein synthesis. It prevents protein chain elongation by inhibiting the peptidyl transferase activity of the bacterial ribosome. It specifically binds to A2451 and A2452 residues in the 23S rRNA of the 50S ribosomal subunit, preventing peptide bond formation. Chloramphenicol directly interferes with substrate binding in the ribosome, as compared to macrolides, which sterically block the progression of the growing peptide.\nHistory.\nChloramphenicol was first isolated from \"Streptomyces venezuelae\" in 1947 and in 1949 a team of scientists at Parke-Davis including Mildred Rebstock published their identification of the chemical structure and their synthesis, making it the first antibiotic to be made instead of extracted from a microorganism.\nIn 2007, the accumulation of reports associating aplastic anemia and blood dyscrasia with chloramphenicol eye drops lead to the classification of \u201cprobable human carcinogen\u201d according to World Health Organization criteria, based on the known published case reports and the spontaneous reports submitted to the National Registry of Drug-Induced Ocular Side Effects.\nSociety and culture.\nNames.\nChloramphenicol is available as a generic worldwide under many brandnames and also under various generic names in eastern Europe and Russia, including chlornitromycin, levomycetin, and chloromycetin; the racemate is known as synthomycetin.\nFormulations.\nChloramphenicol is available as a capsule or as a liquid. In some countries, it is sold as chloramphenicol palmitate ester (CPE). CPE is inactive, and is hydrolysed to active chloramphenicol in the small intestine. No difference in bioavailability is noted between chloramphenicol and CPE.\nManufacture of oral chloramphenicol in the U.S. stopped in 1991, because the vast majority of chloramphenicol-associated cases of aplastic anaemia are associated with the oral preparation. No oral formulation of chloramphenicol is now available in the U.S.\nIn molecular biology, chloramphenicol is prepared in ethanol.\nIntravenous.\nThe intravenous (IV) preparation of chloramphenicol is the succinate ester. This creates a problem: Chloramphenicol succinate ester is an inactive prodrug and must first be hydrolysed to chloramphenicol; however, the hydrolysis process is often incomplete, and 30% of the dose is lost and removed in the urine. Serum concentrations of IV chloramphenicol are only 70% of those achieved when chloramphenicol is given orally. For this reason, the dose needs to be increased to 75\u00a0mg/kg/day when administered IV to achieve levels equivalent to the oral dose.\nOily.\nOily chloramphenicol (or chloramphenicol oil suspension) is a long-acting preparation of chloramphenicol first introduced by Roussel in 1954; marketed as Tifomycine, it was originally used as a treatment for typhoid. Roussel stopped production of oily chloramphenicol in 1995; the International Dispensary Association has manufactured it since 1998, first in Malta and then in India from December 2004.\nOily chloramphenicol was first used to treat meningitis in 1975 and numerous studies since have demonstrated its efficacy. It is the cheapest treatment available for meningitis (US$5 per treatment course, compared to US$30 for ampicillin and US$15 for five days of ceftriaxone). It has the great advantage of requiring only a single injection, whereas ceftriaxone is traditionally given daily for five days. This recommendation may yet change, now that a single dose of ceftriaxone (cost US$3) has been shown to be equivalent to one dose of oily chloramphenicol.\nEye drops.\nChloramphenicol is still used occasionally in topical preparations (ointments and eye drops) for the treatment of bacterial conjunctivitis. Isolated case reports of aplastic anaemia following use of chloramphenicol eyedrops exist, but the risk is estimated to be of the order of less than one in 224,716 prescriptions. In Mexico, this is the treatment used prophylactically in newborns.\nVeterinary uses.\nAlthough its use in veterinary medicine is highly restricted, chloramphenicol still has some important veterinary uses. It is currently considered the most useful treatment of chlamydial disease in koalas. The pharmacokinetics of chloramphenicol have been investigated in koalas.\nAlthough unpublished, recent research suggests chloramphenicol could also be applied to frogs to prevent their widespread destruction from fungal infections. It has recently been discovered to be a life-saving cure for chytridiomycosis in amphibians. Chytridiomycosis is a fungal disease, blamed for the extinction of one-third of the 120 frog species lost since 1980."}
{"id": "6347", "revid": "15228523", "url": "https://en.wikipedia.org/wiki?curid=6347", "title": "Cut-up technique", "text": "The cut-up technique (or \"d\u00e9coup\u00e9\" in French) is an aleatory literary technique in which a written text is cut up and rearranged to create a new text. The concept can be traced to at least the Dadaists of the 1920s, but was popularized in the late 1950s and early 1960s by writer, chaos magician and member of the international magical organization Illuminates of Thanateros, William S. Burroughs, and has since been used in a wide variety of contexts.\nTechnique.\nThe cut-up and the closely associated fold-in are the two main techniques:\nWilliam Burroughs cited T. S. Eliot's 1922 poem, \"The Waste Land\", and John Dos Passos' \"U.S.A.\" trilogy, which incorporated newspaper clippings, as early examples of the cut ups he popularized.\nGil J. Wolman developed cut-up techniques as part of his lettrist practice in the early 1950s.\nAlso in the 1950s, painter and writer Brion Gysin more fully developed the cut-up method after accidentally re-discovering it. He had placed layers of newspapers as a mat to protect a tabletop from being scratched while he cut papers with a razor blade. Upon cutting through the newspapers, Gysin noticed that the sliced layers offered interesting juxtapositions of text and image. He began deliberately cutting newspaper articles into sections, which he randomly rearranged. The book \"Minutes to Go\" resulted from his initial cut-up experiment: unedited and unchanged cut-ups which emerged as coherent and meaningful prose. South African poet Sinclair Beiles also used this technique and co-authored \"Minutes To Go\".\nGysin introduced Burroughs to the technique at the Beat Hotel. The pair later applied the technique to printed media and audio recordings in an effort to decode the material's implicit content, hypothesizing that such a technique could be used to discover the true meaning of a given text. Burroughs also suggested cut-ups may be effective as a form of divination saying, \"When you cut into the present the future leaks out.\" Burroughs also further developed the \"fold-in\" technique. In 1977, Burroughs and Gysin published \"The Third Mind\", a collection of cut-up writings and essays on the form. Jeff Nuttall's publication \"My Own Mag\" was another important outlet for the then-radical technique.\nIn an interview, Alan Burns noted that for \"Europe After The Rain\" (1965) and subsequent novels he used a version of cut-ups: \"I did not actually use scissors, but I folded pages, read across columns, and so on, discovering for myself many of the techniques Burroughs and Gysin describe\".\nArgentine writer Julio Cort\u00e1zar often used cut ups in his 1963 novel \"Hopscotch\".\nHistory in literature.\nIn 1969, poets Howard W. Bergerson and J. A. Lindon developed a cut-up technique known as vocabularyclept poetry, in which a poem is formed by taking all the words of an existing poem and rearranging them, often preserving the metre and stanza lengths.\nA precedent of the technique occurred during a Dadaist rally in the 1920s in which Tristan Tzara offered to create a poem on the spot by pulling words at random from a hat. Collage, which was popularized roughly contemporaneously with the Surrealist movement, sometimes incorporated texts such as newspapers or brochures. Prior to this event, the technique had been published in an issue of 391 in the poem by Tzara, \"dada manifesto on feeble love and bitter love\" under the sub-title, \"TO MAKE A DADAIST POEM\".\nA drama scripted for five voices by performance poet Hedwig Gorski in 1977 originated the idea of creating poetry only for performance instead of for print publication. The \"neo-verse drama\" titled \"Booby, Mama!\" written for \"guerilla theater\" performances in public places used a combination of newspaper cut-ups that were edited and choreographed for a troupe of non-professional street actors.\nKathy Acker, a literary and intermedia artist, sampled external sources and reconfigured them into the creation of shifting versions of her own constructed identity. In her late 1970s novel \"Blood and Guts in High School\", Acker explored literary cut-up and appropriation as an integral part of her method.\nHistory in film.\nAntony Balch and Burroughs created a collaboration film, \"The Cut-Ups\" that opened in London in 1967. This was part of an abandoned project called \"Guerrilla Conditions\" meant as a documentary on Burroughs and filmed throughout 1961\u20131965. Inspired by Burroughs' and Gysin's technique of cutting up text and rearranging it in random order, Balch had an editor cut his footage for the documentary into little pieces and impose no control over its reassembly. The film opened at Oxford Street's Cinephone cinema and had a disturbing reaction. Many audience members claimed the film made them ill, others demanded their money back, while some just stumbled out of the cinema ranting \"it's disgusting\". Other cut-up films include \"Ghost at n\u00b09 (Paris)\" (1963\u201372), a posthumously released short film compiled from reels found at Balch's office after his death, and \"William Buys a Parrott\" (1982), \"Bill and Tony\" (1972), \"Towers Open Fire\" (1963) and \"The Junky's Christmas\" (1966).\nInfluence in music.\nFrom the early 1970s, David Bowie used cut-ups to create some of his lyrics. Thom Yorke applied a similar method in Radiohead's \"Kid A\" (2000) album, writing single lines, putting them into a hat, and drawing them out at random while the band rehearsed the songs. Perhaps indicative of Thom Yorke's influences, instructions for \"How to make a Dada poem\" appeared on Radiohead's website at this time.\nStephen Mallinder of Cabaret Voltaire reported to \"Inpress\" magazine's Andrez Bergen that \"I do think the manipulation of sound in our early days \u2013 the physical act of cutting up tapes, creating tape loops and all that \u2013 has a strong reference to Burroughs and Gysin.\" Another industrial music pioneer, Al Jourgensen of Ministry, named Burroughs and his cut-up technique as the most important influence on how he approached the use of samples.\nA modern example of the cut-up technique used in music is the EP \"Fetus\" by Patrick Roach."}
{"id": "6348", "revid": "835", "url": "https://en.wikipedia.org/wiki?curid=6348", "title": "Congressional Medal of Honour", "text": ""}
{"id": "6352", "revid": "40876282", "url": "https://en.wikipedia.org/wiki?curid=6352", "title": "Congenital iodine deficiency syndrome", "text": "Congenital iodine deficiency syndrome is a medical condition present at birth marked by impaired physical and mental development, due to insufficient thyroid hormone (hypothyroidism) often caused by insufficient dietary iodine during pregnancy. It is one cause of underactive thyroid function at birth, called congenital hypothyroidism, and also referred to as \"cretinism\".\nIf untreated, it results in impairment of both physical and mental development. Symptoms may include goiter, poor length growth in infants, reduced adult stature, thickened skin, hair loss, enlarged tongue, a protruding abdomen; delayed bone maturation and puberty in children; and mental deterioration, neurological impairment, impeded ovulation, and infertility in adults.\nIn developed countries, thyroid function testing of newborns has assured that in those affected, treatment with the thyroid hormone thyroxine is begun promptly. This screening and treatment has virtually eliminated the consequences of the disease.\nSigns and symptoms.\nIodine deficiency causes gradual enlargement of the thyroid gland, referred to as a goiter. Poor length growth is apparent as early as the first year of life. Adult stature without treatment ranges from , depending on severity, sex, and other genetic factors. Other signs include thickened skin, hair loss, enlarged tongue, and a protruding abdomen. In children, bone maturation and puberty are severely delayed. In adults, ovulation is impeded and infertility is common.&lt;ref&gt;"}
{"id": "6353", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=6353", "title": "Cretin", "text": "Cretin may refer to:\nEducation.\nSome education institutions are named after bishop Joseph Cr\u00e9tin:"}
{"id": "6354", "revid": "14965160", "url": "https://en.wikipedia.org/wiki?curid=6354", "title": "Council of Trent", "text": "The Council of Trent (), held between 1545 and 1563 in Trent (or Trento, in northern Italy), was the 19th ecumenical council of the Catholic Church. Prompted by the Protestant Reformation, it has been described as the embodiment of the Counter-Reformation.\nThe Council issued condemnations of what it defined to be heresies committed by proponents of Protestantism, and also issued key statements and clarifications of the Church's doctrine and teachings, including scripture, the Biblical canon, sacred tradition, original sin, justification, salvation, the sacraments, the Mass, and the veneration of saints. The Council met for twenty-five sessions between 13 December 1545 and 4 December 1563. Pope Paul III, who convoked the Council, oversaw the first eight sessions (1545\u201347), while the twelfth to sixteenth sessions (1551\u201352) were overseen by Pope Julius III and the seventeenth to twenty-fifth sessions (1562\u201363) by Pope Pius IV.\nThe consequences of the Council were also significant with regard to the Church's liturgy and practices. During its deliberations, the Council made the Vulgate the official example of the Biblical canon and commissioned the creation of a standard version, although this was not achieved until the 1590s. In 1565, a year after the Council finished its work, Pius IV issued the Tridentine Creed (after \"Tridentum\", Trent's Latin name) and his successor Pius V then issued the Roman Catechism and revisions of the Breviary and Missal in, respectively, 1566, 1568 and 1570. These, in turn, led to the codification of the Tridentine Mass, which remained the Church's primary form of the Mass for the next four hundred years.\nMore than three hundred years passed until the next ecumenical council, the First Vatican Council, was convened in 1869.\nBackground information.\nObstacles and events before the Council's problem area.\nOn 15 March 1517, the Fifth Council of the Lateran closed its activities with a number of reform proposals (on the selection of bishops, taxation, censorship and preaching) but not on the major problems that confronted the Church in Germany and other parts of Europe. A few months later, on 31 October 1517, Martin Luther issued his \"95 Theses\" in Wittenberg.\nA general, free council in Germany.\nLuther's position on ecumenical councils shifted over time, but in 1520 he appealed to the German princes to oppose the papal Church, if necessary with a council in Germany, open and free of the Papacy. After the Pope condemned in \"Exsurge Domine\" fifty-two of Luther's theses as heresy, German opinion considered a council the best method to reconcile existing differences. German Catholics, diminished in number, hoped for a council to clarify matters.\nIt took a generation for the council to materialise, partly due to papal fears over potentially renewing a schism over conciliarism; partly because Lutherans demanded the exclusion of the papacy from the Council; partly because of ongoing political rivalries between France and the Holy Roman Empire; and partly due to the Turkish dangers in the Mediterranean. Under Pope Clement VII (1523\u201334), troops of the Catholic Holy Roman Emperor Charles V sacked Papal Rome in 1527, \"raping, killing, burning, stealing, the like had not been seen since the Vandals\". Saint Peter's Basilica and the Sistine Chapel were used for horses. Pope Clement, fearful of the potential for more violence, delayed calling the Council.\nCharles V strongly favoured a council but needed the support of King Francis I of France, who attacked him militarily. Francis I generally opposed a general council due to partial support of the Protestant cause within France. In 1532 he agreed to the Nuremberg Religious Peace granting religious liberty to the Protestants, and in 1533 he further complicated matters when suggesting a general council to include both Catholic and Protestant rulers of Europe that would devise a compromise between the two theological systems. This proposal met the opposition of the Pope for it gave recognition to Protestants and also elevated the secular Princes of Europe above the clergy on church matters. Faced with a Turkish attack, Charles held the support of the Protestant German rulers, all of whom delayed the opening of the Council of Trent.\nOccasion, sessions, and attendance.\nIn reply to the Papal bull \"Exsurge Domine\" of Pope Leo X (1520), Martin Luther burned the document and appealed for a general council. In 1522 German diets joined in the appeal, with Charles V seconding and pressing for a council as a means of reunifying the Church and settling the Reformation controversies. Pope Clement VII (1523\u20131534) was vehemently against the idea of a council, agreeing with Francis I of France, after Pope Pius II, in his bull \"Execrabilis\" (1460) and his reply to the University of Cologne (1463), set aside the theory of the supremacy of general councils laid down by the Council of Constance.\nPope Paul III (1534\u20131549), seeing that the Protestant Reformation was no longer confined to a few preachers, but had won over various princes, particularly in Germany, to its ideas, desired a council. Yet when he proposed the idea to his cardinals, it was almost unanimously opposed. Nonetheless, he sent nuncios throughout Europe to propose the idea. Paul III issued a decree for a general council to be held in Mantua, Italy, to begin on 23 May 1537. Martin Luther wrote the Smalcald Articles in preparation for the general council. The Smalcald Articles were designed to sharply define where the Lutherans could and could not compromise. The council was ordered by the Emperor and Pope Paul III to convene in Mantua on 23 May 1537. It failed to convene after another war broke out between France and Charles V, resulting in a non-attendance of French prelates. Protestants refused to attend as well. Financial difficulties in Mantua led the Pope in the autumn of 1537 to move the council to Vicenza, where participation was poor. The Council was postponed indefinitely on 21 May 1539. Pope Paul III then initiated several internal Church reforms while Emperor Charles V convened with Protestants and Cardinal Gasparo Contarini at the Diet of Regensburg, to reconcile differences. Mediating and conciliatory formulations were developed on certain topics. In particular, a two-part doctrine of justification was formulated that would later be rejected at Trent. Unity failed between Catholic and Protestant representatives \"because of different concepts of \"Church\" and \"justification\"\".\nHowever, the council was delayed until 1545 and, as it happened, convened right before Luther's death. Unable, however, to resist the urging of Charles V, the pope, after proposing Mantua as the place of meeting, convened the council at Trent (at that time ruled by a prince-bishop under the Holy Roman Empire), on 13 December 1545; the Pope's decision to transfer it to Bologna in March 1547 on the pretext of avoiding a plague failed to take effect and the Council was indefinitely prorogued on 17 September 1549. None of the three popes reigning over the duration of the council ever attended, which had been a condition of Charles V. Papal legates were appointed to represent the Papacy.\nReopened at Trent on 1 May 1551 by the convocation of Pope Julius III (1550\u20131555), it was broken up by the sudden victory of Maurice, Elector of Saxony over Emperor Charles V and his march into surrounding state of Tirol on 28 April 1552. There was no hope of reassembling the council while the very anti-Protestant Paul IV was Pope. The council was reconvened by Pope Pius IV (1559\u20131565) for the last time, meeting from 18 January 1562 at Santa Maria Maggiore, and continued until its final adjournment on 4 December 1563. It closed with a series of ritual acclamations honouring the reigning Pope, the Popes who had convoked the Council, the emperor and the kings who had supported it, the papal legates, the cardinals, the ambassadors present, and the bishops, followed by acclamations of acceptance of the faith of the Council and its decrees, and of anathema for all heretics.\nThe history of the council is thus divided into three distinct periods: 1545\u20131549, 1551\u20131552 and 1562\u20131563. During the second period, the Protestants present asked for a renewed discussion on points already defined and for bishops to be released from their oaths of allegiance to the Pope. When the last period began, all intentions of conciliating the Protestants was gone and the Jesuits had become a strong force. This last period was begun especially as an attempt to prevent the formation of a general council including Protestants, as had been demanded by some in France.\nThe number of attending members in the three periods varied considerably. The council was small to begin with, opening with only about 30 bishops. It increased toward the close, but never reached the number of the First Council of Nicaea (which had 318 members) nor of the First Vatican Council (which numbered 744). The decrees were signed in 1563 by 255 members, the highest attendance of the whole council, including four papal legates, two cardinals, three patriarchs, twenty-five archbishops, and 168 bishops, two-thirds of whom were Italians. The Italian and Spanish prelates were vastly preponderant in power and numbers. At the passage of the most important decrees, not more than sixty prelates were present. Although most Protestants did not attend, ambassadors and theologians of Brandenburg, W\u00fcrttemberg, and Strasbourg attended having been granted an improved safe conduct\nThe French monarchy boycotted the entire council until the last minute when a delegation led by Charles de Guise, Cardinal of Lorraine finally arrived in November 1562. The first outbreak of the French Wars of Religion had occurred earlier in the year and the French Church, facing a significant and powerful Protestant minority in France, experienced iconoclasm violence regarding the use of sacred images. Such concerns were not primary in the Italian and Spanish Churches. The last-minute inclusion of a decree on sacred images was a French initiative, and the text, never discussed on the floor of the council or referred to council theologians, was based on a French draft.\nObjectives and overall results.\nThe main objectives of the council were twofold, although there were other issues that were also discussed:\nThe doctrinal decisions of the council are set forth in decrees (\"decreta\"), which are divided into chapters (\"capita\"), which contain the positive statement of the conciliar dogmas, and into short canons (\"canones\"), which condemn the dissenting Protestant views with the concluding \"anathema sit\" (\"let him be anathema\").\nDecrees.\nThe doctrinal acts are as follows: after reaffirming the Niceno-Constantinopolitan Creed (third session), the decree was passed (fourth session) confirming that the deuterocanonical books were on a par with the other books of the canon (against Luther's placement of these books in the Apocrypha of his edition) and coordinating church tradition with the Scriptures as a rule of faith. The Vulgate translation was affirmed to be authoritative for the text of Scripture.\nJustification (sixth session) was declared to be offered upon the basis of human cooperation with divine grace as opposed to the Protestant doctrine of passive reception of grace. Understanding the Protestant \"faith alone\" doctrine to be one of simple human confidence in divine mercy, the Council rejected the \"vain confidence\" of the Protestants, stating that no one can know who has received the grace of God. Furthermore, the Council affirmed\u2014against some Protestants\u2014that the grace of God can be forfeited through mortal sin.\nThe greatest weight in the Council's decrees is given to the sacraments. The seven sacraments were reaffirmed and the Eucharist pronounced to be a true propitiatory sacrifice as well as a sacrament, in which the bread and wine were consecrated into the Eucharist (thirteenth and twenty-second sessions). The term transubstantiation was used by the Council, but the specific Aristotelian explanation given by Scholasticism was not cited as dogmatic. Instead, the decree states that Christ is \"really, truly, substantially present\" in the consecrated forms. The sacrifice of the Mass was to be offered for dead and living alike and in giving to the apostles the command \"do this in remembrance of me,\" Christ conferred upon them a sacerdotal power. The practise of withholding the cup from the laity was confirmed (twenty-first session) as one which the Church Fathers had commanded for good and sufficient reasons; yet in certain cases the Pope was made the supreme arbiter as to whether the rule should be strictly maintained. On the language of the Mass, \"contrary to what is often said\", the council condemned the belief that only vernacular languages should be used, while insisting on the use of Latin.\nOrdination (twenty-third session) was defined to imprint an indelible character on the soul. The priesthood of the New Testament takes the place of the Levitical priesthood. To the performance of its functions, the consent of the people is not necessary.\nIn the decrees on marriage (twenty-fourth session) the excellence of the celibate state was reaffirmed, concubinage condemned and the validity of marriage made dependent upon the wedding taking place before a priest and two witnesses, although the lack of a requirement for parental consent ended a debate that had proceeded from the 12th century. In the case of a divorce, the right of the innocent party to marry again was denied so long as the other party was alive, even if the other party had committed adultery. However the council \"refused \u2026 to assert the necessity or usefulness of clerical celibacy\".\nIn the twenty-fifth and last session, the doctrines of purgatory, the invocation of saints and the veneration of relics were reaffirmed, as was also the efficacy of indulgences as dispensed by the Church according to the power given her, but with some cautionary recommendations, and a ban on the sale of indulgences. Short and rather inexplicit passages concerning religious images, were to have great impact on the development of Catholic Church art. Much more than the Second Council of Nicaea (787) the Council fathers of Trent stressed the pedagogical purpose of Christian images.\nThe council appointed, in 1562 (eighteenth session), a commission to prepare a list of forbidden books (\"Index Librorum Prohibitorum\"), but it later left the matter to the Pope. The preparation of a catechism and the revision of the Breviary and Missal were also left to the pope. The catechism embodied the council's far-reaching results, including reforms and definitions of the sacraments, the Scriptures, church dogma, and duties of the clergy.\nRatification and promulgation.\nOn adjourning, the Council asked the supreme pontiff to ratify all its decrees and definitions. This petition was complied with by Pope Pius IV, on 26 January 1564, in the papal bull, \"Benedictus Deus\", which enjoins strict obedience upon all Catholics and forbids, under pain of ex-communication, all unauthorised interpretation, reserving this to the Pope alone and threatens the disobedient with \"the indignation of Almighty God and of his blessed apostles, Peter and Paul.\" Pope Pius appointed a commission of cardinals to assist him in interpreting and enforcing the decrees.\nThe \"Index librorum prohibitorum\" was announced in 1564 and the following books were issued with the papal imprimatur: the Profession of the Tridentine Faith and the Tridentine Catechism (1566), the Breviary (1568), the Missal (1570) and the Vulgate (1590 and then 1592).\nThe decrees of the council were acknowledged in Italy, Portugal, Poland and by the Catholic princes of Germany at the Diet of Augsburg in 1566. Philip II of Spain accepted them for Spain, the Netherlands and Sicily inasmuch as they did not infringe the royal prerogative. In France, they were officially recognised by the king only in their doctrinal parts. Although the disciplinary or moral reformatory decrees were never published by the throne, they received official recognition at provincial synods and were enforced by the bishops. Holy Roman Emperors Ferdinand I and Maximilian II never recognized the existence of any of the decrees. No attempt was made to introduce it into England. Pius IV sent the decrees to Mary, Queen of Scots, with a letter dated 13 June 1564, requesting her to publish them in Scotland, but she dared not do it in the face of John Knox and the Reformation.\nThese decrees were later supplemented by the First Vatican Council of 1870.\nPublication of documents.\nA comprehensive history is found in Hubert Jedin's \"The History of the Council of Trent (Geschichte des Konzils von Trient)\" with about 2500 pages in four volumes: \"The History of the Council of Trent: The fight for a Council\" (Vol I, 1951); \"The History of the Council of Trent: The first Sessions in Trent (1545\u20131547)\" (Vol II, 1957); \"The History of the Council of Trent: Sessions in Bologna 1547\u20131548 and Trento 1551\u20131552\" (Vol III, 1970, 1998); \"The History of the Council of Trent: Third Period and Conclusion\" (Vol IV, 1976).\nThe canons and decrees of the council have been published very often and in many languages. The first issue was by Paulus Manutius (Rome, 1564). Commonly-used Latin editions are by Judocus Le Plat (Antwerp, 1779) and by Johann Friedrich von Schulte and Aemilius Ludwig Richter (Leipzig, 1853). Other editions are in vol. vii. of the \"Acta et decreta conciliorum recentiorum. Collectio Lacensis\" (7 vols., Freiburg, 1870\u201390), reissued as independent volume (1892); \"Concilium Tridentinum: Diariorum, actorum, epistularum, \u2026 collectio\", ed. Sebastianus Merkle (4 vols., Freiburg, 1901 sqq.); as well as Mansi, \"Concilia\", xxxv. 345 sqq. Note also Carl Mirbt, \"Quellen\", 2d ed, pp.\u00a0202\u2013255. An English edition is by James Waterworth (London, 1848; \"With Essays on the External and Internal History of the Council\").\nThe original acts and debates of the council, as prepared by its general secretary, Bishop Angelo Massarelli, in six large folio volumes, are deposited in the Vatican Library and remained there unpublished for more than 300 years and were brought to light, though only in part, by Augustin Theiner, priest of the oratory (d. 1874), in \"Acta genuina sancti et oecumenici Concilii Tridentini nunc primum integre edita\" (2 vols., Leipzig, 1874).\nMost of the official documents and private reports, however, which bear upon the council, were made known in the 16th century and since. The most complete collection of them is that of J. Le Plat, \"Monumentorum ad historicam Concilii Tridentini collectio\" (7 vols., Leuven, 1781\u201387). New materials(Vienna, 1872); by JJI von D\u00f6llinger \"(Ungedruckte Berichte und Tageb\u00fccher zur Geschichte des Concilii von Trient)\" (2 parts, N\u00f6rdlingen, 1876); and August von Druffel, \"Monumenta Tridentina\" (Munich, 1884\u201397).\nProtestant response.\nOut of 87 books written between 1546 and 1564 attacking the Council of Trent, 41 were written by Pier Paolo Vergerio, a former papal nuncio turned Protestant Reformer. The 1565\u201373 \"Examen decretorum Concilii Tridentini\" (\"Examination of the Council of Trent\") by Martin Chemnitz was the main Lutheran response to the Council of Trent. Making extensive use of scripture and patristic sources, it was presented in response to a polemical writing which Diogo de Payva de Andrada had directed against Chemnitz. The \"Examen\" had four parts: Volume I examined sacred scripture, free will, original sin, justification, and good works. Volume II examined the sacraments, including baptism, confirmation, the sacrament of the eucharist, communion under both kinds, the mass, penance, extreme unction, holy orders, and matrimony. Volume III examined virginity, celibacy, purgatory, and the invocation of saints. Volume IV examined the relics of the saints, images, indulgences, fasting, the distinction of foods, and festivals.\nIn response, Andrada wrote the five-part \"Defensio Tridentin\u00e6 fidei\", which was published posthumously in 1578. However, the \"Defensio\" did not circulate as extensively as the \"Examen\", nor were any full translations ever published. A French translation of the \"Examen\" by Eduard Preuss was published in 1861. German translations were published in 1861, 1884, and 1972. In English, a complete translation by Fred Kramer drawing from the original Latin and the 1861 German was published beginning in 1971."}
{"id": "6355", "revid": "262666", "url": "https://en.wikipedia.org/wiki?curid=6355", "title": "Chloroplast", "text": "Chloroplasts are organelles that conduct photosynthesis, where the photosynthetic pigment chlorophyll captures the energy from sunlight, converts it, and stores it in the energy-storage molecules ATP and NADPH while freeing oxygen from water in plant and algal cells. They then use the ATP and NADPH to make organic molecules from carbon dioxide in a process known as the Calvin cycle. Chloroplasts carry out a number of other functions, including fatty acid synthesis, much amino acid synthesis, and the immune response in plants. The number of chloroplasts per cell varies from one, in unicellular algae, up to 100 in plants like \"Arabidopsis\" and wheat.\nA chloroplast is a type of organelle known as a plastid, characterized by its two membranes and a high concentration of chlorophyll. Other plastid types, such as the leucoplast and the chromoplast, contain little chlorophyll and do not carry out photosynthesis.\nChloroplasts are highly dynamic\u2014they circulate and are moved around within plant cells, and occasionally pinch in two to reproduce. Their behavior is strongly influenced by environmental factors like light color and intensity. Chloroplasts, like mitochondria, contain their own DNA, which is thought to be inherited from their ancestor\u2014a photosynthetic cyanobacterium that was engulfed by an early eukaryotic cell. Chloroplasts cannot be made by the plant cell and must be inherited by each daughter cell during cell division.\nWith one exception (the amoeboid \"Paulinella chromatophora\"), all chloroplasts can probably be traced back to a single endosymbiotic event, when a cyanobacterium was engulfed by the eukaryote. Despite this, chloroplasts can be found in an extremely wide set of organisms, some not even directly related to each other\u2014a consequence of many secondary and even tertiary endosymbiotic events.\nThe word \"chloroplast\" is derived from the Greek words \"chloros\" (\u03c7\u03bb\u03c9\u03c1\u03cc\u03c2), which means green, and \"plastes\" (\u03c0\u03bb\u03ac\u03c3\u03c4\u03b7\u03c2), which means \"the one who forms\".\nDiscovery.\nThe first definitive description of a chloroplast (\"Chlorophyllk\u00f6rnen\", \"grain of chlorophyll\") was given by Hugo von Mohl in 1837 as discrete bodies within the green plant cell. In 1883, Andreas Franz Wilhelm Schimper would name these bodies as \"chloroplastids\" (\"Chloroplastiden\"). In 1884, Eduard Strasburger adopted the term \"chloroplasts\" (\"Chloroplasten\").\nLineages and evolution.\nChloroplasts are one of many types of organelles in the plant cell. They are considered to have evolved from endosymbiotic cyanobacteria. Mitochondria are thought to have come from a similar endosymbiosis event, where an aerobic prokaryote was engulfed. This origin of chloroplasts was first suggested by the Russian biologist Konstantin Mereschkowski in 1905 after Andreas Franz Wilhelm Schimper observed in 1883 that chloroplasts closely resemble cyanobacteria. Chloroplasts are only found in plants, algae, and the amoeboid \"Paulinella chromatophora\".\nParent group: Cyanobacteria.\nChloroplasts are considered endosymbiotic Cyanobacteria. Cyanobacteria are sometimes called blue-green algae even though they are prokaryotes. They are a diverse phylum of bacteria capable of carrying out photosynthesis, and are gram-negative, meaning that they have two cell membranes. Cyanobacteria also contain a peptidoglycan cell wall, which is thicker than in other gram-negative bacteria, and which is located between their two cell membranes. Like chloroplasts, they have thylakoids within. On the thylakoid membranes are photosynthetic pigments, including chlorophyll \"a\". Phycobilins are also common cyanobacterial pigments, usually organized into hemispherical phycobilisomes attached to the outside of the thylakoid membranes (phycobilins are not shared with all chloroplasts though).\nPrimary endosymbiosis.\nSomewhere between 1 to 2 billion years ago,\na free-living cyanobacterium entered an early eukaryotic cell, either as food or as an internal parasite, but managed to escape the phagocytic vacuole it was contained in. The two innermost lipid-bilayer membranes that surround all chloroplasts correspond to the outer and inner membranes of the ancestral cyanobacterium's gram negative cell wall, and not the phagosomal membrane from the host, which was probably lost.\nThe new cellular resident quickly became an advantage, providing food for the eukaryotic host, which allowed it to live within it. Over time, the cyanobacterium was assimilated, and many of its genes were lost or transferred to the nucleus of the host. From genomes that probably originally contained over 3000 genes only about 130 genes remain in the chloroplasts of contemporary plants. Some of its proteins were then synthesized in the cytoplasm of the host cell, and imported back into the chloroplast (formerly the cyanobacterium). Separately, somewhere about 90\u2013140 million years ago, it happened again and led to the amoeboid \"Paulinella chromatophora\".\nThis event is called \"endosymbiosis\", or \"cell living inside another cell with a mutual benefit for both\". The external cell is commonly referred to as the \"host\" while the internal cell is called the \"endosymbiont\".\nChloroplasts are believed to have arisen after mitochondria, since all eukaryotes contain mitochondria, but not all have chloroplasts. This is called \"serial endosymbiosis\"\u2014an early eukaryote engulfing the mitochondrion ancestor, and some descendants of it then engulfing the chloroplast ancestor, creating a cell with both chloroplasts and mitochondria.\nWhether or not primary chloroplasts came from a single endosymbiotic event, or many independent engulfments across various eukaryotic lineages, has long been debated. It is now generally held that organisms with primary chloroplasts share a single ancestor that took in a cyanobacterium 600\u20132000 million years ago. It has been proposed this the closest living relative of this bacterium is \"Gloeomargarita lithophora.\" The exception is the amoeboid \"Paulinella chromatophora\", which descends from an ancestor that took in a \"Prochlorococcus\" cyanobacterium 90\u2013500 million years ago.\nThese chloroplasts, which can be traced back directly to a cyanobacterial ancestor, are known as \"primary plastids\" (\"plastid\" in this context means almost the same thing as chloroplast). All primary chloroplasts belong to one of four chloroplast lineages\u2014the glaucophyte chloroplast lineage, the amoeboid \"Paulinella chromatophora\" lineage, the rhodophyte (red algal) chloroplast lineage, or the chloroplastidan (green) chloroplast lineage. The rhodophyte and chloroplastidan lineages are the largest, with chloroplastidan (green) being the one that contains the land plants.\nGlaucophyta.\nUsually the endosymbiosis event is considered to have occurred in the Archaeplastida, within which the glaucophyta being the possible earliest diverging lineage. The glaucophyte chloroplast group is the smallest of the three primary chloroplast lineages, being found in only 13 species, and is thought to be the one that branched off the earliest. Glaucophytes have chloroplasts that retain a peptidoglycan wall between their double membranes, like their cyanobacterial parent. For this reason, glaucophyte chloroplasts are also known as 'muroplasts' (besides 'cyanoplasts' or 'cyanelles'). Glaucophyte chloroplasts also contain concentric unstacked thylakoids, which surround a carboxysome \u2013 an icosahedral structure that glaucophyte chloroplasts and cyanobacteria keep their carbon fixation enzyme RuBisCO in. The starch that they synthesize collects outside the chloroplast. Like cyanobacteria, glaucophyte and rhodophyte chloroplast thylakoids are studded with light collecting structures called phycobilisomes. For these reasons, glaucophyte chloroplasts are considered a primitive intermediate between cyanobacteria and the more evolved chloroplasts in red algae and plants.\nRhodophyceae (red algae).\nThe rhodophyte, or red algae chloroplast group is another large and diverse chloroplast lineage. Rhodophyte chloroplasts are also called \"rhodoplasts\", literally \"red chloroplasts\".\nRhodoplasts have a double membrane with an intermembrane space and phycobilin pigments organized into phycobilisomes on the thylakoid membranes, preventing their thylakoids from stacking. Some contain pyrenoids. Rhodoplasts have chlorophyll \"a\" and phycobilins for photosynthetic pigments; the phycobilin phycoerythrin is responsible for giving many red algae their distinctive red color. However, since they also contain the blue-green chlorophyll \"a\" and other pigments, many are reddish to purple from the combination. The red phycoerytherin pigment is an adaptation to help red algae catch more sunlight in deep water\u2014as such, some red algae that live in shallow water have less phycoerythrin in their rhodoplasts, and can appear more greenish. Rhodoplasts synthesize a form of starch called floridean starch, which collects into granules outside the rhodoplast, in the cytoplasm of the red alga.\nChloroplastida (green algae and plants).\nThe chloroplastida chloroplasts, or green chloroplasts, are another large, highly diverse primary chloroplast lineage. Their host organisms are commonly known as the green algae and land plants. They differ from glaucophyte and red algal chloroplasts in that they have lost their phycobilisomes, and contain chlorophyll \"b\" instead. Most green chloroplasts are (obviously) green, though some aren't, like some forms of \"H\u00e6matococcus pluvialis\", due to accessory pigments that override the chlorophylls' green colors. Chloroplastida chloroplasts have lost the peptidoglycan wall between their double membrane, leaving an intermembrane space. Some plants seem to have kept the genes for the synthesis of the peptidoglycan layer, though they've been repurposed for use in chloroplast division instead.\nMost of the chloroplasts depicted in this article are green chloroplasts.\nGreen algae and plants keep their starch \"inside\" their chloroplasts, and in plants and some algae, the chloroplast thylakoids are arranged in grana stacks. Some green algal chloroplasts contain a structure called a pyrenoid, which is functionally similar to the glaucophyte carboxysome in that it is where RuBisCO and CO are concentrated in the chloroplast.\n\"Helicosporidium\" is a genus of nonphotosynthetic parasitic green algae that is thought to contain a vestigial chloroplast. Genes from a chloroplast and nuclear genes indicating the presence of a chloroplast have been found in \"Helicosporidium\" even if nobody's seen the chloroplast itself.\n\"Paulinella chromatophora\".\nWhile most chloroplasts originate from that first set of endosymbiotic events, \"Paulinella chromatophora\" is an exception that acquired a photosynthetic cyanobacterial endosymbiont more recently. It is not clear whether that symbiont is closely related to the ancestral chloroplast of other eukaryotes. Being in the early stages of endosymbiosis, \"Paulinella chromatophora\" can offer some insights into how chloroplasts evolved. \"Paulinella\" cells contain one or two sausage shaped blue-green photosynthesizing structures called chromatophores, descended from the cyanobacterium \"Synechococcus\". Chromatophores cannot survive outside their host. Chromatophore DNA is about a million base pairs long, containing around 850 protein encoding genes\u2014far less than the three million base pair \"Synechococcus\" genome, but much larger than the approximately 150,000 base pair genome of the more assimilated chloroplast. Chromatophores have transferred much less of their DNA to the nucleus of their host. About 0.3\u20130.8% of the nuclear DNA in \"Paulinella\" is from the chromatophore, compared with 11\u201314% from the chloroplast in plants.\nSecondary and tertiary endosymbiosis.\nMany other organisms obtained chloroplasts from the primary chloroplast lineages through secondary endosymbiosis\u2014engulfing a red or green alga that contained a chloroplast. These chloroplasts are known as secondary plastids.\nWhile primary chloroplasts have a double membrane from their cyanobacterial ancestor, secondary chloroplasts have additional membranes outside of the original two, as a result of the secondary endosymbiotic event, when a nonphotosynthetic eukaryote engulfed a chloroplast-containing alga but failed to digest it\u2014much like the cyanobacterium at the beginning of this story. The engulfed alga was broken down, leaving only its chloroplast, and sometimes its cell membrane and nucleus, forming a chloroplast with three or four membranes\u2014the two cyanobacterial membranes, sometimes the eaten alga's cell membrane, and the phagosomal vacuole from the host's cell membrane.\nThe genes in the phagocytosed eukaryote's nucleus are often transferred to the secondary host's nucleus.\nCryptomonads and chlorarachniophytes retain the phagocytosed eukaryote's nucleus, an object called a nucleomorph, located between the second and third membranes of the chloroplast.\nAll secondary chloroplasts come from green and red algae\u2014no secondary chloroplasts from glaucophytes have been observed, probably because glaucophytes are relatively rare in nature, making them less likely to have been taken up by another eukaryote.\nGreen algal derived chloroplasts.\nGreen algae have been taken up by the euglenids, chlorarachniophytes, a lineage of dinoflagellates, and possibly the ancestor of the CASH lineage (cryptomonads, alveolates, stramenopiles and haptophytes) in three or four separate engulfments. Many green algal derived chloroplasts contain pyrenoids, but unlike chloroplasts in their green algal ancestors, storage product collects in granules outside the chloroplast.\nEuglenophytes.\nEuglenophytes are a group of common flagellated protists that contain chloroplasts derived from a green alga. Euglenophyte chloroplasts have three membranes\u2014it is thought that the membrane of the primary endosymbiont was lost, leaving the cyanobacterial membranes, and the secondary host's phagosomal membrane. Euglenophyte chloroplasts have a pyrenoid and thylakoids stacked in groups of three. Photosynthetic product is stored in the form of paramylon, which is contained in membrane-bound granules in the cytoplasm of the euglenophyte.\nChlorarachniophytes.\nChlorarachniophytes are a rare group of organisms that also contain chloroplasts derived from green algae, though their story is more complicated than that of the euglenophytes. The ancestor of chlorarachniophytes is thought to have been a eukaryote with a \"red\" algal derived chloroplast. It is then thought to have lost its first red algal chloroplast, and later engulfed a green alga, giving it its second, green algal derived chloroplast.\nChlorarachniophyte chloroplasts are bounded by four membranes, except near the cell membrane, where the chloroplast membranes fuse into a double membrane. Their thylakoids are arranged in loose stacks of three. Chlorarachniophytes have a form of polysaccharide called chrysolaminarin, which they store in the cytoplasm, often collected around the chloroplast pyrenoid, which bulges into the cytoplasm.\nChlorarachniophyte chloroplasts are notable because the green alga they are derived from has not been completely broken down\u2014its nucleus still persists as a nucleomorph found between the second and third chloroplast membranes\u2014the periplastid space, which corresponds to the green alga's cytoplasm.\nPrasinophyte-derived dinophyte chloroplast.\n\"Lepidodinium viride\" and its close relatives are dinophytes (see below) that lost their original peridinin chloroplast and replaced it with a green algal derived chloroplast (more specifically, a prasinophyte). \"Lepidodinium\" is the only dinophyte that has a chloroplast that's not from the rhodoplast lineage. The chloroplast is surrounded by two membranes and has no nucleomorph\u2014all the nucleomorph genes have been transferred to the dinophyte nucleus. The endosymbiotic event that led to this chloroplast was serial secondary endosymbiosis rather than tertiary endosymbiosis\u2014the endosymbiont was a green alga containing a primary chloroplast (making a secondary chloroplast).\nRed algal derived chloroplasts.\nCryptophytes.\nCryptophytes, or cryptomonads are a group of algae that contain a red-algal derived chloroplast. Cryptophyte chloroplasts contain a nucleomorph that superficially resembles that of the chlorarachniophytes. Cryptophyte chloroplasts have four membranes, the outermost of which is continuous with the rough endoplasmic reticulum. They synthesize ordinary starch, which is stored in granules found in the periplastid space\u2014outside the original double membrane, in the place that corresponds to the red alga's cytoplasm. Inside cryptophyte chloroplasts is a pyrenoid and thylakoids in stacks of two.\nTheir chloroplasts do not have phycobilisomes, but they do have phycobilin pigments which they keep in their thylakoid space, rather than anchored on the outside of their thylakoid membranes.\nCryptophytes may have played a key role in the spreading of red algal based chloroplasts.\nHaptophytes.\nHaptophytes are similar and closely related to cryptophytes or heterokontophytes. Their chloroplasts lack a nucleomorph, their thylakoids are in stacks of three, and they synthesize chrysolaminarin sugar, which they store completely outside of the chloroplast, in the cytoplasm of the haptophyte.\nHeterokontophytes (stramenopiles).\nThe heterokontophytes, also known as the stramenopiles, are a very large and diverse group of eukaryotes. The photoautotrophic lineage, Ochrophyta, including the diatoms and the brown algae, golden algae, and yellow-green algae, also contains red algal derived chloroplasts.\nHeterokont chloroplasts are very similar to haptophyte chloroplasts, containing a pyrenoid, triplet thylakoids, and with some exceptions, having four layer plastidic envelope, the outermost epiplastid membrane connected to the endoplasmic reticulum. Like haptophytes, heterokontophytes store sugar in chrysolaminarin granules in the cytoplasm. Heterokontophyte chloroplasts contain chlorophyll \"a\" and with a few exceptions chlorophyll \"c\", but also have carotenoids which give them their many colors.\nApicomplexans, chromerids, and dinophytes.\nThe alveolates are a major clade of unicellular eukaryotes of both autotrophic and heterotrophic members. The most notable shared characteristic is the presence of cortical (outer-region) alveoli (sacs). These are flattened vesicles (sacs) packed into a continuous layer just under the membrane and supporting it, typically forming a flexible pellicle (thin skin). In dinoflagellates they often form armor plates. Many members contain a red-algal derived plastid. One notable characteristic of this diverse group is the frequent loss of photosynthesis. However, a majority of these heterotrophs continue to process a non-photosynthetic plastid.\nApicomplexans are a group of alveolates. Like the helicosproidia, they're parasitic, and have a nonphotosynthetic chloroplast. They were once thought to be related to the helicosproidia, but it is now known that the helicosproida are green algae rather than part of the CASH lineage. The apicomplexans include \"Plasmodium\", the malaria parasite. Many apicomplexans keep a vestigial red algal derived chloroplast called an apicoplast, which they inherited from their ancestors. Other apicomplexans like \"Cryptosporidium\" have lost the chloroplast completely. Apicomplexans store their energy in amylopectin granules that are located in their cytoplasm, even though they are nonphotosynthetic.\nApicoplasts have lost all photosynthetic function, and contain no photosynthetic pigments or true thylakoids. They are bounded by four membranes, but the membranes are not connected to the endoplasmic reticulum. The fact that apicomplexans still keep their nonphotosynthetic chloroplast around demonstrates how the chloroplast carries out important functions other than photosynthesis. Plant chloroplasts provide plant cells with many important things besides sugar, and apicoplasts are no different\u2014they synthesize fatty acids, isopentenyl pyrophosphate, iron-sulfur clusters, and carry out part of the heme pathway. This makes the apicoplast an attractive target for drugs to cure apicomplexan-related diseases. The most important apicoplast function is isopentenyl pyrophosphate synthesis\u2014in fact, apicomplexans die when something interferes with this apicoplast function, and when apicomplexans are grown in an isopentenyl pyrophosphate-rich medium, they dump the organelle.\nThe Chromerida is a newly discovered group of algae from Australian corals which comprises some close photosynthetic relatives of the apicomplexans. The first member, \"Chromera velia\", was discovered and first isolated in 2001. The discovery of \"Chromera velia\" with similar structure to the apicomplexanss, provides an important link in the evolutionary history of the apicomplexans and dinophytes. Their plastids have four membranes, lack chlorophyll c and use the type II form of RuBisCO obtained from a horizontal transfer event.\nThe dinoflagellates are yet another very large and diverse group of protists, around half of which are (at least partially) photosynthetic.\nMost dinophyte chloroplasts are secondary red algal derived chloroplasts. Many other dinophytes have lost the chloroplast (becoming the nonphotosynthetic kind of dinoflagellate), or replaced it though \"tertiary\" endosymbiosis\u2014the engulfment of another eukaryotic algae containing a red algal derived chloroplast. Others replaced their original chloroplast with a green algal derived one.\nMost dinophyte chloroplasts contain form II RuBisCO, at least the photosynthetic pigments chlorophyll \"a\", chlorophyll \"c2\", \"beta\"-carotene, and at least one dinophyte-unique xanthophyll (peridinin, dinoxanthin, or diadinoxanthin), giving many a golden-brown color. All dinophytes store starch in their cytoplasm, and most have chloroplasts with thylakoids arranged in stacks of three.\nThe most common dinophyte chloroplast is the peridinin-type chloroplast, characterized by the carotenoid pigment peridinin in their chloroplasts, along with chlorophyll \"a\" and chlorophyll \"c\"2. Peridinin is not found in any other group of chloroplasts. The peridinin chloroplast is bounded by three membranes (occasionally two), having lost the red algal endosymbiont's original cell membrane. The outermost membrane is not connected to the endoplasmic reticulum. They contain a pyrenoid, and have triplet-stacked thylakoids. Starch is found outside the chloroplast. An important feature of these chloroplasts is that their chloroplast DNA is highly reduced and fragmented into many small circles. Most of the genome has migrated to the nucleus, and only critical photosynthesis-related genes remain in the chloroplast.\nThe peridinin chloroplast is thought to be the dinophytes' \"original\" chloroplast, which has been lost, reduced, replaced, or has company in several other dinophyte lineages.\nFucoxanthin-containing (haptophyte-derived) dinophyte chloroplasts.\nThe fucoxanthin dinophyte lineages (including \"Karlodinium\" and \"Karenia\") lost their original red algal derived chloroplast, and replaced it with a new chloroplast derived from a haptophyte endosymbiont. \"Karlodinium\" and \"Karenia\" probably took up different heterokontophytes. Because the haptophyte chloroplast has four membranes, tertiary endosymbiosis would be expected to create a six membraned chloroplast, adding the haptophyte's cell membrane and the dinophyte's phagosomal vacuole. However, the haptophyte was heavily reduced, stripped of a few membranes and its nucleus, leaving only its chloroplast (with its original double membrane), and possibly one or two additional membranes around it.\nFucoxanthin-containing chloroplasts are characterized by having the pigment fucoxanthin (actually 19\u2032-hexanoyloxy-fucoxanthin and/or 19\u2032-butanoyloxy-fucoxanthin) and no peridinin. Fucoxanthin is also found in haptophyte chloroplasts, providing evidence of ancestry.\nDiatom-derived dinophyte chloroplasts.\nSome dinophytes, like \"Kryptoperidinium\" and \"Durinskia\" have a diatom (heterokontophyte) derived chloroplast. These chloroplasts are bounded by up to \"five\" membranes, (depending on whether the entire diatom endosymbiont is counted as the chloroplast, or just the red algal derived chloroplast inside it). The diatom endosymbiont has been reduced relatively little\u2014it still retains its original mitochondria, and has endoplasmic reticulum, ribosomes, a nucleus, and of course, red algal derived chloroplasts\u2014practically a complete cell, all inside the host's endoplasmic reticulum lumen. However the diatom endosymbiont can't store its own food\u2014its storage polysaccharide is found in granules in the dinophyte host's cytoplasm instead. The diatom endosymbiont's nucleus is present, but it probably can't be called a nucleomorph because it shows no sign of genome reduction, and might have even been \"expanded\". Diatoms have been engulfed by dinoflagellates at least three times.\nThe diatom endosymbiont is bounded by a single membrane, inside it are chloroplasts with four membranes. Like the diatom endosymbiont's diatom ancestor, the chloroplasts have triplet thylakoids and pyrenoids.\nIn some of these genera, the diatom endosymbiont's chloroplasts aren't the only chloroplasts in the dinophyte. The original three-membraned peridinin chloroplast is still around, converted to an eyespot.\nKleptoplastidy.\nIn some groups of mixotrophic protists, like some dinoflagellates (e.g. \"Dinophysis\"), chloroplasts are separated from a captured alga and used temporarily. These klepto chloroplasts may only have a lifetime of a few days and are then replaced.\nCryptophyte-derived dinophyte chloroplast.\nMembers of the genus \"Dinophysis\" have a phycobilin-containing chloroplast taken from a cryptophyte. However, the cryptophyte is not an endosymbiont\u2014only the chloroplast seems to have been taken, and the chloroplast has been stripped of its nucleomorph and outermost two membranes, leaving just a two-membraned chloroplast. Cryptophyte chloroplasts require their nucleomorph to maintain themselves, and \"Dinophysis\" species grown in cell culture alone cannot survive, so it is possible (but not confirmed) that the \"Dinophysis\" chloroplast is a kleptoplast\u2014if so, \"Dinophysis\" chloroplasts wear out and \"Dinophysis\" species must continually engulf cryptophytes to obtain new chloroplasts to replace the old ones.\nChloroplast DNA.\nChloroplasts have their own DNA, often abbreviated as ctDNA, or cpDNA. It is also known as the plastome. Its existence was first proved in 1962, and first sequenced in 1986\u2014when two Japanese research teams sequenced the chloroplast DNA of liverwort and tobacco. Since then, hundreds of chloroplast DNAs from various species have been sequenced, but they are mostly those of land plants and green algae\u2014glaucophytes, red algae, and other algal groups are extremely underrepresented, potentially introducing some bias in views of \"typical\" chloroplast DNA structure and content.\nMolecular structure.\nWith few exceptions, most chloroplasts have their entire chloroplast genome combined into a single large circular DNA molecule, typically 120,000\u2013170,000 base pairs long. They can have a contour length of around 30\u201360 micrometers, and have a mass of about 80\u2013130 million daltons.\nWhile usually thought of as a circular molecule, there is some evidence that chloroplast DNA molecules more often take on a linear shape.\nInverted repeats.\nMany chloroplast DNAs contain two \"inverted repeats\", which separate a long single copy section (LSC) from a short single copy section (SSC).\nWhile a given pair of inverted repeats are rarely completely identical, they are always very similar to each other, apparently resulting from concerted evolution.\nThe inverted repeats vary wildly in length, ranging from 4,000 to 25,000 base pairs long each and containing as few as four or as many as over 150 genes. Inverted repeats in plants tend to be at the upper end of this range, each being 20,000\u201325,000 base pairs long.\nThe inverted repeat regions are highly conserved among land plants, and accumulate few mutations. Similar inverted repeats exist in the genomes of cyanobacteria and the other two chloroplast lineages (glaucophyta and rhodophyceae), suggesting that they predate the chloroplast, though some chloroplast DNAs have since lost or flipped the inverted repeats (making them direct repeats). It is possible that the inverted repeats help stabilize the rest of the chloroplast genome, as chloroplast DNAs which have lost some of the inverted repeat segments tend to get rearranged more.\nNucleoids.\nNew chloroplasts may contain up to 100 copies of their DNA, though the number of chloroplast DNA copies decreases to about 15\u201320 as the chloroplasts age. They are usually packed into nucleoids, which can contain several identical chloroplast DNA rings. Many nucleoids can be found in each chloroplast.\nIn primitive red algae, the chloroplast DNA nucleoids are clustered in the center of the chloroplast, while in green plants and green algae, the nucleoids are dispersed throughout the stroma.\nThough chloroplast DNA is not associated with true histones, in red algae, similar proteins that tightly pack each chloroplast DNA ring into a nucleoid have been found.\nDNA repair.\nIn chloroplasts of the moss \"Physcomitrella patens\", the DNA mismatch repair protein Msh1 interacts with the recombinational repair proteins RecA and RecG to maintain chloroplast genome stability. In chloroplasts of the plant \"Arabidopsis thaliana\" the RecA protein maintains the integrity of the chloroplast's DNA by a process that likely involves the recombinational repair of DNA damage.\nDNA replication.\nThe leading model of cpDNA replication.\nThe mechanism for chloroplast DNA (cpDNA) replication has not been conclusively determined, but two main models have been proposed. Scientists have attempted to observe chloroplast replication via electron microscopy since the 1970s. The results of the microscopy experiments led to the idea that chloroplast DNA replicates using a double displacement loop (D-loop). As the D-loop moves through the circular DNA, it adopts a theta intermediary form, also known as a Cairns replication intermediate, and completes replication with a rolling circle mechanism. Transcription starts at specific points of origin. Multiple replication forks open up, allowing replication machinery to transcribe the DNA. As replication continues, the forks grow and eventually converge. The new cpDNA structures separate, creating daughter cpDNA chromosomes.\nIn addition to the early microscopy experiments, this model is also supported by the amounts of deamination seen in cpDNA. Deamination occurs when an amino group is lost and is a mutation that often results in base changes. When adenine is deaminated, it becomes hypoxanthine. Hypoxanthine can bind to cytosine, and when the XC base pair is replicated, it becomes a GC (thus, an A \u2192 G base change). \nDeamination.\nIn cpDNA, there are several A \u2192 G deamination gradients. DNA becomes susceptible to deamination events when it is single stranded. When replication forks form, the strand not being copied is single stranded, and thus at risk for A \u2192 G deamination. Therefore, gradients in deamination indicate that replication forks were most likely present and the direction that they initially opened (the highest gradient is most likely nearest the start site because it was single stranded for the longest amount of time). This mechanism is still the leading theory today; however, a second theory suggests that most cpDNA is actually linear and replicates through homologous recombination. It further contends that only a minority of the genetic material is kept in circular chromosomes while the rest is in branched, linear, or other complex structures.\nAlternative model of replication.\nOne of competing model for cpDNA replication asserts that most cpDNA is linear and participates in homologous recombination and replication structures similar to the linear and circular DNA structures of bacteriophage T4. It has been established that some plants have linear cpDNA, such as maize, and that more species still contain complex structures that scientists do not yet understand. When the original experiments on cpDNA were performed, scientists did notice linear structures; however, they attributed these linear forms to broken circles. If the branched and complex structures seen in cpDNA experiments are real and not artifacts of concatenated circular DNA or broken circles, then a D-loop mechanism of replication is insufficient to explain how those structures would replicate. At the same time, homologous recombination does not expand the multiple A --&gt; G gradients seen in plastomes. Because of the failure to explain the deamination gradient as well as the numerous plant species that have been shown to have circular cpDNA, the predominant theory continues to hold that most cpDNA is circular and most likely replicates via a D loop mechanism.\nGene content and protein synthesis.\nThe chloroplast genome most commonly includes around 100 genes that code for a variety of things, mostly to do with the protein pipeline and photosynthesis. As in prokaryotes, genes in chloroplast DNA are organized into operons. Unlike prokaryotic DNA molecules, chloroplast DNA molecules contain introns (plant mitochondrial DNAs do too, but not human mtDNAs).\nAmong land plants, the contents of the chloroplast genome are fairly similar.\nChloroplast genome reduction and gene transfer.\nOver time, many parts of the chloroplast genome were transferred to the nuclear genome of the host, a process called \"endosymbiotic gene transfer\". As a result, the chloroplast genome is heavily reduced compared to that of free-living cyanobacteria. Chloroplasts may contain 60\u2013100 genes whereas cyanobacteria often have more than 1500 genes in their genome. Recently, a plastid without a genome was found, demonstrating chloroplasts can lose their genome during endosymbiotic the gene transfer process.\nEndosymbiotic gene transfer is how we know about the lost chloroplasts in many CASH lineages. Even if a chloroplast is eventually lost, the genes it donated to the former host's nucleus persist, providing evidence for the lost chloroplast's existence. For example, while diatoms (a heterokontophyte) now have a red algal derived chloroplast, the presence of many green algal genes in the diatom nucleus provide evidence that the diatom ancestor had a green algal derived chloroplast at some point, which was subsequently replaced by the red chloroplast.\nIn land plants, some 11\u201314% of the DNA in their nuclei can be traced back to the chloroplast, up to 18% in \"Arabidopsis\", corresponding to about 4,500 protein-coding genes. There have been a few recent transfers of genes from the chloroplast DNA to the nuclear genome in land plants.\nOf the approximately 3000 proteins found in chloroplasts, some 95% of them are encoded by nuclear genes. Many of the chloroplast's protein complexes consist of subunits from both the chloroplast genome and the host's nuclear genome. As a result, protein synthesis must be coordinated between the chloroplast and the nucleus. The chloroplast is mostly under nuclear control, though chloroplasts can also give out signals regulating gene expression in the nucleus, called \"retrograde signaling\".\nProtein synthesis.\nProtein synthesis within chloroplasts relies on two RNA polymerases. One is coded by the chloroplast DNA, the other is of nuclear origin. The two RNA polymerases may recognize and bind to different kinds of promoters within the chloroplast genome. The ribosomes in chloroplasts are similar to bacterial ribosomes.\nProtein targeting and import.\nBecause so many chloroplast genes have been moved to the nucleus, many proteins that would originally have been translated in the chloroplast are now synthesized in the cytoplasm of the plant cell. These proteins must be directed back to the chloroplast, and imported through at least two chloroplast membranes.\nCuriously, around half of the protein products of transferred genes aren't even targeted back to the chloroplast. Many became exaptations, taking on new functions like participating in cell division, protein routing, and even disease resistance. A few chloroplast genes found new homes in the mitochondrial genome\u2014most became nonfunctional pseudogenes, though a few tRNA genes still work in the mitochondrion. Some transferred chloroplast DNA protein products get directed to the secretory pathway, though many secondary plastids are bounded by an outermost membrane derived from the host's cell membrane, and therefore topologically outside of the cell because to reach the chloroplast from the cytosol, the cell membrane must be crossed, which signifies entrance into the extracellular space. In those cases, chloroplast-targeted proteins do initially travel along the secretory pathway.\nBecause the cell acquiring a chloroplast already had mitochondria (and peroxisomes, and a cell membrane for secretion), the new chloroplast host had to develop a unique protein targeting system to avoid having chloroplast proteins being sent to the wrong organelle.\nIn most, but not all cases, nuclear-encoded chloroplast proteins are translated with a \"cleavable transit peptide\" that's added to the N-terminus of the protein precursor. Sometimes the transit sequence is found on the C-terminus of the protein, or within the functional part of the protein.\nTransport proteins and membrane translocons.\nAfter a chloroplast polypeptide is synthesized on a ribosome in the cytosol, an enzyme specific to chloroplast proteins phosphorylates, or adds a phosphate group to many (but not all) of them in their transit sequences.\nPhosphorylation helps many proteins bind the polypeptide, keeping it from folding prematurely. This is important because it prevents chloroplast proteins from assuming their active form and carrying out their chloroplast functions in the wrong place\u2014the cytosol. At the same time, they have to keep just enough shape so that they can be recognized by the chloroplast. These proteins also help the polypeptide get imported into the chloroplast.\nFrom here, chloroplast proteins bound for the stroma must pass through two protein complexes\u2014the TOC complex, or translocon on the outer chloroplast membrane\", and the TIC translocon, or translocon on the inner chloroplast membrane translocon\". Chloroplast polypeptide chains probably often travel through the two complexes at the same time, but the TIC complex can also retrieve preproteins lost in the intermembrane space.\nStructure.\nIn land plants, chloroplasts are generally lens-shaped, 3\u201310 \u03bcm in diameter and 1\u20133 \u03bcm thick. Corn seedling chloroplasts are \u224820 \u00b5m3 in volume. Greater diversity in chloroplast shapes exists among the algae, which often contain a single chloroplast that can be shaped like a net (e.g., \"Oedogonium\"), a cup (e.g., \"Chlamydomonas\"), a ribbon-like spiral around the edges of the cell (e.g., \"Spirogyra\"), or slightly twisted bands at the cell edges (e.g., \"Sirogonium\"). Some algae have two chloroplasts in each cell; they are star-shaped in \"Zygnema\", or may follow the shape of half the cell in order Desmidiales. In some algae, the chloroplast takes up most of the cell, with pockets for the nucleus and other organelles, for example, some species of \"Chlorella\" have a cup-shaped chloroplast that occupies much of the cell.\nAll chloroplasts have at least three membrane systems\u2014the outer chloroplast membrane, the inner chloroplast membrane, and the thylakoid system. Chloroplasts that are the product of secondary endosymbiosis may have additional membranes surrounding these three. Inside the outer and inner chloroplast membranes is the chloroplast stroma, a semi-gel-like fluid that makes up much of a chloroplast's volume, and in which the thylakoid system floats.\nThere are some common misconceptions about the outer and inner chloroplast membranes. The fact that chloroplasts are surrounded by a double membrane is often cited as evidence that they are the descendants of endosymbiotic cyanobacteria. This is often interpreted as meaning the outer chloroplast membrane is the product of the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium\u2014which is not true\u2014both chloroplast membranes are homologous to the cyanobacterium's original double membranes.\nThe chloroplast double membrane is also often compared to the mitochondrial double membrane. This is not a valid comparison\u2014the inner mitochondria membrane is used to run proton pumps and carry out oxidative phosphorylation across to generate ATP energy. The only chloroplast structure that can considered analogous to it is the internal thylakoid system. Even so, in terms of \"in-out\", the direction of chloroplast H ion flow is in the opposite direction compared to oxidative phosphorylation in mitochondria. In addition, in terms of function, the inner chloroplast membrane, which regulates metabolite passage and synthesizes some materials, has no counterpart in the mitochondrion.\nOuter chloroplast membrane.\nThe outer chloroplast membrane is a semi-porous membrane that small molecules and ions can easily diffuse across. However, it is not permeable to larger proteins, so chloroplast polypeptides being synthesized in the cell cytoplasm must be transported across the outer chloroplast membrane by the TOC complex, or \"translocon on the outer chloroplast\" membrane.\nThe chloroplast membranes sometimes protrude out into the cytoplasm, forming a stromule, or stroma-containing tubule. Stromules are very rare in chloroplasts, and are much more common in other plastids like chromoplasts and amyloplasts in petals and roots, respectively. They may exist to increase the chloroplast's surface area for cross-membrane transport, because they are often branched and tangled with the endoplasmic reticulum. When they were first observed in 1962, some plant biologists dismissed the structures as artifactual, claiming that stromules were just oddly shaped chloroplasts with constricted regions or dividing chloroplasts. However, there is a growing body of evidence that stromules are functional, integral features of plant cell plastids, not merely artifacts.\nIntermembrane space and peptidoglycan wall.\nUsually, a thin intermembrane space about 10\u201320 nanometers thick exists between the outer and inner chloroplast membranes.\nGlaucophyte algal chloroplasts have a peptidoglycan layer between the chloroplast membranes. It corresponds to the peptidoglycan cell wall of their cyanobacterial ancestors, which is located between their two cell membranes. These chloroplasts are called \"muroplasts\" (from Latin \"mura\", meaning \"wall\"). Other chloroplasts have lost the cyanobacterial wall, leaving an intermembrane space between the two chloroplast envelope membranes.\nInner chloroplast membrane.\nThe inner chloroplast membrane borders the stroma and regulates passage of materials in and out of the chloroplast. After passing through the TOC complex in the outer chloroplast membrane, polypeptides must pass through the TIC complex \"(translocon on the inner chloroplast membrane)\" which is located in the inner chloroplast membrane.\nIn addition to regulating the passage of materials, the inner chloroplast membrane is where fatty acids, lipids, and carotenoids are synthesized.\nPeripheral reticulum.\nSome chloroplasts contain a structure called the chloroplast peripheral reticulum. It is often found in the chloroplasts of plants, though it has also been found in some angiosperms, and even some gymnosperms. The chloroplast peripheral reticulum consists of a maze of membranous tubes and vesicles continuous with the inner chloroplast membrane that extends into the internal stromal fluid of the chloroplast. Its purpose is thought to be to increase the chloroplast's surface area for cross-membrane transport between its stroma and the cell cytoplasm. The small vesicles sometimes observed may serve as transport vesicles to shuttle stuff between the thylakoids and intermembrane space.\nStroma.\nThe protein-rich, alkaline, aqueous fluid within the inner chloroplast membrane and outside of the thylakoid space is called the stroma, which corresponds to the cytosol of the original cyanobacterium. Nucleoids of chloroplast DNA, chloroplast ribosomes, the thylakoid system with plastoglobuli, starch granules, and many proteins can be found floating around in it. The Calvin cycle, which fixes CO into G3P takes place in the stroma.\nChloroplast ribosomes.\nChloroplasts have their own ribosomes, which they use to synthesize a small fraction of their proteins. Chloroplast ribosomes are about two-thirds the size of cytoplasmic ribosomes (around 17 nm vs 25 nm). They take mRNAs transcribed from the chloroplast DNA and translate them into protein. While similar to bacterial ribosomes, chloroplast translation is more complex than in bacteria, so chloroplast ribosomes include some chloroplast-unique features.\nSmall subunit ribosomal RNAs in several Chlorophyta and euglenid chloroplasts lack motifs for shine-dalgarno sequence recognition, which is considered essential for translation initiation in most chloroplasts and prokaryotes. Such loss is also rarely observed in other plastids and prokaryotes.\nPlastoglobuli.\nPlastoglobuli (singular \"plastoglobulus\", sometimes spelled \"plastoglobule(s)\"), are spherical bubbles of lipids and proteins about 45\u201360 nanometers across. They are surrounded by a lipid monolayer. Plastoglobuli are found in all chloroplasts, but become more common when the chloroplast is under oxidative stress, or when it ages and transitions into a gerontoplast. Plastoglobuli also exhibit a greater size variation under these conditions. They are also common in etioplasts, but decrease in number as the etioplasts mature into chloroplasts.\nPlastoglubuli contain both structural proteins and enzymes involved in lipid synthesis and metabolism. They contain many types of lipids including plastoquinone, vitamin E, carotenoids and chlorophylls.\nPlastoglobuli were once thought to be free-floating in the stroma, but it is now thought that they are permanently attached either to a thylakoid or to another plastoglobulus attached to a thylakoid, a configuration that allows a plastoglobulus to exchange its contents with the thylakoid network. In normal green chloroplasts, the vast majority of plastoglobuli occur singularly, attached directly to their parent thylakoid. In old or stressed chloroplasts, plastoglobuli tend to occur in linked groups or chains, still always anchored to a thylakoid.\nPlastoglobuli form when a bubble appears between the layers of the lipid bilayer of the thylakoid membrane, or bud from existing plastoglubuli\u2014though they never detach and float off into the stroma. Practically all plastoglobuli form on or near the highly curved edges of the thylakoid disks or sheets. They are also more common on stromal thylakoids than on granal ones.\nStarch granules.\nStarch granules are very common in chloroplasts, typically taking up 15% of the organelle's volume, though in some other plastids like amyloplasts, they can be big enough to distort the shape of the organelle. Starch granules are simply accumulations of starch in the stroma, and are not bounded by a membrane.\nStarch granules appear and grow throughout the day, as the chloroplast synthesizes sugars, and are consumed at night to fuel respiration and continue sugar export into the phloem, though in mature chloroplasts, it is rare for a starch granule to be completely consumed or for a new granule to accumulate.\nStarch granules vary in composition and location across different chloroplast lineages. In red algae, starch granules are found in the cytoplasm rather than in the chloroplast. In plants, mesophyll chloroplasts, which do not synthesize sugars, lack starch granules.\nRuBisCO.\nThe chloroplast stroma contains many proteins, though the most common and important is RuBisCO, which is probably also the most abundant protein on the planet. RuBisCO is the enzyme that fixes CO into sugar molecules. In plants, RuBisCO is abundant in all chloroplasts, though in plants, it is confined to the bundle sheath chloroplasts, where the Calvin cycle is carried out in plants.\nPyrenoids.\nThe chloroplasts of some hornworts and algae contain structures called pyrenoids. They are not found in higher plants. Pyrenoids are roughly spherical and highly refractive bodies which are a site of starch accumulation in plants that contain them. They consist of a matrix opaque to electrons, surrounded by two hemispherical starch plates. The starch is accumulated as the pyrenoids mature. In algae with carbon concentrating mechanisms, the enzyme RuBisCO is found in the pyrenoids. Starch can also accumulate around the pyrenoids when CO2 is scarce. Pyrenoids can divide to form new pyrenoids, or be produced \"de novo\".\nThylakoid system.\nThylakoids (sometimes spelled \"thylako\u00efds\"), are small interconnected sacks which contain the membranes that the light reactions of photosynthesis take place on. The word \"thylakoid\" comes from the Greek word \"thylakos\" which means \"sack\".\nSuspended within the chloroplast stroma is the thylakoid system, a highly dynamic collection of membranous sacks called thylakoids where chlorophyll is found and the light reactions of photosynthesis happen.\nIn most vascular plant chloroplasts, the thylakoids are arranged in stacks called grana, though in certain plant chloroplasts and some algal chloroplasts, the thylakoids are free floating.\nThylakoid structure.\nUsing a light microscope, it is just barely possible to see tiny green granules\u2014which were named grana. With electron microscopy, it became possible to see the thylakoid system in more detail, revealing it to consist of stacks of flat thylakoids which made up the grana, and long interconnecting stromal thylakoids which linked different grana.\nIn the transmission electron microscope, thylakoid membranes appear as alternating light-and-dark bands, 8.5 nanometers thick.\nFor a long time, the three-dimensional structure of the thylakoid membrane system had been unknown or disputed. Many models have been proposed, the most prevalent being the helical model, in which granum stacks of thylakoids are wrapped by helical stromal thylakoids. Another model known as the 'bifurcation model', which was based on the first electron tomography study of plant thylakoid membranes, depicts the stromal membranes as wide lamellar sheets perpendicular to the grana columns which bifurcates into multiple parallel discs forming the granum-stroma assembly. The helical model was supported by several additional works, but ultimately it was determined in 2019 that features from both the helical and bifurcation models are consolidated by newly-discovered left-handed helical membrane junctions. Likely for ease, the thylakoid system is still commonly depicted by older \"hub and spoke\" models where the grana are connected to each other by tubes of stromal thylakoids.\nGrana consist of a stacks of flattened circular granal thylakoids that resemble pancakes. Each granum can contain anywhere from two to a hundred thylakoids, though grana with 10\u201320 thylakoids are most common. Wrapped around the grana are multiple parallel right-handed helical stromal thylakoids, also known as frets or lamellar thylakoids. The helices ascend at an angle of ~20\u00b0, connecting to each granal thylakoid at a bridge-like slit junction.\nThe stroma lamellae extend as large sheets perpendicular to the grana columns. These sheets are connected to the right-handed helices either directly or through bifurcations that form left-handed helical membrane surfaces. The left-handed helical surfaces have a similar tilt angle to the right-handed helices (~20\u00b0), but \u00bc the pitch. Approximately 4 left-handed helical junctions are present per granum, resulting in a pitch-balanced array of right- and left-handed helical membrane surfaces of different radii and pitch that consolidate the network with minimal surface and bending energies. While different parts of the thylakoid system contain different membrane proteins, the thylakoid membranes are continuous and the thylakoid space they enclose form a single continuous labyrinth.\nThylakoid composition.\nEmbedded in the thylakoid membranes are important protein complexes which carry out the light reactions of photosynthesis. Photosystem II and photosystem I contain light-harvesting complexes with chlorophyll and carotenoids that absorb light energy and use it to energize electrons. Molecules in the thylakoid membrane use the energized electrons to pump hydrogen ions into the thylakoid space, decreasing the pH and turning it acidic. ATP synthase is a large protein complex that harnesses the concentration gradient of the hydrogen ions in the thylakoid space to generate ATP energy as the hydrogen ions flow back out into the stroma\u2014much like a dam turbine.\nThere are two types of thylakoids\u2014granal thylakoids, which are arranged in grana, and stromal thylakoids, which are in contact with the stroma. Granal thylakoids are pancake-shaped circular disks about 300\u2013600 nanometers in diameter. Stromal thylakoids are helicoid sheets that spiral around grana. The flat tops and bottoms of granal thylakoids contain only the relatively flat photosystem II protein complex. This allows them to stack tightly, forming grana with many layers of tightly appressed membrane, called granal membrane, increasing stability and surface area for light capture.\nIn contrast, photosystem I and ATP synthase are large protein complexes which jut out into the stroma. They can't fit in the appressed granal membranes, and so are found in the stromal thylakoid membrane\u2014the edges of the granal thylakoid disks and the stromal thylakoids. These large protein complexes may act as spacers between the sheets of stromal thylakoids.\nThe number of thylakoids and the total thylakoid area of a chloroplast is influenced by light exposure. Shaded chloroplasts contain larger and more grana with more thylakoid membrane area than chloroplasts exposed to bright light, which have smaller and fewer grana and less thylakoid area. Thylakoid extent can change within minutes of light exposure or removal.\nPigments and chloroplast colors.\nInside the photosystems embedded in chloroplast thylakoid membranes are various photosynthetic pigments, which absorb and transfer light energy. The types of pigments found are different in various groups of chloroplasts, and are responsible for a wide variety of chloroplast colorations.\n box-shadow: 1px 1px 3px rgba(0,0,0,0.2);\"&gt;\nPaper chroma-tography of some spinach leaf extract shows the various pigments present in their chloroplasts.\nXanthophylls\nChlorophyll \"a\"\nChlorophyll \"b\"\nChlorophylls.\nChlorophyll \"a\" is found in all chloroplasts, as well as their cyanobacterial ancestors. Chlorophyll \"a\" is a blue-green pigment partially responsible for giving most cyanobacteria and chloroplasts their color. Other forms of chlorophyll exist, such as the accessory pigments chlorophyll \"b\", chlorophyll \"c\", chlorophyll \"d\", and chlorophyll \"f\".\nChlorophyll \"b\" is an olive green pigment found only in the chloroplasts of plants, green algae, any secondary chloroplasts obtained through the secondary endosymbiosis of a green alga, and a few cyanobacteria. It is the chlorophylls \"a\" and \"b\" together that make most plant and green algal chloroplasts green.\nChlorophyll \"c\" is mainly found in secondary endosymbiotic chloroplasts that originated from a red alga, although it is not found in chloroplasts of red algae themselves. Chlorophyll \"c\" is also found in some green algae and cyanobacteria.\nChlorophylls \"d\" and \"f\" are pigments found only in some cyanobacteria.\nCarotenoids.\nIn addition to chlorophylls, another group of yellow\u2013orange pigments called carotenoids are also found in the photosystems. There are about thirty photosynthetic carotenoids. They help transfer and dissipate excess energy, and their bright colors sometimes override the chlorophyll green, like during the fall, when the leaves of some land plants change color. \u03b2-carotene is a bright red-orange carotenoid found in nearly all chloroplasts, like chlorophyll \"a\". Xanthophylls, especially the orange-red zeaxanthin, are also common. Many other forms of carotenoids exist that are only found in certain groups of chloroplasts.\nPhycobilins.\nPhycobilins are a third group of pigments found in cyanobacteria, and glaucophyte, red algal, and cryptophyte chloroplasts. Phycobilins come in all colors, though phycoerytherin is one of the pigments that makes many red algae red. Phycobilins often organize into relatively large protein complexes about 40 nanometers across called phycobilisomes. Like photosystem I and ATP synthase, phycobilisomes jut into the stroma, preventing thylakoid stacking in red algal chloroplasts. Cryptophyte chloroplasts and some cyanobacteria don't have their phycobilin pigments organized into phycobilisomes, and keep them in their thylakoid space instead.\nSpecialized chloroplasts in plants.\nTo fix carbon dioxide into sugar molecules in the process of photosynthesis, chloroplasts use an enzyme called RuBisCO. RuBisCO has a problem\u2014it has trouble distinguishing between carbon dioxide and oxygen, so at high oxygen concentrations, RuBisCO starts accidentally adding oxygen to sugar precursors. This has the end result of ATP energy being wasted and being released, all with no sugar being produced. This is a big problem, since O is produced by the initial light reactions of photosynthesis, causing issues down the line in the Calvin cycle which uses RuBisCO.\nplants evolved a way to solve this\u2014by spatially separating the light reactions and the Calvin cycle. The light reactions, which store light energy in ATP and NADPH, are done in the mesophyll cells of a leaf. The Calvin cycle, which uses the stored energy to make sugar using RuBisCO, is done in the bundle sheath cells, a layer of cells surrounding a vein in a leaf.\nAs a result, chloroplasts in mesophyll cells and bundle sheath cells are specialized for each stage of photosynthesis. In mesophyll cells, chloroplasts are specialized for the light reactions, so they lack RuBisCO, and have normal grana and thylakoids, which they use to make ATP and NADPH, as well as oxygen. They store in a four-carbon compound, which is why the process is called \" photosynthesis\". The four-carbon compound is then transported to the bundle sheath chloroplasts, where it drops off and returns to the mesophyll. Bundle sheath chloroplasts do not carry out the light reactions, preventing oxygen from building up in them and disrupting RuBisCO activity. Because of this, they lack thylakoids organized into grana stacks\u2014though bundle sheath chloroplasts still have free-floating thylakoids in the stroma where they still carry out cyclic electron flow, a light-driven method of synthesizing ATP to power the Calvin cycle without generating oxygen. They lack photosystem II, and only have photosystem I\u2014the only protein complex needed for cyclic electron flow. Because the job of bundle sheath chloroplasts is to carry out the Calvin cycle and make sugar, they often contain large starch grains.\nBoth types of chloroplast contain large amounts of chloroplast peripheral reticulum, which they use to get more surface area to transport stuff in and out of them. Mesophyll chloroplasts have a little more peripheral reticulum than bundle sheath chloroplasts.\nLocation.\nDistribution in a plant.\nNot all cells in a multicellular plant contain chloroplasts. All green parts of a plant contain chloroplasts\u2014the chloroplasts, or more specifically, the chlorophyll in them are what make the photosynthetic parts of a plant green. The plant cells which contain chloroplasts are usually parenchyma cells, though chloroplasts can also be found in collenchyma tissue. A plant cell which contains chloroplasts is known as a chlorenchyma cell. A typical chlorenchyma cell of a land plant contains about 10 to 100 chloroplasts.\nIn some plants such as cacti, chloroplasts are found in the stems, though in most plants, chloroplasts are concentrated in the leaves. One square millimeter of leaf tissue can contain half a million chloroplasts. Within a leaf, chloroplasts are mainly found in the mesophyll layers of a leaf, and the guard cells of stomata. Palisade mesophyll cells can contain 30\u201370 chloroplasts per cell, while stomatal guard cells contain only around 8\u201315 per cell, as well as much less chlorophyll. Chloroplasts can also be found in the bundle sheath cells of a leaf, especially in C plants, which carry out the Calvin cycle in their bundle sheath cells. They are often absent from the epidermis of a leaf.\nCellular location.\nChloroplast movement.\nThe chloroplasts of plant and algal cells can orient themselves to best suit the available light. In low-light conditions, they will spread out in a sheet\u2014maximizing the surface area to absorb light. Under intense light, they will seek shelter by aligning in vertical columns along the plant cell's cell wall or turning sideways so that light strikes them edge-on. This reduces exposure and protects them from photooxidative damage. This ability to distribute chloroplasts so that they can take shelter behind each other or spread out may be the reason why land plants evolved to have many small chloroplasts instead of a few big ones.\nChloroplast movement is considered one of the most closely regulated stimulus-response systems that can be found in plants. Mitochondria have also been observed to follow chloroplasts as they move.\nIn higher plants, chloroplast movement is run by phototropins, blue light photoreceptors also responsible for plant phototropism. In some algae, mosses, ferns, and flowering plants, chloroplast movement is influenced by red light in addition to blue light, though very long red wavelengths inhibit movement rather than speeding it up. Blue light generally causes chloroplasts to seek shelter, while red light draws them out to maximize light absorption.\nStudies of \"Vallisneria gigantea\", an aquatic flowering plant, have shown that chloroplasts can get moving within five minutes of light exposure, though they don't initially show any net directionality. They may move along microfilament tracks, and the fact that the microfilament mesh changes shape to form a honeycomb structure surrounding the chloroplasts after they have moved suggests that microfilaments may help to anchor chloroplasts in place.\nFunction and chemistry.\nGuard cell chloroplasts.\nUnlike most epidermal cells, the guard cells of plant stomata contain relatively well-developed chloroplasts. However, exactly what they do is controversial.\nPlant innate immunity.\nPlants lack specialized immune cells\u2014all plant cells participate in the plant immune response. Chloroplasts, along with the nucleus, cell membrane, and endoplasmic reticulum, are key players in pathogen defense. Due to its role in a plant cell's immune response, pathogens frequently target the chloroplast.\nPlants have two main immune responses\u2014the hypersensitive response, in which infected cells seal themselves off and undergo programmed cell death, and systemic acquired resistance, where infected cells release signals warning the rest of the plant of a pathogen's presence.\nChloroplasts stimulate both responses by purposely damaging their photosynthetic system, producing reactive oxygen species. High levels of reactive oxygen species will cause the hypersensitive response. The reactive oxygen species also directly kill any pathogens within the cell. Lower levels of reactive oxygen species initiate systemic acquired resistance, triggering defense-molecule production in the rest of the plant.\nIn some plants, chloroplasts are known to move closer to the infection site and the nucleus during an infection.\nChloroplasts can serve as cellular sensors. After detecting stress in a cell, which might be due to a pathogen, chloroplasts begin producing molecules like salicylic acid, jasmonic acid, nitric oxide and reactive oxygen species which can serve as defense-signals. As cellular signals, reactive oxygen species are unstable molecules, so they probably don't leave the chloroplast, but instead pass on their signal to an unknown second messenger molecule. All these molecules initiate retrograde signaling\u2014signals from the chloroplast that regulate gene expression in the nucleus.\nIn addition to defense signaling, chloroplasts, with the help of the peroxisomes, help synthesize an important defense molecule, jasmonate. Chloroplasts synthesize all the fatty acids in a plant cell\u2014linoleic acid, a fatty acid, is a precursor to jasmonate.\nPhotosynthesis.\nOne of the main functions of the chloroplast is its role in photosynthesis, the process by which light is transformed into chemical energy, to subsequently produce food in the form of sugars. Water (H2O) and carbon dioxide (CO2) are used in photosynthesis, and sugar and oxygen (O2) is made, using light energy. Photosynthesis is divided into two stages\u2014the light reactions, where water is split to produce oxygen, and the dark reactions, or Calvin cycle, which builds sugar molecules from carbon dioxide. The two phases are linked by the energy carriers adenosine triphosphate (ATP) and nicotinamide adenine dinucleotide phosphate (NADP+).\nLight reactions.\nThe light reactions take place on the thylakoid membranes. They take light energy and store it in NADPH, a form of NADP+, and ATP to fuel the dark reactions.\nEnergy carriers.\nATP is the phosphorylated version of adenosine diphosphate (ADP), which stores energy in a cell and powers most cellular activities. ATP is the energized form, while ADP is the (partially) depleted form. NADP+ is an electron carrier which ferries high energy electrons. In the light reactions, it gets reduced, meaning it picks up electrons, becoming NADPH.\nPhotophosphorylation.\nLike mitochondria, chloroplasts use the potential energy stored in an H+, or hydrogen ion gradient to generate ATP energy. The two photosystems capture light energy to energize electrons taken from water, and release them down an electron transport chain. The molecules between the photosystems harness the electrons' energy to pump hydrogen ions into the thylakoid space, creating a concentration gradient, with more hydrogen ions (up to a thousand times as many) inside the thylakoid system than in the stroma. The hydrogen ions in the thylakoid space then diffuse back down their concentration gradient, flowing back out into the stroma through ATP synthase. ATP synthase uses the energy from the flowing hydrogen ions to phosphorylate adenosine diphosphate into adenosine triphosphate, or ATP. Because chloroplast ATP synthase projects out into the stroma, the ATP is synthesized there, in position to be used in the dark reactions.\nNADP+ reduction.\nElectrons are often removed from the electron transport chains to charge NADP+ with electrons, reducing it to NADPH. Like ATP synthase, ferredoxin-NADP+ reductase, the enzyme that reduces NADP+, releases the NADPH it makes into the stroma, right where it is needed for the dark reactions.\nBecause NADP+ reduction removes electrons from the electron transport chains, they must be replaced\u2014the job of photosystem II, which splits water molecules (H2O) to obtain the electrons from its hydrogen atoms.\nCyclic photophosphorylation.\nWhile photosystem II photolyzes water to obtain and energize new electrons, photosystem I simply reenergizes depleted electrons at the end of an electron transport chain. Normally, the reenergized electrons are taken by NADP+, though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP. This is termed cyclic photophosphorylation because the electrons are recycled. Cyclic photophosphorylation is common in plants, which need more ATP than NADPH.\nDark reactions.\nThe Calvin cycle, also known as the dark reactions, is a series of biochemical reactions that fixes CO2 into G3P sugar molecules and uses the energy and electrons from the ATP and NADPH made in the light reactions. The Calvin cycle takes place in the stroma of the chloroplast.\nWhile named \"the dark reactions\", in most plants, they take place in the light, since the dark reactions are dependent on the products of the light reactions.\nCarbon fixation and G3P synthesis.\nThe Calvin cycle starts by using the enzyme RuBisCO to fix CO2 into five-carbon Ribulose bisphosphate (RuBP) molecules. The result is unstable six-carbon molecules that immediately break down into three-carbon molecules called 3-phosphoglyceric acid, or 3-PGA.\nThe ATP and NADPH made in the light reactions is used to convert the 3-PGA into glyceraldehyde-3-phosphate, or G3P sugar molecules. Most of the G3P molecules are recycled back into RuBP using energy from more ATP, but one out of every six produced leaves the cycle\u2014the end product of the dark reactions.\nSugars and starches.\nGlyceraldehyde-3-phosphate can double up to form larger sugar molecules like glucose and fructose. These molecules are processed, and from them, the still larger sucrose, a disaccharide commonly known as table sugar, is made, though this process takes place outside of the chloroplast, in the cytoplasm.\nAlternatively, glucose monomers in the chloroplast can be linked together to make starch, which accumulates into the starch grains found in the chloroplast.\nUnder conditions such as high atmospheric CO2 concentrations, these starch grains may grow very large, distorting the grana and thylakoids. The starch granules displace the thylakoids, but leave them intact.\nWaterlogged roots can also cause starch buildup in the chloroplasts, possibly due to less sucrose being exported out of the chloroplast (or more accurately, the plant cell). This depletes a plant's free phosphate supply, which indirectly stimulates chloroplast starch synthesis.\nWhile linked to low photosynthesis rates, the starch grains themselves may not necessarily interfere significantly with the efficiency of photosynthesis, and might simply be a side effect of another photosynthesis-depressing factor.\nPhotorespiration.\nPhotorespiration can occur when the oxygen concentration is too high. RuBisCO cannot distinguish between oxygen and carbon dioxide very well, so it can accidentally add O2 instead of CO2 to RuBP. This process reduces the efficiency of photosynthesis\u2014it consumes ATP and oxygen, releases CO2, and produces no sugar. It can waste up to half the carbon fixed by the Calvin cycle. Several mechanisms have evolved in different lineages that raise the carbon dioxide concentration relative to oxygen within the chloroplast, increasing the efficiency of photosynthesis. These mechanisms are called carbon dioxide concentrating mechanisms, or CCMs. These include Crassulacean acid metabolism, carbon fixation, and pyrenoids. Chloroplasts in plants are notable as they exhibit a distinct chloroplast dimorphism.\npH.\nBecause of the H+ gradient across the thylakoid membrane, the interior of the thylakoid is acidic, with a pH around 4, while the stroma is slightly basic, with a pH of around 8.\nThe optimal stroma pH for the Calvin cycle is 8.1, with the reaction nearly stopping when the pH falls below 7.3.\nCO2 in water can form carbonic acid, which can disturb the pH of isolated chloroplasts, interfering with photosynthesis, even though CO2 is used in photosynthesis. However, chloroplasts in living plant cells are not affected by this as much.\nChloroplasts can pump K+ and H+ ions in and out of themselves using a poorly understood light-driven transport system.\nIn the presence of light, the pH of the thylakoid lumen can drop up to 1.5 pH units, while the pH of the stroma can rise by nearly one pH unit.\nAmino acid synthesis.\nChloroplasts alone make almost all of a plant cell's amino acids in their stroma except the sulfur-containing ones like cysteine and methionine. Cysteine is made in the chloroplast (the proplastid too) but it is also synthesized in the cytosol and mitochondria, probably because it has trouble crossing membranes to get to where it is needed. The chloroplast is known to make the precursors to methionine but it is unclear whether the organelle carries out the last leg of the pathway or if it happens in the cytosol.\nOther nitrogen compounds.\nChloroplasts make all of a cell's purines and pyrimidines\u2014the nitrogenous bases found in DNA and RNA. They also convert nitrite (NO2\u2212) into ammonia (NH3) which supplies the plant with nitrogen to make its amino acids and nucleotides.\nOther chemical products.\nThe plastid is the site of diverse and complex lipid synthesis in plants. The carbon used to form the majority of the lipid is from acetyl-CoA, which is the decarboxylation product of pyruvate. Pyruvate may enter the plastid from the cytosol by passive diffusion through the membrane after production in glycolysis. Pyruvate is also made in the plastid from phosphoenolpyruvate, a metabolite made in the cytosol from pyruvate or PGA. Acetate in the cytosol is unavailable for lipid biosynthesis in the plastid. The typical length of fatty acids produced in the plastid are 16 or 18 carbons, with 0-3 cis double bonds.\nThe biosynthesis of fatty acids from acetyl-CoA primarily requires two enzymes. Acetyl-CoA carboxylase creates malonyl-CoA, used in both the first step and the extension steps of synthesis. Fatty acid synthase (FAS) is a large complex of enzymes and cofactors including acyl carrier protein (ACP) which holds the acyl chain as it is synthesized. The initiation of synthesis begins with the condensation of malonyl-ACP with acetyl-CoA to produce ketobutyryl-ACP. 2 reductions involving the use of NADPH and one dehydration creates butyryl-ACP. Extension of the fatty acid comes from repeated cycles of malonyl-ACP condensation, reduction, and dehydration.\nOther lipids are derived from the methyl-erythritol phosphate (MEP) pathway and consist of gibberelins, sterols, abscisic acid, phytol, and innumerable secondary metabolites.\nDifferentiation, replication, and inheritance.\nChloroplasts are a special type of a plant cell organelle called a plastid, though the two terms are sometimes used interchangeably. There are many other types of plastids, which carry out various functions. All chloroplasts in a plant are descended from undifferentiated proplastids found in the zygote, or fertilized egg. Proplastids are commonly found in an adult plant's apical meristems. Chloroplasts do not normally develop from proplastids in root tip meristems\u2014instead, the formation of starch-storing amyloplasts is more common.\nIn shoots, proplastids from shoot apical meristems can gradually develop into chloroplasts in photosynthetic leaf tissues as the leaf matures, if exposed to the required light. This process involves invaginations of the inner plastid membrane, forming sheets of membrane that project into the internal stroma. These membrane sheets then fold to form thylakoids and grana.\nIf angiosperm shoots are not exposed to the required light for chloroplast formation, proplastids may develop into an etioplast stage before becoming chloroplasts. An etioplast is a plastid that lacks chlorophyll, and has inner membrane invaginations that form a lattice of tubes in their stroma, called a prolamellar body. While etioplasts lack chlorophyll, they have a yellow chlorophyll precursor stocked. Within a few minutes of light exposure, the prolamellar body begins to reorganize into stacks of thylakoids, and chlorophyll starts to be produced. This process, where the etioplast becomes a chloroplast, takes several hours. Gymnosperms do not require light to form chloroplasts.\nLight, however, does not guarantee that a proplastid will develop into a chloroplast. Whether a proplastid develops into a chloroplast some other kind of plastid is mostly controlled by the nucleus and is largely influenced by the kind of cell it resides in.\nPlastid interconversion.\nPlastid differentiation is not permanent, in fact many interconversions are possible. Chloroplasts may be converted to chromoplasts, which are pigment-filled plastids responsible for the bright colors seen in flowers and ripe fruit. Starch storing amyloplasts can also be converted to chromoplasts, and it is possible for proplastids to develop straight into chromoplasts. Chromoplasts and amyloplasts can also become chloroplasts, like what happens when a carrot or a potato is illuminated. If a plant is injured, or something else causes a plant cell to revert to a meristematic state, chloroplasts and other plastids can turn back into proplastids. Chloroplast, amyloplast, chromoplast, proplast, etc., are not absolute states\u2014intermediate forms are common.\nDivision.\nMost chloroplasts in a photosynthetic cell do not develop directly from proplastids or etioplasts. In fact, a typical shoot meristematic plant cell contains only 7\u201320 proplastids. These proplastids differentiate into chloroplasts, which divide to create the 30\u201370 chloroplasts found in a mature photosynthetic plant cell. If the cell divides, chloroplast division provides the additional chloroplasts to partition between the two daughter cells.\nIn single-celled algae, chloroplast division is the only way new chloroplasts are formed. There is no proplastid differentiation\u2014when an algal cell divides, its chloroplast divides along with it, and each daughter cell receives a mature chloroplast.\nAlmost all chloroplasts in a cell divide, rather than a small group of rapidly dividing chloroplasts. Chloroplasts have no definite S-phase\u2014their DNA replication is not synchronized or limited to that of their host cells.\nMuch of what we know about chloroplast division comes from studying organisms like \"Arabidopsis\" and the red alga \"Cyanidioschyzon merol\u00e6\".\nThe division process starts when the proteins FtsZ1 and FtsZ2 assemble into filaments, and with the help of a protein ARC6, form a structure called a Z-ring within the chloroplast's stroma. The Min system manages the placement of the Z-ring, ensuring that the chloroplast is cleaved more or less evenly. The protein MinD prevents FtsZ from linking up and forming filaments. Another protein ARC3 may also be involved, but it is not very well understood. These proteins are active at the poles of the chloroplast, preventing Z-ring formation there, but near the center of the chloroplast, MinE inhibits them, allowing the Z-ring to form.\nNext, the two plastid-dividing rings, or PD rings form. The inner plastid-dividing ring is located in the inner side of the chloroplast's inner membrane, and is formed first. The outer plastid-dividing ring is found wrapped around the outer chloroplast membrane. It consists of filaments about 5 nanometers across, arranged in rows 6.4 nanometers apart, and shrinks to squeeze the chloroplast. This is when chloroplast constriction begins. In a few species like \"Cyanidioschyzon merol\u00e6\", chloroplasts have a third plastid-dividing ring located in the chloroplast's intermembrane space.\nLate into the constriction phase, dynamin proteins assemble around the outer plastid-dividing ring, helping provide force to squeeze the chloroplast. Meanwhile, the Z-ring and the inner plastid-dividing ring break down. During this stage, the many chloroplast DNA plasmids floating around in the stroma are partitioned and distributed to the two forming daughter chloroplasts.\nLater, the dynamins migrate under the outer plastid dividing ring, into direct contact with the chloroplast's outer membrane, to cleave the chloroplast in two daughter chloroplasts.\nA remnant of the outer plastid dividing ring remains floating between the two daughter chloroplasts, and a remnant of the dynamin ring remains attached to one of the daughter chloroplasts.\nOf the five or six rings involved in chloroplast division, only the outer plastid-dividing ring is present for the entire constriction and division phase\u2014while the Z-ring forms first, constriction does not begin until the outer plastid-dividing ring forms.\nRegulation.\nIn species of algae that contain a single chloroplast, regulation of chloroplast division is extremely important to ensure that each daughter cell receives a chloroplast\u2014chloroplasts can't be made from scratch. In organisms like plants, whose cells contain multiple chloroplasts, coordination is looser and less important. It is likely that chloroplast and cell division are somewhat synchronized, though the mechanisms for it are mostly unknown.\nLight has been shown to be a requirement for chloroplast division. Chloroplasts can grow and progress through some of the constriction stages under poor quality green light, but are slow to complete division\u2014they require exposure to bright white light to complete division. Spinach leaves grown under green light have been observed to contain many large dumbbell-shaped chloroplasts. Exposure to white light can stimulate these chloroplasts to divide and reduce the population of dumbbell-shaped chloroplasts.\nChloroplast inheritance.\nLike mitochondria, chloroplasts are usually inherited from a single parent. Biparental chloroplast inheritance\u2014where plastid genes are inherited from both parent plants\u2014occurs in very low levels in some flowering plants.\nMany mechanisms prevent biparental chloroplast DNA inheritance, including selective destruction of chloroplasts or their genes within the gamete or zygote, and chloroplasts from one parent being excluded from the embryo. Parental chloroplasts can be sorted so that only one type is present in each offspring.\nGymnosperms, such as pine trees, mostly pass on chloroplasts paternally, while flowering plants often inherit chloroplasts maternally. Flowering plants were once thought to only inherit chloroplasts maternally. However, there are now many documented cases of angiosperms inheriting chloroplasts paternally.\nAngiosperms, which pass on chloroplasts maternally, have many ways to prevent paternal inheritance. Most of them produce sperm cells that do not contain any plastids. There are many other documented mechanisms that prevent paternal inheritance in these flowering plants, such as different rates of chloroplast replication within the embryo.\nAmong angiosperms, paternal chloroplast inheritance is observed more often in hybrids than in offspring from parents of the same species. This suggests that incompatible hybrid genes might interfere with the mechanisms that prevent paternal inheritance.\nTransplastomic plants.\nRecently, chloroplasts have caught attention by developers of genetically modified crops. Since, in most flowering plants, chloroplasts are not inherited from the male parent, transgenes in these plastids cannot be disseminated by pollen. This makes plastid transformation a valuable tool for the creation and cultivation of genetically modified plants that are biologically contained, thus posing significantly lower environmental risks. This biological containment strategy is therefore suitable for establishing the coexistence of conventional and organic agriculture. While the reliability of this mechanism has not yet been studied for all relevant crop species, recent results in tobacco plants are promising, showing a failed containment rate of transplastomic plants at 3 in 1,000,000."}
{"id": "6357", "revid": "1013127580", "url": "https://en.wikipedia.org/wiki?curid=6357", "title": "Camp David", "text": "Camp David is the country retreat for the president of the United States. It is located in the wooded hills of Catoctin Mountain Park, in Frederick County, Maryland, near the towns of Thurmont and Emmitsburg, about 62 miles (100\u00a0km) north-northwest of the national capital city of Washington, D.C. It is officially known as the Naval Support Facility Thurmont. Because it is technically a military installation, the staffing is primarily provided by the Seabees, Civil Engineer Corps (CEC), the United States Navy and the United States Marine Corps. Naval construction battalions are tasked with base construction and send detachments as needed.\nOriginally known as Hi-Catoctin, Camp David was built as a camp for federal government agents and their families by the Works Progress Administration. Construction started in 1935 and was completed in 1938. In 1942, President Franklin D. Roosevelt converted it to a presidential retreat and renamed it \"Shangri-La\", for the fictional Himalayan paradise in the 1933 novel \"Lost Horizon\" by British author James Hilton.\nCamp David received its present name in 1953 from Dwight D. Eisenhower, in honor of his father, and grandson, both named David. Eisenhower had the practice golf facility built at Camp David.\nThe Catoctin Mountain Park does not indicate the location of Camp David on park maps due to privacy and security concerns, although it can be seen through the use of publicly accessible satellite images.\nPresidential use.\nFranklin D. Roosevelt hosted Sir Winston Churchill at Shangri-La in May 1943. Dwight Eisenhower held his first cabinet meeting there on November 22, 1955 following hospitalization and convalescence he required after a heart attack suffered in Denver, Colorado on September 24. Eisenhower met Nikita Khrushchev there for two days of discussions in September 1959.\nJohn F. Kennedy and his family often enjoyed riding, golf and other recreational activities there, and Kennedy often allowed White House staff and Cabinet members to use the retreat when he or his family were not there. Lyndon B. Johnson met with advisors in this setting and hosted both Australian prime minister Harold Holt and Canadian prime minister Lester B. Pearson there. Richard Nixon was a frequent visitor. He personally directed the construction of a swimming pool and other improvements to Aspen Lodge. Gerald Ford hosted Indonesian president Suharto at Camp David.\nJimmy Carter initially favored closing Camp David in order to save money. Once Carter actually visited the retreat, he decided to keep it. Carter brokered the Camp David Accords there in September 1978 between Egyptian president Anwar al-Sadat and Israeli prime minister Menachem Begin. Ronald Reagan visited the retreat more than any other president. In 1984, Reagan hosted British prime minister Margaret Thatcher. Reagan restored the nature trails that Nixon paved over so he could horseback ride at Camp David. George H. W. Bush's daughter, Dorothy Bush Koch, was married there in 1992, in the first wedding held at Camp David. During his tenure as president, Bill Clinton spent every Thanksgiving at Camp David with his family. In July 2000, he hosted the 2000 Camp David Summit negotiations between Israeli prime minister Ehud Barak and Palestinian Authority chairman Yasser Arafat there.\nIn February 2001, George W. Bush held his first meeting with a European leader, UK prime minister Tony Blair, at Camp David, to discuss missile defense, Iraq, and NATO. During his two terms in office, Bush visited Camp David 149 times, for a total of 487 days, for hosting foreign visitors as well as a personal retreat. He met Blair there four times. Among the numerous other foreign leaders he hosted at Camp David were Russian president Vladimir Putin and President Musharraf of Pakistan in 2003, Danish prime minister Anders Fogh Rasmussen in June 2006, and British prime minister Gordon Brown in 2007.\nBarack Obama chose Camp David to host the 38th G8 summit in 2012. President Obama also hosted Russian prime minister Dmitry Medvedev at Camp David, as well as the GCC Summit there in 2015.\nDonald Trump hosted Mitch McConnell and Paul Ryan at Camp David while Republicans prepared to defend both houses of Congress in the 2018 midterm elections. The 46th G7 summit was to be held at Camp David on June 10\u201312, 2020, but was cancelled due to health concerns during the ongoing COVID-19 pandemic.\nPractice golf facility.\nTo be able to play his favorite sport, President Eisenhower had golf course architect Robert Trent Jones design a practice golf facility at Camp David. Around 1954, Jones built one golf hole\u00a0\u2013 a par 3\u00a0\u2013 with four different tees; Eisenhower added a 250-yard (228.6\u00a0m) driving range near the helicopter landing zone.\nSecurity issues.\nOn July 2, 2011, an F-15 intercepted a civilian aircraft approximately from Camp David, when President Obama was in the residence. The two-seater, which was out of radio communication, was escorted to nearby Hagerstown, Maryland, without incident.\nOn July 10, 2011, an F-15 intercepted another small plane near Camp David when Obama was again in the residence; a total of three were intercepted that weekend."}
{"id": "6359", "revid": "17692702", "url": "https://en.wikipedia.org/wiki?curid=6359", "title": "Crux", "text": "Crux () is a constellation centred on four stars in the southern sky in a bright portion of the Milky Way. It is among the most easily distinguished constellations as its hallmark (asterism) stars each have an apparent visual magnitude brighter than +2.8, even though it is the smallest of all 88 modern constellations. Its name is Latin for cross, and it is dominated by a cross-shaped or kite-like asterism that is commonly known as the Southern Cross.\nBlue-white \u03b1 Crucis (Acrux) is the most southerly member of the constellation and, at magnitude 0.8, also the brightest. The three remaining stars of the main cross asterism appear clockwise and in order of lessening magnitude: \u03b2 Crucis (Mimosa), \u03b3 Crucis (Gacrux), and \u03b4 Crucis (Imai). \u03b5 Crucis (Ginan) also lies within the cross asterism. Many of these brighter stars are members of the Scorpius\u2013Centaurus Association, a large but loose group of hot blue-white stars that appear to share common origins and motion across the southern Milky Way.\nCrux contains four Cepheid variables, each visible to the naked eye under optimum conditions. Crux also contains the bright and colourful open cluster known as the Jewel Box (NGC 4755) on its western border. To the southeast figures a large, relatively near dark nebula spanning 7\u00b0 by 5\u00b0 known as the Coalsack Nebula, portions of which are mapped in the neighbouring constellations of Centaurus and Musca.\nHistory.\nThe bright stars in Crux were known to the Ancient Greeks, where Ptolemy regarded them as part of the constellation Centaurus. They were entirely visible as far north as Britain in the fourth millennium BC. However, the precession of the equinoxes gradually lowered the stars below the European horizon, and they were eventually forgotten by the inhabitants of northern latitudes. By 400\u00a0CE, the stars in the constellation we now call Crux never rose above the horizon throughout most of Europe. Dante may have known about the constellation in the 14th century, as he describes an asterism of four bright stars in the southern sky in his \"Divine Comedy\". His description, however, may be allegorical, and the similarity to the constellation a coincidence.\nThe 15th\u00a0century Venetian navigator Alvise Cadamosto made note of what was probably the Southern Cross on exiting the Gambia River in 1455, calling it the \"carro dell'ostro\" (\"southern chariot\"). However, Cadamosto's accompanying diagram was inaccurate. Historians generally credit Jo\u00e3o Faras for being the first European to depict it correctly. Faras sketched and described the constellation (calling it \"Las Guardas\") in a letter written on the beaches of Brazil on 1\u00a0May 1500 to the Portuguese monarch.\nExplorer Amerigo Vespucci seems to have observed not only the Southern Cross but also the neighboring Coalsack Nebula on his second voyage in 1501\u20131502.\nAnother early modern description clearly describing Crux as a separate constellation is attributed to Andrea Corsali, an Italian navigator who from 1515\u20131517 sailed to China and the East Indies in an expedition sponsored by King Manuel\u00a0I. In 1516, Corsali wrote a letter to the monarch describing his observations of the southern sky, which included a rather crude map of the stars around the south celestial pole including the Southern Cross and the two Magellanic Clouds seen in an external orientation, as on a globe.\nEmery Molyneux and Petrus Plancius have also been cited as the first uranographers (sky mappers) to distinguish Crux as a separate constellation; their representations date from 1592, the former depicting it on his celestial globe and the latter in one of the small celestial maps on his large wall map. Both authors, however, depended on unreliable sources and placed Crux in the wrong position. Crux was first shown in its correct position on the celestial globes of Petrus Plancius and Jodocus Hondius in 1598 and 1600. Its stars were first catalogued separately from Centaurus by Frederick de Houtman in 1603. The constellation was later adopted by Jakob Bartsch in 1624 and Augustin Royer in 1679. Royer is sometimes wrongly cited as initially distinguishing Crux.\nCharacteristics.\nCrux is bordered by the constellations Centaurus (which surrounds it on three sides) on the east, north and west, and Musca to the south. Covering 68\u00a0square degrees and 0.165% of the night sky, it is the smallest of the 88 constellations. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"Cru\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of four segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between \u221255.68\u00b0 and \u221264.70\u00b0. Its totality figures at least part of the year south of the 25th parallel north.\nIn tropical regions Crux can be seen in the sky from April to June. Crux is exactly opposite to Cassiopeia on the celestial sphere, and therefore it cannot appear in the sky with the latter at the same time. In this era, south of Cape Town, Adelaide and Buenos Aires (the 34th parallel south), Crux is circumpolar and thus always appears in the sky.\nCrux is sometimes confused with the nearby False Cross by stargazers. The False Cross is larger and dimmer, does not have a fifth star, and lacks the two prominent nearby \"Pointer Stars\". Between the two is the even larger and dimmer Diamond Cross.\nVisibility.\nCrux is easily visible from the southern hemisphere at practically any time of year. It is also visible near the horizon from tropical latitudes of the northern hemisphere for a few hours every night during the northern winter and spring. For instance, it is visible from Cancun or any other place at latitude 25\u00b0 N or less at around 10 pm at the end of April. There are 5 main stars.\nDue to precession, Crux will move closer to the South Pole in the next millennia, up to 67 degrees south declination for the middle of the constellation. However, by the year 14,000 Crux will be visible for most parts of Europe and continental United States which will extend to North Europe by the year 18,000 as it will be less than 30 degrees south declination.\nUse in navigation.\nIn the Southern Hemisphere, the Southern Cross is frequently used for navigation in much the same way that Polaris is used in the Northern Hemisphere. Projecting a line from \u03b3 to \u03b1 Crucis (the foot of the crucifix) approximately times beyond gives a point close to the Southern Celestial Pole which is also, coincidentally, where intersects a perpendicular line taken southwards from the east-west axis of Alpha Centauri to Beta Centauri, which are stars at an alike declination to Crux and of a similar width as the cross, but higher magnitude.\nArgentine gauchos are documented as using Crux for night orientation in the Pampas and Patagonia.\nAlpha and Beta Centauri are of similar declinations (thus distance from the pole) and are often referred as the \"Southern Pointers\" or just \"The Pointers\", allowing people to easily identify the Southern Cross, the constellation of Crux. Very few bright stars lie between Crux and the pole itself, although the constellation Musca is fairly easily recognised immediately south of Crux.\nCircumscribed limits around apparent bright stars.\nDown to apparent magnitude +2.5 are 92 stars that shine the brightest as viewed from the Earth. Three of these stars are in Crux making it the most densely populated as to those stars (this being 3.26% of these 92 stars, and in turn being 19.2 times more than the expected 0.17% that would result on a homogenous distribution of all bright stars and a randomised drawing of all 88 constellations, given its area, 0.17% of the sky).\nFeatures.\nStars.\nWithin the constellation's borders, there are 49 stars brighter than or equal to apparent magnitude 6.5. The four main stars that form the asterism are Alpha, Beta, Gamma, and Delta Crucis.\nThere is also a fifth star, that is often included with the Southern Cross.\nThere are several other naked-eye stars within the borders of Crux, especially:\nScorpius\u2013Centaurus Association members.\nUnusually, a total of 15 of the 23 brightest stars in Crux are spectrally blue-white B-type stars. Among the five main bright stars, Delta, and probably Alpha and Beta, are likely co-moving B-type members of the Scorpius\u2013Centaurus Association, the nearest OB association to the Sun. They are among the highest-mass stellar members of the Lower Centaurus-Crux subgroup of the association, with ages of roughly 10 to 20\u00a0million years. Other members include the blue-white stars Zeta, Lambda and both the components of the visual double star, Mu.\nVariable stars.\nCrux contains many variable stars. It boasts four Cepheid variables that may all reach naked eye visibility.\nOther well studied variable stars includes:\nHost star exoplanets in Crux.\nThe star HD 106906 has been found to have a planet\u2014HD 106906 b\u2014that has one of the widest orbits of any currently known planetary-mass companions..\nVisible objects beyond the Local Arm.\nCrux is backlit by the multitude of stars of the Scutum-Crux Arm (more commonly called the Scutum-Centaurus Arm) of the Milky Way. This is the main inner arm in the local radial quarter of the galaxy. Part-obscuring this is:\nA key feature of the Scutum-Crux Arm is:\nCultural significance.\nThe most prominent feature of Crux is the distinctive asterism known as the Southern Cross. It has great significance in the cultures of the southern hemisphere, particularly of Australia and New Zealand.\nFlags and symbols.\nSeveral southern countries and organisations have traditionally used Crux as a national or distinctive symbol. The four or five brightest stars of Crux appear, heraldically standardised in various ways, on the flags of Australia, Brazil, New Zealand, Papua New Guinea and Samoa. They also appear on the flags of the Australian state of Victoria, the Australian Capital Territory, the Northern Territory, as well as the flag of Magallanes Region of Chile, the flag of Londrina (Brazil) and several Argentine provincial flags and emblems (for example, \"Tierra del Fuego\" and \"Santa Cruz\"). The flag of the Mercosur trading zone displays the four brightest stars. Crux also appears on the Brazilian coat of arms and, , on the cover of Brazilian passports.\nFive stars appear in the logo of the Brazilian football team Cruzeiro Esporte Clube and in the insignia of the Order of the Southern Cross, and the cross has featured as name of the Brazilian currency (the \"cruzeiro\" from 1942 to 1986 and again from 1990 to 1994). All coins of the (1998) series of the Brazilian real display the constellation.\nSongs and literature reference the Southern Cross, including the Argentine epic poem \"Mart\u00edn Fierro\". The Argentinian singer Charly Garc\u00eda says that he is \"from the Southern Cross\" in the song \"No voy en tren\".\nThe Cross gets a mention in the lyrics of the Brazilian National Anthem (1909): \"A imagem do Cruzeiro resplandece\" (\"the image of the Cross shines\").\nThe Southern Cross is mentioned in the Australian National Anthem, \"\"Beneath our radiant Southern Cross we'll toil with hearts and hands\"\nThe Southern Cross features in the coat of arms of William Birdwood, 1st Baron Birdwood, the British officer who commanded the Australian and New Zealand Army Corps during the Gallipoli Campaign of the First World War.\nThe Southern Cross is also mentioned in the Samoan \nNational Anthem.\n\"Vaai 'i na fetu o lo'u a agiagia ai:\nLe faailoga lea o Iesu, na maliu ai mo Samoa.\"\" (\"Look at those stars that are waving on it:\nThis is the symbol of Jesus, who died on it for Samoa.\")\nThe 1952-53 NBC Television Series \"Victory At Sea\" contained a musical number entitled \"Beneath the Southern Cross\".\n\"Southern Cross\" is a single released by Crosby, Stills and Nash in 1981. It reached #18 on Billboard Hot 100 in late 1982.\nThe Order of the Southern Cross is a Brazilian order of chivalry awarded to \"those who have rendered significant service to the Brazilian nation\".\nIn \"O Sweet Saint Martin's Land\", the lyrics mention the Southern Cross: \"Thy Southern Cross the night\".\nA stylized version of Crux appears on the Australian Eureka Flag. The constellation was also used on the dark blue, shield-like patch worn by personnel of the U.S. Army's Americal Division, which was organized in the Southern Hemisphere, on the island of New Caledonia, and also on the blue diamond of the U.S. 1st Marine Division, which fought on the Southern Hemisphere islands of Guadalcanal and New Britain.\nThe \"Petersflagge\" flag of the German East Africa Company of 1885\u20131920, which included a constellation of five white five-pointed Crux \"stars\" on a red ground, later served as the model for symbolism associated with generic German colonial-oriented organisations: the Reichskolonialbund of 1936\u20131943 and the (1956/1983 to the present).\nSouthern Cross station is a major rail terminal in Melbourne, Australia.\nThe Personal Ordinariate of Our Lady of the Southern Cross is a personal ordinariate of the Roman Catholic Church primarily within the territory of the Australian Catholic Bishops Conference for groups of Anglicans who desire full communion with the Catholic Church in Australia and Asia.\nThe Knights of the Southern Cross (KSC) is a Catholic fraternal order throughout Australia.\nVarious cultures.\nIn Chinese, (), meaning \"Cross\", refers to an asterism consisting of \u03b3 Crucis, \u03b1 Crucis, \u03b2 Crucis and \u03b4 Crucis.\nIn Australian Aboriginal astronomy, Crux and the Coalsack mark the head of the 'Emu in the Sky' (which is seen in the dark spaces rather than in the patterns of stars) in several Aboriginal cultures, while Crux itself is said to be a possum sitting in a tree (Boorong people of the Wimmera region of northwestern Victoria), a representation of the sky deity Mirrabooka (Quandamooka people of Stradbroke Island), a stingray (Yolngu people of Arnhem Land), or an eagle (Kaurna people of the Adelaide Plains). Two Pacific constellations also included Gamma Centauri. Torres Strait Islanders in modern-day Australia saw Gamma Centauri as the handle and the four stars as the trident of Tagai's Fishing Spear. The Aranda people of central Australia saw the four Cross stars as the talon of an eagle and Gamma Centauri as its leg.\nVarious peoples in the East Indies and Brazil viewed the four main stars as the body of a ray. In both Indonesia and Malaysia, it is known as \"Bintang Pari\" and \"Buruj Pari\", respectively (\"ray stars\"). This aquatic theme is also shared by an archaic name of the constellation in Vietnam, where it was once known as \"sao C\u00e1 Li\u1ec7t\" (the ponyfish star).\nThe Javanese people of Indonesia called this constellation \"Gubug p\u00e8nc\u00e8ng\" (\"raking hut\") or \"lumbung\" (\"the granary\"), because the shape of the constellation was like that of a raking hut.\nThe Southern Cross (\u03b1, \u03b2, \u03b3 and \u03b4 Crucis) together with \u03bc Crucis is one of the asterisms used by Bugis sailors for navigation, called \"binto\u00e9ng bola k\u00e9ppang\", meaning \"incomplete house star\"\nThe M\u0101ori name for the Southern Cross is \"M\u0101hutonga\" and it is thought of as the anchor (\"Te Punga\") of Tama-rereti's \"waka\" (the Milky Way), while the Pointers are its rope. In Tonga it is known as \"Toloa\" (\"duck\"); it is depicted as a duck flying south, with one of his wings (\u03b4 Crucis) wounded because \"Ongo tangata\" (\"two men\", \u03b1 and \u03b2 Centauri) threw a stone at it. The Coalsack is known as \"Humu\" (the \"triggerfish\"), because of its shape. In Samoa the constellation is called \"Sumu\" (\"triggerfish\") because of its rhomboid shape, while \u03b1 and \u03b2 Centauri are called \"Luatagata\" (Two Men), just as they are in Tonga. The peoples of the Solomon Islands saw several figures in the Southern Cross. These included a knee protector and a net used to catch Palolo worms. Neighboring peoples in the Marshall Islands saw these stars as a fish.\nIn Mapudungun, the language of Patagonian Mapuches, the name of the Southern Cross is \"Melipal\", which means \"four stars\". In Quechua, the language of the Inca civilization, Crux is known as \"Chakana\", which means literally \"stair\" (\"chaka\", bridge, link; \"hanan\", high, above), but carries a deep symbolism within Quechua mysticism. Alpha and Beta Crucis make up one foot of the Great Rhea, a constellation encompassing Centaurus and Circinus along with the two bright stars. The Great Rhea was a constellation of the Bororo of Brazil. The Mocov\u00ed people of Argentina also saw a rhea including the stars of Crux. Their rhea is attacked by two dogs, represented by bright stars in Centaurus and Circinus. The dogs' heads are marked by Alpha and Beta Centauri. The rhea's body is marked by the four main stars of Crux, while its head is Gamma Centauri and its feet are the bright stars of Musca. The Bakairi people of Brazil had a sprawling constellation representing a bird snare. It included the bright stars of Crux, the southern part of Centaurus, Circinus, at least one star in Lupus, the bright stars of Musca, Beta and the optical double star Delta1,2 Chamaeleontis: and some of the stars of Volans, and Mensa. The Kalapalo people of Mato Grosso state in Brazil saw the stars of Crux as \"Aganagi\" angry bees having emerged from the Coalsack, which they saw as the beehive.\nAmong Tuaregs, the four most visible stars of Crux are considered \"iggaren\", i.e. four \"Maerua crassifolia\" trees. The Tswana people of Botswana saw the constellation as \"Dithutlwa\", two giraffes \u2013 Alpha and Beta Crucis forming a male, and Gamma and Delta forming the female."}
{"id": "6360", "revid": "87355", "url": "https://en.wikipedia.org/wiki?curid=6360", "title": "Cepheus", "text": "Cepheus (Ancient Greek: \u039a\u03b7\u03c6\u03b5\u03cd\u03c2 \"Kephe\u00fas\") may refer to:"}
{"id": "6361", "revid": "8747689", "url": "https://en.wikipedia.org/wiki?curid=6361", "title": "Cassiopeia", "text": "Cassiopeia ( ) or Cassiopea may refer to:"}
{"id": "6362", "revid": "8240947", "url": "https://en.wikipedia.org/wiki?curid=6362", "title": "Cetus", "text": "Cetus () is a constellation. The Cetus was a sea monster in Greek mythology as both Perseus and Heracles needed to slay, sometimes in English called 'the whale'. Cetus is in the region of the sky that contains other water-related constellations: Aquarius, Pisces and Eridanus.\nFeatures.\nEcliptic.\nCetus is not among the 12 true zodiac constellations in the J2000 epoch, nor classical 12-part zodiac. The ecliptic passes less than 0.25\u00b0 from one of its corners. Thus the moon and planets will enter Cetus (occulting any stars as a foreground object) in 50% of their successive orbits briefly and the southern part of the sun appears in Cetus for about one day each year. Many asteroids in belts have longer phases occulting the north-western part of Cetus, that bulk with a slightly greater inclination to the ecliptic than the moon and planets.\nAs seen from Mars, the ecliptic (apparent plane of the sun and also the average plane of the planets which is almost the same) passes into it.\nStars.\nMira (\"wonderful\", named by Bayer: Omicron Ceti, a star of the neck of the asterism) was the first variable star to be discovered and the prototype of its class, Mira variables. Over a period of 332 days, it reaches a maximum apparent magnitude of 3 - visible to the naked eye - and dips to a minimum magnitude of 10, invisible to the unaided eye. Its seeming appearance and disappearance gave it its name. Mira pulsates with a minimum size of 400 solar diameters and a maximum size of 500 solar diameters. 420 light-years from Earth, it was discovered by David Fabricius in 1596.\n\u03b1 Ceti, traditionally called Menkar (\"the nose\"), is a red-hued giant star of magnitude 2.5, 220 light-years from Earth. It is a wide double star; the secondary is 93 Ceti, a blue-white hued star of magnitude 5.6, 440 light-years away. \u03b2 Ceti, also called Deneb Kaitos and Diphda is the brightest star in Cetus. It is an orange-hued giant star of magnitude 2.0, 96 light-years from Earth. The traditional name \"Deneb Kaitos\" means \"the whale's tail\". \u03b3 Ceti, Kaffaljidhma (\"head of the whale\") is a very close double star. The primary is a yellow-hued star of magnitude 3.5, 82 light-years from Earth, and the secondary is a blue-hued star of magnitude 6.6. Tau Ceti is noted for being the nearest Sun-like star at a distance of 11.9 light-years. It is a yellow-hued main-sequence star of magnitude 3.5.\nAA Ceti is a triple star system; the brightest member has a magnitude of 6.2. The primary and secondary are separated by 8.4 arcseconds at an angle of 304 degrees. The tertiary is not visible in telescopes. AA Ceti is an eclipsing variable star; the tertiary star passes in front of the primary and causes the system's apparent magnitude to decrease by 0.5 magnitudes. UV Ceti is an unusual binary variable star. 8.7 light-years from Earth, the system consists of two red dwarfs. Both of magnitude 13. One of the stars is a flare star, which are prone to sudden, random outbursts that last several minutes; these increase the pair's apparent brightness significantly - as high as magnitude 7.\nDeep-sky objects.\nCetus lies far from the galactic plane, so that many distant galaxies are visible, unobscured by dust from the Milky Way. Of these, the brightest is Messier 77 (NGC 1068), a 9th magnitude spiral galaxy near Delta Ceti. It appears face-on and has a clearly visible nucleus of magnitude 10. About 50 million light-years from Earth, M77 is also a Seyfert galaxy and thus a bright object in the radio spectrum. Recently, the galactic cluster JKCS\u00a0041 was confirmed to be the most distant cluster of galaxies yet discovered.\nThe massive cD galaxy Holmberg 15A is also found in Cetus. As is spiral galaxy NGC 1042 and ultra-diffuse galaxy NGC 1052-DF2.\nIC 1613 (Caldwell 51) is an irregular dwarf galaxy near the star 26 Ceti and is a member of the Local Group.\nNGC 246 (Caldwell 56), also called the Cetus Ring, is a planetary nebula with a magnitude of 8.0, 1600 light-years from Earth. Among some amateur astronomers, NGC 246 has garnered the nickname \"Pac-Man Nebula\" because of the arrangement of its central stars and the surrounding star field.\nHistory and mythology.\nCetus may have originally been associated with a whale, which would have had mythic status amongst Mesopotamian cultures. It is often now called the Whale, though it is most strongly associated with Cetus the sea-monster, who was slain by Perseus as he saved the princess Andromeda from Poseidon's wrath. It is in the middle of \"The Sea\" recognised by mythologists, a set of water-associated constellations, its other members being Eridanus, Pisces, Piscis Austrinus and Aquarius.\nCetus has been depicted in many ways throughout its history. In the 17th century, Cetus was depicted as a \"dragon fish\" by Johann Bayer. Both Willem Blaeu and Andreas Cellarius depicted Cetus as a whale-like creature in the same century. However, Cetus has also been variously depicted with animal heads attached to a piscine body.\nIn global astronomy.\nIn Chinese astronomy, the stars of Cetus are found among two areas: the Black Tortoise of the North (\u5317\u65b9\u7384\u6b66, \"B\u011bi F\u0101ng Xu\u00e1n W\u01d4\") and the White Tiger of the West (\u897f\u65b9\u767d\u864e, \"X\u012b F\u0101ng B\u00e1i H\u01d4\").\nThe Tukano and Kobeua people of the Amazon used the stars of Cetus to create a jaguar, representing the god of hurricanes and other violent storms. Lambda, Mu, Xi, Nu, Gamma, and Alpha Ceti represented its head; Omicron, Zeta, and Chi Ceti represented its body; Eta Eri, Tau Cet, and Upsilon Cet marked its legs and feet; and Theta, Eta, and Beta Ceti delineated its tail.\nIn Hawaii, the constellation was called \"Na Kuhi\", and Mira (Omicron Ceti) may have been called \"Kane\".\nNamesakes.\nUSS Cetus (AK-77) was a United States Navy Crater class cargo ship named after the constellation.\n\"Cetus\" is the title of a ragtime piano composition by Tom Brier on the album \"Constellations\"."}
{"id": "6363", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6363", "title": "Carina (constellation)", "text": "Carina ( (U.S.) (Brit.)) is a constellation in the southern sky. Its name is Latin for the hull or keel of a ship, and it was the southern foundation of the larger constellation of Argo Navis (the ship \"Argo\") until it was divided into three pieces, the other two being Puppis (the poop deck), and Vela (the sails of the ship).\nHistory and mythology.\nCarina was once a part of Argo Navis, the great ship of Jason and the Argonauts who searched for the Golden Fleece. The constellation of Argo was introduced in ancient Greece. However, due to the massive size of Argo Navis and the sheer number of stars that required separate designation, Nicolas Louis de Lacaille divided Argo into three sections in 1763, including Carina (the hull or keel). In the 19th century, these three became established as separate constellations, and were formally included in the list of 88 modern IAU constellations in 1930. Lacaille kept a single set of Greek letters for the whole of Argo, and separate sets of Latin letter designations for each of the three sections. Therefore, Carina has the \u03b1, \u03b2 and \u03b5, Vela has \u03b3 and \u03b4, Puppis has \u03b6, and so on.\nNotable features.\nStars.\nCarina contains Canopus, a white-hued supergiant that is the second brightest star in the night sky at magnitude \u22120.72. Alpha Carinae, as Canopus is formally designated, is 313 light-years from Earth. Its traditional name comes from the mythological Canopus, who was a navigator for Menelaus, king of Sparta.\nThere are several other stars above magnitude 3 in Carina. Beta Carinae, traditionally called Miaplacidus, is a blue-white hued star of magnitude 1.7, 111 light-years from Earth. Epsilon Carinae is an orange-hued giant star similarly bright to Miaplacidus at magnitude 1.9; it is 630 light-years from Earth. Another fairly bright star is the blue-white hued Theta Carinae; it is a magnitude 2.7 star 440 light-years from Earth. Theta Carinae is also the most prominent member of the cluster IC 2602. Iota Carinae is a white-hued supergiant star of magnitude 2.2, 690 light-years from Earth.\nEta Carinae is the most prominent variable star in Carina; with a mass of approximately 100 solar masses and 4 million times as bright as the Sun. It was first discovered to be unusual in 1677, when its magnitude suddenly rose to 4, attracting the attention of Edmond Halley. Eta Carinae is inside NGC 3372, commonly called the Carina Nebula. It had a long outburst in 1827, when it brightened to magnitude 1, only fading to magnitude 1.5 in 1828. Its most prominent outburst made Eta Carinae the equal of Sirius; it brightened to magnitude \u22121.5 in 1843. In the decades following 1843 it appeared relatively placid, having a magnitude between 6.5 and 7.9. However, in 1998, it brightened again, though only to magnitude 5.0, a far less drastic outburst. Eta Carinae is a binary star, with a companion that has a period of 5.5 years; the two stars are surrounded by the Homunculus Nebula, which is composed of gas that was ejected in 1843.\nThere are several less prominent variable stars in Carina. l Carinae is a Cepheid variable noted for its brightness; it is the brightest Cepheid that is variable to the unaided eye. It is a yellow-hued supergiant star with a minimum magnitude of 4.2 and a maximum magnitude of 3.3; it has a period of 35.5 days.\nTwo bright Mira variable stars are in Carina: R Carinae and S Carinae; both stars are red giants. R Carinae has a minimum magnitude of 10.0 and a maximum magnitude of 4.0. Its period is 309 days and it is 416 light-years from Earth. S Carinae is similar, with a minimum magnitude of 10.0 and a maximum magnitude of 5.0. However, S Carinae has a shorter period\u00a0\u2013 150 days, though it is much more distant at 1300 light-years from Earth.\nCarina is home to several double stars and binary stars. Upsilon Carinae is a binary star with two blue-white hued giant components, 1600 light-years from Earth. The primary is of magnitude 3.0 and the secondary is of magnitude 6.0; the two components are distinguishable in a small amateur telescope.\nTwo asterisms are prominent in Carina. One is known as the 'Diamond Cross', which is larger than the Southern Cross (but fainter), and, from the perspective of the southern hemisphere viewer, upside down, the long axes of the two crosses being close to parallel. Another asterism in the constellation is the False Cross, often mistaken for the Southern Cross, which is an asterism in Crux. The False Cross consists of two stars in Carina, Iota Carinae and Epsilon Carinae, and two stars in Vela, Kappa Velorum and Delta Velorum.\nDeep-sky objects.\nCarina is known for its namesake nebula, NGC 3372, discovered by French astronomer Nicolas Louis de Lacaille in 1751, which contains several nebulae. The Carina Nebula overall is an extended emission nebula approximately 8,000 light-years away and 300 light-years wide that includes vast star-forming regions. It has an overall magnitude of 8.0 and an apparent diameter of over 2 degrees. Its central region is called the Keyhole, or the Keyhole Nebula. This was described in 1847 by John Herschel, and likened to a keyhole by Emma Converse in 1873. The Keyhole is about seven light-years wide and is composed mostly of ionized hydrogen, with two major star-forming regions. The Homunculus Nebula is a planetary nebula visible to the naked eye that is being ejected by the erratic luminous blue variable star Eta Carinae, the most massive visible star known. Eta Carinae is so massive that it has reached the theoretical upper limit for the mass of a star and is therefore unstable. It is known for its outbursts; in 1840 it briefly became one of the brightest stars in the sky due to a particularly massive outburst, which largely created the Homunculus Nebula. Because of this instability and history of outbursts, Eta Carinae is considered a prime supernova candidate for the next several hundred thousand years because it has reached the end of its estimated million-year life span.\nNGC 2516 is an open cluster that is both quite large (approximately half a degree square) and bright, visible to the unaided eye. It is located 1100 light-years from Earth and has approximately 80 stars, the brightest of which is a red giant star of magnitude 5.2. NGC 3114 is another open cluster approximately of the same size, though it is more distant at 3000 light-years from Earth. It is more loose and dim than NGC 2516, as its brightest stars are only 6th magnitude. The most prominent open cluster in Carina is IC 2602, also called the \"Southern Pleiades\". It contains Theta Carinae, along with several other stars visible to the unaided eye. In total, the cluster possesses approximately 60 stars. The Southern Pleiades is particularly large for an open cluster, with a diameter of approximately one degree. Like IC 2602, NGC 3532 is visible to the unaided eye and is of comparable size. It possesses approximately 150 stars that are arranged in an unusual shape, approximating an ellipse with a dark central area. Several prominent orange giants are among the cluster's bright stars, of the 7th magnitude. Superimposed on the cluster is Chi Carinae, a yellow-white hued star of magnitude 3.9, far more distant than NGC 3532.\nCarina also contains the naked-eye globular cluster NGC 2808. Epsilon Carinae and Upsilon Carinae are double stars visible in small telescopes.\nOne noted galaxy cluster is 1E 0657-56, the Bullet Cluster. At a distance of 4 billion light years (redshift 0.296), this galaxy cluster is named for the shock wave seen in the intracluster medium, which resembles the shock wave of a supersonic bullet. The bow shock visible is thought to be due to the smaller galaxy cluster moving through the intracluster medium at a relative speed of 3000\u20134000 kilometers per second to the larger cluster. Because this gravitational interaction has been ongoing for hundreds of millions of years, the smaller cluster is being destroyed and will eventually merge with the larger cluster.\nMeteors.\nCarina contains the radiant of the Eta Carinids meteor shower, which peaks around January 21 each year.\nEquivalents.\nFrom China (especially northern China), the stars of Carina can barely be seen. The star Canopus (the south polar star in Chinese astronomy) was located by Chinese astronomers in the Vermilion Bird of the South (\u5357\u65b9\u6731\u96c0, \"N\u00e1n F\u0101ng Zh\u016b Qu\u00e8\"). The rest of the stars were first classified by Xu Guanggi during the Ming Dynasty, based on the knowledge acquired from western star charts, and placed among The Southern Asterisms (\u8fd1\u5357\u6975\u661f\u5340, \"J\u00ecnn\u00e1nj\u00edx\u012bng\u014du\").\nPolynesian peoples had no name for the constellation in particular, though they had many names for Canopus. \nThe M\u0101ori name \"Ariki\" (\"High-born\"), . and the Hawaiian \"Ke Alii-o-kona-i-ka-lewa\", \"The Chief of the southern expanse\". both attest to the star's prominence in the southern sky, while the M\u0101ori \"Atutahi\", \"First-light\" or \"Single-light\", and the Tuamotu \"Te Tau-rari\" and \"Marere-te-tavahi\", \"He-who-stands-alone\". refer to the star's solitary nature.\nIt was also called \"Kapae-poto\", (\"Short horizon\"), because it rarely sets from the vantage point of New Zealand; and \"Kauanga\" (\"Solitary\"), when it was the last star visible before sunrise.\nFuture.\nCarina is in the southern sky quite near the south celestial pole, making it never set (circumpolar) for most of the southern hemisphere. Due to precession of Earth's axis, by the year 4700 the south celestial pole will be in Carina. Three bright stars in Carina will come within 1 degree of the southern celestial pole and take turns as the southern pole star: Omega Carinae (mag 3.29) in 5600, Upsilon Carinae (mag 2.97) in 6700, and Iota Carinae (mag 2.21) in 7900. About 13860, the bright Canopus (-0.7) will have a greater declination than -82\u00b0.\nNamesakes.\n was a United States Navy Crater class cargo ship named after the constellation."}
{"id": "6364", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6364", "title": "Camelopardalis", "text": "Camelopardalis is a large but faint constellation of the northern sky representing a giraffe. The constellation was introduced in 1612 or 1613 by Petrus Plancius. Some older astronomy books give Camelopardalus or Camelopardus as alternative forms of the name, but the version recognized by the International Astronomical Union matches the genitive form, seen suffixed to most of its key stars.\nEtymology.\nFirst attested in English in 1785, the word \"camelopardalis\" comes from Latin, and it is the romanization of the Greek \"\u03ba\u03b1\u03bc\u03b7\u03bb\u03bf\u03c0\u03ac\u03c1\u03b4\u03b1\u03bb\u03b9\u03c2\" meaning \"giraffe\", from \"\u03ba\u03ac\u03bc\u03b7\u03bb\u03bf\u03c2\" (\"kam\u0113los\"), \"camel\" + \"\u03c0\u03ac\u03c1\u03b4\u03b1\u03bb\u03b9\u03c2\" (\"pardalis\"), \"spotted\", because it has a long neck like a camel and spots.\nFeatures.\nStars.\nAlthough Camelopardalis is the 18th largest constellation, it is not a particularly bright constellation, as the brightest stars are only of fourth magnitude. In fact, it only contains four stars brighter than magnitude 5.0.\nOther variable stars are U Camelopardalis, VZ Camelopardalis, and Mira variables T Camelopardalis, X Camelopardalis, and R Camelopardalis. RU Camelopardalis is one of the brighter Type II Cepheids visible in the night sky.\nIn 2011 a supernova was discovered in the constellation.\nDeep-sky objects.\nCamelopardalis is in the part of the celestial sphere facing away from the galactic plane. Accordingly, many distant galaxies are visible within its borders. \nMeteor showers.\nThe annual May meteor shower Camelopardalids from comet 209P/LINEAR have a radiant in Camelopardalis.\nSpace exploration.\nThe space probe \"Voyager 1\" is moving in the direction of this constellation, though it will not be nearing any of the stars in this constellation for many thousands of years, by which time its power source will be long dead.\nHistory.\nCamelopardalis is not one of Ptolemy's 48 constellations in the \"Almagest\". It was created by Petrus Plancius in 1613. It first appeared in a globe designed by him and produced by Pieter van den Keere. One year later, Jakob Bartsch featured it in his atlas. Johannes Hevelius depicted this constellation in his works which were so influential that it was referred to as Camelopardali Hevelii or abbreviated as Camelopard. Hevel.\nPart of the constellation was hived off to form the constellation Sciurus Volans, the Flying Squirrel, by William Croswell in 1810. However this was not taken up by later cartographers.\nEquivalents.\nIn Chinese astronomy, the stars of Camelopardalis are located within a group of circumpolar stars called the Purple Forbidden Enclosure (\u7d2b\u5fae\u57a3 \"Z\u01d0 W\u0113i Yu\u00e1n\")."}
{"id": "6365", "revid": "60435", "url": "https://en.wikipedia.org/wiki?curid=6365", "title": "Convention of Kanagawa", "text": "Convention of Kanagawa or Kanagawa Treaty (, \"Kanagawa J\u014dyaku\"), Japan\u2013US Treaty of Peace and Amity (, \"Nichibei Washin J\u014dyaku\") was a treaty signed between the United States and the Tokugawa shogunate on March 31, 1854. Signed under threat of force, it effectively meant the end of Japan's 220-year-old policy of national seclusion (\"sakoku\") by opening the ports of Shimoda and Hakodate to American vessels. It also ensured the safety of American castaways and established the position of an American consul in Japan. The treaty precipitated the signing of similar treaties establishing diplomatic relations with other Western powers.\nIsolation of Japan.\nSince the beginning of the 17th century, the Tokugawa shogunate pursued a policy of isolating the country from outside influences. Foreign trade was maintained only with the Dutch and the Chinese and was conducted exclusively at Nagasaki under a strict government monopoly. This \"Pax Tokugawa\" period is largely associated with domestic peace, social stability, commercial development, and expanded literacy. This policy had two main objectives:\nBy the early 19th century, this policy of isolation was increasingly under challenge. In 1844, King William II of the Netherlands sent a letter urging Japan to end the isolation policy on its own before change would be forced from the outside. In 1846, an official American expedition led by Commodore James Biddle arrived in Japan asking for ports to be opened for trade but was sent away.\nPerry expedition.\nIn 1853, United States Navy Commodore Matthew C. Perry was sent with a fleet of warships by U.S. President Millard Fillmore to force the opening of Japanese ports to American trade, through the use of gunboat diplomacy if necessary. The growing commerce between America and China, the presence of American whalers in waters offshore Japan, and the increasing monopolization of potential coaling stations by the British and French in Asia were all contributing factors. The Americans were also driven by concepts of manifest destiny and the desire to impose the benefits of western civilization and the Christian religion on what they perceived as backward Asian nations. From the Japanese perspective, increasing contacts with foreign warships and the increasing disparity between western military technology and the Japanese feudal armies created growing concern. The Japanese had been keeping abreast of world events via information gathered from Dutch traders in Dejima and had been forewarned by the Dutch of Perry's voyage. There was a considerable internal debate in Japan on how best to meet this potential threat to Japan's economic and political sovereignty in light of events occurring in China with the Opium Wars.\nPerry arrived with four warships at Uraga, at the mouth of Edo Bay on July 8, 1853. He blatantly refused Japanese demands that he proceed to Nagasaki, which was the designated port for foreign contact. After threatening to continue directly on to Edo, the nation's capital, and to burn it to the ground if necessary, he was allowed to land at nearby Kurihama on July 14 and to deliver his letter. Such refusal was intentional, as Perry wrote in his journal: \u201cTo show these princes how little I regarded their order for me to depart, on getting on board I immediately ordered the whole squadron underway, not to leave the bay\u2026 but to go higher up\u2026 would produce a decided influence upon the pride and conceit of the gov\u2019t, and cause a more favorable consideration of the President\u2019s letter.\" Perry\u2019s power front did not stop with refusing to land in Uraga, but he continued to push the boundaries of the Japanese. He ordered the squadron to survey Edo bay, which led to a stand-off between Japanese officers with swords and Americans with guns. By firing the guns into the water, Perry demonstrated their military might, which greatly affected Japanese perceptions of Perry and the United States. Namely, a perception of fear and disrespect.\nDespite years of debate on the isolation policy, Perry's letter created great controversy within the highest levels of the Tokugawa shogunate. The \"sh\u014dgun\" himself, Tokugawa Ieyoshi, died days after Perry's departure and was succeeded by his sickly young son, Tokugawa Iesada, leaving effective administration in the hands of the Council of Elders (\"r\u014dj\u016b\") led by Abe Masahiro. Abe felt that it was impossible for Japan to resist the American demands by military force and yet was reluctant to take any action on his own authority for such an unprecedented situation. Attempting to legitimize any decision taken, Abe polled all of the \"daimy\u014d\" for their opinions. This was the first time that the Tokugawa shogunate had allowed its decision-making to be a matter of public debate and had the unforeseen consequence of portraying the shogunate as weak and indecisive. The results of the poll also failed to provide Abe with an answer; of the 61 known responses, 19 were in favour of accepting the American demands and 19 were equally opposed. Of the remainder, 14 gave vague responses expressing concern of possible war, 7 suggested making temporary concessions and 2 advised that they would simply go along with whatever was decided.\nPerry returned again on February 11, 1854, with an even larger force of eight warships and made it clear that he would not be leaving until a treaty was signed. Perry continued his manipulation of the setting, such as keeping himself aloof from lower-ranking officials, implying the use of force, surveying the harbor, and refusing to meet in the designated negotiation sites. Negotiations began on March 8 and proceeded for around one month. Each party shared a performance when Perry arrived. The Americans had a technology demonstration, and the Japanese had a sumo wrestling show. While the new technology awed the Japanese people, Perry was unimpressed by the sumo wrestlers and perceived such performance as foolish and degrading: \u201cThis disgusting exhibition did not terminate until the whole twenty-five had, successively, in pairs, displayed their immense powers and savage qualities.\" The Japanese side gave in to almost all of Perry's demands, with the exception of a commercial agreement modelled after previous American treaties with China, which Perry agreed to defer to a later time. The main controversy centered on the selection of the ports to open, with Perry adamantly rejecting Nagasaki. The treaty, written in English, Dutch, Chinese and Japanese, was signed on March 31, 1854, at what is now Kaik\u014d Hiroba (Port Opening Square) Yokohama, a site adjacent to the current Yokohama Archives of History.\nTreaty of Peace and Amity (1854).\nThe \"Japan-US Treaty of Peace and Amity\" has twelve articles: \nAt the time, \"sh\u014dgun\" Tokugawa Iesada was the de facto ruler of Japan; for the Emperor of Japan to interact in any way with foreigners was out of the question. Perry concluded the treaty with representatives of the shogun, led by plenipotentiary and the text was endorsed subsequently, albeit reluctantly, by Emperor K\u014dmei.\nThe treaty was ratified on February 21, 1855.\nConsequences of the treaty.\nIn the short term, the U.S. was content with the agreement since Perry had achieved his primary objective of breaking Japan's \"sakoku\" policy and setting the grounds for protection of American citizens and an eventual commercial agreement. On the other hand, the Japanese were forced into this trade, and many saw it as a sign of weakness. The Tokugawa shogunate could point out that the treaty was not actually signed by the shogun, or indeed any of his \"r\u014dj\u016b\", and that it had at least temporarily averted the possibility of immediate military confrontation.\nExternally, the treaty led to the United States-Japan Treaty of Amity and Commerce, the \"Harris Treaty\" of 1858, which allowed the establishment of foreign concessions, extraterritoriality for foreigners, and minimal import taxes for foreign goods. The Japanese chafed under the \"unequal treaty system\" which characterized Asian and western relations during this period. The Kanagawa treaty was also followed by similar agreements with the United Kingdom (Anglo-Japanese Friendship Treaty, October 1854), Russia (Treaty of Shimoda, February 7, 1855), and France (Treaty of Amity and Commerce between France and Japan, October 9, 1858).\nInternally, the treaty had far-reaching consequences. Decisions to suspend previous restrictions on military activities led to re-armament by many domains and further weakened the position of the shogun. Debate over foreign policy and popular outrage over perceived appeasement to the foreign powers was a catalyst for the \"sonn\u014d j\u014di\" movement and a shift in political power from Edo back to the Imperial Court in Kyoto. The opposition of Emperor K\u014dmei to the treaties further lent support to the \"t\u014dbaku\" (overthrow the shogunate) movement, and eventually to the Meiji Restoration, which affected all realms of Japanese life. Following this period came an increase in foreign trade, the rise of Japanese military might, and the later rise of Japanese economic and technological advancement. Westernization at the time was a defense mechanism, but Japan has since found a balance between Western popular culture and Japanese tradition. "}
{"id": "6366", "revid": "25112844", "url": "https://en.wikipedia.org/wiki?curid=6366", "title": "Canis Major", "text": "Canis Major is a constellation in the southern celestial hemisphere. In the second century, it was included in Ptolemy's 48 constellations, and is counted among the 88 modern constellations. Its name is Latin for \"greater dog\" in contrast to Canis Minor, the \"lesser dog\"; both figures are commonly represented as following the constellation of Orion the hunter through the sky. The Milky Way passes through Canis Major and several open clusters lie within its borders, most notably M41.\nCanis Major contains Sirius, the brightest star in the night sky, known as the \"dog star\". It is bright because of its proximity to the Solar System. In contrast, the other bright stars of the constellation are stars of great distance and high luminosity. At magnitude 1.5, Epsilon Canis Majoris (Adhara) is the second-brightest star of the constellation and the brightest source of extreme ultraviolet radiation in the night sky. Next in brightness are the yellow-white supergiant Delta (Wezen) at 1.8, the blue-white giant Beta (Mirzam) at 2.0, blue-white supergiants Eta (Aludra) at 2.4 and Omicron2 at 3.0, and white spectroscopic binary Zeta (Furud), also at 3.0. The red hypergiant VY Canis Majoris is one of the largest stars known, while the neutron star RX J0720.4-3125 has a radius of a mere 5\u00a0km.\nHistory and mythology.\nIn western astronomy.\nIn ancient Mesopotamia, Sirius, named KAK.SI.DI by the Babylonians, was seen as an arrow aiming towards Orion, while the southern stars of Canis Major and a part of Puppis were viewed as a bow, named BAN in the \"Three Stars Each\" tablets, dating to around 1100 BC. In the later compendium of Babylonian astronomy and astrology titled \"MUL.APIN\", the arrow, Sirius, was also linked with the warrior Ninurta, and the bow with Ishtar, daughter of Enlil. Ninurta was linked to the later deity Marduk, who was said to have slain the ocean goddess Tiamat with a great bow, and worshipped as the principal deity in Babylon. The Ancient Greeks replaced the bow and arrow depiction with that of a dog.\nIn Greek Mythology, Canis Major represented the dog Laelaps, a gift from Zeus to Europa; or sometimes the hound of Procris, Diana's nymph; or the one given by Aurora to Cephalus, so famed for its speed that Zeus elevated it to the sky. It was also considered to represent one of Orion's hunting dogs, pursuing Lepus the Hare or helping Orion fight Taurus the Bull; and is referred to in this way by Aratos, Homer and Hesiod. The ancient Greeks refer only to one dog, but by Roman times, Canis Minor appears as Orion's second dog. Alternative names include Canis Sequens and Canis Alter. Canis Syrius was the name used in the 1521 \"Alfonsine tables\".\nThe Roman myth refers to Canis Major as \"Custos Europae\", the dog guarding Europa but failing to prevent her abduction by Jupiter in the form of a bull, and as \"Janitor Lethaeus\", \"the watchdog\". In medieval Arab astronomy, the constellation became \"al-Kalb al-Akbar\", \"the Greater Dog\", transcribed as \"Alcheleb Alachbar\" by 17th century writer Edmund Chilmead. Islamic scholar Ab\u016b Ray\u1e25\u0101n al-B\u012br\u016bn\u012b referred to Orion as \"Kalb al-Jabb\u0101r\", \"the Dog of the Giant\". Among the Merazig of Tunisia, shepherds note six constellations that mark the passage of the dry, hot season. One of them, called \"Merzem\", includes the stars of Canis Major and Canis Minor and is the herald of two weeks of hot weather.\nIn non-western astronomy.\nIn Chinese astronomy, the modern constellation of Canis Major is located in the Vermilion Bird (), where the stars were classified in several separate asterisms of stars. The Military Market () was a circular pattern of stars containing Nu3, Beta, Xi1 and Xi2, and some stars from Lepus. The Wild Cockerel () was at the centre of the Military Market, although it is uncertain which stars depicted what. Schlegel reported that the stars Omicron and Pi Canis Majoris might have been them, while Beta or Nu2 have also been proposed. Sirius was ' (), the Celestial Wolf, denoting invasion and plunder. Southeast of the Wolf was the asterism ' (), the celestial Bow and Arrow, which was interpreted as containing Delta, Epsilon, Eta and Kappa Canis Majoris and Delta Velorum. Alternatively, the arrow was depicted by Omicron2 and Eta and aiming at Sirius (the Wolf), while the bow comprised Kappa, Epsilon, Sigma, Delta and 164 Canis Majoris, and Pi and Omicron Puppis.\nBoth the M\u0101ori people and the people of the Tuamotus recognized the figure of Canis Major as a distinct entity, though it was sometimes absorbed into other constellations. ', also called ' and ', (\"The Assembly of \" or \"The Assembly of Sirius\") was a M\u0101ori constellation that included both Canis Minor and Canis Major, along with some surrounding stars. Related was ', also called ', the Mirror of , formed from an undefined group of stars in Canis Major. They called Sirius ' and ', corresponding to two of the names for the constellation, though ' was a name applied to other stars in various M\u0101ori groups and other Polynesian cosmologies. The Tuamotu people called Canis Major \"\", \"the abiding assemblage of \".\nThe Tharumba people of the Shoalhaven River saw three stars of Canis Major as ' (Bat) and his two wives ' (Mrs Brown Snake) and ' (Mrs Black Snake); bored of following their husband around, the women try to bury him while he is hunting a wombat down its hole. He spears them and all three are placed in the sky as the constellation '. To the Boorong people of Victoria, Sigma Canis Majoris was ' (which has become the official name of this star), and its flanking stars Delta and Epsilon were his two wives. The moon (', \"native cat\") sought to lure the further wife (Epsilon) away, but assaulted him and he has been wandering the sky ever since.\nCharacteristics.\nCanis Major is a constellation in the Southern Hemisphere's summer (or northern hemisphere's winter) sky, bordered by Monoceros (which lies between it and Canis Minor) to the north, Puppis to the east and southeast, Columba to the southwest, and Lepus to the west. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"CMa\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a quadrilateral; in the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between \u221211.03\u00b0 and \u221233.25\u00b0. Covering 380 square degrees or 0.921% of the sky, it ranks 43rd of the 88 currently-recognized constellations in size.\nFeatures.\nStars.\nCanis Major is a prominent constellation because of its many bright stars. These include Sirius (Alpha Canis Majoris), the brightest star in the night sky, as well as three other stars above magnitude 2.0. Furthermore, two other stars are thought to have previously outshone all others in the night sky\u2014Adhara (Epsilon Canis Majoris) shone at \u22123.99 around 4.7\u00a0million years ago, and Mirzam (Beta Canis Majoris) peaked at \u22123.65 around 4.42\u00a0million years ago. Another, NR Canis Majoris, will be brightest at magnitude \u22120.88 in about 2.87\u00a0million years' time.\nThe German cartographer Johann Bayer used the Greek letters Alpha through Omicron to label the most prominent stars in the constellation, including three adjacent stars as Nu and two further pairs as Xi and Omicron, while subsequent observers designated further stars in the southern parts of the constellation that were hard to discern from Central Europe. Bayer's countryman Johann Elert Bode later added Sigma, Tau and Omega; the French astronomer Nicolas Louis de Lacaille added lettered stars a to k (though none are in use today). John Flamsteed numbered 31 stars, with 3 Canis Majoris being placed by Lacaille into Columba as Delta Columbae (Flamsteed had not recognised Columba as a distinct constellation). He also labelled two stars\u2014his 10 and 13 Canis Majoris\u2014as Kappa1 and Kappa2 respectively, but subsequent cartographers such as Francis Baily and John Bevis dropped the fainter former star, leaving Kappa2 as the sole Kappa. Flamsteed's listing of Nu1, Nu2, Nu3, Xi1, Xi2, Omicron1 and Omicron2 have all remained in use.\nSirius is the brightest star in the night sky at apparent magnitude \u22121.46 and one of the closest stars to Earth at a distance of 8.6 light-years. Its name comes from the Greek word for \"scorching\" or \"searing\". Sirius is also a binary star; its companion Sirius B is a white dwarf with a magnitude of 8.4\u201310,000 times fainter than Sirius A to observers on Earth. The two orbit each other every 50 years. Their closest approach last occurred in 1993 and they will be at their greatest separation between 2020 and 2025. Sirius was the basis for the ancient Egyptian calendar. The star marked the Great Dog's mouth on Bayer's star atlas.\nFlanking Sirius are Beta and Gamma Canis Majoris. Also called Mirzam or Murzim, Beta is a blue-white Beta Cephei variable star of magnitude 2.0, which varies by a few hundredths of a magnitude over a period of six hours. Mirzam is 500 light-years from Earth, and its traditional name means \"the announcer\", referring to its position as the \"announcer\" of Sirius, as it rises a few minutes before Sirius does. Gamma, also known as Muliphein, is a fainter star of magnitude 4.12, in reality a blue-white bright giant of spectral type B8IIe located 441 light-years from earth. Iota Canis Majoris, lying between Sirius and Gamma, is another star that has been classified as a Beta Cephei variable, varying from magnitude 4.36 to 4.40 over a period of 1.92 hours. It is a remote blue-white supergiant star of spectral type B3Ib, around 46,000 times as luminous as the sun and, at 2500 light-years distant, 300 times further away than Sirius.\nEpsilon, Omicron2, Delta, and Eta Canis Majoris were called \"Al Adzari\" \"the virgins\" in medieval Arabic tradition. Marking the dog's right thigh on Bayer's atlas is Epsilon Canis Majoris, also known as Adhara. At magnitude 1.5, it is the second-brightest star in Canis Major and the 23rd-brightest star in the sky. It is a blue-white supergiant of spectral type B2Iab, around 404 light-years from Earth. This star is one of the brightest known extreme ultraviolet sources in the sky. It is a binary star; the secondary is of magnitude 7.4. Its traditional name means \"the virgins\", having been transferred from the group of stars to Epsilon alone. Nearby is Delta Canis Majoris, also called Wezen. It is a yellow-white supergiant of spectral type F8Iab and magnitude 1.84, around 1605 light-years from Earth. With a traditional name meaning \"the weight\", Wezen is 17 times as massive and 50,000 times as luminous as the Sun. If located in the centre of the Solar System, it would extend out to Earth as its diameter is 200 times that of the Sun. Only around 10\u00a0million years old, Wezen has stopped fusing hydrogen in its core. Its outer envelope is beginning to expand and cool, and in the next 100,000 years it will become a red supergiant as its core fuses heavier and heavier elements. Once it has a core of iron, it will collapse and explode as a supernova. Nestled between Adhara and Wezen lies Sigma Canis Majoris, known as Unurgunite to the Boorong and Wotjobaluk people, a red supergiant of spectral type K7Ib that varies irregularly between magnitudes 3.43 and 3.51.\nAlso called Aludra, Eta Canis Majoris is a blue-white supergiant of spectral type B5Ia with a luminosity 176,000 times and diameter around 80 times that of the Sun. Classified as an Alpha Cygni type variable star, Aludra varies in brightness from magnitude 2.38 to 2.48 over a period of 4.7 days. It is located 1120 light-years away. To the west of Adhara lies 3.0-magnitude Zeta Canis Majoris or Furud, around 362 light-years distant from Earth. It is a spectroscopic binary, whose components orbit each other every 1.85 years, the combined spectrum indicating a main star of spectral type B2.5V.\nBetween these stars and Sirius lie Omicron1, Omicron2, and Pi Canis Majoris. Omicron2 is a massive supergiant star about 21 times as massive as the Sun. Only 7\u00a0million years old, it has exhausted the supply of hydrogen at its core and is now processing helium. It is an Alpha Cygni variable that undergoes periodic non-radial pulsations, which cause its brightness to cycle from magnitude 2.93 to 3.08 over a 24.44-day interval. Omicron1 is an orange K-type supergiant of spectral type K2.5Iab that is an irregular variable star, varying between apparent magnitudes 3.78 and 3.99. Around 18 times as massive as the Sun, it shines with 65,000 times its luminosity.\nNorth of Sirius lie Theta and Mu Canis Majoris, Theta being the most northerly star with a Bayer designation in the constellation. Around 8\u00a0billion years old, it is an orange giant of spectral type K4III that is around as massive as the Sun but has expanded to 30 times the Sun's diameter. Mu is a multiple star system located around 1244 light-years distant, its components discernible in a small telescope as a 5.3-magnitude yellow-hued and 7.1-magnitude bluish star. The brighter star is a giant of spectral type K2III, while the companion is a main sequence star of spectral type B9.5V. Nu Canis Majoris is a yellow-hued giant star of magnitude 5.7, 278 light-years away; it is at the threshold of naked-eye visibility. It has a companion of magnitude 8.1.\nAt the southern limits of the constellation lie Kappa and Lambda Canis Majoris. Although of similar spectra and nearby each other as viewed from Earth, they are unrelated. Kappa is a Gamma Cassiopeiae variable of spectral type B2Vne, which brightened by 50% between 1963 and 1978, from magnitude 3.96 or so to 3.52. It is around 659 light-years distant. Lambda is a blue-white B-type main sequence dwarf with an apparent magnitude of 4.48 located around 423 light-years from Earth. It is 3.7 times as wide as and 5.5 times as massive as the Sun, and shines with 940 times its luminosity.\nCanis Major is also home to many variable stars. EZ Canis Majoris is a Wolf\u2013Rayet star of spectral type WN4 that varies between magnitudes 6.71 and 6.95 over a period of 3.766 days; the cause of its variability is unknown but thought to be related to its stellar wind and rotation. VY Canis Majoris is a remote red hypergiant located approximately 3,800 light-years away from Earth. It is one of largest stars known (sometimes described as the largest known) and is also one of most luminous with a radius varying from 1,420 to 2,200 times the Sun's radius, and a luminosity around 300,000 times greater than the Sun. Its current mass is about 17 \u00b1 8 solar masses, having shed material from an initial mass of 25\u201332 solar masses. VY CMa is also surrounded by a red reflection nebula that has been made by the material expelled by the strong stellar winds of its central star. W Canis Majoris is a type of red giant known as a carbon star\u2014a semiregular variable, it ranges between magnitudes 6.27 and 7.09 over a period of 160 days. A cool star, it has a surface temperature of around 2,900 K and a radius 234 times that of the Sun, its distance estimated at 1,444\u20131,450 light-years from Earth. At the other extreme in size is RX J0720.4-3125, a neutron star with a radius of around 5\u00a0km. Exceedingly faint, it has an apparent magnitude of 26.6. Its spectrum and temperature appear to be mysteriously changing over several years. The nature of the changes are unclear, but it is possible they were caused by an event such as the star's absorption of an accretion disc.\nTau Canis Majoris is a Beta Lyrae-type eclipsing multiple star system that varies from magnitude 4.32 to 4.37 over 1.28 days. Its four main component stars are hot O-type stars, with a combined mass 80 times that of the Sun and shining with 500,000 times its luminosity, but little is known of their individual properties. A fifth component, a magnitude 10 star, lies at a distance of . The system is only 5\u00a0million years old. UW Canis Majoris is another Beta Lyrae-type star 3000 light-years from Earth; it is an eclipsing binary that ranges in magnitude from a minimum of 5.3 to a maximum of 4.8. It has a period of 4.4 days; its components are two massive hot blue stars, one a blue supergiant of spectral type O7.5\u20138 Iab, while its companion is a slightly cooler, less evolved and less luminous supergiant of spectral type O9.7Ib. The stars are 200,000 and 63,000 times as luminous as the Sun. However the fainter star is the more massive at 19 solar masses to the primary's 16. R Canis Majoris is another eclipsing binary that varies from magnitude 5.7 to 6.34 over 1.13 days, with a third star orbiting these two every 93 years. The shortness of the orbital period and the low ratio between the two main components make this an unusual Algol-type system.\nSeven star systems have been found to have planets. Nu2 Canis Majoris is an ageing orange giant of spectral type K1III of apparent magnitude 3.91 located around 64 light-years distant. Around 1.5 times as massive and 11 times as luminous as the Sun, it is orbited over a period of 763 days by a planet 2.6 times as massive as Jupiter. HD 47536 is likewise an ageing orange giant found to have a planetary system\u2014echoing the fate of the Solar System in a few billion years as the Sun ages and becomes a giant. Conversely, HD 45364 is a star 107 light-years distant that is a little smaller and cooler than the Sun, of spectral type G8V, which has two planets discovered in 2008. With orbital periods of 228 and 342 days, the planets have a 3:2 orbital resonance, which helps stabilise the system. HD 47186 is another sunlike star with two planets; the inner\u2014HD 47186 b\u2014takes four days to complete an orbit and has been classified as a Hot Neptune, while the outer\u2014HD 47186 c\u2014has an eccentric 3.7-year period orbit and has a similar mass to Saturn. HD 43197 is a sunlike star around 183 light-years distant that has a Jupiter-size planet with an eccentric orbit.\nZ Canis Majoris is a star system a mere 300,000 years old composed of two pre-main-sequence stars\u2014a FU Orionis star and a Herbig Ae/Be star, which has brightened episodically by two magnitudes to magnitude 8 in 1987, 2000, 2004 and 2008. The more massive Herbig Ae/Be star is enveloped in an irregular roughly spherical cocoon of dust that has an inner diameter of and outer diameter of . The cocoon has a hole in it through which light shines that covers an angle of 5 to 10 degrees of its circumference. Both stars are surrounded by a large envelope of in-falling material left over from the original cloud that formed the system. Both stars are emitting jets of material, that of the Herbig Ae/Be star being much larger\u201411.7 light-years long. Meanwhile, FS Canis Majoris is another star with infra-red emissions indicating a compact shell of dust, but it appears to be a main-sequence star that has absorbed material from a companion. These stars are thought to be significant contributors to interstellar dust.\nDeep-sky objects.\nThe band of the Milky Way goes through Canis Major, with only patchy obscurement by interstellar dust clouds. It is bright in the northeastern corner of the constellation, as well as in a triangular area between Adhara, Wezen and Aludra, with many stars visible in binoculars. Canis Major boasts several open clusters. The only Messier object is M41 (NGC 2287), an open cluster with a combined visual magnitude of 4.5, around 2300 light-years from Earth. Located 4 degrees south of Sirius, it contains contrasting blue, yellow and orange stars and covers an area the apparent size of the full moon\u2014in reality around 25 light-years in diameter. Its most luminous stars have already evolved into giants. The brightest is a 6.3-magnitude star of spectral type K3. Located in the field is 12 Canis Majoris, though this star is only 670 light-years distant. NGC 2360, known as Caroline's Cluster after its discoverer Caroline Herschel, is an open cluster located 3.5 degrees west of Muliphein and has a combined apparent magnitude of 7.2. Around 15 light-years in diameter, it is located 3700 light-years away from Earth, and has been dated to around 2.2\u00a0billion years old. NGC 2362 is a small, compact open cluster, 5200 light-years from Earth. It contains about 60 stars, of which Tau Canis Majoris is the brightest member. Located around 3 degrees northeast of Wezen, it covers an area around 12 light-years in diameter, though the stars appear huddled around Tau when seen through binoculars. It is a very young open cluster as its member stars are only a few million years old. Lying 2 degrees southwest of NGC 2362 is NGC 2354 a fainter open cluster of magnitude 6.5, with around 15 member stars visible with binoculars. Located around 30' northeast of NGC 2360, NGC 2359 (Thor's Helmet or the Duck Nebula) is a relatively bright emission nebula in Canis Major, with an approximate magnitude of 10, which is 10,000 light-years from Earth. The nebula is shaped by HD 56925, an unstable Wolf\u2013Rayet star embedded within it.\nIn 2003, an overdensity of stars in the region was announced to be the Canis Major Dwarf, the closest satellite galaxy to Earth. However, there remains debate over whether it represents a disrupted dwarf galaxy or in fact a variation in the thin and thick disk and spiral arm populations of the Milky Way. Investigation of the area yielded only ten RR Lyrae variables\u2014consistent with the Milky Way's halo and thick disk populations rather than a separate dwarf spheroidal galaxy. On the other hand, a globular cluster in Puppis, NGC 2298\u2014which appears to be part of the Canis Major dwarf system\u2014is extremely metal-poor, suggesting it did not arise from the Milky Way's thick disk, and instead is of extragalactic origin.\nNGC 2207 and IC 2163 are a pair of face-on interacting spiral galaxies located 125\u00a0million light-years from Earth. About 40\u00a0million years ago, the two galaxies had a close encounter and are now moving farther apart; nevertheless, the smaller IC 2163 will eventually be incorporated into NGC 2207. As the interaction continues, gas and dust will be perturbed, sparking extensive star formation in both galaxies. Supernovae have been observed in NGC 2207 in 1975 (type Ia SN 1975a), 1999 (the type Ib SN 1999ec), 2003 (type 1b supernova SN 2003H), and 2013 (type II supernova SN 2013ai). Located 16\u00a0million light-years distant, ESO 489-056 is an irregular dwarf- and low-surface-brightness galaxy that has one of the lowest metallicities known."}
{"id": "6367", "revid": "8240947", "url": "https://en.wikipedia.org/wiki?curid=6367", "title": "Canis Minor", "text": "Canis Minor is a small constellation in the northern celestial hemisphere. In the second century, it was included as an asterism, or pattern, of two stars in Ptolemy's 48 constellations, and it is counted among the 88 modern constellations. Its name is Latin for \"lesser dog\", in contrast to Canis Major, the \"greater dog\"; both figures are commonly represented as following the constellation of Orion the hunter.\nCanis Minor contains only two stars brighter than the fourth magnitude, Procyon (Alpha Canis Minoris), with a magnitude of 0.34, and Gomeisa (Beta Canis Minoris), with a magnitude of 2.9. The constellation's dimmer stars were noted by Johann Bayer, who named eight stars including Alpha and Beta, and John Flamsteed, who numbered fourteen. Procyon is the seventh-brightest star in the night sky, as well as one of the closest. A yellow-white main sequence star, it has a white dwarf companion. Gomeisa is a blue-white main sequence star. Luyten's Star is a ninth-magnitude red dwarf and the Solar System's next closest stellar neighbour in the constellation after Procyon. The fourth-magnitude HD 66141, which has evolved into an orange giant towards the end of its life cycle, was discovered to have a planet in 2012. There are two faint deep-sky objects within the constellation's borders. The 11 Canis-Minorids are a meteor shower that can be seen in early December.\nHistory and mythology.\nThough strongly associated with the Classical Greek uranographic tradition, Canis Minor originates from ancient Mesopotamia. Procyon and Gomeisa were called \"MASH.TAB.BA\" or \"twins\" in the \"Three Stars Each\" tablets, dating to around 1100 BC. In the later \"MUL.APIN\", this name was also applied to the pairs of Pi3 and Pi4 Orionis and Zeta and Xi Orionis. The meaning of \"MASH.TAB.BA\" evolved as well, becoming the twin deities Lulal and Latarak, who are on the opposite side of the sky from \"Papsukal\", the True Shepherd of Heaven in Babylonian mythology. Canis Minor was also given the name \"DAR.LUGAL\", its position defined as \"the star which stands behind it [Orion]\", in the \"MUL.APIN\"; the constellation represents a rooster. This name may have also referred to the constellation Lepus. \"DAR.LUGAL\" was also denoted \"DAR.MU\u0160EN\" and \"DAR.LUGAL.MU\u0160EN\" in Babylonia. Canis Minor was then called \"tarlugallu\" in Akkadian astronomy.\nCanis Minor was one of the original 48 constellations formulated by Ptolemy in his second-century Almagest, in which it was defined as a specific pattern (asterism) of stars; Ptolemy identified only two stars and hence no depiction was possible. The Ancient Greeks called the constellation \u03c0\u03c1\u03bf\u03ba\u03c5\u03c9\u03bd/\"Procyon\", \"coming before the dog\", transliterated into Latin as \"Antecanis\", \"Praecanis\", or variations thereof, by Cicero and others. Roman writers also appended the descriptors \"parvus\", \"minor\" or \"minusculus\" (\"small\" or \"lesser\", for its faintness), \"septentrionalis\" (\"northerly\", for its position in relation to Canis Major), \"primus\" (rising \"first\") or \"sinister\" (rising to the \"left\") to its name \"Canis\".\nIn Greek mythology, Canis Minor was sometimes connected with the Teumessian Fox, a beast turned into stone with its hunter, Laelaps, by Zeus, who placed them in heaven as Canis Major (Laelaps) and Canis Minor (Teumessian Fox). Eratosthenes accompanied the Little Dog with Orion, while Hyginus linked the constellation with Maera, a dog owned by Icarius of Athens. On discovering the latter's death, the dog and Icarius' daughter Erigone took their lives and all three were placed in the sky\u2014Erigone as Virgo and Icarius as Bo\u00f6tes. As a reward for his faithfulness, the dog was placed along the \"banks\" of the Milky Way, which the ancients believed to be a heavenly river, where he would never suffer from thirst.\nThe medieval Arabic astronomers maintained the depiction of Canis Minor (\"al-Kalb al-Asghar\" in Arabic) as a dog; in his Book of the Fixed Stars, Abd al-Rahman al-Sufi included a diagram of the constellation with a canine figure superimposed. There was one slight difference between the Ptolemaic vision of Canis Minor and the Arabic; al-Sufi claims Mirzam, now assigned to Orion, as part of both Canis Minor\u2014the collar of the dog\u2014and its modern home. The Arabic names for both Procyon and Gomeisa alluded to their proximity and resemblance to Sirius, though they were not direct translations of the Greek; Procyon was called \"ash-Shi'ra ash-Shamiya\", the \"Syrian Sirius\" and Gomeisa was called \"ash-Shira al-Ghamisa\", the Sirius with bleary eyes. Among the Merazig of Tunisia, shepherds note six constellations that mark the passage of the dry, hot season. One of them, called \"Merzem\", includes the stars of Canis Minor and Canis Major and is the herald of two weeks of hot weather.\nThe ancient Egyptians thought of this constellation as Anubis, the jackal god.\nAlternative names have been proposed: Johann Bayer in the early 17th century termed the constellation \"Fovea\" \"The Pit\", and \"Morus\" \"Sycamine Tree\". Seventeenth-century German poet and author Philippus Caesius linked it to the dog of Tobias from the Apocrypha. Richard A. Proctor gave the constellation the name \"Felis\" \"the Cat\" in 1870 (contrasting with Canis Major, which he had abbreviated to \"Canis\" \"the Dog\"), explaining that he sought to shorten the constellation names to make them more manageable on celestial charts. Occasionally, Canis Minor is confused with Canis Major and given the name \"Canis Orionis\" (\"Orion's Dog\").\nIn non-Western astronomy.\nIn Chinese astronomy, the stars corresponding to Canis Minor lie in the Vermilion Bird of the South (\u5357\u65b9\u6731\u96c0, \"N\u00e1n F\u0101ng Zh\u016b Qu\u00e8\"). Procyon, Gomeisa and Eta Canis Minoris form an asterism known as N\u00e1nh\u00e9, the Southern River. With its counterpart, the Northern River Beihe (Castor and Pollux), N\u00e1nh\u00e9 was also associated with a gate or sentry. Along with Zeta and 8 Cancri, 6 Canis Minoris and 11 Canis Minoris formed the asterism \"Shuiwei\", which literally means \"water level\". Combined with additional stars in Gemini, Shuiwei represented an official who managed floodwaters or a marker of the water level. Neighboring Korea recognized four stars in Canis Minor as part of a different constellation, \"the position of the water\". This constellation was located in the Red Bird, the southern portion of the sky.\nPolynesian peoples often did not recognize Canis Minor as a constellation, but they saw Procyon as significant and often named it; in the Tuamotu Archipelago it was known as \"Hiro\", meaning \"twist as a thread of coconut fiber\", and \"Kopu-nui-o-Hiro\" (\"great paunch of Hiro\"), which was either a name for the modern figure of Canis Minor or an alternative name for Procyon. Other names included \"Vena\" (after a goddess), on Mangaia and \"Puanga-hori\" (false \"Puanga\", the name for Rigel), in New Zealand. In the Society Islands, Procyon was called \"Ana-tahua-vahine-o-toa-te-manava\", literally \"Aster the priestess of brave heart\", figuratively the \"pillar for elocution\". The Wardaman people of the Northern Territory in Australia gave Procyon and Gomeisa the names \"Magum\" and \"Gurumana\", describing them as humans who were transformed into gum trees in the dreamtime. Although their skin had turned to bark, they were able to speak with a human voice by rustling their leaves.\nThe Aztec calendar was related to their cosmology. The stars of Canis Minor were incorporated along with some stars of Orion and Gemini into an asterism associated with the day called \"Water\".\nCharacteristics.\nLying directly south of Gemini's bright stars Castor and Pollux, Canis Minor is a small constellation bordered by Monoceros to the south, Gemini to the north, Cancer to the northeast, and Hydra to the east. It does not border Canis Major; Monoceros is in between the two. Covering 183 square degrees, Canis Minor ranks seventy-first of the 88 constellations in size. It appears prominently in the southern sky during the Northern Hemisphere's winter. The constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of 14 sides. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between and . Most visible in the evening sky from January to March, Canis Minor is most prominent at 10 PM during mid-February. It is then seen earlier in the evening until July, when it is only visible after sunset before setting itself, and rising in the morning sky before dawn. The constellation's three-letter abbreviation, as adopted by the International Astronomical Union in 1922, is \"CMi\".\nFeatures.\nStars.\nCanis Minor contains only two stars brighter than fourth magnitude. At magnitude 0.34, Procyon, or Alpha Canis Minoris, is the seventh-brightest star in the night sky, as well as one of the closest. Its name means \"before the dog\" or \"preceding the dog\" in Greek, as it rises an hour before the \"Dog Star\", Sirius, of Canis Major. It is a binary star system, consisting of a yellow-white main sequence star of spectral type F5\u00a0IV-V, named Procyon\u00a0A, and a faint white dwarf companion of spectral type DA, named Procyon\u00a0B. Procyon\u00a0B, which orbits the more massive star every 41 years, is of magnitude 10.7. Procyon\u00a0A is 1.4 times the Sun's mass, while its smaller companion is 0.6 times as massive as the Sun. The system is from Earth, the shortest distance to a northern-hemisphere star of the first magnitude. Gomeisa, or Beta Canis Minoris, with a magnitude of 2.89, is the second-brightest star in Canis Minor. Lying from the Solar System, it is a blue-white main sequence star of spectral class B8\u00a0Ve. Although fainter to Earth observers, it is much brighter than Procyon, and is 250 times as luminous and three times as massive as the Sun. Although its variations are slight, Gomeisa is classified as a shell star (Gamma Cassiopeiae variable), with a maximum magnitude of 2.84 and a minimum magnitude of 2.92. It is surrounded by a disk of gas which it heats and causes to emit radiation.\nJohann Bayer used the Greek letters Alpha to Eta to label the most prominent eight stars in the constellation, designating two stars as Delta (named Delta1 and Delta2). John Flamsteed numbered fourteen stars, discerning a third star he named Delta3; his star 12 Canis Minoris was not found subsequently. In Bayer's 1603 work \"Uranometria\", Procyon is located on the dog's belly, and Gomeisa on its neck. Gamma, Epsilon and Eta Canis Minoris lie nearby, marking the dog's neck, crown and chest respectively. Although it has an apparent magnitude of 4.34, Gamma Canis Minoris is an orange K-type giant of spectral class K3-III C, which lies away. Its colour is obvious when seen through binoculars. It is a multiple system, consisting of the spectroscopic binary Gamma A and three optical companions, Gamma B, magnitude 13; Gamma C, magnitude 12; and Gamma D, magnitude 10. The two components of Gamma A orbit each other every 389.2 days, with an eccentric orbit that takes their separation between 2.3 and 1.4 astronomical units (AU). Epsilon Canis Minoris is a yellow bright giant of spectral class G6.5IIb of magnitude of 4.99. It lies from Earth, with 13 times the diameter and 750 times the luminosity of the Sun. Eta Canis Minoris is a giant of spectral class F0III of magnitude 5.24, which has a yellowish hue when viewed through binoculars as well as a faint companion of magnitude 11.1. Located 4 arcseconds from the primary, the companion star is actually around 440 AU from the main star and takes around 5000 years to orbit it.\nNear Procyon, three stars share the name Delta Canis Minoris. Delta1 is a yellow-white F-type giant of magnitude 5.25 located around from Earth. About 360 times as luminous and 3.75 times as massive as the Sun, it is expanding and cooling as it ages, having spent much of its life as a main sequence star of spectrum B6V. Also known as 8 Canis Minoris, Delta2 is an F-type main-sequence star of spectral type F2V and magnitude 5.59 which is distant. The last of the trio, Delta3 (also known as 9 Canis Minoris), is a white main sequence star of spectral type A0Vnn and magnitude 5.83 which is distant. These stars mark the paws of the Lesser Dog's left hind leg, while magnitude 5.13 Zeta marks the right. A blue-white bright giant of spectral type B8II, Zeta lies around away from the Solar System.\nLying 222 \u00b1 7 light-years away with an apparent magnitude of 4.39, HD 66141 is 6.8\u00a0billion years old and has evolved into an orange giant of spectral type K2III with a diameter around 22 times that of the Sun, and weighing 1.1 solar masses. It is 174 times as luminous as the Sun, with an absolute magnitude of \u22120.15. HD 66141 was mistakenly named 13 Puppis, as its celestial coordinates were recorded incorrectly when catalogued and hence mistakenly thought to be in the constellation of Puppis; Bode gave it the name Lambda Canis Minoris, which is now obsolete. The orange giant is orbited by a planet, HD 66141b, which was detected in 2012 by measuring the star's radial velocity. The planet has a mass around 6 times that of Jupiter and a period of 480 days.\nA red giant of spectral type M4III, BC Canis Minoris lies around distant from the Solar System. It is a semiregular variable star that varies between a maximum magnitude of 6.14 and minimum magnitude of 6.42. Periods of 27.7, 143.3 and 208.3 days have been recorded in its pulsations. AZ, AD and BI Canis Minoris are Delta Scuti variables\u2014short period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. AZ is of spectral type A5IV, and ranges between magnitudes 6.44 and 6.51 over a period of 2.3 hours. AD has a spectral type of F2III, and has a maximum magnitude of 9.21 and minimum of 9.51, with a period of approximately 2.95 hours. BI is of spectral type F2 with an apparent magnitude varying around 9.19 and a period of approximately 2.91 hours.\nAt least three red giants are Mira variables in Canis Minor. S Canis Minoris, of spectral type M7e, is the brightest, ranging from magnitude 6.6 to 13.2 over a period of 332.94 days. V Canis Minoris ranges from magnitude 7.4 to 15.1 over a period of 366.1 days. Similar in magnitude is R Canis Minoris, which has a maximum of 7.3, but a significantly brighter minimum of 11.6. An S-type star, it has a period of 337.8 days.\nYZ Canis Minoris is a red dwarf of spectral type M4.5V and magnitude 11.2, roughly three times the size of Jupiter and from Earth. It is a flare star, emitting unpredictable outbursts of energy for mere minutes, which might be much more powerful analogues of solar flares. Luyten's Star (GJ 273) is a red dwarf star of spectral type M3.5V and close neighbour of the Solar System. Its visual magnitude of 9.9 renders it too faint to be seen with the naked eye, even though it is only away. Fainter still is PSS 544-7, an eighteenth-magnitude red dwarf around 20 percent the mass of the Sun, located from Earth. First noticed in 1991, it is thought to be a cannonball star, shot out of a star cluster and now moving rapidly through space directly away from the galactic disc.\nThe WZ Sagittae-type dwarf nova DY Canis Minoris (also known as VSX J074727.6+065050) flared up to magnitude 11.4 over January and February 2008 before dropping eight magnitudes to around 19.5 over approximately 80 days. It is a remote binary star system where a white dwarf and low mass star orbit each other close enough for the former star to draw material off the latter and form an accretion disc. This material builds up until it erupts dramatically.\nDeep-sky objects.\nThe Milky Way passes through much of Canis Minor, yet it has few deep-sky objects. William Herschel recorded four objects in his 1786 work \"Catalogue of Nebulae and Clusters of Stars\", including two he mistakenly believed were star clusters. NGC 2459 is a group of five thirteenth- and fourteenth-magnitude stars that appear to lie close together in the sky but are not related. A similar situation has occurred with NGC 2394, also in Canis Minor. This is a collection of fifteen unrelated stars of ninth-magnitude and fainter.\nHerschel also observed three faint galaxies, two of which are interacting with each other. NGC 2508 is a lenticular galaxy of thirteenth-magnitude, estimated at 205\u00a0million light-years (63\u00a0million parsecs) distance with a diameter of 80 thousand light-years (25 thousand parsecs). Named as a single object by Herschel, NGC 2402 is actually a pair of near-adjacent galaxies that appear to be interacting with each other. Only of fourteenth- and fifteenth-magnitudes respectively, the elliptical and spiral galaxy are thought to be approximately 245\u00a0million light-years distant, and each measure 55,000 light-years in diameter.\nMeteor showers.\nThe 11 Canis-Minorids, also called the Beta Canis Minorids, are a meteor shower that arise near the fifth-magnitude star 11 Canis Minoris and were discovered in 1964 by Keith Hindley, who investigated their trajectory and proposed a common origin with the comet D/1917 F1 Mellish. However, this conclusion has been refuted subsequently as the number of orbits analysed was low and their trajectories too disparate to confirm a link. They last from 4 to 15 December, peaking over 10 and 11 December."}
{"id": "6368", "revid": "22041646", "url": "https://en.wikipedia.org/wiki?curid=6368", "title": "Choshu", "text": ""}
{"id": "6371", "revid": "8240947", "url": "https://en.wikipedia.org/wiki?curid=6371", "title": "Centaurus", "text": "Centaurus is a bright constellation in the southern sky. One of the largest constellations, Centaurus was included among the 48 constellations listed by the 2nd-century astronomer Ptolemy, and it remains one of the 88 modern constellations. In Greek mythology, Centaurus represents a centaur; a creature that is half human, half horse (another constellation named after a centaur is one from the zodiac: Sagittarius). Notable stars include Alpha Centauri, the nearest star system to the Solar System, its neighbour in the sky Beta Centauri, and V766 Centauri, one of the largest stars yet discovered. The constellation also contains Omega Centauri, the brightest globular cluster as visible from Earth and the largest identified in the Milky Way, possibly a remnant of a dwarf galaxy.\nNotable features.\nStars.\nCentaurus contains several very bright stars. Its alpha and beta stars are used as \"pointer stars\" to help observers find the constellation Crux. Centaurus has 281 stars above magnitude 6.5, meaning that they are visible to the unaided eye, the most of any constellation. Alpha Centauri, the closest star system to the Sun, has a high proper motion; it will be a mere half-degree from Beta Centauri in approximately 4000 years.\nAlpha Centauri is a triple star system composed of a binary system (Rigil Kentaurus and Toliman) orbited by Proxima Centauri, currently the nearest star to the Sun. Traditionally called Rigil Kentaurus or Toliman, meaning \"foot of the centaur\", the system has an overall magnitude of \u22120.28 and is 4.4 light-years from Earth. The primary and secondary are both yellow-hued stars; the first is of magnitude \u22120.01 and the second: 1.35. Proxima, the tertiary star, is a red dwarf of magnitude 11.0; it appears almost 2 degrees away from the close pairing of Alpha and has a period of approximately one million years. Also a flare star, Proxima has minutes-long outbursts where it brightens by over a magnitude. The Alpha couple revolve in 80-year periodicity and will next appear closest as seen from Earth's telescopes in 2037 and 2038, together as they appear to the naked eye they present the third-brightest \"star\" in the night sky.\nOne other first magnitude star Beta Centauri is in the constellation in a position beyond Proxima and toward the narrow axis of Crux, thus with Alpha forming a far-south limb of the constellation. Also called Hadar and Agena, it is a double star; the primary is a blue-hued giant star of magnitude 0.6, 525 light-years from Earth. The secondary is of magnitude 4.0 and has a modest separation, appearing only under intense magnification due to its distance.\nThe northerly star Theta Centauri, officially named Menkent, is an orange giant star of magnitude 2.06. It is the only bright star of Centaurus that is easily visible from mid-northern latitudes.\nThe next bright object is Gamma Centauri, a binary star which appears to the naked eye at magnitude 2.2. The primary and secondary are both blue-white hued stars of magnitude 2.9; their period is 84 years.\nCentaurus also has many dimmer double stars and binary stars. 3 Centauri is a double star with a blue-white hued primary of magnitude 4.5 and a secondary of magnitude 6.0. The primary is 344 light-years away.\nCentaurus is home to many variable stars. R Centauri is a Mira variable star with a minimum magnitude of 11.8 and a maximum magnitude of 5.3; it is about 1,250 light-years from Earth and has a period of 18 months. V810 Centauri is a semiregular variable.\nBPM 37093 is a white dwarf star whose carbon atoms are thought to have formed a crystalline structure. Since diamond also consists of carbon arranged in a crystalline lattice (though of a different configuration), scientists have nicknamed this star \"Lucy\" after the Beatles song \"\"Lucy in the Sky with Diamonds\".\"\nPDS 70, (V1032 Centauri) a low mass T Tauri star is found in the constellation Centauras. In July 2018 astronomers captured the first conclusive image of a protoplanetary disk containing a nascent exoplanet, named PDS 70b.\nDeep-sky objects.\n\u03c9 Centauri (NGC 5139), despite being listed as the constellation's \"omega\" star, is in fact a naked-eye globular cluster, 17,000 light-years away with a diameter of 150 light-years. It is the largest and brightest globular cluster in the Milky Way; at ten times the size of the next-largest cluster, it has a magnitude of 3.7. It is also the most luminous globular cluster in the Milky Way, at over one million solar luminosities. Omega Centauri is classified as a Shapley class VIII cluster, which means that its center is loosely concentrated. It is also the only globular cluster to be designated with a Bayer letter; the globular cluster 47 Tucanae is the only one designated with a Flamsteed number. It contains several million stars, most of which are yellow dwarf stars, but also possesses red giants and blue-white stars; the stars have an average age of 12 billion years. This has prompted suspicion that Omega Centauri was the core of a dwarf galaxy that had been absorbed by the Milky Way. Omega Centauri was determined to be nonstellar in 1677 by the English astronomer Edmond Halley, though it was visible as a star to the ancients. Its status as a globular cluster was determined by James Dunlop in 1827. To the unaided eye, Omega Centauri appears fuzzy and is obviously non-circular; it is approximately half a degree in diameter, the same size as the full Moon.\nCentaurus is also home to open clusters. NGC 3766 is an open cluster 6,300 light-years from Earth that is visible to the unaided eye. It contains approximately 100 stars, the brightest of which are 7th magnitude. NGC 5460 is another naked-eye open cluster, 2,300 light-years from Earth, that has an overall magnitude of 6 and contains approximately 40 stars.\nThere is one bright planetary nebula in Centaurus, NGC 3918, also known as the Blue Planetary. It has an overall magnitude of 8.0 and a central star of magnitude 11.0; it is 2600 light-years from Earth. The Blue Planetary was discovered by John Herschel and named for its color's similarity to Uranus, though the nebula is apparently three times larger than the planet.\nCentaurus is rich in galaxies as well. NGC 4622 is a face-on spiral galaxy located 200 million light-years from Earth (redshift 0.0146). Its spiral arms wind in both directions, which makes it nearly impossible for astronomers to determine the rotation of the galaxy. Astronomers theorize that a collision with a smaller companion galaxy near the core of the main galaxy could have led to the unusual spiral structure. NGC 5253, a peculiar irregular galaxy, is located near the border with Hydra and M83, with which it likely had a close gravitational interaction 1\u20132 billion years ago. This may have sparked the galaxy's high rate of star formation, which continues today and contributes to its high surface brightness. NGC 5253 includes a large nebula and at least 12 large star clusters. In the eyepiece, it is a small galaxy of magnitude 10 with dimensions of 5 arcminutes by 2 arcminutes and a bright nucleus. NGC 4945 is a spiral galaxy seen edge-on from Earth, 13 million light-years away. It is visible with any amateur telescope, as well as binoculars under good conditions; it has been described as \"shaped like a candle flame\", being long and thin (16' by 3'). In the eyepiece of a large telescope, its southeastern dust lane becomes visible. Another galaxy is NGC 5102, found by star-hopping from Iota Centauri. In the eyepiece, it appears as an elliptical object 9 arcminutes by 2.5 arcminutes tilted on a southwest-northeast axis.\nOne of the closest active galaxies to Earth is the Centaurus A galaxy, NGC 5128, at 11 million light-years away (redshift 0.00183). It has a supermassive black hole at its core, which expels massive jets of matter that emit radio waves due to synchrotron radiation. Astronomers posit that its dust lanes, not common in elliptical galaxies, are due to a previous merger with another galaxy, probably a spiral galaxy. NGC 5128 appears in the optical spectrum as a fairly large elliptical galaxy with a prominent dust lane. Its overall magnitude is 7.0 and it has been seen under perfect conditions with the naked eye, making it one of the most distant objects visible to the unaided observer. In equatorial and southern latitudes, it is easily found by star hopping from Omega Centauri. In small telescopes, the dust lane is not visible; it begins to appear with about 4 inches of aperture under good conditions. In large amateur instruments, above about 12 inches in aperture, the dust lane's west-northwest to east-southeast direction is easily discerned. Another dim dust lane on the east side of the 12-arcminute-by-15-arcminute galaxy is also visible. ESO 270-17, also called the Fourcade-Figueroa Object, is a low-surface brightness object believed to be the remnants of a galaxy; it does not have a core and is very difficult to observe with an amateur telescope. It measures 7 arcminutes by 1 arcminute. It likely originated as a spiral galaxy and underwent a catastrophic gravitational interaction with Centaurus A around 500 million years ago, stopping its rotation and destroying its structure.\nNGC 4650A is a polar-ring galaxy 136 million light-years from Earth (redshift 0.01). It has a central core made of older stars that resembles an elliptical galaxy, and an outer ring of young stars that orbits around the core. The plane of the outer ring is distorted, which suggests that NGC 4650A is the result of a galaxy collision about a billion years ago. This galaxy has also been cited in studies of dark matter, because the stars in the outer ring orbit too quickly for their collective mass. This suggests that the galaxy is surrounded by a dark matter halo, which provides the necessary mass.\nOne of the closest galaxy clusters to Earth is the Centaurus Cluster at 160 million light-years away, having redshift 0.0114. It has a cooler, denser central region of gas and a hotter, more diffuse outer region. The intracluster medium in the Centaurus Cluster has a high concentration of metals (elements heavier than helium) due to a large number of supernovae. This cluster also possesses a plume of gas whose origin is unknown.\nHistory.\nWhile Centaurus now has a high southern latitude, at the dawn of civilization it was an equatorial constellation. Precession has been slowly shifting it southward for millennia, and it is now close to its maximal southern declination. In a little over 7000 years it will be at maximum visibility for those in the northern hemisphere, visible at times in the year up to quite a high northern latitude.\nThe figure of Centaurus can be traced back to a Babylonian constellation known as the Bison-man (MUL.GUD.ALIM). This being was depicted in two major forms: firstly, as a 4-legged bison with a human head, and secondly, as a being with a man's head and torso attached to the rear legs and tail of a bull or bison. It has been closely associated with the Sun god Utu-Shamash from very early times.\nThe Greeks depicted the constellation as a centaur and gave it its current name. It was mentioned by Eudoxus in the 4th century BC and Aratus in the 3rd century BC. In the 2nd century AD, Claudius Ptolemy catalogued 37 stars in Centaurus, including Alpha Centauri. Large as it is now, in earlier times it was even larger, as the constellation Lupus was treated as an asterism within Centaurus, portrayed in illustrations as an unspecified animal either in the centaur's grasp or impaled on its spear. The Southern Cross, which is now regarded as a separate constellation, was treated by the ancients as a mere asterism formed of the stars composing the centaur's legs. Additionally, what is now the minor constellation Circinus was treated as undefined stars under the centaur's front hooves.\nAccording to the Roman poet Ovid (\"Fasti\" v.379), the constellation honors the centaur Chiron, who was tutor to many of the earlier Greek heroes including Heracles (Hercules), Theseus, and Jason, the leader of the Argonauts. It is not to be confused with the more warlike centaur represented by the zodiacal constellation Sagittarius. The legend associated with Chiron says that he was accidentally poisoned with an arrow shot by Hercules, and was subsequently placed in the heavens.\nEquivalents.\nIn Chinese astronomy, the stars of Centaurus are found in three areas: the Azure Dragon of the East (\u6771\u65b9\u9752\u9f8d, \"D\u014dng F\u0101ng Q\u012bng L\u00f3ng\"), the Vermillion Bird of the South (\u5357\u65b9\u6731\u96c0, \"N\u00e1n F\u0101ng Zh\u016b Qu\u00e8\"), and the Southern Asterisms (\u8fd1\u5357\u6975\u661f\u5340, \"J\u00ecnn\u00e1nj\u00edx\u012bng\u014du\"). Not all of the stars of Centaurus can be seen from China, and the unseen stars were classified among the Southern Asterisms by Xu Guangqi, based on his study of western star charts. However, most of the brightest stars of Centaurus, including \u03b1 Centauri, \u03b8 Centauri (or Menkent), \u03b5 Centauri and \u03b7 Centauri, can be seen in the Chinese sky.\nSome Polynesian peoples considered the stars of Centaurus to be a constellation as well. On Pukapuka, Centaurus had two names: \"Na Mata-o-te-tokolua\" and \"Na Lua-mata-o-Wua-ma-Velo\". In Tonga, the constellation was called by four names: \"O-nga-tangata\", \"Tautanga-ufi\", \"Mamangi-Halahu\", and \"Mau-kuo-mau\". Alpha and Beta Centauri were not named specifically by the people of Pukapuka or Tonga, but they were named by the people of Hawaii and the Tuamotus. In Hawaii, the name for Alpha Centauri was either \"Melemele\" or \"Ka Maile-hope\" and the name for Beta Centauri was either \"Polapola\" or \"Ka Maile-mua\". In the Tuamotu islands, Alpha was called \"Na Kuhi\" and Beta was called \"Tere\".\nThe Pointer (\u03b1 Centauri and \u03b2 Centauri) is one of the asterisms used by Bugis sailors for navigation, called \"binto\u00e9ng balu\u00e9\", meaning \"the widowed-before-marriage\". It is also called \"binto\u00e9ng sallatang\" meaning \"southern star\" \nNamesakes.\nTwo United States Navy ships, and , were named after Centaurus, the constellation."}
{"id": "6416", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=6416", "title": "Impact crater", "text": "An impact crater is an approximately circular depression in the surface of a planet, moon, or other solid body in the Solar System or elsewhere, formed by the hypervelocity impact of a smaller body. In contrast to volcanic craters, which result from explosion or internal collapse, impact craters typically have raised rims and floors that are lower in elevation than the surrounding terrain. Impact craters range from small, simple, bowl-shaped depressions to large, complex, multi-ringed impact basins. Meteor Crater is a well-known example of a small impact crater on Earth.\nImpact craters are the dominant geographic features on many solid Solar System objects including the Moon, Mercury, Callisto, Ganymede and most small moons and asteroids. On other planets and moons that experience more active surface geological processes, such as Earth, Venus, Mars, Europa, Io and Titan, visible impact craters are less common because they become eroded, buried or transformed by tectonics over time. Where such processes have destroyed most of the original crater topography, the terms impact structure or astrobleme are more commonly used. In early literature, before the significance of impact cratering was widely recognised, the terms cryptoexplosion or cryptovolcanic structure were often used to describe what are now recognised as impact-related features on Earth.\nThe cratering records of very old surfaces, such as Mercury, the Moon, and the southern highlands of Mars, record a period of intense early bombardment in the inner Solar System around 3.9 billion years ago. The rate of crater production on Earth has since been considerably lower, but it is appreciable nonetheless; Earth experiences from one to three impacts large enough to produce a crater about once every million years on average. This indicates that there should be far more relatively young craters on the planet than have been discovered so far. The cratering rate in the inner solar system fluctuates as a consequence of collisions in the asteroid belt that create a family of fragments that are often sent cascading into the inner solar system. Formed in a collision 80 million years ago, the Baptistina family of asteroids is thought to have caused a large spike in the impact rate. Note that the rate of impact cratering in the outer Solar System could be different from the inner Solar System.\nAlthough Earth's active surface processes quickly destroy the impact record, about 190 terrestrial impact craters have been identified. These range in diameter from a few tens of meters up to about , and they range in age from recent times (e.g. the Sikhote-Alin craters in Russia whose creation was witnessed in 1947) to more than two billion years, though most are less than 500 million years old because geological processes tend to obliterate older craters. They are also selectively found in the stable interior regions of continents. Few undersea craters have been discovered because of the difficulty of surveying the sea floor, the rapid rate of change of the ocean bottom, and the subduction of the ocean floor into Earth's interior by processes of plate tectonics.\nImpact craters are not to be confused with landforms that may appear similar, including calderas, sinkholes, glacial cirques, ring dikes, salt domes, and others.\nHistory.\nDaniel M. Barringer, a mining engineer, was convinced already in 1903 that the crater he owned, Meteor Crater, was of cosmic origin. Yet most geologists at the time assumed it formed as the result of a volcanic steam eruption.\nIn the 1920s, the American geologist Walter H. Bucher studied a number of sites now recognized as impact craters in the United States. He concluded they had been created by some great explosive event, but believed that this force was probably volcanic in origin. However, in 1936, the geologists John D. Boon and Claude C. Albritton Jr. revisited Bucher's studies and concluded that the craters that he studied were probably formed by impacts.\nGrove Karl Gilbert suggested in 1893 that the Moon's craters were formed by large asteroid impacts. Ralph Baldwin in 1949 wrote that the Moon's craters were mostly of impact origin. Around 1960, Gene Shoemaker revived the idea. According to David H. Levy, Gene \"saw the craters on the Moon as logical impact sites that were formed not gradually, in eons, but explosively, in seconds.\" For his Ph.D. degree at Princeton (1960), under the guidance of Harry Hammond Hess, Shoemaker studied the impact dynamics of Barringer Meteor Crater. Shoemaker noted Meteor Crater had the same form and structure as two explosion craters created from atomic bomb tests at the Nevada Test Site, notably Jangle U in 1951 and Teapot Ess in 1955. In 1960, Edward C. T. Chao and Shoemaker identified coesite (a form of silicon dioxide) at Meteor Crater, proving the crater was formed from an impact generating extremely high temperatures and pressures. They followed this discovery with the identification of coesite within suevite at N\u00f6rdlinger Ries, proving its impact origin.\nArmed with the knowledge of shock-metamorphic features, Carlyle S. Beals and colleagues at the Dominion Astrophysical Observatory in Victoria, British Columbia, Canada and Wolf von Engelhardt of the University of T\u00fcbingen in Germany began a methodical search for impact craters. By 1970, they had tentatively identified more than 50. Although their work was controversial, the American Apollo Moon landings, which were in progress at the time, provided supportive evidence by recognizing the rate of impact cratering on the Moon. Because the processes of erosion on the Moon are minimal, craters persist. Since the Earth could be expected to have roughly the same cratering rate as the Moon, it became clear that the Earth had suffered far more impacts than could be seen by counting evident craters.\nCrater formation.\nImpact cratering involves high velocity collisions between solid objects, typically much greater than the speed of sound in those objects. Such hyper-velocity impacts produce physical effects such as melting and vaporization that do not occur in familiar sub-sonic collisions. On Earth, ignoring the slowing effects of travel through the atmosphere, the lowest impact velocity with an object from space is equal to the gravitational escape velocity of about 11\u00a0km/s. The fastest impacts occur at about 72\u00a0km/s in the \"worst case\" scenario in which an object in a retrograde near-parabolic orbit hits Earth. The median impact velocity on Earth is about 20\u00a0km/s.\nHowever, the slowing effects of travel through the atmosphere rapidly decelerate any potential impactor, especially in the lowest 12 kilometres where 90% of the earth's atmospheric mass lies. Meteorites of up to 7,000\u00a0kg lose all their cosmic velocity due to atmospheric drag at a certain altitude (retardation point), and start to accelerate again due to Earth's gravity until the body reaches its terminal velocity of 0.09 to 0.16\u00a0km/s. The larger the meteoroid (i.e. asteroids and comets) the more of its initial cosmic velocity it preserves. While an object of 9,000\u00a0kg maintains about 6% of its original velocity, one of 900,000\u00a0kg already preserves about 70%. Extremely large bodies (about 100,000 tonnes) are not slowed by the atmosphere at all, and impact with their initial cosmic velocity if no prior disintegration occurs.\nImpacts at these high speeds produce shock waves in solid materials, and both impactor and the material impacted are rapidly compressed to high density. Following initial compression, the high-density, over-compressed region rapidly depressurizes, exploding violently, to set in train the sequence of events that produces the impact crater. Impact-crater formation is therefore more closely analogous to cratering by high explosives than by mechanical displacement. Indeed, the energy density of some material involved in the formation of impact craters is many times higher than that generated by high explosives. Since craters are caused by explosions, they are nearly always circular \u2013 only very low-angle impacts cause significantly elliptical craters.\nThis describes impacts on solid surfaces. Impacts on porous surfaces, such as that of Hyperion, may produce internal compression without ejecta, punching a hole in the surface without filling in nearby craters. This may explain the 'sponge-like' appearance of that moon.\nIt is convenient to divide the impact process conceptually into three distinct stages: (1) initial contact and compression, (2) excavation, (3) modification and collapse. In practice, there is overlap between the three processes with, for example, the excavation of the crater continuing in some regions while modification and collapse is already underway in others.\nContact and compression.\nIn the absence of atmosphere, the impact process begins when the impactor first touches the target surface. This contact accelerates the target and decelerates the impactor. Because the impactor is moving so rapidly, the rear of the object moves a significant distance during the short-but-finite time taken for the deceleration to propagate across the impactor. As a result, the impactor is compressed, its density rises, and the pressure within it increases dramatically. Peak pressures in large impacts exceed 1 TPa to reach values more usually found deep in the interiors of planets, or generated artificially in nuclear explosions.\nIn physical terms, a shock wave originates from the point of contact. As this shock wave expands, it decelerates and compresses the impactor, and it accelerates and compresses the target. Stress levels within the shock wave far exceed the strength of solid materials; consequently, both the impactor and the target close to the impact site are irreversibly damaged. Many crystalline minerals can be transformed into higher-density phases by shock waves; for example, the common mineral quartz can be transformed into the higher-pressure forms coesite and stishovite. Many other shock-related changes take place within both impactor and target as the shock wave passes through, and some of these changes can be used as diagnostic tools to determine whether particular geological features were produced by impact cratering.\nAs the shock wave decays, the shocked region decompresses towards more usual pressures and densities. The damage produced by the shock wave raises the temperature of the material. In all but the smallest impacts this increase in temperature is sufficient to melt the impactor, and in larger impacts to vaporize most of it and to melt large volumes of the target. As well as being heated, the target near the impact is accelerated by the shock wave, and it continues moving away from the impact behind the decaying shock wave.\nExcavation.\nContact, compression, decompression, and the passage of the shock wave all occur within a few tenths of a second for a large impact. The subsequent excavation of the crater occurs more slowly, and during this stage the flow of material is largely subsonic. During excavation, the crater grows as the accelerated target material moves away from the point of impact. The target's motion is initially downwards and outwards, but it becomes outwards and upwards. The flow initially produces an approximately hemispherical cavity that continues to grow, eventually producing a paraboloid (bowl-shaped) crater in which the centre has been pushed down, a significant volume of material has been ejected, and a topographically elevated crater rim has been pushed up. When this cavity has reached its maximum size, it is called the transient cavity.\nThe depth of the transient cavity is typically a quarter to a third of its diameter. Ejecta thrown out of the crater do not include material excavated from the full depth of the transient cavity; typically the depth of maximum excavation is only about a third of the total depth. As a result, about one third of the volume of the transient crater is formed by the ejection of material, and the remaining two thirds is formed by the displacement of material downwards, outwards and upwards, to form the elevated rim. For impacts into highly porous materials, a significant crater volume may also be formed by the permanent compaction of the pore space. Such compaction craters may be important on many asteroids, comets and small moons.\nIn large impacts, as well as material displaced and ejected to form the crater, significant volumes of target material may be melted and vaporized together with the original impactor. Some of this impact melt rock may be ejected, but most of it remains within the transient crater, initially forming a layer of impact melt coating the interior of the transient cavity. In contrast, the hot dense vaporized material expands rapidly out of the growing cavity, carrying some solid and molten material within it as it does so. As this hot vapor cloud expands, it rises and cools much like the archetypal mushroom cloud generated by large nuclear explosions. In large impacts, the expanding vapor cloud may rise to many times the scale height of the atmosphere, effectively expanding into free space.\nMost material ejected from the crater is deposited within a few crater radii, but a small fraction may travel large distances at high velocity, and in large impacts it may exceed escape velocity and leave the impacted planet or moon entirely. The majority of the fastest material is ejected from close to the center of impact, and the slowest material is ejected close to the rim at low velocities to form an overturned coherent flap of ejecta immediately outside the rim. As ejecta escapes from the growing crater, it forms an expanding curtain in the shape of an inverted cone. The trajectory of individual particles within the curtain is thought to be largely ballistic.\nSmall volumes of un-melted and relatively un-shocked material may be spalled at very high relative velocities from the surface of the target and from the rear of the impactor. Spalling provides a potential mechanism whereby material may be ejected into inter-planetary space largely undamaged, and whereby small volumes of the impactor may be preserved undamaged even in large impacts. Small volumes of high-speed material may also be generated early in the impact by jetting. This occurs when two surfaces converge rapidly and obliquely at a small angle, and high-temperature highly shocked material is expelled from the convergence zone with velocities that may be several times larger than the impact velocity.\nModification and collapse.\nIn most circumstances, the transient cavity is not stable and collapses under gravity. In small craters, less than about 4\u00a0km diameter on Earth, there is some limited collapse of the crater rim coupled with debris sliding down the crater walls and drainage of impact melts into the deeper cavity. The resultant structure is called a simple crater, and it remains bowl-shaped and superficially similar to the transient crater. In simple craters, the original excavation cavity is overlain by a lens of collapse breccia, ejecta and melt rock, and a portion of the central crater floor may sometimes be flat.\nAbove a certain threshold size, which varies with planetary gravity, the collapse and modification of the transient cavity is much more extensive, and the resulting structure is called a complex crater. The collapse of the transient cavity is driven by gravity, and involves both the uplift of the central region and the inward collapse of the rim. The central uplift is not the result of \"elastic rebound\", which is a process in which a material with elastic strength attempts to return to its original geometry; rather the collapse is a process in which a material with little or no strength attempts to return to a state of gravitational equilibrium.\nComplex craters have uplifted centers, and they have typically broad flat shallow crater floors, and terraced walls. At the largest sizes, one or more exterior or interior rings may appear, and the structure may be labeled an \"impact basin\" rather than an impact crater. Complex-crater morphology on rocky planets appears to follow a regular sequence with increasing size: small complex craters with a central topographic peak are called \"central peak craters\", for example Tycho; intermediate-sized craters, in which the central peak is replaced by a ring of peaks, are called \"peak-ring craters\", for example Schr\u00f6dinger; and the largest craters contain multiple concentric topographic rings, and are called \"multi-ringed basins\", for example Orientale. On icy (as opposed to rocky) bodies, other morphological forms appear that may have central pits rather than central peaks, and at the largest sizes may contain many concentric rings. Valhalla on Callisto is an example of this type.\nIdentifying impact craters.\nNon-explosive volcanic craters can usually be distinguished from impact craters by their irregular shape and the association of volcanic flows and other volcanic materials. Impact craters produce melted rocks as well, but usually in smaller volumes with different characteristics.\nThe distinctive mark of an impact crater is the presence of rock that has undergone shock-metamorphic effects, such as shatter cones, melted rocks, and crystal deformations. The problem is that these materials tend to be deeply buried, at least for simple craters. They tend to be revealed in the uplifted center of a complex crater, however.\nImpacts produce distinctive shock-metamorphic effects that allow impact sites to be distinctively identified. Such shock-metamorphic effects can include:\nEconomic importance of impacts.\nOn Earth impact craters have resulted in useful minerals. Some of the ores produced from impact related effects on Earth include ores of iron, uranium, gold, copper, and nickel. It is estimated that the value of materials mined from impact structures is five billion dollars/year just for North America. \nThe eventual usefulness of impact craters depends on several factors especially the nature of the materials that were impacted and when the materials were affected. In some cases the deposits were already in place and the impact brought them to the surface. These are called \u201cprogenetic economic deposits.\u201d Others were created during the actual impact. The great energy involved caused melting. Useful minerals formed as a result of this energy are classified as \u201csyngenetic deposits.\u201d The third type, called \u201cepigenetic deposits,\u201d is caused by the creation of a basin from the impact.\nMany of the minerals that our modern lives depend on are associated with impacts in the past. The Vredeford Dome in the center of the Witwatersrand Basin is the largest goldfield in the world which has supplied about 40% of all the gold ever mined in an impact structure (though the gold did not come from the bolide). The asteroid that struck the region was wide. The Sudbury Basin was caused by an impacting body over in diameter. This basin is famous for its deposits of nickel, copper, and Platinum Group Elements. An impact was involved in making the Carswell structure in Saskatchewan, Canada; it contains uranium deposits.\nHydrocarbons are common around impact structures. Fifty percent of impact structures in North America in hydrocarbon-bearing sedimentary basins contain oil/gas fields.\nMartian craters.\nBecause of the many missions studying Mars since the 1960s, there is good coverage of its surface which contains large numbers of craters. Many of the craters on Mars differ from those on the Moon and other moons since Mars contains ice under the ground, especially in the higher latitudes. Some of the types of craters that have special shapes due to impact into ice-rich ground are pedestal craters, rampart craters, expanded craters, and LARLE craters.\nLists of craters.\nImpact craters on Earth.\nOn Earth, the recognition of impact craters is a branch of geology, and is related to planetary geology in the study of other worlds. Out of many proposed craters, relatively few are confirmed. The following twenty are a sample of articles of confirmed and well-documented impact sites.\nSee the Earth Impact Database, a website concerned with 190 () scientifically-confirmed impact craters on Earth.\nLargest named craters in the Solar System.\nThere are approximately twelve more impact craters/basins larger than 300\u00a0km on the Moon, five on Mercury, and four on Mars. Large basins, some unnamed but mostly smaller than 300\u00a0km, can also be found on Saturn's moons Dione, Rhea and Iapetus."}
{"id": "6417", "revid": "1741963", "url": "https://en.wikipedia.org/wiki?curid=6417", "title": "Corvus (disambiguation)", "text": "Corvus is a genus of birds including species commonly known as crows, ravens, rooks and jackdaws.\nCorvus may also refer to:"}
{"id": "6420", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=6420", "title": "Corona Borealis", "text": "Corona Borealis is a small constellation in the Northern Celestial Hemisphere. It is one of the 48\u00a0constellations listed by the 2nd-century astronomer Ptolemy, and remains one of the 88 modern constellations. Its brightest stars form a semicircular arc. Its Latin name, inspired by its shape, means \"northern crown\". In classical mythology Corona Borealis generally represented the crown given by the god Dionysus to the Cretan princess Ariadne and set by him in the heavens. Other cultures likened the pattern to a circle of elders, an eagle's nest, a bear's den, or even a smokehole. Ptolemy also listed a southern counterpart, Corona Australis, with a similar pattern.\nThe brightest star is the magnitude\u00a02.2 Alpha Coronae Borealis. The yellow supergiant R Coronae Borealis is the prototype of a rare class of giant stars\u2014the R Coronae Borealis variables\u2014that are extremely hydrogen deficient, and thought to result from the merger of two white dwarfs. T Coronae Borealis, also known as the Blaze Star, is another unusual type of variable star known as a recurrent nova. Normally of magnitude\u00a010, it last flared up to magnitude\u00a02 in 1946. ADS 9731 and Sigma Coronae Borealis are multiple star systems with six and five components respectively. Five star systems have been found to have Jupiter-sized exoplanets. Abell 2065 is a highly concentrated galaxy cluster one billion light-years from the Solar System containing more than 400 members, and is itself part of the larger Corona Borealis Supercluster.\nCharacteristics.\nCovering 179 square degrees and hence 0.433% of the sky, Corona Borealis ranks 73rd of the 88 modern constellations by area. Its position in the Northern Celestial Hemisphere means that the whole constellation is visible to observers north of 50\u00b0S. It is bordered by Bo\u00f6tes to the north and west, Serpens Caput to the south, and Hercules to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"CrB\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of eight segments (\"illustrated in infobox\"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between 39.71\u00b0 and 25.54\u00b0. It has a counterpart\u2014Corona Australis\u2014in the Southern Celestial Hemisphere.\nFeatures.\nStars.\nThe seven stars that make up the constellation's distinctive crown-shaped pattern are all 4th-magnitude stars except for the brightest of them, Alpha Coronae Borealis. The other six stars are Theta, Beta, Gamma, Delta, Epsilon and Iota Coronae Borealis. The German cartographer Johann Bayer gave twenty stars in Corona Borealis Bayer designations from Alpha to Upsilon in his 1603 star atlas \"Uranometria\". Zeta Coronae Borealis was noted to be a double star by later astronomers and its components designated Zeta1 and Zeta2. John Flamsteed did likewise with Nu Coronae Borealis; classed by Bayer as a single star, it was noted to be two close stars by Flamsteed. He named them 20 and 21 Coronae Borealis in his catalogue, alongside the designations Nu1 and Nu2 respectively. Chinese astronomers deemed nine stars to make up the asterism, adding Pi and Rho Coronae Borealis. Within the constellation's borders, there are 37 stars brighter than or equal to apparent magnitude\u00a06.5.\nAlpha Coronae Borealis (officially named Alphecca by the IAU, but sometimes also known as Gemma) appears as a blue-white star of magnitude\u00a02.2. In fact, it is an Algol-type eclipsing binary that varies by 0.1\u00a0magnitude with a period of 17.4\u00a0days. The primary is a white main-sequence star of spectral type A0V that is 2.91\u00a0times the mass of the Sun () and 57 times as luminous (), and is surrounded by a debris disk out to a radius of around 60\u00a0astronomical units (AU). The secondary companion is a yellow main-sequence star of spectral type G5V that is a little smaller (0.9 times) the diameter of the Sun. Lying 75\u00b10.5\u00a0light-years from Earth, Alphecca is believed to be a member of the Ursa Major Moving Group of stars that have a common motion through space.\nLocated 112\u00b13\u00a0light-years away, Beta Coronae Borealis or Nusakan is a spectroscopic binary system whose two components are separated by 10\u00a0AU and orbit each other every 10.5 years. The brighter component is a rapidly oscillating Ap star, pulsating with a period of 16.2\u00a0minutes. Of spectral type A5V with a surface temperature of around 7980\u00a0K, it has around , 2.6\u00a0solar radii (), and . The smaller star is of spectral type F2V with a surface temperature of around 6750\u00a0K, and has around , , and between 4 and . Near Nusakan is Theta Coronae Borealis, a binary system that shines with a combined magnitude of 4.13 located 380\u00b120 light-years distant. The brighter component, Theta Coronae Borealis A, is a blue-white star that spins extremely rapidly\u2014at a rate of around 393\u00a0km per second. A Be star, it is surrounded by a debris disk.\nFlanking Alpha to the east is Gamma Coronae Borealis, yet another binary star system, whose components orbit each other every 92.94\u00a0years and are roughly as far apart from each other as the Sun and Neptune. The brighter component has been classed as a Delta Scuti variable star, though this view is not universal. The components are main sequence stars of spectral types B9V and A3V. Located 170\u00b12\u00a0light-years away, 4.06-magnitude Delta Coronae Borealis is a yellow giant star of spectral type G3.5III that is around and has swollen to . It has a surface temperature of 5180\u00a0K. For most of its existence, Delta Coronae Borealis was a blue-white main-sequence star of spectral type B before it ran out of hydrogen fuel in its core. Its luminosity and spectrum suggest it has just crossed the Hertzsprung gap, having finished burning core hydrogen and just begun burning hydrogen in a shell that surrounds the core.\nZeta Coronae Borealis is a double star with two blue-white components 6.3\u00a0arcseconds apart that can be readily separated at 100x\u00a0magnification. The primary is of magnitude\u00a05.1 and the secondary is of magnitude\u00a06.0. Nu Coronae Borealis is an optical double, whose components are a similar distance from Earth but have different radial velocities, hence are assumed to be unrelated. The primary, Nu1 Coronae Borealis, is a red giant of spectral type M2III and magnitude 5.2, lying 640\u00b130 light-years distant, and the secondary, Nu2 Coronae Borealis, is an orange-hued giant star of spectral type K5III and magnitude 5.4, estimated to be 590\u00b130\u00a0light-years away. Sigma Coronae Borealis, on the other hand, is a true multiple star system divisible by small amateur telescopes. It is actually a complex system composed of two stars around as massive as the Sun that orbit each other every 1.14\u00a0days, orbited by a third Sun-like star every 726\u00a0years. The fourth and fifth components are a binary red dwarf system that is 14,000\u00a0AU distant from the other three stars. ADS 9731 is an even rarer multiple system in the constellation, composed of six stars, two of which are spectroscopic binaries.\nCorona Borealis is home to two remarkable variable stars. T Coronae Borealis is a cataclysmic variable star also known as the Blaze Star. Normally placid around magnitude 10\u2014it has a minimum of 10.2 and maximum of 9.9\u2014it brightens to magnitude 2 in a period of hours, caused by a nuclear chain reaction and the subsequent explosion. T Coronae Borealis is one of a handful of stars called recurrent novae, which include T Pyxidis and U Scorpii. An outburst of T Coronae Borealis was first recorded in 1866; its second recorded outburst was in February 1946. T Coronae Borealis is a binary star with a red-hued giant primary and a white dwarf secondary, the two stars orbiting each other over a period of approximately 8 months. R Coronae Borealis is a yellow-hued variable supergiant star, over 7000 light-years from Earth, and prototype of a class of stars known as R Coronae Borealis variables. Normally of magnitude 6, its brightness periodically drops as low as magnitude 15 and then slowly increases over the next several months. These declines in magnitude come about as dust that has been ejected from the star obscures it. Direct imaging with the Hubble Space Telescope shows extensive dust clouds out to a radius of around 2000\u00a0AU from the star, corresponding with a stream of fine dust (composed of grains 5\u00a0nm in diameter) associated with the star's stellar wind and coarser dust (composed of grains with a diameter of around 0.14\u00a0\u00b5m) ejected periodically.\nThere are several other variables of reasonable brightness for amateur astronomer to observe, including three Mira-type long period variables: S Coronae Borealis ranges between magnitudes 5.8 and 14.1 over a period of 360\u00a0days. Located around 1946\u00a0light-years distant, it shines with a luminosity 16,643\u00a0times that of the Sun and has a surface temperature of 3033 K. One of the reddest stars in the sky, V Coronae Borealis is a cool star with a surface temperature of 2877\u00a0K that shines with a luminosity 102,831 times that of the Sun and is a remote 8810\u00a0light-years distant from Earth. Varying between magnitudes 6.9 and 12.6 over a period of 357\u00a0days, it is located near the junction of the border of Corona Borealis with Hercules and Bootes. Located 1.5\u00b0 northeast of Tau Coronae Borealis, W Coronae Borealis ranges between magnitudes 7.8 and 14.3 over a period of 238\u00a0days. Another red giant, RR Coronae Borealis is a M3-type semiregular variable star that varies between magnitudes 7.3 and 8.2 over 60.8 days. RS Coronae Borealis is yet another semiregular variable red giant, which ranges between magnitudes 8.7 to 11.6 over 332 days. It is unusual in that it is a red star with a high proper motion (greater than 50 milliarcseconds a year). Meanwhile, U Coronae Borealis is an Algol-type eclipsing binary star system whose magnitude varies between 7.66 and 8.79 over a period of 3.45 days\nTY Coronae Borealis is a pulsating white dwarf (of ZZ Ceti) type, which is around 70% as massive as the Sun, yet has only 1.1% of its diameter. Discovered in 1990, UW Coronae Borealis is a low-mass X-ray binary system composed of a star less massive than the Sun and a neutron star surrounded by an accretion disk that draws material from the companion star. It varies in brightness in an unusually complex manner: the two stars orbit each other every 111 minutes, yet there is another cycle of 112.6 minutes, which corresponds to the orbit of the disk around the degenerate star. The beat period of 5.5 days indicates the time the accretion disk\u2014which is asymmetrical\u2014takes to precess around the star.\nExtrasolar planetary systems.\nExtrasolar planets have been confirmed in five star systems, four of which were found by the radial velocity method. The spectrum of Epsilon Coronae Borealis was analysed for seven years from 2005 to 2012, revealing a planet around 6.7\u00a0times as massive as Jupiter () orbiting every 418\u00a0days at an average distance of around 1.3\u00a0AU. Epsilon itself is a orange giant of spectral type K2III that has swollen to and . Kappa Coronae Borealis is a spectral type K1IV orange subgiant nearly twice as massive as the Sun; around it lie a dust debris disk, and one planet with a period of 3.4\u00a0years. This planet's mass is estimated at . The dimensions of the debris disk indicate it is likely there is a second substellar companion. Omicron Coronae Borealis is a K-type clump giant with one confirmed planet with a mass of that orbits every 187\u00a0days\u2014one of the two least massive planets known around clump giants. HD 145457 is an orange giant of spectral type K0III found to have one planet of . Discovered by the Doppler method in 2010, it takes 176\u00a0days to complete an orbit. XO-1 is a magnitude 11 yellow main-sequence star located approximately light-years away, of spectral type G1V with a mass and radius similar to the Sun. In 2006 the hot Jupiter exoplanet XO-1b was discovered orbiting XO-1 by the transit method using the XO Telescope. Roughly the size of Jupiter, it completes an orbit around its star every three days.\nThe discovery of a Jupiter-sized planetary companion was announced in 1997 via analysis of the radial velocity of Rho Coronae Borealis, a yellow main sequence star and Solar analog of spectral type G0V, around 57 light-years distant from Earth. More accurate measurement of data from the Hipparcos satellite subsequently showed it instead to be a low-mass star somewhere between 100 and 200 times the mass of Jupiter. Possible stable planetary orbits in the habitable zone were calculated for the binary star Eta Coronae Borealis, which is composed of two stars\u2014yellow main sequence stars of spectral type G1V and G3V respectively\u2014similar in mass and spectrum to the Sun. No planet has been found, but a brown dwarf companion about 63 times as massive as Jupiter with a spectral type of L8 was discovered at a distance of 3640\u00a0AU from the pair in 2001.\nDeep-sky objects.\nCorona Borealis contains few galaxies observable with amateur telescopes. NGC 6085 and 6086 are a faint spiral and elliptical galaxy respectively close enough to each other to be seen in the same visual field through a telescope. Abell 2142 is a huge (six million light-year diameter), X-ray luminous galaxy cluster that is the result of an ongoing merger between two galaxy clusters. It has a redshift of 0.0909 (meaning it is moving away from us at 27,250\u00a0km/s) and a visual magnitude of 16.0. It is about 1.2 billion light-years away. Another galaxy cluster in the constellation, RX\u00a0J1532.9+3021, is approximately 3.9 billion light-years from Earth. At the cluster's center is a large elliptical galaxy containing one of the most massive and most powerful supermassive black holes yet discovered. Abell 2065 is a highly concentrated galaxy cluster containing more than 400 members, the brightest of which are 16th magnitude; the cluster is more than one billion light-years from Earth. On a larger scale still, Abell\u00a02065, along with Abell 2061, Abell 2067, Abell 2079, Abell 2089, and Abell 2092, make up the Corona Borealis Supercluster. Another galaxy cluster, Abell 2162, is a member of the Hercules Superclusters.\nMythology.\nIn Greek mythology, Corona Borealis was linked to the legend of Theseus and the minotaur. It was generally considered to represent a crown given by Dionysus to Ariadne, the daughter of Minos of Crete, after she had been abandoned by the Athenian prince Theseus. When she wore the crown at her marriage to Dionysus, he placed it in the heavens to commemorate their wedding. An alternate version has the besotted Dionysus give the crown to Ariadne, who in turn gives it to Theseus after he arrives in Crete to kill the minotaur that the Cretans have demanded tribute from Athens to feed. The hero uses the crown's light to escape the labyrinth after disposing of the creature, and Dionysus later sets it in the heavens. The Latin author Hyginus linked it to a crown or wreath worn by Bacchus (Dionysus) to disguise his appearance when first approaching Mount Olympus and revealing himself to the gods, having been previously hidden as yet another child of Jupiter's trysts with a mortal, in this case Semele. Corona Borealis was one of the 48 constellations mentioned in the \"Almagest\" of classical astronomer Ptolemy.\nIn Welsh mythology, it was called Caer Arianrhod, \"the Castle of the Silver Circle\", and was the heavenly abode of the Lady Arianrhod. To the ancient Balts, Corona Borealis was known as \"Dar\u017eelis\", the \"flower garden\".\nThe Arabs called the constellation Alphecca (a name later given to Alpha Coronae Borealis), which means \"separated\" or \"broken up\" ( '), a reference to the resemblance of the stars of Corona Borealis to a loose string of jewels. This was also interpreted as a broken dish. Among the Bedouins, the constellation was known as ' (), or \"the dish/bowl of the poor people\".\nThe Skidi people of Native Americans saw the stars of Corona Borealis representing a council of stars whose chief was Polaris. The constellation also symbolised the smokehole over a fireplace, which conveyed their messages to the gods, as well as how chiefs should come together to consider matters of importance. The Shawnee people saw the stars as the \"Heavenly Sisters\", who descended from the sky every night to dance on earth. Alphecca signifies the youngest and most comely sister, who was seized by a hunter who transformed into a field mouse to get close to her. They married though she later returned to the sky, with her heartbroken husband and son following later. The Mi'kmaq of eastern Canada saw Corona Borealis as \"Mskegw\u01d2m\", the den of the celestial bear (Alpha, Beta, Gamma and Delta Ursae Majoris).\nPolynesian peoples often recognized Corona Borealis; the people of the Tuamotus named it \"Na Kaua-ki-tokerau\" and probably \"Te Hetu\". The constellation was likely called \"Kaua-mea\" in Hawaii, \"Rangawhenua\" in New Zealand, and \"Te Wale-o-Awitu\" in the Cook Islands atoll of Pukapuka. Its name in Tonga was uncertain; it was either called \"Ao-o-Uvea\" or \"Kau-kupenga\".\nIn Australian Aboriginal astronomy, the constellation is called \"womera\" (\"the boomerang\") due to the shape of the stars. The Wailwun people of northwestern New South Wales saw Corona Borealis as \"mullion wollai\" \"eagle's nest\", with Altair and Vega\u2014each called \"mullion\"\u2014the pair of eagles accompanying it. The Wardaman people of northern Australia held the constellation to be a gathering point for Men's Law, Women's Law and Law of both sexes come together and consider matters of existence.\nLater references.\nCorona Borealis was renamed Corona Firmiana in honour of the Archbishop of Salzburg in the 1730 Atlas \"Mercurii Philosophicii Firmamentum Firminianum Descriptionem\" by Corbinianus Thomas, but this was not taken up by subsequent cartographers. The constellation was featured as a main plot ingredient in the short story \"Hypnos\" by H. P. Lovecraft, published in 1923; it is the object of fear of one of the protagonists in the short story. Finnish band Cadacross released an album titled \"Corona Borealis\" in 2002."}
{"id": "6421", "revid": "1013136784", "url": "https://en.wikipedia.org/wiki?curid=6421", "title": "Cygnus (constellation)", "text": "Cygnus is a northern constellation lying on the plane of the Milky Way, deriving its name from the Latinized Greek word for swan. Cygnus is one of the most recognizable constellations of the northern summer and autumn, and it features a prominent asterism known as the Northern Cross (in contrast to the Southern Cross). Cygnus was among the 48 constellations listed by the 2nd century astronomer Ptolemy, and it remains one of the 88 modern constellations.\nCygnus contains Deneb (\u0630\u0646\u0628, translit. \"\u1e0fanab,\" tail)one of the brightest stars in the night sky and the most distant first-magnitude staras its \"tail star\" and one corner of the Summer Triangle. It also has some notable X-ray sources and the giant stellar association of Cygnus OB2. Cygnus is also known as the Northern Cross. One of the stars of this association, NML Cygni, is one of the largest stars currently known. The constellation is also home to Cygnus X-1, a distant X-ray binary containing a supergiant and unseen massive companion that was the first object widely held to be a black hole. Many star systems in Cygnus have known planets as a result of the Kepler Mission observing one patch of the sky, an area around Cygnus.\nMost of the east has part of the Hercules\u2013Corona Borealis Great Wall in the deep sky, a giant galaxy filament that is the largest known structure in the observable universe, covering most of the northern sky.\nHistory and mythology.\nIn Eastern and World Astronomy.\nIn Hinduism, the period of time (or Muhurta) between 4:24 AM to 5:12 AM is called the Brahmamuhurtha, which means \"the moment of the Universe\"; the star system in correlation is the Cygnus constellation. This is believed to be a highly auspicious time to meditate, do any task, or start the day.\nIn Polynesia, Cygnus was often recognized as a separate constellation. In Tonga it was called \"Tuula-lupe\", and in the Tuamotus it was called \"Fanui-tai\". In New Zealand it was called \"Mara-tea\", in the Society Islands it was called \"Pirae-tea\" or \"Taurua-i-te-haapa-raa-manu\", and in the Tuamotus it was called \"Fanui-raro\". Beta Cygni was named in New Zealand; it was likely called \"Whetu-kaupo\". Gamma Cygni was called \"Fanui-runga\" in the Tuamotus.\nDeneb was also often a given name, in the Islamic world of astronomy. The name \"Deneb\" comes from the Arabic name \"dhaneb\", meaning \"tail\", from the phrase \"Dhanab ad-Daj\u0101jah\", which means \u201cthe tail of the hen\u201d.\nIn Western and Greek Astronomy.\nIn Greek mythology, Cygnus has been identified with several different legendary swans. Zeus disguised himself as a swan to seduce Leda, Spartan king Tyndareus's wife, who gave birth to the Gemini, Helen of Troy, and Clytemnestra; Orpheus was transformed into a swan after his murder, and was said to have been placed in the sky next to his lyre (Lyra); and the King Cygnus was transformed into a swan.\nThe Greeks also associated this constellation with the tragic story of Phaethon, the son of Helios the sun god, who demanded to ride his father's sun chariot for a day. Phaethon, however, was unable to control the reins, forcing Zeus to destroy the chariot (and Phaethon) with a thunderbolt, causing it to plummet to the earth into the river Eridanus. According to the myth, Phaethon's close friend or lover, Cygnus, grieved bitterly and spent many days diving into the river to collect Phaethon's bones to give him a proper burial. The gods were so touched by Cygnus's devotion that they turned him into a swan and placed him among the stars.\nIn Ovid's \"Metamorphoses\", there are three people named Cygnus, all of whom are transformed into swans. Alongside Cygnus, noted above, he mentions a boy from Tempe who commits suicide when Phyllius refuses to give him a tamed bull that he demands, but is transformed into a swan and flies away. He also mentions a son of Neptune who is an invulnerable warrior in the Trojan War who is eventually defeated by Achilles, but Neptune saves him by transforming him into a swan.\nTogether with other avian constellations near the summer solstice, Vultur cadens and Aquila, Cygnus may be a significant part of the origin of the myth of the Stymphalian Birds, one of The Twelve Labours of Hercules.\nCharacteristics.\nA very large constellation, Cygnus is bordered by Cepheus to the north and east, Draco to the north and west, Lyra to the west, Vulpecula to the south, Pegasus to the southeast and Lacerta to the east. The three-letter abbreviation for the constellation, as adopted by the IAU in 1922, is \"Cyg\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined as a polygon of 28 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between 27.73\u00b0 and 61.36\u00b0. Covering 804 square degrees and around 1.9% of the night sky, Cygnus ranks 16th of the 88 constellations in size.\nCygnus culminates at midnight on 29 June, and is most visible in the evening from the early summer to mid-autumn in the Northern Hemisphere.\nNormally, Cygnus is depicted with Delta and Epsilon Cygni as its wings. Deneb, the brightest in the constellation is at its tail, and Albireo as the tip of its beak.\nThere are several asterisms in Cygnus. In the 17th-century German celestial cartographer Johann Bayer's star atlas the \"Uranometria\", Alpha, Beta and Gamma Cygni form the pole of a cross, while Delta and Epsilon form the cross beam. The nova P Cygni was then considered to be the body of Christ.\nFeatures.\nStars.\nBayer catalogued many stars in the constellation, giving them the Bayer designations from Alpha to Omega and then using lowercase Roman letters to g. John Flamsteed added the Roman letters h, i, k, l and m (these stars were considered \"informes\" by Bayer as they lay outside the asterism of Cygnus), but were dropped by Francis Baily.\nThere are several bright stars in Cygnus. Alpha Cygni, called Deneb, is the brightest star in Cygnus. It is a white supergiant star of spectral type A2Iae that varies between magnitudes 1.21 and 1.29, one of the largest and most luminous A-class stars known. It is located about 3200 light-years away. Its traditional name means \"tail\" and refers to its position in the constellation. Albireo, designated Beta Cygni, is a celebrated binary star among amateur astronomers for its contrasting hues. The primary is an orange-hued giant star of magnitude 3.1 and the secondary is a blue-green hued star of magnitude 5.1. The system is 380 light-years away and is visible in large binoculars and all amateur telescopes. Gamma Cygni, traditionally named Sadr, is a yellow-tinged supergiant star of magnitude 2.2, 1500 light-years away. Its traditional name means \"breast\" and refers to its position in the constellation. Delta Cygni (the proper name is Fawaris) is another bright binary star in Cygnus, 171 light-years with a period of 800 years. The primary is a blue-white hued giant star of magnitude 2.9, and the secondary is a star of magnitude 6.6. The two components are visible in a medium-sized amateur telescope. The fifth star in Cygnus above magnitude 3 is Aljanah, designated Epsilon Cygni. It is an orange-hued giant star of magnitude 2.5, 72 light-years from Earth.\nThere are several other dimmer double and binary stars in Cygnus. Mu Cygni is a binary star with an optical tertiary component. The binary system has a period of 790 years and is 73 light-years from Earth. The primary and secondary, both white stars, are of magnitude 4.8 and 6.2, respectively. The unrelated tertiary component is of magnitude 6.9. Though the tertiary component is visible in binoculars, the primary and secondary currently require a medium-sized amateur telescope to split, as they will through the year 2020. The two stars will be closest between 2043 and 2050, when they will require a telescope with larger aperture to split. The stars 30 and 31 Cygni form a contrasting double star similar to the brighter Albireo. The two are visible in binoculars. The primary, 31 Cygni, is an orange-hued star of magnitude 3.8, 1400 light-years from Earth. The secondary, 30 Cygni, appears blue-green. It is of spectral type A5IIIn and magnitude 4.83, and is around 610 light-years from Earth. 31 Cygni itself is a binary star; the tertiary component is a blue star of magnitude 7.0. Psi Cygni is a binary star visible in small amateur telescopes, with two white components. The primary is of magnitude 5.0 and the secondary is of magnitude 7.5. 61 Cygni is a binary star visible in large binoculars or a small amateur telescope. It is 11.4 light-years from Earth and has a period of 750 years. Both components are orange-hued dwarf (main sequence) stars; the primary is of magnitude 5.2 and the secondary is of magnitude 6.1. 61 Cygni is significant because Friedrich Wilhelm Bessel determined its parallax in 1838, the first star to have a known parallax.\nLocated near Eta Cygni is the X-ray source Cygnus X-1, which is now thought to be caused by a black hole accreting matter in a binary star system. This was the first x-ray source widely believed to be a black hole.\nCygnus also contains several other noteworthy X-ray sources. Cygnus X-3 is a microquasar containing a Wolf\u2013Rayet star in orbit around a very compact object, with a period of only 4.8 hours. The system is one of the most intrinsically luminous X-ray sources observed. The system undergoes periodic outbursts of unknown nature, and during one such outburst, the system was found to be emitting muons, likely caused by neutrinos. While the compact object is thought to be a neutron star or possibly a black hole, it is possible that the object is instead a more exotic stellar remnant, possibly the first discovered quark star, hypothesized due to its production of cosmic rays that cannot be explained if the object is a normal neutron star. The system also emits cosmic rays and gamma rays, and has helped shed insight on to the formation of such rays. Cygnus X-2 is another X-ray binary, containing an A-type giant in orbit around a neutron star with a 9.8 day period. The system is interesting due to the rather small mass of the companion star, as most millisecond pulsars have much more massive companions. Another black hole in Cygnus is V404 Cygni, which consists of a K-type star orbiting around a black hole of around 12 solar masses. The black hole, similar to that of Cygnus X-3, has been hypothesized to be a quark star. 4U 2129+ 47 is another X-ray binary containing a neutron star which undergoes outbursts, as is EXO 2030+ 375.\nCygnus is also home to several variable stars. SS Cygni is a dwarf nova which undergoes outbursts every 7\u20138 weeks. The system's total magnitude varies from 12th magnitude at its dimmest to 8th magnitude at its brightest. The two objects in the system are incredibly close together, with an orbital period of less than 0.28 days. Chi Cygni is a red giant and the second-brightest Mira variable star at its maximum. It ranges between magnitudes 3.3 and 14.2, and spectral types S6,2e to S10,4e (MSe) over a period of 408 days; it has a diameter of 300 solar diameters and is 350 light-years from Earth. P Cygni is a luminous blue variable that brightened suddenly to 3rd magnitude in 1600 AD. Since 1715, the star has been of 5th magnitude, despite being more than 5000 light-years from Earth. The star's spectrum is unusual in that it contains very strong emission lines resulting from surrounding nebulosity. W Cygni is a semi-regular variable red giant star, 618 light-years from Earth.It has a maximum magnitude of 5.10 and a minimum magnitude 6.83; its period of 131 days. It is a red giant ranging between spectral types M4e-M6e(Tc:)III, NML Cygni is a red hypergiant semi-regular variable star located at 5,300 light-years away from Earth. It is one of largest stars currently known in the galaxy with a radius exceeding 1,000 solar radii. Its magnitude is around 16.6, its period is about 940 days.\nCygnus contains the binary star system KIC 9832227. It is predicted that the two stars will coalesce in about 2022, briefly forming a new naked-eye object. The star KIC 8462852 (Tabby's Star) has received widespread press coverage because of unusual light fluctuations.\nCygnus is one of the constellations that the Kepler satellite surveyed in its search for extrasolar planets, and as a result, there are about a hundred stars in Cygnus with known planets, the most of any constellation. One of the most notable systems is the Kepler-11 system, containing six transiting planets, all within a plane of approximately one degree. With a spectral type of G6V, the star is somewhat cooler than the Sun. The planets are very close to the star; all but the last planet are closer to Kepler-11 than Mercury is to the Sun, and all the planets are more massive than Earth. The naked-eye star 16 Cygni, a triple star approximately 70 light-years from Earth composed two Sun-like stars and a red dwarf, contains a planet orbiting one of the sun-like stars, found due to variations in the star's radial velocity. Gliese 777, another naked-eye multiple star system containing a yellow star and a red dwarf, also contains a planet. The planet is somewhat similar to Jupiter, but with slightly more mass and a more eccentric orbit. The Kepler-22 system is also notable for having the most Earth-like exoplanet when it was discovered in 2011.\nDeep-sky objects.\nThere is an abundance of deep-sky objects, with many open clusters, nebulae of various types and supernova remnants found in Cygnus due to its position on the Milky Way. Some open clusters can be difficult to make out from a rich background of stars.\nM39 (NGC 7092) is an open cluster 950 light-years from Earth that is visible to the unaided eye under dark skies. It is loose, with about 30 stars arranged over a wide area; their conformation appears triangular. The brightest stars of M39 are of the 7th magnitude. Another open cluster in Cygnus is NGC 6910, also called the Rocking Horse Cluster, possessing 16 stars with a diameter of 5 arcminutes visible in a small amateur instrument; it is of magnitude 7.4. The brightest of these are two gold-hued stars, which represent the bottom of the toy it is named for. A larger amateur instrument reveals 8 more stars, nebulosity to the east and west of the cluster, and a diameter of 9 arcminutes. The nebulosity in this region is part of the Gamma Cygni Nebula. The other stars, approximately 3700 light-years from Earth, are mostly blue-white and very hot.\nOther open clusters in Cygnus include Dolidze 9, Collinder 421, Dolidze 11, and Berkeley 90. Dolidze 9, 2800 light-years from Earth and relatively young at 20 million light-years old, is a faint open cluster with up to 22 stars visible in small and medium-sized amateur telescopes. Nebulosity is visible to the north and east of the cluster, which is 7 arcminutes in diameter. The brightest star appears in the eastern part of the cluster and is of the 7th magnitude; another bright star has a yellow hue. Dolidze 11 is an open cluster 400 million years old, farthest away of the three at 3700 light-years. More than 10 stars are visible in an amateur instrument in this cluster, of similar size to Dolidze 9 at 7 arcminutes in diameter, whose brightest star is of magnitude 7.5. It, too, has nebulosity in the east. Collinder 421 is a particularly old open cluster at an age of approximately 1 billion years; it is of magnitude 10.1. 3100 light-years from Earth, more than 30 stars are visible in a diameter of 8 arcseconds. The prominent star in the north of the cluster has a golden color, whereas the stars in the south of the cluster appear orange. Collinder 421 appears to be embedded in nebulosity, which extends past the cluster's borders to its west. Berkeley 90 is a smaller open cluster, with a diameter of 5 arcminutes. More than 16 members appear in an amateur telescope.\nNGC 6826, the Blinking Planetary Nebula, is a planetary nebula with a magnitude of 8.5, 3200 light-years from Earth. It appears to \"blink\" in the eyepiece of a telescope because its central star is unusually bright (10th magnitude). When an observer focuses on the star, the nebula appears to fade away. Less than one degree from the Blinking Planetary is the double star 16 Cygni.\nThe North America Nebula (NGC 7000) is one of the most well-known nebulae in Cygnus, because it is visible to the unaided eye under dark skies, as a bright patch in the Milky Way. However, its characteristic shape is only visible in long-exposure photographs \u2013 it is difficult to observe in telescopes because of its low surface brightness. It has low surface brightness because it is so large; at its widest, the North America Nebula is 2 degrees across. Illuminated by a hot embedded star of magnitude 6, NGC 7000 is 1500 light-years from Earth.\nTo the south of Epsilon Cygni is the Veil Nebula (NGC 6960, 6962, 6979, 6992, and 6995), a 5,000-year-old supernova remnant covering approximately 3 degrees of the sky - it is over 50 light-years long. Because of its appearance, it is also called the Cygnus Loop. The Loop is only visible in long-exposure astrophotographs. However, the brightest portion, NGC 6992, is faintly visible in binoculars, and a dimmer portion, NGC 6960, is visible in wide-angle telescopes.\nThe DR 6 cluster is also nicknamed the \"Galactic Ghoul\" because of the nebula's resemblance to a human face;\nThe Northern Coalsack Nebula, also called the Cygnus Rift, is a dark nebula located in the Cygnus Milky Way.\nThe Gamma Cygni Nebula (IC 1318) includes both bright and dark nebulae in an area of over 4 degrees. DWB 87 is another of the many bright emission nebulae in Cygnus, 7.8 by 4.3 arcminutes. It is in the Gamma Cygni area. Two other emission nebulae include Sharpless 2-112 and Sharpless 2-115. When viewed in an amateur telescope, Sharpless 2\u2013112 appears to be in a teardrop shape. More of the nebula's eastern portion is visible with an O III (doubly ionized oxygen) filter. There is an orange star of magnitude 10 nearby and a star of magnitude 9 near the nebula's northwest edge. Further to the northwest, there is a dark rift and another bright patch. The whole nebula measures 15 arcminutes in diameter. Sharpless 2\u2013115 is another emission nebula with a complex pattern of light and dark patches. Two pairs of stars appear in the nebula; it is larger near the southwestern pair. The open cluster Berkeley 90 is embedded in this large nebula, which measures 30 by 20 arcminutes.\nAlso of note is the Crescent Nebula (NGC 6888), located between Gamma and Eta Cygni, which was formed by the Wolf\u2013Rayet star HD 192163.\nIn recent years, amateur astronomers have made some notable Cygnus discoveries. The \"Soap bubble nebula\" (PN G75.5+1.7), near the Crescent nebula, was discovered on a digital image by Dave Jurasevich in 2007. In 2011, Austrian amateur Matthias Kronberger discovered a planetary nebula (Kronberger 61, now nicknamed \"The Soccer Ball\") on old survey photos, confirmed recently in images by the Gemini Observatory; both of these are likely too faint to be detected by eye in a small amateur scope.\nBut a much more obscure and relatively 'tiny' object\u2014one which is readily seen in dark skies by amateur telescopes, under good conditions\u2014is the newly discovered nebula (likely reflection type) associated with the star 4 Cygni (HD 183056): an approximately fan-shaped glowing region of several arcminutes' diameter, to the south and west of the fifth-magnitude star. It was first discovered visually near San Jose, California and publicly reported by amateur astronomer Stephen Waldee in 2007, and was confirmed photographically by Al Howard in 2010. California amateur astronomer Dana Patchick also says he detected it on the Palomar Observatory survey photos in 2005 but had not published it for others to confirm and analyze at the time of Waldee's first official notices and later 2010 paper.\nCygnus X is the largest star-forming region in the Solar neighborhood and includes not only some of the brightest and most massive stars known (such as Cygnus OB2-12), but also Cygnus OB2, a massive stellar association classified by some authors as a young globular cluster.\nMore supernovae have been seen in the Fireworks Galaxy (NGC 6946) than in any other galaxy.\nCygnus A is the first radio galaxy discovered; at a distance of 730 million light-years from Earth, it is the closest powerful radio galaxy. In the visible spectrum, it appears as an elliptical galaxy in a small cluster. It is classified as an active galaxy because the supermassive black hole at its nucleus is accreting matter, which produces two jets of matter from the poles. The jets' interaction with the interstellar medium creates radio lobes, one source of radio emissions.\nCygnus is also the apparent source of the WIMP-wind due to the orientation of the solar system's rotation through the galactic halo."}
{"id": "6422", "revid": "10863197", "url": "https://en.wikipedia.org/wiki?curid=6422", "title": "Communion", "text": "Communion may refer to:"}
{"id": "6423", "revid": "1005503331", "url": "https://en.wikipedia.org/wiki?curid=6423", "title": "Calorie", "text": "The calorie is a unit of energy defined as the amount of heat needed to raise a quantity of water by one degree of temperature.\nFor historical reasons, two main definitions of calorie are in wide use. The small calorie or gram calorie (usually denoted cal) is the amount of heat energy needed to raise the temperature of one \"gram\" of water by one degree Celsius (or one kelvin). The large calorie, food calorie, or kilocalorie (Cal, calorie or kcal), most widely used in nutrition, is the amount of heat needed to cause the same increase in one \"kilogram\" of water. Thus, 1 kilocalorie (kcal) = 1000 calories (cal). By convention in food science, the large calorie is commonly called Calorie (with a capital C by some authors to distinguish from the smaller unit). In most countries, labels of industrialized food products are required to indicate the nutritional energy value in (kilo or large) calories per serving or per weight.\nCalorie relates directly to the metric system, and therefore to the SI system. It is regarded as obsolete within the scientific community, since the adoption of the SI system, but is still in some use. The SI unit of energy is the joule. One calorie is defined as exactly 4.184 J, and one Calorie (kilocalorie) is 4184 J.\nHistory.\nThe calorie was first introduced by Nicolas Cl\u00e9ment, as a unit of heat energy, in lectures during the years 1819\u20131824. This was the \"large\" calorie, viz. modern kilocalorie. \nThe term entered French and English dictionaries between 1841 and 1867. It comes .\nThe \"small\" calorie (modern calorie) was introduced by Pierre Antoine Favre (Chemist) and Johann T. Silbermann (Physicist) in 1852. \nIn 1879, Marcellin Berthelot distinguished between gram-calorie (modern calorie) and kilogram-calorie (modern kilocalorie). Berthelot also introduced the convention of capitalizing the kilogram-calorie, as \"Calorie\".\nThe use of the kilogram-calorie (kcal) for nutrition was introduced to the American public by Wilbur Olin Atwater, a professor at Wesleyan University, in 1887.\nThe modern calorie (cal) was first recognized as a unit of the cm-g-s system (cgs) in 1896,\nalongside the already-existing cgs unit of energy, the erg (first suggested by Clausius in 1864, under the name \"ergon\", and officially adopted in 1882).\nAlready in 1928 there were serious complaints about the possible confusion arising from the two main definitions of the calorie and whether the notion of using the capital letter to distinguish them was sound.\nUse of the calorie was officially deprecated by the ninth General Conference on Weights and Measures, in 1948.\nThe alternate spelling \"calory\" is archaic.\nDefinitions.\nThe modern (small) calorie is defined as the amount of energy needed to increase the temperature of 1\u00a0gram of water by 1\u00a0\u00b0C (or 1\u00a0K, which is the same increment).\nThe definition depends on the atmospheric pressure and the starting temperature. Accordingly, several different precise definitions of the calorie have been used.\nThe two definitions most common in older literature appear to be the \"15\u00a0\u00b0C calorie\" and the \"thermochemical calorie\". Until 1948, the latter was defined as 4.1833 international joules; the current standard of 4.184\u00a0J was chosen to have the new thermochemical calorie represent the same quantity of energy as before.\nThe calorie was first defined specifically to measure energy in the form of heat, especially in experimental calorimetry.\nNutrition.\nIn a nutritional context, the kilojoule (kJ) is the SI unit of food energy, although the \"calorie\" is commonly used. The word \"calorie\" is commonly used with the number of kilocalories (kcal) of nutritional energy measured.\nIn the United States, most nutritionists prefer the unit kilocalorie to the unit kilojoules, whereas most physiologists prefer to use kilojoules. In the majority of other countries, nutritionists prefer the kilojoule to the kilocalorie. US food labelling laws require the use of kilocalories (under the name of \"Calories\"); kilojoules are permitted to be included on food labels alongside kilocalories, but most food labels do not do so. In Australia, kilojoules are officially preferred over kilocalories, but kilocalories retain some degree of popular use. Australian and New Zealand food labelling laws require the use of kilojoules; kilocalories are allowed to be included on labels in addition to kilojoules, but are not required. EU food labelling laws require both kilojoules and kilocalories on all nutritional labels, with the kilojoules listed first.\nTo facilitate comparison, specific energy or energy density figures are often quoted as \"calories per serving\" or \"kcal per 100\u00a0g\". A nutritional requirement or consumption is often expressed in calories or kilocalories per day. \nFood nutrients as fat (lipids) contains 9 kilocalories per gram (kcal/g), while carbohydrate (sugar) or protein contains approximately 4 kcal/g. Alcohol in food contains 7 kcal/g. Food nutrients are also often quoted \"per 100 g\".\nChemistry.\nIn other scientific contexts, the term \"calorie\" almost always refers to the small calorie. Even though it is not an SI unit, it is still used in chemistry. For example, the energy released in a chemical reaction per mole of reagent is occasionally expressed in kilocalories per mole. Typically, this use was largely due to the ease with which it could be calculated in laboratory reactions, especially in aqueous solution: a volume of reagent dissolved in water forming a solution, with concentration expressed in moles per litre (1 litre weighing 1\u00a0kilogram), will induce a temperature change in degrees Celsius in the total volume of water solvent, and these quantities (volume, molar concentration and temperature change) can then be used to calculate energy per mole. It is also occasionally used to specify energy quantities that relate to reaction energy, such as enthalpy of formation and the size of activation barriers. However, its use is being superseded by the SI unit, the joule, and multiples thereof such as the kilojoule.\nMeasurement of energy content of food.\nIn the past, a bomb calorimeter was used to determine the energy content of food by burning a sample and measuring a temperature change in the surrounding water. Today, this method is not commonly used in the United States and has been replaced by calculating the energy content indirectly from adding up the energy provided by energy-containing nutrients of food (such as protein, carbohydrates, and fats), the Modified Atwater system. The fibre content is also subtracted to account for the fact that fibre is not digested by the body."}
{"id": "6424", "revid": "8240947", "url": "https://en.wikipedia.org/wiki?curid=6424", "title": "Corona Australis", "text": "Corona Australis is a constellation in the Southern Celestial Hemisphere. Its Latin name means \"southern crown\", and it is the southern counterpart of Corona Borealis, the northern crown. It is one of the 48 constellations listed by the 2nd-century astronomer Ptolemy, and it remains one of the 88 modern constellations. The Ancient Greeks saw Corona Australis as a wreath rather than a crown and associated it with Sagittarius or Centaurus. Other cultures have likened the pattern to a turtle, ostrich nest, a tent, or even a hut belonging to a rock hyrax.\nAlthough fainter than its northern counterpart, the oval- or horseshoe-shaped pattern of its brighter stars renders it distinctive. Alpha and Beta Coronae Australis are the two brightest stars with an apparent magnitude of around 4.1. Epsilon Coronae Australis is the brightest example of a W Ursae Majoris variable in the southern sky. Lying alongside the Milky Way, Corona Australis contains one of the closest star-forming regions to the Solar System\u2014a dusty dark nebula known as the Corona Australis Molecular Cloud, lying about 430 light years away. Within it are stars at the earliest stages of their lifespan. The variable stars R and TY Coronae Australis light up parts of the nebula, which varies in brightness accordingly.\nName.\nThe name of the constellation was entered as \"Corona Australis\" when the International Astronomical Union (IAU) established the 88 modern constellations in 1922.\nIn 1932, the name was instead recorded as \"Corona Austrina\" when the IAU's commission on notation approved a list of four-letter abbreviations for the constellations.\nThe four-letter abbreviations were repealed in 1955. The IAU presently uses \"Corona Australis\" exclusively.\nCharacteristics.\nCorona Australis is a small constellation bordered by Sagittarius to the north, Scorpius to the west, Telescopium to the south, and Ara to the southwest. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"CrA\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of four segments (\"illustrated in infobox\"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between \u221236.77\u00b0 and \u221245.52\u00b0. Covering 128 square degrees, Corona Australis culminates at midnight around the 30th of June and ranks 80th in area. Only visible at latitudes south of 53\u00b0 north, Corona Australis cannot be seen from the British Isles as it lies too far south, but it can be seen from southern Europe and readily from the southern United States.\nFeatures.\nWhile not a bright constellation, Corona Australis is nonetheless distinctive due to its easily identifiable pattern of stars, which has been described as horseshoe- or oval-shaped. Though it has no stars brighter than 4th magnitude, it still has 21 stars visible to the unaided eye (brighter than magnitude 5.5). Nicolas Louis de Lacaille used the Greek letters Alpha through to Lambda to label the most prominent eleven stars in the constellation, designating two stars as Eta and omitting Iota altogether. Mu Coronae Australis, a yellow star of spectral type G5.5III and apparent magnitude 5.21, was labelled by Johann Elert Bode and retained by Benjamin Gould, who deemed it bright enough to warrant naming.\nStars.\nThe only star in the constellation to have received a name is Alfecca Meridiana or Alpha CrA. The name combines the Arabic name of the constellation with the Latin for \"southern\". In Arabic, \"Alfecca\" means \"break\", and refers to the shape of both Corona Australis and Corona Borealis. Also called simply \"Meridiana\", it is a white main sequence star located 125 light years away from Earth, with an apparent magnitude of 4.10 and spectral type A2Va. A rapidly rotating star, it spins at almost 200\u00a0km per second at its equator, making a complete revolution in around 14 hours. Like the star Vega, it has excess infrared radiation, which indicates it may be ringed by a disk of dust. It is currently a main-sequence star, but will eventually evolve into a white dwarf; currently, it has a luminosity 31 times greater, and a radius and mass of 2.3 times that of the Sun. Beta Coronae Australis is an orange giant 474 light years from Earth. Its spectral type is K0II, and it is of apparent magnitude 4.11. Since its formation, it has evolved from a B-type star to a K-type star. Its luminosity class places it as a bright giant; its luminosity is 730 times that of the Sun, designating it one of the highest-luminosity K0-type stars visible to the naked eye. 100 million years old, it has a radius of 43 solar radii () and a mass of between 4.5 and 5 solar masses (). Alpha and Beta are so similar as to be indistinguishable in brightness to the naked eye.\nSome of the more prominent double stars include Gamma Coronae Australis\u2014a pair of yellowish white stars 58 light years away from Earth, which orbit each other every 122 years. Widening since 1990, the two stars can be seen as separate with a 100\u00a0mm aperture telescope; they are separated by 1.3 arcseconds at an angle of 61 degrees. They have a combined visual magnitude of 4.2; each component is an F8V dwarf star with a magnitude of 5.01. Epsilon Coronae Australis is an eclipsing binary belonging to a class of stars known as W Ursae Majoris variables. These star systems are known as contact binaries as the component stars are so close together they touch. Varying by a quarter of a magnitude around an average apparent magnitude of 4.83 every seven hours, the star system lies 98 light years away. Its spectral type is F4VFe-0.8+. At the southern end of the crown asterism are the stars Eta\u00b9 and Eta\u00b2 Coronae Australis, which form an optical double. Of magnitude 5.1 and 5.5, they are separable with the naked eye and are both white. Kappa Coronae Australis is an easily resolved optical double\u2014the components are of apparent magnitudes 6.3 and 5.6 and are about 1000 and 150 light years away respectively. They appear at an angle of 359 degrees, separated by 21.6 arcseconds. Kappa\u00b2 is actually the brighter of the pair and is more bluish white, with a spectral type of B9V, while Kappa\u00b9 is of spectral type A0III. Lying 202 light years away, Lambda Coronae Australis is a double splittable in small telescopes. The primary is a white star of spectral type A2Vn and magnitude of 5.1, while the companion star has a magnitude of 9.7. The two components are separated by 29.2 arcseconds at an angle of 214 degrees.\nZeta Coronae Australis is a rapidly rotating main sequence star with an apparent magnitude of 4.8, 221.7 light years from Earth. The star has blurred lines in its hydrogen spectrum due to its rotation. Its spectral type is B9V. Theta Coronae Australis lies further to the west, a yellow giant of spectral type G8III and apparent magnitude 4.62. Corona Australis harbours RX J1856.5-3754, an isolated neutron star that is thought to lie 140 (\u00b140) parsecs, or 460 (\u00b1130) light years, away, with a diameter of 14\u00a0km. It was once suspected to be a strange star, but this has been discounted.\nDeep sky objects.\nIn the north of the constellation is the Corona Australis Molecular Cloud, a dark molecular cloud with many embedded reflection nebulae, including NGC 6729, NGC 6726\u20137, and IC 4812. A star-forming region of around , it contains Herbig\u2013Haro objects (protostars) and some very young stars. About 430 light years (130 parsecs) away, it is one of the closest star-forming regions to the Solar System. The related NGC 6726 and 6727, along with unrelated NGC 6729, were first recorded by Johann Friedrich Julius Schmidt in 1865. The Coronet cluster, about 554 light years (170 parsecs) away at the edge of the Gould Belt, is also used in studying star and protoplanetary disk formation.\nR Coronae Australis is an irregular variable star ranging from magnitudes 9.7 to 13.9. Blue-white, it is of spectral type B5IIIpe. A very young star, it is still accumulating interstellar material. It is obscured by, and illuminates, the surrounding nebula, NGC 6729, which brightens and darkens with it. The nebula is often compared to a comet for its appearance in a telescope, as its length is five times its width. S Coronae Australis is a G-class dwarf in the same field as R and is a T Tauri star. Nearby, another young variable star, TY Coronae Australis, illuminates another nebula: reflection nebula NGC 6726\u20137. TY Coronae Australis ranges irregularly between magnitudes 8.7 and 12.4, and the brightness of the nebula varies with it. Blue-white, it is of spectral type B8e. The largest young stars in the region, R, S, T, TY and VV Coronae Australis, are all ejecting jets of material which cause surrounding dust and gas to coalesce and form Herbig\u2013Haro objects, many of which have been identified nearby. Lying adjacent to the nebulosity is the globular cluster known as NGC 6723, which is actually in the neighbouring constellation of Sagittarius and is much much further away.\nNear Epsilon and Gamma Coronae Australis is Bernes 157, a dark nebula and star forming region. It is a large nebula, 55 by 18 arcminutes, that possesses several stars around magnitude 13. These stars have been dimmed by up to 8 magnitudes by its dust clouds.\nIC 1297 is a planetary nebula of apparent magnitude 10.7, which appears as a green-hued roundish object in higher-powered amateur instruments. The nebula surrounds the variable star RU Coronae Australis, which has an average apparent magnitude of 12.9 and is a WC class Wolf\u2013Rayet star. IC 1297 is small, at only 7 arcseconds in diameter; it has been described as \"a square with rounded edges\" in the eyepiece, elongated in the north\u2013south direction. Descriptions of its color encompass blue, blue-tinged green, and green-tinged blue.\nCorona Australis' location near the Milky Way means that galaxies are uncommonly seen. NGC 6768 is a magnitude 11.2 object 35\u2032 south of IC 1297. It is made up of two galaxies merging, one of which is an elongated elliptical galaxy of classification E4 and the other a lenticular galaxy of classification S0. IC 4808 is a galaxy of apparent magnitude 12.9 located on the border of Corona Australis with the neighbouring constellation of Telescopium and 3.9 degrees west-southwest of Beta Sagittarii. However, amateur telescopes will only show a suggestion of its spiral structure. It is 1.9 arcminutes by 0.8 arcminutes. The central area of the galaxy does appear brighter in an amateur instrument, which shows it to be tilted northeast\u2013southwest.\nSoutheast of Theta and southwest of Eta lies the open cluster ESO 281-SC24, which is composed of the yellow 9th magnitude star GSC 7914 178 1 and five 10th to 11th magnitude stars. Halfway between Theta Coronae Australis and Theta Scorpii is the dense globular cluster NGC 6541. Described as between magnitude 6.3 and magnitude 6.6, it is visible in binoculars and small telescopes. Around 22000 light years away, it is around 100 light years in diameter. It is estimated to be around 14 billion years old. NGC 6541 appears 13.1 arcminutes in diameter and is somewhat resolvable in large amateur instruments; a 12-inch telescope reveals approximately 100 stars but the core remains unresolved.\nMeteor showers.\nThe Corona Australids are a meteor shower that takes place between 14 and 18 March each year, peaking around 16 March. This meteor shower does not have a high peak hourly rate. In 1953 and 1956, observers noted a maximum of 6 meteors per hour and 4 meteors per hour respectively; in 1955 the shower was \"barely resolved\". However, in 1992, astronomers detected a peak rate of 45 meteors per hour. The Corona Australids' rate varies from year to year. At only six days, the shower's duration is particularly short, and its meteoroids are small; the stream is devoid of large meteoroids. The Corona Australids were first seen with the unaided eye in 1935 and first observed with radar in 1955. Corona Australid meteors have an entry velocity of 45 kilometers per second. In 2006, a shower originating near Beta Coronae Australis was designated as the Beta Coronae Australids. They appear in May, the same month as a nearby shower known as the May Microscopids, but the two showers have different trajectories and are unlikely to be related.\nHistory.\nCorona Australis may have been recorded by ancient Mesopotamians in the MUL.APIN, as a constellation called MA.GUR (\"The Bark\"). However, this constellation, adjacent to SUHUR.MASH (\"The Goat-Fish\", modern Capricornus), may instead have been modern Epsilon Sagittarii. As a part of the southern sky, MA.GUR was one of the fifteen \"stars of Ea\".\nIn the 3rd century BC, the Greek didactic poet Aratus wrote of, but did not name the constellation, instead calling the two crowns \u03a3\u03c4\u03b5\u03c6\u03ac\u03bd\u03bf\u03b9 (\"Stephanoi\"). The Greek astronomer Ptolemy described the constellation in the 2nd century AD, though with the inclusion of Alpha Telescopii, since transferred to Telescopium. Ascribing 13 stars to the constellation, he named it \u03a3\u03c4\u03b5\u03c6\u03ac\u03bd\u03bf\u03c2 \u03bd\u03bf\u03c4\u03b9\u03bf\u03c2 (), \"Southern Wreath\", while other authors associated it with either Sagittarius (having fallen off his head) or Centaurus; with the former, it was called \"Corona Sagittarii\". Similarly, the Romans called Corona Australis the \"Golden Crown of Sagittarius\". It was known as \"Parvum Coelum\" (\"Canopy\", \"Little Sky\") in the 5th century. The 18th-century French astronomer J\u00e9r\u00f4me Lalande gave it the names \"Sertum Australe\" (\"Southern Garland\") and \"Orbiculus Capitis\", while German poet and author Philippus Caesius called it \"Corolla\" (\"Little Crown\") or \"Spira Australis\" (\"Southern Coil\"), and linked it with the Crown of Eternal Life from the New Testament. Seventeenth-century celestial cartographer Julius Schiller linked it to the Diadem of Solomon. Sometimes, Corona Australis was not the wreath of Sagittarius but arrows held in his hand.\nCorona Australis has been associated with the myth of Bacchus and Stimula. Jupiter had impregnated Stimula, causing Juno to become jealous. Juno convinced Stimula to ask Jupiter to appear in his full splendor, which the mortal woman could not handle, causing her to burn. After Bacchus, Stimula's unborn child, became an adult and the god of wine, he honored his deceased mother by placing a wreath in the sky.\nIn Chinese astronomy, the stars of Corona Australis are located within the Black Tortoise of the North (\u5317\u65b9\u7384\u6b66, \"B\u011bi F\u0101ng Xu\u00e1n W\u01d4\"). The constellation itself was known as \"ti'en pieh\" (\"Heavenly Turtle\") and during the Western Zhou period, marked the beginning of winter. However, precession over time has meant that the \"Heavenly River\" (Milky Way) became the more accurate marker to the ancient Chinese and hence supplanted the turtle in this role. Arabic names for Corona Australis include \"Al \u0136ubbah\" \"the Tortoise\", \"Al \u0124ib\u0101\" \"the Tent\" or \"Al Ud\u1e25\u0101 al Na'\u0101m\" \"the Ostrich Nest\". It was later given the name \"Al Ikl\u012bl al Jan\u016bbiyyah\", which the European authors Chilmead, Riccioli and Caesius transliterated as Alachil Elgenubi, Elkleil Elgenubi and Aladil Algenubi respectively.\nThe \u01c0Xam speaking San people of South Africa knew the constellation as \"\u2260nabbe ta !nu\" \"house of branches\"\u2014owned originally by the Dassie (rock hyrax), and the star pattern depicting people sitting in a semicircle around a fire.\nThe indigenous Boorong people of northwestern Victoria saw it as \"Won\", a boomerang thrown by \"Totyarguil\" (Altair). The Aranda people of Central Australia saw Corona Australis as a coolamon carrying a baby, which was accidentally dropped to earth by a group of sky-women dancing in the Milky Way. The impact of the coolamon created Gosses Bluff crater, 175\u00a0km west of Alice Springs. The Torres Strait Islanders saw Corona Australis as part of a larger constellation encompassing part of Sagittarius and the tip of Scorpius's tail; the Pleiades and Orion were also associated. This constellation was Tagai's canoe, crewed by the Pleiades, called the \"Usiam\", and Orion, called the \"Seg\". The myth of Tagai says that he was in charge of this canoe, but his crewmen consumed all of the supplies onboard without asking permission. Enraged, Tagai bound the Usiam with a rope and tied them to the side of the boat, then threw them overboard. Scorpius's tail represents a suckerfish, while Eta Sagittarii and Theta Coronae Australis mark the bottom of the canoe. On the island of Futuna, the figure of Corona Australis was called \"Tanuma\" and in the Tuamotus, it was called \"Na Kaua-ki-Tonga\".\nReferences.\nSources.\n\"SIMBAD\""}
{"id": "6426", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=6426", "title": "Corcovado", "text": "Corcovado (), which means \"hunchback\" in Portuguese, is a mountain in central Rio de Janeiro, Brazil. It is a 710-metre (2,329\u00a0ft) granite peak located in the Tijuca Forest, a national park.\nCorcovado hill lies just west of the city center but is wholly within the city limits and visible from great distances. It is known worldwide for the 38-metre (125\u00a0ft) statue of Jesus atop its peak, entitled \"Christ the Redeemer\".\nAccess.\nThe peak and statue can be accessed via a narrow road, by the 3.8 kilometre (2.4\u00a0mi) Corcovado Rack Railway, which was opened in 1884 and refurbished in 1980, or by the walking trail on the south side of the mountain that starts from Parque Lage. The railway uses three electrically powered trains, with a passenger capacity of 540 passengers per hour. The rail trip takes approximately 20 minutes and departs every 20 minutes. Due to its limited passenger capacity, the wait to board at the entry station can take several hours. The year-round schedule is 8:30 to 18:30.\nFrom the train terminus and road, the observation deck at the foot of the statue is reached by 223 steps, or by elevators and escalators. Among the most popular year-round tourist attractions in Rio, the Corcovado railway, access roads, and statue platform are commonly crowded.\nAttractions.\nThe most popular attraction of Corcovado mountain is the statue and viewing platform at its peak, drawing over 300,000 visitors per year. From the peak's platform the panoramic view includes downtown Rio, Sugarloaf Mountain, the Lagoa Rodrigo de Freitas (lake), Copacabana and Ipanema beaches, Est\u00e1dio do Maracan\u00e3 (Maracan\u00e3 Stadium), and several of Rio's favelas. Cloud cover is common in Rio and the view from the platform is often obscured. Sunny days are recommended for optimal viewing.\nNotable past visitors to the mountain peak include Pope Pius XII, Pope John Paul II, Alberto Santos-Dumont, Albert Einstein, Diana, Princess of Wales, and General Sherman, among others. An additional attraction of the mountain is rock climbing. The south face had 54 climbing routes in 1992. The easiest way starts from Park Lage.\nThe Corcovado is also a symbol of the Brazilian culture.\nGeology.\nThe peak of Corcovado is a big granite dome, which describes a generally vertical rocky formation. It is claimed to be the highest such formation in Brazil, the second highest being Pedra Agulha, situated near to the town of Pancas in Esp\u00edrito Santo."}
{"id": "6427", "revid": "492987", "url": "https://en.wikipedia.org/wiki?curid=6427", "title": "Cheddar, Somerset", "text": "Cheddar is a large village and civil parish in the Sedgemoor district of the English county of Somerset. It is situated on the southern edge of the Mendip Hills, north-west of Wells, south-east of Weston-super-Mare and south-west of Bristol. The civil parish includes the hamlets of Nyland and Bradley Cross. The parish had a population of 5,755 in 2011 and an acreage of as of 1961.\nCheddar Gorge, on the northern edge of the village, is the largest gorge in the United Kingdom and includes several show caves, including Gough's Cave. The gorge has been a centre of human settlement since Neolithic times including a Saxon palace. It has a temperate climate and provides a unique geological and biological environment that has been recognised by the designation of several Sites of Special Scientific Interest. It is also the site of several limestone quarries. The village gave its name to Cheddar cheese and has been a centre for strawberry growing. The crop was formerly transported on the Cheddar Valley rail line, which closed in the late 1960s but is now a cycle path. The village is now a major tourist destination with several cultural and community facilities, including the Cheddar Show Caves Museum.\nThe village supports a variety of community groups including religious, sporting and cultural organisations. Several of these are based on the site of The Kings of Wessex Academy, which is the largest educational establishment.\nHistory.\nThe name Cheddar comes from the Old English word \"ceodor\", meaning deep dark cavity or pouch.\nThere is evidence of occupation from the Neolithic period in Cheddar. Britain's oldest complete human skeleton, Cheddar Man, estimated to be 9,000 years old, was found in Cheddar Gorge in 1903. Older remains from the Upper Late Palaeolithic era (12,000\u201313,000 years ago) have been found. There is some evidence of a Bronze Age field system at the Batts Combe quarry site. There is also evidence of Bronze Age barrows at the mound in the Longwood valley, which if man-made it is likely to be a field system. The remains of a Roman villa have been excavated in the grounds of the current vicarage.\nThe village of Cheddar had been important during the Roman and Saxon eras. There was a royal palace at Cheddar during the Saxon period, which was used on three occasions in the 10th century to host the Witenagemot. The ruins of the palace were excavated in the 1960s. They are located on the grounds of The Kings of Wessex Academy, together with a 14th-century chapel dedicated to St. Columbanus. Roman remains have also been uncovered at the site. Cheddar was listed in the Domesday Book of 1086 as \"Ceder\", meaning \"Shear Water\", from the Old English \"scear\" and Old Welsh \"d\u0175r\". An alternative spelling in earlier documents, common through the 1850s is \"Chedder\". As early as 1130\u00a0AD, the Cheddar Gorge was recognised as one of the \"Four wonders of England\". Historically, Cheddar's source of wealth was farming and cheese making for which it was famous as early as 1170\u00a0AD. The parish was part of the Winterstoke Hundred.\nThe manor of Cheddar was deforested in 1337 and Bishop Ralph was granted a licence by the King to create a hunting forest.\nAs early as 1527 there are records of watermills on the river. In the 17th and 18th centuries, there were several watermills which ground corn and made paper, with 13 mills on the Yeo at the peak, declining to seven by 1791 and just three by 1915.\nIn the Victorian era it also became a centre for the production of clothing. The last mill, used as a shirt factory, closed in the early 1950s. William Wilberforce saw the poor conditions of the locals when he visited Cheddar in 1789. He inspired Hannah More in her work to improve the conditions of the Mendip miners and agricultural workers. In 1801, of common land were enclosed under the Inclosure Acts.\nTourism of the Cheddar gorge and caves began with the opening of the Cheddar Valley Railway in 1869.\nCheddar, its surrounding villages and specifically the gorge has been subject to flooding. In the Chew Stoke flood of 1968 the flow of water washed large boulders down the gorge, washed away cars, and damaged the cafe and the entrance to Gough's Cave.\nGovernment.\nCheddar is recognised as a village. The adjacent settlement of Axbridge, although only about a third the population of Cheddar, is a town. This apparently illogical situation is explained by the relative importance of the two places in historic times. While Axbridge grew in importance as a centre for cloth manufacturing in the Tudor period and gained a charter from King John, Cheddar remained a more dispersed mining and dairy-farming village. Its population grew with the arrival of the railways in the Victorian era and the advent of tourism.\nThe parish council, which has 15 members who are elected for four years, is responsible for local issues, including setting an annual precept (local rate) to cover the council's operating costs and producing annual accounts for public scrutiny. The parish council evaluates local planning applications and works with the police, district council officers, and neighbourhood watch groups on matters of crime, security, and traffic. The parish council's role also includes initiating projects for the maintenance and repair of parish facilities, as well as consulting with the district council on the maintenance, repair, and improvement of highways, drainage, footpaths, public transport, and street cleaning. Conservation matters (including trees and listed buildings) and environmental issues are also the responsibility of the council.\nThe village is in the 'Cheddar and Shipham' electoral ward. After including Shipham the total population of the ward taken at the 2011 census is 6,842.\nThe village falls within the non-metropolitan district of Sedgemoor, which was formed on 1 April 1974 under the Local Government Act 1972. It was previously part of Axbridge Rural District. Sedgemoor is responsible for local planning and building control, local roads, council housing, environmental health, markets and fairs, refuse collection and recycling, cemeteries and crematoria, leisure services, parks, and tourism. Somerset County Council is responsible for running the largest and most expensive local services such as education, social services, the library, roads, public transport, trading standards, waste disposal and strategic planning, although fire, police and ambulance services are provided jointly with other authorities through the Devon and Somerset Fire and Rescue Service, Avon and Somerset Constabulary and the South Western Ambulance Service.\nIt is also part of the Wells county constituency represented in the House of Commons of the Parliament of the United Kingdom. It elects one Member of Parliament (MP) by the first past the post system of election. Prior to Brexit in 2020, it was part of the South West England constituency of the European Parliament.\nInternational relations.\nCheddar is twinned with Felsberg, Germany and Vernouillet, France, and it has an active programme of exchange visits. Initially, Cheddar twinned with Felsberg in 1984. In 2000, Cheddar twinned with Vernouillet, which had also been twinned with Felsberg. Cheddar also has a friendship link with Ocho Rios in Saint Ann Parish, Jamaica.\nGeography.\nThe area is underlain by Black Rock slate, Burrington Oolite and Clifton Down Limestone of the Carboniferous Limestone Series, which contain ooliths and fossil debris on top of Old Red Sandstone, and by Dolomitic Conglomerate of the Keuper. Evidence for Variscan orogeny is seen in the sheared rock and cleaved shales. In many places weathering of these strata has resulted in the formation of immature calcareous soils.\nGorge and caves.\nCheddar Gorge, which is located on the edge of the village, is the largest gorge in the United Kingdom.\nThe gorge is the site of the Cheddar Caves, where Cheddar Man was found in 1903. Older remains from the Upper Late Palaeolithic era (12,000\u201313,000 years ago) have been found. The caves, produced by the activity of an underground river, contain stalactites and stalagmites. Gough's Cave, which was discovered in 1903, leads around into the rock-face, and contains a variety of large rock chambers and formations. Cox's Cave, discovered in 1837, is smaller but contains many intricate formations. A further cave houses a children's entertainment walk known as the \"Crystal Quest\".\nCheddar Gorge, including Cox's Cave, Gough's Cave and other attractions, has become a tourist destination, attracting about 500,000 visitors per year.\nIn a 2005 poll of \"Radio Times\" readers, following its appearance on the 2005 television programme \"Seven Natural Wonders\", Cheddar Gorge was named as the second greatest natural wonder in Britain, surpassed only by the Dan yr Ogof caves.\nSites of Special Scientific Interest.\nThere are several large and unique Sites of Special Scientific Interest (SSSI) around the village.\nCheddar Reservoir is a near-circular artificial reservoir operated by Bristol Water. Dating from the 1930s, it has a capacity of 135\u00a0million\u00a0gallons (614,000\u00a0cubic\u00a0metres). The reservoir is supplied with water taken from the Cheddar Yeo, which rises in Gough's Cave in Cheddar Gorge and is a tributary of the River Axe. The inlet grate for the water pipe that is used to transport the water can be seen next to the sensory garden in Cheddar Gorge. It has been designated as a Site of Special Scientific Interest (SSSI) due to its wintering waterfowl populations.\nCheddar Wood and the smaller Macall's Wood form a biological Site of Special Scientific Interest from what remains of the wood of the Bishops of Bath and Wells in the 13th century and of King Edmund the Magnificent's wood in the 10th. During the 19th century, its lower fringes were grubbed out to make strawberry fields. Most of these have been allowed to revert to woodland. The wood was coppiced until 1917. This site compromises a wide range of habitats which include ancient and secondary semi-natural broadleaved woodland, unimproved neutral grassland, and a complex mosaic of calcareous grassland and acidic dry dwarf-shrub heath. Cheddar Wood is one of only a few English stations for starved wood-sedge (\"Carex depauperata\"). Purple gromwell (\"Lithospermum purpurocaeruleum\"), a nationally rare plant, also grows in the wood. Butterflies include silver-washed fritillary (\"Argynnis paphia\"), dark green fritillary (\"Argynnis aglaja\"), pearl-bordered fritillary (\"Boloria euphrosyne\"), holly blue (\"Celastrina argiolus\") and brown argus (\"Aricia agestis\"). The slug \"Arion fasciatus\", which has a restricted distribution in the south of England, and the soldier beetle \"Cantharis fusca\" also occur.\nBy far the largest of the SSSIs is called Cheddar Complex and covers of the gorge, caves and the surrounding area. It is important because of both biological and geological features. It includes four SSSIs, formerly known as Cheddar Gorge SSSI, August Hole/Longwood Swallet SSSI, GB Cavern Charterhouse SSSI and Charterhouse on-Mendip SSSI. It is partly owned by the National Trust who acquired it in 1910 and partly managed by the Somerset Wildlife Trust.\nQuarries.\nClose to the village and gorge are Batts Combe quarry and Callow Rock quarry, two of the active Quarries of the Mendip Hills where limestone is still extracted. Operating since the early 20th century, Batts Combe is owned and operated by Hanson Aggregates. The output in 2005 was around 4,000 tonnes of limestone per day, one third of which was supplied to an on-site lime kiln, which closed in 2009; the remainder was sold as coated or dusted aggregates. The limestone at this site is close to 99\u00a0percent carbonate of calcium and magnesium (dolomite).\nThe Chelmscombe Quarry finished its work as a limestone quarry in the 1950s and was then used by the Central Electricity Generating Board as a tower testing station. During the 1970s and 1980s it was also used to test the ability of containers of radioactive material to withstand impacts and other accidents.\nClimate.\nAlong with the rest of South West England, Cheddar has a temperate climate which is generally wetter and milder than the rest of the country. The annual mean temperature is approximately . Seasonal temperature variation is less extreme than most of the United Kingdom because of the adjacent sea, which moderates temperature. The summer months of July and August are the warmest with mean daily maxima of approximately . In winter mean minimum temperatures of or are common. In the summer the Azores high-pressure system affects the south-west of England. Convective cloud sometimes forms inland, reducing the number of hours of sunshine; annual sunshine rates are slightly less than the regional average of 1,600\u00a0hours. In December 1998 there were 20 days without sun recorded at Yeovilton. Most of the rainfall in the south-west is caused by Atlantic depressions or by convection. Most of the rainfall in autumn and winter is caused by the Atlantic depressions, which are most active during those seasons. In summer, a large proportion of the rainfall is caused by sun heating the ground leading to convection and to showers and thunderstorms. Average rainfall is around . About 8\u201315 days of snowfall per year is typical. November to March have the highest mean wind speeds, and June to August have the lightest winds. The predominant wind direction is from the south-west.\nDemography.\nThe parish has a population in 2011 of 5,093, with a mean age of 43 years. Residents lived in 2,209 households. The vast majority of households (2,183) gave their ethnic status at the 2001 census as white.\nEconomy.\nThe village gave its name to Cheddar cheese, which is the most popular type of cheese in the United Kingdom. The cheese is now made and consumed worldwide, and only one producer remains in the village.\nSince the 1880s, Cheddar's other main produce has been the strawberry,\nwhich is grown on the south-facing lower slopes of the Mendip hills. As a consequence of its use for transporting strawberries to market, the since-closed Cheddar Valley line became known as \"The Strawberry Line\" after it opened in 1869.\nThe line ran from Yatton to Wells. When the rest of the line was closed and all passenger services ceased, the section of the line between Cheddar and Yatton remained open for goods traffic. It provided a fast link with the main markets for the strawberries in Birmingham and London, but finally closed in 1964, becoming part of the Cheddar Valley Railway Nature Reserve.\nCheddar Ales is a small brewery based in the village, producing beer for local public houses. Tourism is a significant source of employment. Around 15\u00a0percent of employment in Sedgemoor is provided by tourism, but within Cheddar it is estimated to employ as many as 1,000 people.\nThe village also has a youth hostel, and a number of camping and caravan sites.\nCulture and community.\nCheddar has a number of active service clubs including Cheddar Vale Lions Club, Mendip Rotary and Mendip Inner Wheel Club. The clubs raise money for projects in the local community and hold annual events such as a fireworks display, duck races in the Gorge, a dragon boat race on the reservoir and concerts on the grounds of the nearby St Michael's Cheshire Home.\nSeveral notable people have been born or lived in Cheddar. Musician Jack Bessant, the bass guitarist with the band Reef grew up on his parents' strawberry farm, and Matt Goss and Luke Goss, former members of Bros, lived in Cheddar for nine months as children. Trina Gulliver, eight-time World Professional Darts Champion, currently lives in Cheddar. Forex trader Dan Legg was born in Cheddar. The comedian Richard Herring grew up in Cheddar. His 2008 Edinburgh Festival Fringe show, \"The Headmaster's Son\" is based on his time at The Kings of Wessex School, where his father Keith was the headmaster. The final performance of this show was held at the school in November 2009. He also visited the school in March 2010 to perform his show \"Hitler Moustache\". In May 2013, a community radio station called Pulse was launched.\nLandmarks.\nThe market cross in Bath Street dates from the 15th century, with the shelter having been rebuilt in 1834. It has a central octagonal pier, a socket raised on four steps, a hexagonal shelter with six arched four-centred openings, shallow two-stage buttresses at each angle, and an embattled parapet. The shaft is crowned by an abacus with figures in niches, probably from the late 19th century, although the cross is now missing. It was rebuilt by Thomas, Marquess of Bath. It is a scheduled monument (Somerset County No\u00a021) and Grade\u00a0II* listed building.\nIn January 2000, the cross was seriously damaged in a traffic accident. By 2002, the cross had been rebuilt and the area around it was redesigned to protect and enhance its appearance.\nThe cross was badly damaged again in March 2012, when a taxi crashed into it late at night demolishing two sides.\nRepair work, which included the addition of wooden-clad steel posts to protect against future crashes, was completed in November 2012 at a cost of \u00a360,000.\nHannah More, a philanthropist and educator, founded a school in the village in the late 18th century for the children of miners. Her first school was located in a 17th-century house. Now named \"Hannah More's Cottage\", the Grade II-listed building is used by the local community as a meeting place.\nTransport.\nThe village is situated on the A371 road which runs from Wincanton, to Weston-super-Mare. It is approximately from the route of the M5 motorway with around a drive to junction 22.\nIt was on the Cheddar Valley line, a railway line that was opened in 1869 and closed in 1963. It became known as The Strawberry Line because of the large volume of locally-grown strawberries that it carried. It ran from Yatton railway station through to Wells (Tucker Street) railway station and joined the East Somerset Railway to make a through route via Shepton Mallet (High Street) railway station to Witham. Sections of the now-disused railway have been opened as the Strawberry Line Trail, which currently runs from Yatton to Cheddar. The Cheddar Valley line survived until the \"Beeching Axe\". Towards the end of its life there were so few passengers that diesel railcars were sometimes used. The Cheddar branch closed to passengers on 9 September 1963 and to goods in 1964. The line closed in the 1960s, when it became part of the Cheddar Valley Railway Nature Reserve, and part of the National Cycle Network route\u00a026. The cycle route also intersects with the West Mendip Way and various other footpaths.\nThe principle bus route is hourly service 126 between Weston-super-Mare and Wells operated by First West of England.\nEducation.\nThe first school in Cheddar was set up by Hannah More during the 18th Century, however now Cheddar has three schools belonging to the Cheddar Valley Group of Schools, twelve schools that provide Cheddar Valley's three-tier education system. Cheddar First School has ten classes for children between 4 and 9 years. Fairlands Middle School, a middle school categorised as a middle-deemed-secondary school, has 510 pupils between 9 and 13. Fairlands takes children moving up from Cheddar First School as well as other first schools in the Cheddar Valley. The Kings of Wessex Academy, a coeducational comprehensive school, has been rated as \"good\" by Ofsted. It has 1,176 students aged 13 to 18, including 333 in the sixth form. Kings is a faith school linked to the Church of England. It was awarded the specialist status of Technology College in 2001, enabling it to develop its Information Technology (IT) facilities and improve courses in science, mathematics and design technology. In 2007 it became a foundation school, giving it more control over its own finances. The academy owns and runs a sports centre and swimming pool, Kings Fitness &amp; Leisure, with facilities that are used by students as well as residents. It has since November 2016 been a part of the Wessex Learning Trust which incorporates eight academies from the surrounding area.\nReligious sites.\nThe Church of St Andrew dates from the 14th century. It was restored in 1873 by William Butterfield. It is a Grade\u00a0I listed building and contains some 15th-century stained glass and an altar table of 1631. The chest tomb in the chancel is believed to contain the remains of Sir Thomas Cheddar and is dated 1442. The tower, which rises to , contains a bell dating from 1759 made by Thomas Bilbie of the Bilbie family.\nThere are also churches for Roman Catholic, Methodist and other denominations, including Cheddar Valley Community Church, who not only meet at The Kings of Wessex School on Sunday, but also have their own site on Tweentown for meeting during the week. The Baptist chapel was built in 1831.\nSport.\nKings Fitness &amp; Leisure, situated on the grounds of The Kings of Wessex School, provides a venue for various sports and includes a 20-metre swimming pool, racket sport courts, a sports hall, dance studios and a gym. A youth sports festival was held on Sharpham Road Playing Fields in 2009. In 2010 a skatepark was built in the village, funded by the Cheddar Local Action Team.\nCheddar Football Club, founded in 1892 and nicknamed \"The Cheesemen\", play in the Western Football League Division One. In 2009 plans were revealed to move the club from its present home at Bowdens Park on Draycott Road to a new larger site.\nCheddar Cricket Club was formed in the late 19th century and moved to Sharpham Road Playing Fields in 1964. They now play in the West of England Premier League Somerset Division. Cheddar Rugby Club, who own part of the Sharpham playing fields, was formed in 1836. The club organises an annual Cheddar Rugby Tournament. Cheddar Lawn Tennis Club, was formed in 1924, and play in the North Somerset League and also has social tennis and coaching. Cheddar Running Club organised an annual half marathon until 2009.\nThe village is both on the route of the West Mendip Way and Samaritans Way South West."}
{"id": "6429", "revid": "1879566", "url": "https://en.wikipedia.org/wiki?curid=6429", "title": "Compact disc", "text": "The compact disc (CD) is a digital optical disc data storage format that was co-developed by Philips and Sony to store and play digital audio recordings. It was released in 1982 branded as \"Digital Audio Compact Disc\".\nThe format was later adapted for storage of data (CD-ROM). Several other formats were further derived from these, including write-once audio and data storage (CD-R), rewritable media (CD-RW), Video CD (VCD), Super Video CD (SVCD), Photo CD, Picture CD, Compact Disc-Interactive (CD-i), and Enhanced Music CD.\nStandard CDs have a diameter of and are designed to hold up to 74 minutes of uncompressed stereo digital audio or about 650\u00a0MiB of data. Capacity is routinely extended to 80 minutes and 700\u00a0MiB by arranging more data closely on the same sized disc. The Mini CD has various diameters ranging from ; they are sometimes used for CD singles, storing up to 24 minutes of audio, or delivering device drivers.\nAt the time of the technology's introduction in 1982, a CD could store much more data than a personal computer hard disk drive, which would typically hold 10 MB. By 2010, hard drives commonly offered as much storage space as a thousand CDs, while their prices had plummeted to commodity level. In 2004, worldwide sales of audio CDs, CD-ROMs, and CD-Rs reached about 30 billion discs. By 2007, 200 billion CDs had been sold worldwide.\nPhysical details.\nA CD is made from thick, polycarbonate plastic and weighs 14\u201333 grams. From the center outward, components are: the center spindle hole (15\u00a0mm), the first-transition area (clamping ring), the clamping area (stacking ring), the second-transition area (mirror band), the program (data) area, and the rim. The inner program area occupies a radius from 25 to 58\u00a0mm.\nA thin layer of aluminum or, more rarely, gold is applied to the surface, making it reflective. The metal is protected by a film of lacquer normally spin coated directly on the reflective layer. The label is printed on the lacquer layer, usually by screen printing or offset printing.\nCD data is represented as tiny indentations known as \"pits\", encoded in a spiral track moulded into the top of the polycarbonate layer. The areas between pits are known as \"lands\". Each pit is approximately 100\u00a0nm deep by 500\u00a0nm wide, and varies from 850\u00a0nm to 3.5\u00a0\u00b5m in length. The distance between the tracks (the \"pitch\") is 1.6\u00a0\u00b5m.\nWhen playing an audio CD, a motor within the CD player spins the disc to a scanning velocity of 1.2\u20131.4\u00a0m/s (constant linear velocity, CLV)\u2014equivalent to approximately 500 RPM at the inside of the disc, and approximately 200 RPM at the outside edge. The track on the CD begins at the inside and spirals outward so a disc played from beginning to end slows its rotation rate during playback.\nThe program area is 86.05\u00a0cm2 and the length of the recordable spiral is With a scanning speed of 1.2\u00a0m/s, the playing time is 74 minutes, or 650\u00a0MiB of data on a CD-ROM. A disc with data packed slightly more densely is tolerated by most players (though some old ones fail). Using a linear velocity of 1.2\u00a0m/s and a narrower track pitch of 1.5\u00a0\u00b5m increases the playing time to 80 minutes, and data capacity to 700\u00a0MiB.\nA CD is read by focusing a 780\u00a0nm wavelength (near infrared) semiconductor laser through the bottom of the polycarbonate layer. The change in height between pits and lands results in a difference in the way the light is reflected. Because the pits are indented into the top layer of the disc and are read through the transparent polycarbonate base, the pits form bumps when read. The laser hits the disc, casting a circle of light wider than the modulated spiral track reflecting partially from the lands and partially from the top of any bumps where they are present. As the laser passes over a pit (bump), its height means that the part of the light reflected from its peak is 1/2 wavelength out of phase with the light reflected from the land around it. This causes partial cancellation of the laser's reflection from the surface. By measuring the reflected intensity change with a photodiode, a modulated signal is read back from the disc.\nTo accommodate the spiral pattern of data, the laser is placed on a mobile mechanism within the disc tray of any CD player. This mechanism typically takes the form of a sled that moves along a rail. The sled can be driven by a worm gear or linear motor. Where a worm gear is used, a second shorter-throw linear motor, in the form of a coil and magnet, makes fine position adjustments to track eccentricities in the disk at high speed. Some CD drives (particularly those manufactured by Philips during the 1980s and early 1990s) use a swing arm similar to that seen on a gramophone. This mechanism allows the laser to read information from the center to the edge of a disc without having to interrupt the spinning of the disc itself.\nThe pits and lands do \"not\" directly represent the 0's and 1's of binary data. Instead, non-return-to-zero, inverted encoding is used: a change from either pit to land or land to pit indicates a 1, while no change indicates a series of 0's. There must be at least 2, and no more than 10 0's between each 1, which is defined by the length of the pit. This, in turn, is decoded by reversing the eight-to-fourteen modulation used in mastering the disc, and then reversing the cross-interleaved Reed\u2013Solomon coding, finally revealing the raw data stored on the disc. These encoding techniques (defined in the \"Red Book\") were originally designed for CD Digital Audio, but they later became a standard for almost all CD formats (such as CD-ROM).\nIntegrity.\nCDs are susceptible to damage during handling and from environmental exposure. Pits are much closer to the label side of a disc, enabling defects and contaminants on the clear side to be out of focus during playback. Consequently, CDs are more likely to suffer damage on the label side of the disc. Scratches on the clear side can be repaired by refilling them with similar refractive plastic or by careful polishing. The edges of CDs are sometimes incompletely sealed, allowing gases and liquids to enter the CD and corrode the metal reflective layer and/or interfere with the focus of the laser on the pits, a condition known as disc rot. The fungus \"Geotrichum candidum\" has been found\u2014under conditions of high heat and humidity\u2014to consume the polycarbonate plastic and aluminium found in CDs.\nThe data integrity of compact discs can be measured using surface error scanning, which is able to measure the rates of different types of data errors, known as \"C1\", \"C2\", \"CU\" and extended (finer-grain) error measurements known as \"E11\", \"E12\", \"E21\", \"E22\", \"E31\" and \"E32\", of which higher rates indicate a possibly damaged or unclean data surface, low media quality, deteriorating media and recordable media written to by a malfunctioning CD writer.\nError scanning can reliably predict data losses caused by media deteriorating. Support of error scanning varies among vendors and models of optical disc drives, and \"extended\" error scanning (known as \"advanced error scanning\" in Nero DiscSpeed) has only been available on Plextor and some BenQ optical drives so far, as of 2020.\nDisc shapes and diameters.\nThe digital data on a CD begins at the center of the disc and proceeds toward the edge, which allows adaptation to the different size formats available. Standard CDs are available in two sizes. By far, the most common is in diameter, with a 74- or 80-minute audio capacity and a 650 or 700\u00a0MiB (737,280,000-byte) data capacity. Discs are 1.2\u00a0mm thick, with a 15\u00a0mm center hole. The official Philips history says this capacity was specified by Sony executive Norio Ohga to be able to contain the entirety of Beethoven's Ninth Symphony on one disc. This is a myth according to Kees Immink, as the EFM code format had not yet been decided in December 1979, when the decision to adopt the 120\u00a0mm was made. The adoption of EFM in June 1980 allowed 30 percent more playing time that would have resulted in 97 minutes for 120\u00a0 mm diameter or 74 minutes for a disc as small as 100\u00a0 mm. Instead, however, the information density was lowered by 30 percent to keep the playing time at 74 minutes. The 120\u00a0 mm diameter has been adopted by subsequent formats, including Super Audio CD, DVD, HD DVD, and Blu-ray Disc. The 80-mm-diameter discs (\"Mini CDs\") can hold up to 24 minutes of music or 210\u00a0MiB.\nLogical format.\nAudio CD.\nThe logical format of an audio CD (officially Compact Disc Digital Audio or CD-DA) is described in a document produced in 1980 by the format's joint creators, Sony and Philips. The document is known colloquially as the \"Red Book\" CD-DA after the color of its cover. The format is a two-channel 16-bit PCM encoding at a 44.1\u00a0kHz sampling rate per channel. Four-channel sound was to be an allowable option within the \"Red Book\" format, but has never been implemented. Monaural audio has no existing standard on a \"Red Book\" CD; thus, the mono source material is usually presented as two identical channels in a standard \"Red Book\" stereo track (i.e., mirrored mono); an MP3 CD, however, can have audio file formats with mono sound.\nCD-Text is an extension of the \"Red Book\" specification for an audio CD that allows for the storage of additional text information (e.g., album name, song name, artist) on a standards-compliant audio CD. The information is stored either in the lead-in area of the CD, where there is roughly five kilobytes of space available or in the subcode channels R to W on the disc, which can store about 31 megabytes.\nCompact Disc + Graphics is a special audio compact disc that contains graphics data in addition to the audio data on the disc. The disc can be played on a regular audio CD player, but when played on a special CD+G player, it can output a graphics signal (typically, the CD+G player is hooked up to a television set or a computer monitor); these graphics are almost exclusively used to display lyrics on a television set for karaoke performers to sing along with. The CD+G format takes advantage of the channels R through W. These six bits store the graphics information.\nCD + Extended Graphics (CD+EG, also known as CD+XG) is an improved variant of the Compact Disc + Graphics (CD+G) format. Like CD+G, CD+EG uses basic CD-ROM features to display text and video information in addition to the music being played. This extra data is stored in subcode channels R-W. Very few, if any, CD+EG discs have been published.\nSuper Audio CD.\nSuper Audio CD (SACD) is a high-resolution read-only optical audio disc format that was designed to provide higher-fidelity digital audio reproduction than the \"Red Book\". Introduced in 1999, it was developed by Sony and Philips, the same companies that created the \"Red Book\". SACD was in a format war with DVD-Audio, but neither has replaced audio CDs. The SACD standard is referred to as the \"Scarlet Book\" standard.\nTitles in the SACD format can be issued as hybrid discs; these discs contain the SACD audio stream as well as a standard audio CD layer which is playable in standard CD players, thus making them backward compatible.\nCD-MIDI.\nCD-MIDI is a format used to store music-performance data, which upon playback is performed by electronic instruments that synthesize the audio. Hence, unlike the original \"Red Book\" CD-DA, these recordings are not digitally sampled audio recordings. The CD-MIDI format is defined as an extension of the original \"Red Book\".\nCD-ROM.\nFor the first few years of its existence, the CD was a medium used purely for audio. However, in 1988, the \"Yellow Book\" CD-ROM standard was established by Sony and Philips, which defined a non-volatile optical data computer data storage medium using the same physical format as audio compact discs, readable by a computer with a CD-ROM drive.\nVideo CD (VCD).\nVideo CD (VCD, View CD, and Compact Disc digital video) is a standard digital format for storing video media on a CD. VCDs are playable in dedicated VCD players, most modern DVD-Video players, personal computers, and some video game consoles.\nThe VCD standard was created in 1993 by Sony, Philips, Matsushita, and JVC and is referred to as the \"White Book\" standard.\nOverall picture quality is intended to be comparable to VHS video. Poorly compressed VCD video can sometimes be lower quality than VHS video, but VCD exhibits block artifacts rather than analog noise and does not deteriorate further with each use.\n352\u00d7240 (or SIF) resolution was chosen because it is half the vertical and half the horizontal resolution of the NTSC video. 352\u00d7288 is similarly one-quarter PAL/SECAM resolution. This approximates the (overall) resolution of an analog VHS tape, which, although it has double the number of (vertical) scan lines, has a much lower horizontal resolution.\nSuper Video CD.\nSuper Video CD (Super Video Compact Disc or SVCD) is a format used for storing video media on standard compact discs. SVCD was intended as a successor to VCD and an alternative to DVD-Video and falls somewhere between both in terms of technical capability and picture quality.\nSVCD has two thirds the resolution of DVD, and over 2.7 times the resolution of VCD. One CD-R disc can hold up to 60 minutes of standard-quality SVCD-format video. While no specific limit on SVCD video length is mandated by the specification, one must lower the video bit rate, and therefore quality, to accommodate very long videos. It is usually difficult to fit much more than 100 minutes of video onto one SVCD without incurring significant quality loss, and many hardware players are unable to play video with an instantaneous bit rate lower than 300 to 600 kilobits per second.\nPhoto CD.\nPhoto CD is a system designed by Kodak for digitizing and storing photos on a CD. Launched in 1992, the discs were designed to hold nearly 100 high-quality images, scanned prints and slides using special proprietary encoding. Photo CDs are defined in the \"Beige Book\" and conform to the CD-ROM XA and CD-i Bridge specifications as well. They are intended to play on CD-i players, Photo CD players, and any computer with suitable software (irrespective of operating system). The images can also be printed out on photographic paper with a special Kodak machine. This format is not to be confused with Kodak Picture CD, which is a consumer product in CD-ROM format.\nCD-i.\nThe Philips \"Green Book\" specifies a standard for interactive multimedia compact discs designed for CD-i players (1993). CD-i discs can contain audio tracks that can be played on regular CD players, but CD-i discs are not compatible with most CD-ROM drives and software. The CD-i Ready specification was later created to improve compatibility with audio CD players, and the CD-i Bridge specification was added to create CD-i compatible discs that can be accessed by regular CD-ROM drives.\nCD-i Ready.\nPhilips defined a format similar to CD-i called CD-i Ready, which puts CD-i software and data into the pregap of track 1. This format was supposed to be more compatible with older audio CD players.\nEnhanced Music CD (CD+).\nEnhanced Music CD, also known as CD Extra or CD Plus, is a format which combines audio tracks and data tracks on the same disc by putting audio tracks in a first session and data in a second session. It was developed by Philips and Sony, and it is defined in the \"Blue Book\".\nVinylDisc.\nVinylDisc is the hybrid of a standard audio CD and the vinyl record. The vinyl layer on the disc's label side can hold approximately three minutes of music.\nManufacture.\nIn 1995, material costs were 30 cents for the jewel case and 10 to 15 cents for the CD. Wholesale cost of CDs was $0.75 to $1.15, while the typical retail price of a prerecorded music CD was $16.98. On average, the store received 35 percent of the retail price, the record company 27 percent, the artist 16 percent, the manufacturer 13 percent, and the distributor 9 percent. When 8-track cartridges, compact cassettes and CDs were introduced, each was marketed at a higher price than the format they succeeded, even though the cost to produce the media was reduced. This was done because the apparent value increased. This continued from vinyl to CDs but was broken when Apple marketed MP3s for $0.99, and albums for $9.99. The incremental cost, though, to produce an MP3 is negligible.\nWritable compact discs.\nRecordable CD.\nRecordable Compact Discs, CD-Rs, are injection-molded with a \"blank\" data spiral. A photosensitive dye is then applied, after which the discs are metalized and lacquer-coated. The write laser of the CD recorder changes the color of the dye to allow the read laser of a standard CD player to see the data, just as it would with a standard stamped disc. The resulting discs can be read by most CD-ROM drives and played in most audio CD players. CD-Rs follow the \"Orange Book\" standard.\nCD-R recordings are designed to be permanent. Over time, the dye's physical characteristics may change causing read errors and data loss until the reading device cannot recover with error correction methods. Errors can be predicted using surface error scanning. The design life is from 20 to 100 years, depending on the quality of the discs, the quality of the writing drive, and storage conditions. However, testing has demonstrated such degradation of some discs in as little as 18 months under normal storage conditions. This failure is known as disc rot, for which there are several, mostly environmental, reasons.\nThe recordable audio CD is designed to be used in a consumer audio CD recorder. These consumer audio CD recorders use SCMS (Serial Copy Management System), an early form of digital rights management (DRM), to conform to the AHRA (Audio Home Recording Act). The Recordable Audio CD is typically somewhat more expensive than CD-R due to lower production volume and a 3 percent AHRA royalty used to compensate the music industry for the making of a copy.\nHigh-capacity recordable CD is a higher-density recording format that can hold 20% more data than of conventional discs. The higher capacity is incompatible with some recorders and recording software.\nReWritable CD.\nCD-RW is a re-recordable medium that uses a metallic alloy instead of a dye. The write laser, in this case, is used to heat and alter the properties (amorphous vs. crystalline) of the alloy, and hence change its reflectivity. A CD-RW does not have as great a difference in reflectivity as a pressed CD or a CD-R, and so many earlier CD audio players \"cannot\" read CD-RW discs, although \"most\" later CD audio players and stand-alone DVD players can. CD-RWs follow the \"Orange Book\" standard.\nThe ReWritable Audio CD is designed to be used in a consumer audio CD recorder, which will not (without modification) accept standard CD-RW discs. These consumer audio CD recorders use the Serial Copy Management System (SCMS), an early form of digital rights management (DRM), to conform to the United States' Audio Home Recording Act (AHRA). The ReWritable Audio CD is typically somewhat more expensive than CD-R due to (a) lower volume and (b) a 3 percent AHRA royalty used to compensate the music industry for the making of a copy.\nCopy protection.\nThe \"Red Book\" audio specification, except for a simple \"anti-copy\" statement in the subcode, does not include any copy protection mechanism. Known at least as early as 2001, attempts were made by record companies to market \"copy-protected\" non-standard compact discs, which cannot be ripped, or copied, to hard drives or easily converted to other formats (like FLAC, MP3 or Vorbis). One major drawback to these copy-protected discs is that most will not play on either computer CD-ROM drives or some standalone CD players that use CD-ROM mechanisms. Philips has stated that such discs are not permitted to bear the trademarked \"Compact Disc Digital Audio\" logo because they violate the \"Red Book\" specifications. Numerous copy-protection systems have been countered by readily available, often free, software, or even by simply turning off automatic AutoPlay to prevent the running of the DRM executable program."}
{"id": "6431", "revid": "26801", "url": "https://en.wikipedia.org/wiki?curid=6431", "title": "Charles Farrar Browne", "text": "Charles Farrar Browne (April 26, 1834 \u2013 March 6, 1867) was an American humor writer, better known under his \"nom de plume\", Artemus Ward, which as a character, an illiterate rube with \"Yankee common sense\", Browne also played in public performances. He is considered to be America's first stand-up comedian. His birth name was Brown but he added the \"e\" after he became famous.\nBiography.\nBrowne was born in Waterford, Maine. He began his career as a compositor and occasional contributor to the daily and weekly journals. In 1858, in \"The Plain Dealer\" newspaper (Cleveland, Ohio), he published the first of the \"Artemus Ward\" series, which, in collected form, achieved great popularity in both America and England.\nBrownes' companion at the Plain Dealer, George Hoyt, wrote: \"his desk was a rickety table which had been whittled and gashed until it looked as if it had been the victim of lightning. His chair was a fit companion thereto, a wabbling, unsteady affair, sometimes with four and sometimes with three legs. But Browne saw neither the table, nor the chair, nor any person who might be near, nothing, in fact, but the funny pictures which were tumbling out of his brain. When writing, his gaunt form looked ridiculous enough. One leg hung over the arm of his chair like a great hook, while he would write away, sometimes laughing to himself, and then slapping the table in the excess of his mirth.\"\nIn 1860, he became editor of the first \"Vanity Fair\", a humorous New York weekly that failed in 1863. At about the same time, he began to appear as a lecturer who, by his droll and eccentric humor, attracted large audiences. Browne was also known as a member of the New York bohemian set which included leader Henry Clapp Jr., Walt Whitman, Fitz Hugh Ludlow, and actress Adah Isaacs Menken. \nIn 1863, Browne came to San Francisco to perform as Artemus Ward. An early expert at show business publicity, Browne sent his manager ahead by several weeks to buy advertising in the local papers and promote the show among prominent citizens for endorsements. On November 13, 1863, Browne stood before a packed crowd at Platt's Music Hall, playing the part of Artemus Ward as an illiterate rube but with \"Yankee common sense.\" Writer Brett Harte was in the audience that night and he described it in \"the Golden Era\" as capturing American speech: \"humor that belongs to the country of boundless prairies, limitless rivers, and stupendous cataracts--that fun which overlies the surface of our national life, which is met in the stage, rail-car, canal and flat-boat, which bursts out over camp-fires and around bar-room stoves.\"\n\"Artemus Ward\" was a favorite author of U.S. President Abraham Lincoln. Before presenting \"The Emancipation Proclamation\" to his Cabinet, Lincoln read to them the latest episode, \"Outrage in Utiky\", also known as \"High-Handed Outrage at Utica\".\nWhen Browne performed in Virginia City, Nevada, he met Mark Twain and the two became friends. In his correspondence with Twain, Browne called him \"My Dearest Love.\" Legend has it that, following a stage performance there, Browne, Twain, and Dan De Quille were trekking on a (drunken) rooftop tour of Virginia City until a town constable threatened to blast all three with a shotgun loaded with rock salt. Browne recommended Twain to the editors of the New York Press and urged him to journey to New York.\nIn 1866, Browne visited England and attracted a large following to his playing Artemus Ward, both as lecturer and for his writerly contributions to \"Punch\". But within a year his health gave way and he died of tuberculosis at Southampton on March 6, 1867.\nIn England Browne was buried at Kensal Green Cemetery, but his remains were removed to the United States in 1868 and buried at Elm Vale Cemetery in Waterford, Maine."}
{"id": "6432", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=6432", "title": "Caelum", "text": "Caelum is a faint constellation in the southern sky, introduced in the 1750s by Nicolas Louis de Lacaille and counted among the 88 modern constellations. Its name means \u201c\"chisel\"\u201d in Latin, and it was formerly known as Caelum Sculptorium (\u201c\"the engravers\u2019 chisel\"\u201d); It is a rare word, unrelated to the far more common Latin \"caelum\", meaning \u201csky, heaven, atmosphere\u201d. It is the eighth-smallest constellation, and subtends a solid angle of around 0.038\u00a0steradians, just less than that of Corona Australis.\nDue to its small size and location away from the plane of the Milky Way, Caelum is a rather barren constellation, with few objects of interest. The constellation's brightest star, Alpha Caeli, is only of magnitude\u00a04.45, and only one other star, (Gamma) \u03b3\u00a01\u00a0Caeli, is brighter than magnitude 5\u00a0. Other notable objects in Caelum are RR\u00a0Caeli, a binary star with one known planet approximately away; X\u00a0Caeli, a Delta Scuti variable that forms an optical double with \u03b3\u00a01\u00a0Caeli; and HE0450-2958, a Seyfert galaxy that at first appeared as just a jet, with no host galaxy visible.\nHistory.\nCaelum was incepted as one of fourteen southern constellations in the 18th century by Nicolas Louis de Lacaille, a French astronomer and celebrater of the Age of Enlightenment.\nIt retains its name \"Burin\" among French speakers, latinized in his catalogue of 1763 as \"Caelum Sculptoris\" (\u201c\"Engraver's Chisel\"\u201d).\nFrancis Baily shortened this name to \"Caelum\", as suggested by John Herschel. In Lacaille's original chart, it was shown as a pair of engraver's tools: a standard burin and more specific shape-forming \u00e9choppe tied by a ribbon, but came to be ascribed a simple chisel. Johann Elert Bode stated the name as plural with a singular possessor, \"Caela Scalptoris\" \u2013 in German (\"die\"\u00a0) \"Grabstichel\" (\u201c\"the Engraver\u2019s Chisels\"\u201d) \u2013 but this did not stick.\nCharacteristics.\nCaelum is bordered by Dorado and Pictor to the south, Horologium and Eridanus to the east, Lepus to the north, and Columba to the west. Covering only 125\u00a0square degrees, it ranks 81st of the 88 modern constellations in size. \nIts main asterism consists of four stars, and twenty stars in total are brighter than magnitude\u00a06.5\u00a0.\nThe constellation's boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are a 12-sided polygon. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and and declinations of to . The International Astronomical Union (IAU) adopted the three-letter abbreviation \u201cCae\u201d for the constellation in 1922.\nIts main stars are visible in favourable conditions and with a clear southern horizon, for part of the year as far as about the 41st parallel north\nThese stars avoid being engulfed by daylight for some of every day (when above the horizon) to viewers in mid- and well-inhabited higher latitudes of the Southern Hemisphere. Caelum shares with (to the north) Taurus, Eridanus and Orion midnight culmination in December (high summer), resulting in this fact. In winter (such as June) the constellation can be observed sufficiently inset from the horizons during its rising before dawn and/or setting after dusk as it culminates then at around mid-day, well above the sun. In South Africa, Argentina, their sub-tropical neighbouring areas and some of Australia in high June the key stars may be traced before dawn in the east; near the equator the stars lose night potential in May to June; they ill-compete with the Sun in northern tropics and sub-tropics from late February to mid-September with March being unfavorable as to post-sunset due to the light of the Milky Way.\nNotable features.\nStars.\nCaelum is a faint constellation: It has no star brighter than magnitude\u00a04 and only two stars brighter than magnitude\u00a05.\nLacaille gave six stars Bayer designations, labeling them Alpha (\u03b1\u00a0) to Zeta (\u03b6\u00a0) in 1756, but omitted Epsilon (\u03b5\u00a0) and designated two adjacent stars as Gamma (\u03b3\u00a0). Bode extended the designations to Rho (\u03c1\u00a0) for other stars, but most of these have fallen out of use. Caelum is too far south for any of its stars to bear Flamsteed designations.\nThe brightest star, (Alpha) \u03b1\u00a0Caeli, is a double star, containing an F-type main-sequence star of magnitude\u00a04.45 and a red dwarf of magnitude\u00a012.5\u00a0, from Earth. (Beta) \u03b2\u00a0Caeli, another F-type star of magnitude\u00a05.05\u00a0, is further away, being located from Earth. Unlike \u03b1, \u03b2\u00a0Caeli is a subgiant star, slightly evolved from the main sequence. (Delta) \u03b4\u00a0Caeli, also of magnitude\u00a05.05\u00a0, is a B-type subgiant and is much farther from Earth, at .\n(Gamma) \u03b3\u00a01\u00a0Caeli is a double-star with a red giant primary of magnitude\u00a04.58 and a secondary of magnitude\u00a08.1\u00a0. The primary is from Earth. The two components are difficult to resolve with small amateur telescopes because of their difference in visual magnitude and their close separation. This star system forms an optical double with the unrelated X\u00a0Caeli (previously named \u03b3\u00a02\u00a0Caeli), a Delta Scuti variable located from Earth. These are a class of short-period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. X\u00a0Caeli itself is also a binary star, specifically a contact binary, meaning that the stars are so close that they share envelopes. The only other variable star in Caelum visible to the naked eye is RV\u00a0Caeli, a pulsating red giant of spectral type M1III, which varies between magnitudes\u00a06.44 and 6.56\u00a0.\nThree other stars in Caelum are still occasionally referred to by their Bayer designations, although they are only on the edge of naked-eye visibility. (Nu) \u03bd\u00a0Caeli is another double star, containing a white giant of magnitude\u00a06.07 and a star of magnitude\u00a010.66, with unknown spectral type. The system is approximately away. (Lambda) \u03bb\u00a0Caeli, at magnitude\u00a06.24, is much redder and farther away, being a red giant around from Earth. (Zeta) \u03b6\u00a0Caeli is even fainter, being only of magnitude\u00a06.36\u00a0. This star, located away, is a K-type subgiant of spectral type K1. The other twelve naked-eye stars in Caelum are not referred to by Bode's Bayer designations anymore, including RV\u00a0Caeli.\nOne of the nearest stars in Caelum is the eclipsing binary star RR\u00a0Caeli, at a distance of . This star system consists of a dim red dwarf and a white dwarf. Despite its closeness to the Earth, the system's apparent magnitude is only 14.40 due to the faintness of its components, and thus it cannot be easily seen with amateur equipment. In 2012, the system was found to contain a giant planet, and there is evidence for a second substellar body. The system is a post-common-envelope binary and is losing angular momentum over time, which will eventually cause mass transfer from the red dwarf to the white dwarf. In approximately 9\u201320 billion years, this will cause the system to become a cataclysmic variable.\nDeep-sky objects.\nDue to its small size and location away from the plane of the Milky Way, Caelum is rather devoid of deep-sky objects, and contains no Messier objects. The only deep-sky object in Caelum to receive much attention is HE0450-2958, an unusual Seyfert galaxy. Originally, the jet's host galaxy proved elusive to find, and this jet appeared to be emanating from nothing. Although it has been suggested that the object is an ejected supermassive black hole, the host is now agreed to be a small galaxy that is difficult to see due to light from the jet and a nearby starburst galaxy.\nThe 13th magnitude planetary nebula PN G243-37.1 is also in the eastern regions of the constellation. It is one of only a few planetary nebulae found in the galactic halo, being light-years below the Milky Way's 1000 light-year-thick disk."}
{"id": "6433", "revid": "850615", "url": "https://en.wikipedia.org/wiki?curid=6433", "title": "Clarinet", "text": " \nThe clarinet is a family of woodwind instruments. It has a single-reed mouthpiece, a straight, cylindrical tube with an almost cylindrical bore, and a flared bell. A person who plays a clarinet is called a \"clarinetist\" (sometimes spelled \"clarinettist\").\nWhile the similarity in sound between the earliest clarinets and the trumpet may hold a clue to its name, other factors may have been involved. During the Late Baroque era, composers such as Bach and Handel were making new demands on the skills of their trumpeters, who were often required to play difficult melodic passages in the high, or as it came to be called, \"clarion\" register. Since the trumpets of this time had no valves or pistons, melodic passages would often require the use of the highest part of the trumpet's range, where the harmonics were close enough together to produce scales of adjacent notes as opposed to the gapped scales or arpeggios of the lower register. The trumpet parts that required this specialty were known by the term \"clarino\" and this in turn came to apply to the musicians themselves. It is probable that the term clarinet may stem from the diminutive version of the 'clarion' or 'clarino' and it has been suggested that clarino players may have helped themselves out by playing particularly difficult passages on these newly developed \"mock trumpets\".\nJohann Christoph Denner is generally believed to have invented the clarinet in Germany around the year 1700 by adding a register key to the earlier chalumeau, usually in the key of C. Over time, additional keywork and airtight pads were added to improve the tone and playability.\nIn modern times, the most common clarinet is the B clarinet. However, the clarinet in A, pitched a semitone lower, is regularly used in orchestral, chamber and solo music. An orchestral clarinetist must own both a clarinet in A and B since the repertoire is divided fairly evenly between the two. Since the middle of the 19th century, the bass clarinet (nowadays invariably in B but with extra keys to extend the register down to low written C3) has become an essential addition to the orchestra. The clarinet family ranges from the (extremely rare) BBB octo-contrabass to the A piccolo clarinet. The clarinet has proved to be an exceptionally flexible instrument, used in the classical repertoire as in concert bands, military bands, marching bands, klezmer, jazz, and other styles.\nEtymology.\nThe word \"clarinet\" may have entered the English language via the French \"clarinette\" (the feminine diminutive of Old French \"clarin\" or \"clarion\"), or from Proven\u00e7al \"\", \"oboe\".\nIt would seem, however, that its real roots are to be found among some of the various names for trumpets used around the Renaissance and Baroque eras. \"Clarion\", \"clarin\", and the Italian \"clarino\" are all derived from the medieval term \"claro\", which referred to an early form of trumpet. This is probably the origin of the Italian \"clarinetto\", itself a diminutive of \"clarino\", and consequently of the European equivalents such as \"clarinette\" in French or the German \"Klarinette\". According to Johann Gottfried Walther, writing in 1732, the reason for the name is that \"it sounded from far off not unlike a trumpet\". The English form \"clarinet\" is found as early as 1733, and the now-archaic \"clarionet\" appears from 1784 until the early years of the 20th century.\nCharacteristics.\nSound.\nThe cylindrical bore is primarily responsible for the clarinet's distinctive timbre, which varies between its three main registers, known as the \"chalumeau\", \"clarion\", and \"altissimo\". The tone quality can vary greatly with the clarinetist, music, instrument, mouthpiece, and reed. The differences in instruments and geographical isolation of clarinetists led to the development from the last part of the 18th century onwards of several different schools of playing. The most prominent were the German/Viennese traditions and French school. The latter was centered on the clarinetists of the Conservatoire de Paris. The proliferation of recorded music has made examples of different styles of playing available. The modern clarinetist has a diverse palette of \"acceptable\" tone qualities to choose from.\nThe A and B clarinets have nearly the same bore and use the same mouthpiece. Orchestral clarinetists using the A and B instruments in a concert could use the same mouthpiece (and often the same barrel) (see 'usage' below). The A and B have nearly identical tonal quality, although the A typically has a slightly warmer sound. The tone of the E clarinet is brighter and can be heard even through loud orchestral or concert band textures. The bass clarinet has a characteristically deep, mellow sound, while the alto clarinet is similar in tone to the bass (though not as dark).\nRange.\nClarinets have the largest pitch range of common woodwinds. The intricate key organization that makes this possible can make the playability of some passages awkward. The bottom of the clarinet's written range is defined by the keywork on each instrument, standard keywork schemes allowing a low E on the common B clarinet. The lowest concert pitch depends on the transposition of the instrument in question. The nominal highest note of the B clarinet is a semitone higher than the highest note of the oboe but this depends on the setup and skill of the player. Since the clarinet has a wider range of notes, the lowest note of the B clarinet is significantly deeper (a minor or major sixth) than the lowest note of the oboe.\nNearly all soprano and piccolo clarinets have keywork enabling them to play the E below middle C as their lowest written note (in scientific pitch notation that sounds D3 on a soprano clarinet or C4, i.e. concert middle C, on a piccolo clarinet), though some B clarinets go down to E3 to enable them to match the range of the A clarinet. On the B soprano clarinet, the concert pitch of the lowest note is D3, a whole tone lower than the written pitch. Most alto and bass clarinets have an extra key to allow a (written) E3. Modern professional-quality bass clarinets generally have additional keywork to written C3. Among the less commonly encountered members of the clarinet family, contra-alto and contrabass clarinets may have keywork to written E3, D3, or C3; the basset clarinet and basset horn generally go to low C3.\nDefining the top end of a clarinet's range is difficult, since many advanced players can produce notes well above the highest notes commonly found in method books. G6 is usually the highest note clarinetists encounter in classical repertoire. The C above that (C7 i.e. resting on the fifth ledger line above the treble staff) is attainable by advanced players and is shown on many fingering charts, and fingerings as high as A7 exist.\nThe range of a clarinet can be divided into three distinct registers:\nAll three registers have characteristically different sounds. The chalumeau register is rich and dark. The clarion register is brighter and sweet, like a trumpet (\"clarion\") heard from afar. The altissimo register can be piercing and sometimes shrill.\nAcoustics.\nSound is a wave that propagates through the air as a result of a local variation in air pressure. The production of sound by a clarinet follows these steps:\nThe cycle repeats at a frequency relative to how long it takes a wave to travel to the first open hole and back twice (i.e. four times the length of the pipe). For example: when all the holes bar the very top one are open (i.e. the trill 'B' key is pressed), the note A4 (440 Hz) is produced. This represents a repeat of the cycle 440 times per second.\nIn addition to this primary compression wave, other waves, known as harmonics, are created. Harmonics are caused by factors including the imperfect wobbling and shaking of the reed, the reed sealing the mouthpiece opening for part of the wave cycle (which creates a flattened section of the sound wave), and imperfections (bumps and holes) in the bore. A wide variety of compression waves are created, but only some (primarily the odd harmonics) are reinforced. These extra waves are what gives the clarinet its characteristic tone.\nThe bore is cylindrical for most of the tube with an inner bore diameter between , but there is a subtle hourglass shape, with the thinnest part below the junction between the upper and lower joint. The reduction is depending on the maker. This hourglass shape, although invisible to the naked eye, helps to correct the pitch/scale discrepancy between the chalumeau and clarion registers (perfect twelfth). The diameter of the bore affects characteristics such as available harmonics, timbre, and pitch stability (how far the player can bend a note in the manner required in jazz and other music). The bell at the bottom of the clarinet flares out to improve the tone and tuning of the lowest notes.\nMost modern clarinets have \"undercut\" tone holes that improve intonation and sound. Undercutting means chamfering the bottom edge of tone holes inside the bore. Acoustically, this makes the tone hole function as if it were larger, but its main function is to allow the air column to follow the curve up through the tone hole (surface tension) instead of \"blowing past\" it under the increasingly directional frequencies of the upper registers.\nThe fixed reed and fairly uniform diameter of the clarinet give the instrument an acoustical behavior approximating that of a cylindrical stopped pipe. Recorders use a tapered internal bore to overblow at the octave when the thumb/register hole is pinched open, while the clarinet, with its cylindrical bore, overblows at the twelfth. Adjusting the angle of the bore taper controls the frequencies of the overblown notes (harmonics). Changing the mouthpiece's tip opening and the length of the reed changes aspects of the harmonic timbre or voice of the clarinet because this changes the speed of reed vibrations. Generally, the goal of the clarinetist when producing a sound is to make as much of the reed vibrate as possible, making the sound fuller, warmer, and potentially louder.\nThe lip position and pressure, shaping of the vocal tract, choice of reed and mouthpiece, amount of air pressure created, and evenness of the airflow account for most of the clarinetist's ability to control the tone of a clarinet. A highly skilled clarinetist will provide the ideal lip and air pressure for each frequency (note) being produced. They will have an embouchure which places an even pressure across the reed by carefully controlling their lip muscles. The airflow will also be carefully controlled by using the strong stomach muscles (as opposed to the weaker and erratic chest muscles) and they will use the diaphragm to oppose the stomach muscles to achieve a tone softer than a forte rather than weakening the stomach muscle tension to lower air pressure. Their vocal tract will be shaped to resonate at frequencies associated with the tone being produced.\nCovering or uncovering the tone holes varies the length of the pipe, changing the resonant frequencies of the enclosed air column and hence the pitch. A clarinetist moves between the chalumeau and clarion registers through use of the register key; clarinetists call the change from chalumeau register to clarion register \"the break\". The open register key stops the fundamental frequency from being reinforced, and the reed is forced to vibrate at three times the speed it was originally. This produces a note a twelfth above the original note.\nMost instruments overblow at two times the speed of the fundamental frequency (the octave), but as the clarinet acts as a closed pipe system, the reed cannot vibrate at twice its original speed because it would be creating a 'puff' of air at the time the previous 'puff' is returning as a rarefaction. This means it cannot be reinforced and so would die away. The chalumeau register plays fundamentals, whereas the clarion register, aided by the register key, plays third harmonics (a perfect twelfth higher than the fundamentals). The first several notes of the altissimo range, aided by the register key and venting with the first left-hand hole, play fifth harmonics (a major seventeenth, a perfect twelfth plus a major sixth, above the fundamentals). The clarinet is therefore said to overblow at the twelfth and, when moving to the altissimo register, seventeenth.\nBy contrast, nearly all other woodwind instruments overblow at the octave or (like the ocarina and tonette) do not overblow at all. A clarinet must have holes and keys for nineteen notes, a chromatic octave and a half from bottom E to B, in its lowest register to play the chromatic scale. This overblowing behavior explains the clarinet's great range and complex fingering system. The fifth and seventh harmonics are also available, sounding a further sixth and fourth (a flat, diminished fifth) higher respectively; these are the notes of the altissimo register. This is also why the inner \"waist\" measurement is so critical to these harmonic frequencies.\nThe highest notes can have a shrill, piercing quality and can be difficult to tune accurately. Different instruments often play differently in this respect due to the sensitivity of the bore and reed measurements. Using alternate fingerings and adjusting the embouchure helps correct the pitch of these notes.\nSince approximately 1850, clarinets have been nominally tuned according to twelve-tone equal temperament. Older clarinets were nominally tuned to meantone. Skilled performers can use their embouchures to considerably alter the tuning of individual notes or produce vibrato, a pulsating change of pitch often employed in jazz. Vibrato is rare in classical or concert band literature; however, certain clarinetists, such as Richard Stoltzman, use vibrato in classical music. Special fingerings may be used to play quarter tones and other microtonal intervals.\nAround 1900, Dr. Richard H. Stein, a Berlin musicologist, made a quarter-tone clarinet, which was soon abandoned. Years later, another German, Fritz Sch\u00fcller of Markneukirchen, built a quarter tone clarinet, with two parallel bores of slightly different lengths whose tone holes are operated using the same keywork and a valve to switch from one bore to the other.\nConstruction.\nMaterials.\nClarinet bodies have been made from a variety of materials including wood, plastic, hard rubber, metal, resin, and ivory. The vast majority of clarinets used by professionals are made from African hardwood, mpingo (African Blackwood) or grenadilla, rarely (because of diminishing supplies) Honduran rosewood, and sometimes even cocobolo. Historically other woods, notably boxwood, were used. Most inexpensive clarinets are made of plastic resin, such as ABS. \"Resonite\" is Selmer's trademark name for its type of plastic. Metal soprano clarinets were popular in the early 20th century until plastic instruments supplanted them; metal construction is still used for the bodies of some contra-alto and contrabass clarinets and the necks and bells of nearly all alto and larger clarinets. Ivory was used for a few 18th-century clarinets, but it tends to crack and does not keep its shape well. Buffet Crampon's Greenline clarinets are made from a composite of grenadilla wood powder and carbon fiber. Such clarinets are less affected by humidity and temperature changes than wooden instruments but are heavier. Hard rubber, such as ebonite, has been used for clarinets since the 1860s, although few modern clarinets are made of it. Clarinet designers Alastair Hanson and Tom Ridenour are strong advocates of hard rubber. The Hanson Clarinet Company manufactures clarinets using a grenadilla compound reinforced with ebonite, known as \"BTR\" (bithermal-reinforced) grenadilla. This material is also not affected by humidity, and the weight is the same as that of a wooden clarinet.\nMouthpieces are generally made of hard rubber, although some inexpensive mouthpieces may be made of plastic. Other materials such as crystal/glass, wood, ivory, and metal have also been used. Ligatures are often made of metal and plated in nickel, silver, or gold. Other materials include wire, wire mesh, plastic, naugahyde, string, or leather.\nReed.\nThe clarinet uses a single reed made from the cane of \"Arundo donax\", a type of grass. Reeds may also be manufactured from synthetic materials. The ligature fastens the reed to the mouthpiece. When air is blown through the opening between the reed and the mouthpiece facing, the reed vibrates and produces the clarinet's sound.\nBasic reed measurements are as follows: tip, wide; lay, long (distance from the place where the reed touches the mouthpiece to the tip); gap, (distance between the underside of the reed tip and the mouthpiece). Adjustment to these measurements is one method of affecting tone color.\nMost clarinetists buy manufactured reeds, although many make adjustments to these reeds, and some make their own reeds from cane \"blanks\". Reeds come in varying degrees of hardness, generally indicated on a scale from one (soft) through five (hard). This numbering system is not standardized\u2014reeds with the same number often vary in hardness across manufacturers and models. Reed and mouthpiece characteristics work together to determine ease of playability, pitch stability, and tonal characteristics.\nComponents.\nNote: A B\u00f6hm system soprano clarinet is shown in the photos illustrating this section. However, all modern clarinets have similar components.\nThe \"reed\" is attached to the \"mouthpiece\" by the \"ligature\", and the top half-inch or so of this assembly is held in the player's mouth. In the past, clarinetists used to wrap a string around the mouthpiece and reed instead of using a ligature. The formation of the mouth around the mouthpiece and reed is called the \"embouchure\".\nThe reed is on the underside of the mouthpiece, pressing against the player's lower lip, while the top teeth normally contact the top of the mouthpiece (some players roll the upper lip under the top teeth to form what is called a 'double-lip' embouchure). Adjustments in the strength and shape of the embouchure change the tone and intonation (tuning). It is not uncommon for clarinetists to employ methods to relieve the pressure on the upper teeth and inner lower lip by attaching pads to the top of the mouthpiece or putting (temporary) padding on the front lower teeth, commonly from folded paper.\nNext is the short \"barrel\"; this part of the instrument may be extended to fine-tune the clarinet. As the pitch of the clarinet is fairly temperature-sensitive, some instruments have interchangeable barrels whose lengths vary slightly. Additional compensation for pitch variation and tuning can be made by pulling out the barrel and thus increasing the instrument's length, particularly common in group playing in which clarinets are tuned to other instruments (such as in an orchestra or concert band). Some performers use a plastic barrel with a thumbwheel that adjusts the barrel length. On basset horns and lower clarinets, the barrel is normally replaced by a curved metal neck.\nThe main body of most clarinets is divided into the \"upper joint\", the holes and most keys of which are operated by the left hand, and the \"lower joint\" with holes and most keys operated by the right hand. Some clarinets have a single joint: on some basset horns and larger clarinets the two joints are held together with a screw clamp and are usually not disassembled for storage. The left thumb operates both a \"tone hole\" and the \"register key\". On some models of clarinet, such as many Albert system clarinets and increasingly some higher-end B\u00f6hm system clarinets, the register key is a 'wraparound' key, with the key on the back of the clarinet and the pad on the front. Advocates of the wraparound register key say it improves sound, and it is harder for moisture to accumulate in the tube beneath the pad. Nevertheless, there is a consensus among repair techs that this type of register key is harder to keep in adjustment, i.e., it is hard to have enough spring pressure to close the hole securely.\nThe body of a modern soprano clarinet is equipped with numerous \"tone holes\" of which seven (six front, one back) are covered with the fingertips, and the rest are opened or closed using a set of keys. These tone holes let the player produce every note of the chromatic scale. On alto and larger clarinets, and a few soprano clarinets, key-covered holes replace some or all finger holes. The most common system of keys was named the B\u00f6hm system by its designer Hyacinthe Klos\u00e9 in honour of flute designer Theobald B\u00f6hm, but it is not the same as the B\u00f6hm system used on flutes. The other main system of keys is called the Oehler system and is used mostly in Germany and Austria (see History). The related Albert system is used by some jazz, klezmer, and eastern European folk musicians. The Albert and Oehler systems are both based on the early Mueller system.\nThe cluster of keys at the bottom of the upper joint (protruding slightly beyond the cork of the joint) are known as the \"trill keys\" and are operated by the right hand. These give the player alternative fingerings that make it easy to play ornaments and trills. The entire weight of the smaller clarinets is supported by the right thumb behind the lower joint on what is called the \"thumb-rest\". Basset horns and larger clarinets are supported with a neck strap or a floor peg.\nFinally, the flared end is known as the \"bell\". Contrary to popular belief, the bell does not amplify the sound; rather, it improves the uniformity of the instrument's tone for the lowest notes in each register. For the other notes, the sound is produced almost entirely at the tone holes, and the bell is irrelevant. On basset horns and larger clarinets, the bell curves up and forward and is usually made of metal.\nKeywork.\nTheobald B\u00f6hm did not directly invent the key system of the clarinet. B\u00f6hm was a flautist who created the key system that is now used for the transverse flute. Klos\u00e9 and Buffet applied B\u00f6hm's system to the clarinet. Although the credit goes to those people, B\u00f6hm's name was given to that key system because it was based on that used for the flute.\nThe current B\u00f6hm key system consists of generally 6 rings, on the thumb, 1st, 2nd, 4th, 5th, and 6th holes, and a register key just above the thumb hole, easily accessible with the thumb. Above the 1st hole, there is a key that lifts two covers creating the note A in the throat register (high part of low register) of the clarinet. A key at the side of the instrument at the same height as the A key lifts only one of the two covers, producing G, a semitone lower. The A key can be used in conjunction solely with the register key to produce A/B.\nHistory.\nLineage.\nThe clarinet has its roots in the early single-reed instruments or hornpipes used in Ancient Greece, Ancient Egypt, Middle East, and Europe since the Middle Ages, such as the albogue, alboka, and double clarinet.\nThe modern clarinet developed from a Baroque instrument called the chalumeau. This instrument was similar to a recorder, but with a single-reed mouthpiece and a cylindrical bore. Lacking a register key, it was played mainly in its fundamental register, with a limited range of about one and a half octaves. It had eight finger holes, like a recorder, and two keys for its two highest notes. At this time, contrary to modern practice, the reed was placed in contact with the upper lip.\nAround the turn of the 18th century, the chalumeau was modified by converting one of its keys into a register key to produce the first clarinet. This development is usually attributed to German instrument maker Johann Christoph Denner, though some have suggested his son Jacob Denner was the inventor. This instrument played well in the middle register with a loud, shrill sound, so it was given the name \"clarinetto\" meaning \"little trumpet\" (from \"clarino\" + \"-etto\"). Early clarinets did not play well in the lower register, so players continued to play the chalumeaux for low notes. As clarinets improved, the chalumeau fell into disuse, and these notes became known as the \"chalumeau register\". Original Denner clarinets had two keys, and could play a chromatic scale, but various makers added more keys to get improved tuning, easier fingerings, and a slightly larger range. The classical clarinet of Mozart's day typically had eight finger holes and five keys.\nClarinets were soon accepted into orchestras. Later models had a mellower tone than the originals. Mozart (d. 1791) liked the sound of the clarinet (he considered its tone the closest in quality to the human voice) and wrote numerous pieces for the instrument., and by the time of Beethoven (c. 1800\u20131820), the clarinet was a standard fixture in the orchestra.\nPads.\nThe next major development in the history of clarinet was the invention of the modern pad. Because early clarinets used felt pads to cover the tone holes, they leaked air. This required pad-covered holes to be kept to a minimum, restricting the number of notes the clarinet could play with good tone. In 1812, Iwan M\u00fcller, a Baltic German community-born clarinetist and inventor, developed a new type of pad that was covered in leather or fish bladder. It was airtight and let makers increase the number of pad-covered holes. M\u00fcller designed a new type of clarinet with seven finger holes and thirteen keys. This allowed the instrument to play in any key with near-equal ease. Over the course of the 19th-century, makers made many enhancements to M\u00fcller's clarinet, such as the Albert system and the Baermann system, all keeping the same basic design. Modern instruments may also have cork or synthetic pads.\nArrangement of keys and holes.\nThe final development in the modern design of the clarinet used in most of the world today was introduced by Hyacinthe Klos\u00e9 in 1839. He devised a different arrangement of keys and finger holes, which allow simpler fingering. It was inspired by the Boehm system developed for flutes by Theobald B\u00f6hm. Klos\u00e9 was so impressed by B\u00f6hm's invention that he named his own system for clarinets the Boehm system, although it is different from the one used on flutes. This new system was slow to gain popularity but gradually became the standard, and today the Boehm system is used everywhere in the world except Germany and Austria. These countries still use a direct descendant of the Mueller clarinet known as the Oehler system clarinet. Also, some contemporary Dixieland players continue to use Albert system clarinets.\nOther key systems have been developed, many built around modifications to the basic B\u00f6hm system: Full B\u00f6hm, Mazzeo, McIntyre, Benade NX, and the Reform Boehm system for example. Each of these addressed\u2014and often improved\u2014issues of particular \"weak\" tones, or simplified awkward fingerings, but none has caught on widely among players, and the Boehm system remains the standard, to date.\nUsage and repertoire.\nUse of multiple clarinets.\nThe modern orchestral standard of using soprano clarinets in B and A has to do partly with the history of the instrument and partly with acoustics, aesthetics, and economics. Before about 1800, due to the lack of airtight pads \"(see History)\", practical woodwinds could have only a few keys to control accidentals (notes outside their diatonic home scales). The low (chalumeau) register of the clarinet spans a twelfth (an octave plus a perfect fifth), so the clarinet needs keys/holes to produce all nineteen notes in this range. This involves more keywork than on instruments that \"overblow\" at the octave\u2014oboes, flutes, bassoons, and saxophones, for example, which need only twelve notes before overblowing. Clarinets with few keys cannot therefore easily play chromatically, limiting any such instrument to a few closely related keys. For example, an eighteenth-century clarinet in C could be played in F, C, and G (and their relative minors) with good intonation, but with progressive difficulty and poorer intonation as the key moved away from this range. In contrast, for octave-overblowing instruments, an instrument in C with few keys could much more readily be played in any key. This problem was overcome by using three clarinets\u2014in A, B, and C\u2014so that early 19th-century music, which rarely strayed into the remote keys (five or six sharps or flats), could be played as follows: music in 5 to 2 sharps (B major to D major concert pitch) on A clarinet (D major to F major for the player), music in 1 sharp to 1 flat (G to F) on C clarinet, and music in 2 flats to 4 flats (B to A) on the B clarinet (C to B for the clarinetist). Difficult key signatures and numerous accidentals were thus largely avoided.\nWith the invention of the airtight pad, and as key technology improved and more keys were added to woodwinds, the need for clarinets in multiple keys was reduced. However, the use of multiple instruments in different keys persisted, with the three instruments in C, B, and A all used as specified by the composer.\nThe lower-pitched clarinets sound \"mellower\" (less bright), and the C clarinet\u2014being the highest and therefore brightest of the three\u2014fell out of favour as the other two could cover its range and their sound was considered better. While the clarinet in C began to fall out of general use around 1850, some composers continued to write C parts after this date, e.g., Bizet's Symphony in C (1855), Tchaikovsky's Symphony No. 2 (1872), Smetana's overture to \"The Bartered Bride\" (1866) and \"M\u00e1 Vlast\" (1874), Dvo\u0159\u00e1k's \"Slavonic Dance\" Op. 46, No. 1 (1878), Brahms' Symphony No.\u00a04 (1885), Mahler's Symphony No. 6 (1906), and Richard Strauss deliberately reintroduced it to take advantage of its brighter tone, as in \"Der Rosenkavalier\" (1911).\nWhile technical improvements and an equal-tempered scale reduced the need for two clarinets, the technical difficulty of playing in remote keys persisted, and the A has thus remained a standard orchestral instrument. In addition, by the late 19th century, the orchestral clarinet repertoire contained so much music for clarinet in A that the disuse of this instrument was not practical. Attempts were made to standardise to the B instrument between 1930 and 1950 (e.g., tutors recommended learning routine transposition of orchestral A parts on the B clarinet, including solos written for A clarinet, and some manufacturers provided a low E on the B to match the range of the A), but this failed in the orchestral sphere.\nSimilarly there have been E and D instruments in the upper soprano range, B, A, and C instruments in the bass range, and so forth; but over time the E and B instruments have become predominant. The B instrument remains dominant in concert bands and jazz. B and C instruments are used in some ethnic traditions, such as klezmer.\nClassical music.\nIn classical music, clarinets are part of standard orchestral and concert band instrumentation.\nThe orchestra frequently includes two clarinetists playing individual parts\u2014each player is usually equipped with a pair of standard clarinets in B and A, and clarinet parts commonly alternate between B and A instruments several times over the course of a piece, or less commonly, a movement (e.g., 1st movement Brahms' 3rd symphony). Clarinet sections grew larger during the last few decades of the 19th century, often employing a third clarinetist, an E or a bass clarinet. In the 20th century, composers such as Igor Stravinsky, Richard Strauss, Gustav Mahler, and Olivier Messiaen enlarged the clarinet section on occasion to up to nine players, employing many different clarinets including the E or D soprano clarinets, basset horn, alto clarinet, bass clarinet, and/or contrabass clarinet.\nIn concert bands, clarinets are an important part of the instrumentation. The E clarinet, B clarinet, alto clarinet, bass clarinet, and contra-alto/contrabass clarinet are commonly used in concert bands. Concert bands generally have multiple B clarinets; there are commonly 3 B clarinet parts with 2\u20133 players per part. There is generally only one player per part on the other clarinets. There are not always E clarinet, alto clarinet, and contra-alto clarinets/contrabass clarinet parts in concert band music, but all three are quite common.\nThis practice of using a variety of clarinets to achieve coloristic variety was common in 20th-century classical music and continues today. However, many clarinetists and conductors prefer to play parts originally written for obscure instruments on B or E clarinets, which are often of better quality and more prevalent and accessible.\nThe clarinet is widely used as a solo instrument. The relatively late evolution of the clarinet (when compared to other orchestral woodwinds) has left solo repertoire from the Classical period and later, but few works from the Baroque era. Many clarinet concertos have been written to showcase the instrument, with the concerti by Mozart, Copland, and Weber being well known.\nMany works of chamber music have also been written for the clarinet. Common combinations are:\nJazz.\nThe clarinet was originally a central instrument in jazz, beginning with the New Orleans players in the 1910s. It remained a signature instrument of jazz music through much of the big band era into the 1940s. American players Alphonse Picou, Larry Shields, Jimmie Noone, Johnny Dodds, and Sidney Bechet were all pioneers of the instrument in jazz. The B soprano was the most common instrument, but a few early jazz musicians such as Louis Nelson Delisle and Alcide Nunez preferred the C soprano, and many New Orleans jazz brass bands have used E soprano.\nSwing clarinetists such as Benny Goodman, Artie Shaw, and Woody Herman led successful big bands and smaller groups from the 1930s onward. Duke Ellington, active from the 1920s to the 1970s, used the clarinet as lead instrument in his works, with several players of the instrument (Barney Bigard, Jimmy Hamilton, and Russell Procope) spending a significant portion of their careers in his orchestra. Harry Carney, primarily Ellington's baritone saxophonist, occasionally doubled on bass clarinet. Meanwhile, Pee Wee Russell had a long and successful career in small groups.\nWith the decline of the big bands' popularity in the late 1940s, the clarinet faded from its prominent position in jazz. By that time, an interest in Dixieland or traditional New Orleans jazz had revived; Pete Fountain was one of the best known performers in this genre. Bob Wilber, active since the 1950s, is a more eclectic jazz clarinetist, playing in several classic jazz styles. During the 1950s and 1960s, Britain underwent a surge in the popularity of what was termed 'Trad jazz'. In 1956 the British clarinetist Acker Bilk founded his own ensemble. Several singles recorded by Bilk reached the British pop charts, including the ballad \"Stranger on the Shore\".\nThe clarinet's place in the jazz ensemble was usurped by the saxophone, which projects a more powerful sound and uses a less complicated fingering system. The requirement for an increased speed of execution in modern jazz also did not favour the clarinet, but the clarinet did not entirely disappear. The clarinetist Stan Hasselg\u00e5rd made a transition from swing to bebop in the mid-1940s. A few players such as Buddy DeFranco, Tony Scott, and Jimmy Giuffre emerged during the 1950s playing bebop or other styles. A little later, Eric Dolphy (on bass clarinet), Perry Robinson, John Carter, Theo J\u00f6rgensmann, and others used the clarinet in free jazz. The French composer and clarinetist Jean-Christian Michel initiated a jazz-classical cross-over on the clarinet with the drummer Kenny Clarke.\nIn the U.S., the prominent players on the instrument since the 1980s have included Eddie Daniels, Don Byron, Marty Ehrlich, Ken Peplowski, and others playing the clarinet in more contemporary contexts.\nOther genres.\nThe clarinet is uncommon, but not unheard of, in rock music. Jerry Martini played clarinet on Sly and the Family Stone's 1968 hit, \"Dance to the Music\"; Don Byron, a founder of the Black Rock Coalition who was a member of hard rock guitarist Vernon Reid's band, plays clarinet on the \"Mistaken Identity\" album (1996). The Beatles, Pink Floyd, Radiohead, Aerosmith, Billy Joel, and Tom Waits have also all used clarinet on occasion. A clarinet is prominently featured for two different solos in \"Breakfast in America\", the title song from the Supertramp album of the same name.\nClarinets feature prominently in klezmer music, which entails a distinctive style of playing. The use of quarter-tones requires a different embouchure. Some klezmer musicians prefer Albert system clarinets.\nThe popular Brazilian music styles of choro and samba use the clarinet. Prominent contemporary players include Paulo Moura, Naylor 'Proveta' Azevedo, Paulo S\u00e9rgio dos Santos, and Cuban born Paquito D'Rivera.\nEven though it has been adopted recently in Albanian folklore (around the 18th century), the clarinet, or \"g\u00ebrneta\" as it is called, is one of the most important instruments in Albania, especially in the central and southern areas. The clarinet plays a crucial role in \"saze\" (folk) ensembles that perform in weddings and other celebrations. It is worth mentioning that the \"kaba\" (an instrumental Albanian Isopolyphony included in UNESCO's intangible cultural heritage list) is characteristic of these ensembles. Prominent Albanian clarinet players include Selim Leskoviku, Gaqo Lena, Remzi Lela (\u00c7obani), Laver Bariu (Ustai), and Nevruz Nure (Lulushi i Kor\u00e7\u00ebs).\nThe clarinet is prominent in Bulgarian wedding music as an offshoot of Roma/Romani traditional music. Ivo Papazov is a well-known clarinetist in this genre. In Moravian dulcimer bands, the clarinet is usually the only wind instrument among string instruments.\nIn old-town folk music in North Macedonia (called \u010dalgija (\"\u0447\u0430\u043b\u0433\u0438\u0458\u0430\")), the clarinet has the most important role in wedding music; clarinet solos mark the high point of dancing euphoria. One of the most renowned Macedonian clarinet players is Tale Ognenovski, who gained worldwide fame for his virtuosity.\nIn Greece, the clarinet (usually referred to as \"\u03ba\u03bb\u03b1\u03c1\u03af\u03bd\u03bf\"\u2014\"clarino\") is prominent in traditional music, especially in central, northwest, and northern Greece (Thessaly, Epirus, and Macedonia). The double-reed zurna was the dominant woodwind instrument before the clarinet arrived in the country, although many Greeks regard the clarinet as a native instrument. Traditional dance music, wedding music, and laments include a clarinet soloist and quite often improvisations. Petroloukas Chalkias is a famous clarinetist in this genre.\nThe instrument is equally famous in Turkey, especially the lower-pitched clarinet in G. The western European clarinet crossed via Turkey to Arabic music, where it is widely used in Arabic pop, especially if the intention of the arranger is to imitate the Turkish style.\nAlso in Turkish folk music, a clarinet-like woodwind instrument, the sipsi, is used. However, it is far more rare than the soprano clarinet and is mainly limited to folk music of the Aegean Region.\nGroups of clarinets.\nGroups of clarinets playing together have become increasingly popular among clarinet enthusiasts in recent years. Common forms are:\nClarinet choirs and quartets often play arrangements of both classical and popular music, in addition to a body of literature specially written for a combination of clarinets by composers such as Arnold Cooke, Alfred Uhl, Lucien Caillet, and V\u00e1clav Nelh\u00fdbel.\nExtended family of clarinets.\nThere is a family of many differently pitched clarinet types, some of which are very rare. The following are the most important sizes, from highest to lowest:\nEEE and BBB octocontra-alto and octocontrabass clarinets have also been built. There have also been soprano clarinets in C, A, and B with curved barrels and bells marketed under the names saxonette, claribel, and clariphon."}
{"id": "6434", "revid": "20161611", "url": "https://en.wikipedia.org/wiki?curid=6434", "title": "Chojn\u00f3w", "text": "Chojn\u00f3w (, Silesian German: Hoyn) is a small town in Legnica County, Lower Silesian Voivodeship, in south-western Poland. It is located on the Skora river, a tributary of the Kaczawa at an average altitude of above sea level. Chojn\u00f3w is the administrative seat of the rural gmina called Gmina Chojn\u00f3w, although the town is not part of its territory and forms a separate urban gmina. it had 13,355 inhabitants.\nChojn\u00f3w is located west of Legnica, east from Boles\u0142awiec and north of Z\u0142otoryja, from the A4 motorway. It has railroad connections to Boles\u0142awiec and Legnica.\nHeraldry.\nCoat of arms of the Chojn\u00f3w has is a blue escutcheon. On the dial there is a tower with three bastions of white colour. The central tower has two Windows, and one side. On the towers is located on the right side of the Moon and Sun on the left. In the gate of the Silesian Eagle on a yellow background.\nThe Motto of Chojn\u00f3w is \"Friendly City\".\nGeography.\nChojn\u00f3w is located in the Central-Western part of the Lower Silesia region. The Skora (Leather) River flows through the town in a westerly direction. The city of Chojn\u00f3w is in area, including 41% agricultural land.\nChojn\u00f3w has a connection with the major cities of the country (road and rail) and located south of Chojn\u00f3w has the A4 Autostrada. To the South of the town is the surrounding Chojnowska Plain.\nHistory.\nThe town is first mentioned in a Latin mediaeval document issued in Wroc\u0142aw on February 26, 1253, stating, the Silesian Duke Henry III when the town is mentioned under the name Honowo. Possible the name of nearby Hainau Island. The name is of Polish origin, and in more modern records from the 19th century, the Polish name appears as \"Hajn\u00f3w\", while \"Haynau\" is the Germanized version of the original Polish name.\nThe settlement of \"Haynow\" was mentioned in a 1272 deed. It was already called a \"civitas\" in a 1288 document issued by the Piast duke Henry V of Legnica, and officially received town privileges in 1333 from Duke Boles\u0142aw III the Generous. It was part of the duchies of Wroc\u0142aw, G\u0142og\u00f3w and Legnica of fragmented Poland and remained under the rule of the Piast dynasty until 1675. Its population was predominantly Polish. In 1292 the first castellan of Chojn\u00f3w, Bronis\u0142aw Budziwojowic, was mentioned. In the 14th and early 15th centuries Chojn\u00f3w was granted various privileges, including staple right and gold mining right, thanks to which it flourished.\nThe town survived the Hussites, who burned almost the entire town center and castle, but it quickly helped recover its former glory. The largest boom Chojn\u00f3w experienced was in the 16th century, however by the end of that century began to decline due to fires and epidemic, which claimed many victims in 1613. During the Thirty Years War (1618\u20131648), there was another outbreak in the city, it was occupied by the Austrians and Swedes and in 1642 it was also plundered by the Swedes. It remained part of the Piast-ruled Duchy of Legnica until its dissolution in 1675, when it was incorporated to Habsburg-ruled Bohemia.\nIn the 18th century, cloth production developed and a clothmaking school was established in the town. One of two main routes connecting Warsaw and Dresden ran through the town in the 18th century and Kings Augustus II the Strong and Augustus III of Poland traveled that route numerous times. In 1740 the town was captured by Prussia and subsequently annexed in 1742. In 1804 it suffered a flood. During the Napoleonic wars there were more epidemics. In 1813 in Chojn\u00f3w, Napoleon Bonaparte issued instructions regarding the reorganization of the 8th Polish Corps of Prince J\u00f3zef Poniatowski. The event is commemorated by a plaque in the facade of the Piast Castle. A railway line was opened in the 19th century. Sewer, Gas lighting a Newspaper and a hospital soon followed as the towns economy improved.\nThe city was not spared in World War II, with 30% of the town being destroyed on February 10, 1945 when Soviet Red Army troops took the abandoned town. After World War II and the implementation of the Oder-Neisse line in 1945, the town passed to the Republic of Poland. It was repopulated by Poles, expelled from former eastern Poland annexed by the Soviet Union. In 1946 it was renamed \"Chojn\u00f3w\", a more modern version of the old Polish \"Hajn\u00f3w\". Also Greeks, refugees of the Greek Civil War, settled in Chojn\u00f3w.\nEconomy.\nChojn\u00f3w is an industrial and agricultural town. Among local products are: paper, agricultural machinery, chains, metal furniture for hospitals, equipment for the meat industry, beer, wine, leather clothing, and clothing for infants, children and adults.\nSights and nature.\nAmong the interesting monuments of Chojn\u00f3w are the 13th-century castle of the Dukes of Legnica (currently used as a museum), two old churches, the \"Baszta Tkaczy\" (\"Weavers' Tower\") and preserved fragments of city walls.\nThe biggest green area in Chojn\u00f3w is small forest \"Park Piastowski\" (\"Piast's Park\"), named after Piast dynasty. Wild animals that can be found in the Chojn\u00f3w area are roe deer, foxes, rabbits and wild domestic animals, especially cats.\nCulture and sport.\nEvery year in the first days of June, the \"Days of Chojn\u00f3w\" (\"Dni Chojnowa\") are celebrated. The Whole-Poland bike race \"Masters\" has been organized yearly in Chojn\u00f3w for the past few years.\nChojn\u00f3w has a Municipal sports and recreation center formed in 2008 holding various events, festivals, reviews, exhibitions, and competitions. The regional Museum is housed in the old Piast era castle. The collections include tiles, relics, and the castle garden. Next to the Museum there is a municipal library. In \u015br\u00f3dmiejskim Park, near the Town Hall is the amphitheatre.\nThe local government-run weekly newspaper is Gazeta Chojnowska, which has been published since 1992.\nIt is published biweekly. Editions have a run of 900 copies and it is one of the oldest newspapers in Poland issued without interruption. The \"Chojn\u00f3w\" is the official newspaper of Chojn\u00f3w with copy run of 750 copies.\nEducation.\nIn Chojn\u00f3w, there are two kindergartens, two elementary schools and two middle schools.\nReligion.\nChojn\u00f3w is in the Catholic deanery of Chojn\u00f3w and has two parishes, Immaculate Conception of the Blessed Virgin Mary and also the Holy Apostles Peter and Paul. Both parishes have active congregations.\nThere are also two Congregations of Jehovah's witnesses.\nTwin towns \u2013 sister cities.\nChojn\u00f3w is twinned with:"}
{"id": "6435", "revid": "111744", "url": "https://en.wikipedia.org/wiki?curid=6435", "title": "Canes Venatici", "text": "Canes Venatici is one of the 88 official modern constellations. It is a small northern constellation that was created by Johannes Hevelius in the 17th century. Its name is Latin for 'hunting dogs', and the constellation is often depicted in illustrations as representing the dogs of Bo\u00f6tes the Herdsman, a neighboring constellation.\nCor Caroli is the constellation's brightest star, with an apparent magnitude of 2.9. La Superba (Y\u00a0CVn) is one of the reddest naked-eye stars and one of the brightest carbon stars. The Whirlpool Galaxy is a spiral galaxy tilted face-on to observers on Earth, and was the first galaxy whose spiral nature was discerned. In addition, TON 618 has one of the most massive black holes with the mass of 66 billion solar masses.\nHistory.\nThe stars of Canes Venatici are not bright. In classical times, they were listed by Ptolemy as unfigured stars below the constellation Ursa Major in his star catalogue. \nIn medieval times, the identification of these stars with the dogs of Bo\u00f6tes arose through a mistranslation: some of Bo\u00f6tes's stars were traditionally described as representing the club (, ) of Bo\u00f6tes. When the Greek astronomer Ptolemy's \"Almagest\" was translated from Greek to Arabic, the translator Hunayn ibn Ishaq did not know the Greek word and rendered it as a similar-sounding compound Arabic word for a kind of weapon, writing , which means 'the staff having a hook'.\nWhen the Arabic text was later translated into Latin, the translator, Gerard of Cremona, mistook ('hook') for ('dogs'). Both written words look the same in Arabic text without diacritics, leading Gerard to write it as ('spearshaft-having dogs'). \nIn 1533, the German astronomer Peter Apian depicted Bo\u00f6tes as having two dogs with him.\nThese spurious dogs floated about the astronomical literature until Hevelius decided to make them a separate constellation in 1687. Hevelius chose the name \"Asterion\" for the northern dog and \"Chara\" for the southern dog, as , 'the hunting dogs', in his star atlas.\nIn his star catalogue, the Czech astronomer Anton\u00edn Be\u010dv\u00e1\u0159 assigned the names \"Asterion\" to \u03b2\u00a0CVn and \"Chara\" to \u03b1\u00a0CVn.\nAlthough the International Astronomical Union dropped several constellations in 1930 that were medieval and Renaissance innovations, Canes Venatici survived to become one of the 88 IAU designated constellations.\nNeighbors and borders.\nCanes Venatici is bordered by Ursa Major to the north and west, Coma Berenices to the south, and Bo\u00f6tes to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"CVn\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of 14 sides.\nIn the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between +27.84\u00b0 and +52.36\u00b0. Covering 465 square degrees, it ranks 38th of the 88 constellations in size.\nProminent stars and deep-sky objects.\nStars.\nCanes Venatici contains no bright stars, Alpha and Beta Canum Venaticorum being only of 3rd and 4th magnitude respectively. Flamsteed catalogued 25 stars in the constellation, labelling them 1 to 25 Canum Venaticorum (CVn); however, 1CVn turned out to be in Ursa Major, 13CVn was in Coma Berenices, and 22CVn did not exist.\nSupervoid.\nThe Giant Void, an extremely large void (part of the universe containing very few galaxies), is within the vicinity of this constellation. It may be possibly the largest void ever discovered, slightly larger than the Eridanus Supervoid and 1,200 times the volume of expected typical voids. It was discovered in 1988 in a deep-sky survey.\nDeep-sky objects.\nCanes Venatici contains five Messier objects, including four galaxies. One of the more significant galaxies in Canes Venatici is the Whirlpool Galaxy (M51, NGC\u00a05194) and NGC 5195, a small barred spiral galaxy that is seen face-on. This was the first galaxy recognised as having a spiral structure, this structure being first observed by Lord Rosse in 1845. It is a face-on spiral galaxy 37\u00a0million light-years from Earth. Widely considered to be one of the most beautiful galaxies visible, M51 has many star-forming regions and nebulae in its arms, coloring them pink and blue in contrast to the older yellow core. M\u00a051 has a smaller companion, NGC\u00a05195, that has very few star-forming regions and thus appears yellow. It is passing behind M\u00a051 and may be the cause of the larger galaxy's prodigious star formation.\nOther notable spiral galaxies in Canes Venatici are the Sunflower Galaxy (M63, NGC\u00a05055), M94 (NGC\u00a04736), and M106 (NGC\u00a04258).\nTON 618 is a hyperluminous quasar and blazar in this constellation, near its border with the neighboring Coma Berenices. It possesses a black hole with a mass 66 billion times that of our Sun, making it one of the most massive black holes ever measured."}
{"id": "6436", "revid": "34234035", "url": "https://en.wikipedia.org/wiki?curid=6436", "title": "Chamaeleon", "text": "Chamaeleon () is a small constellation in the southern sky. It is named after the chameleon, a kind of lizard. It was first defined in the 16th century.\nHistory.\nChamaeleon was one of twelve constellations created by Petrus Plancius from the observations of Pieter Dirkszoon Keyser and Frederick de Houtman. It first appeared on a 35-cm diameter celestial globe published in 1597 (or 1598) in Amsterdam by Plancius and Jodocus Hondius. Johann Bayer was the first uranographer to put Chamaeleon in a celestial atlas. It was one of many constellations created by European explorers in the 15th and 16th centuries out of unfamiliar Southern Hemisphere stars.\nFeatures.\nStars.\nThere are four bright stars in Chamaeleon that form a compact diamond-shape approximately 10 degrees from the South Celestial Pole and about 15 degrees south of Acrux, along the axis formed by Acrux and Gamma Crucis. Alpha Chamaeleontis is a white-hued star of magnitude 4.1, 63 light-years from Earth. Beta Chamaeleontis is a blue-white hued star of magnitude 4.2, 271 light-years from Earth. Gamma Chamaeleontis is a red-hued giant star of magnitude 4.1, 413 light-years from Earth. The other bright star in Chamaeleon is Delta Chamaeleontis, a wide double star. The brighter star is Delta2 Chamaeleontis, a blue-hued star of magnitude 4.4. Delta1 Chamaeleontis, the dimmer component, is an orange-hued giant star of magnitude 5.5. They both lie about 350 light years away.\nChamaeleon is also the location of Cha 110913, a unique dwarf star or proto solar system.\nDeep-sky objects.\nIn 1999, a nearby open cluster was discovered centered on the star \u03b7 Chamaeleontis. The cluster, known as either\nthe Eta Chamaeleontis cluster or Mamajek 1, is 8 million years old, and lies 316 light years from Earth.\nThe constellation contains a number of molecular clouds (the Chamaeleon dark clouds) that are forming low-mass T Tauri stars. The cloud complex lies some 400 to 600 light years from Earth, and contains tens of thousands of solar masses of gas and dust. The most prominent cluster of T Tauri stars and young B-type stars are in the Chamaeleon I cloud, and are associated with the reflection nebula IC 2631.\nChamaeleon contains one planetary nebula, NGC 3195, which is fairly faint. It appears in a telescope at about the same apparent size as Jupiter.\nEquivalents.\nIn Chinese astronomy, the stars that form Chamaeleon were classified as the Little Dipper (\u5c0f\u6597, \"Xi\u01ceod\u01d2u\") among the Southern Asterisms (\u8fd1\u5357\u6975\u661f\u5340, \"J\u00ecnn\u00e1nj\u00edx\u012bng\u014du\") by Xu Guangqi. Chamaeleon is sometimes also called the Frying Pan in Australia."}
{"id": "6437", "revid": "211905", "url": "https://en.wikipedia.org/wiki?curid=6437", "title": "Cholesterol", "text": "Cholesterol (from the Ancient Greek \"chole-\" (bile) and \"stereos\" (solid), followed by the chemical suffix \"-ol\" for an alcohol) is an organic molecule. It is a sterol (or modified steroid), a type of lipid. Cholesterol is biosynthesized by all animal cells and is an essential structural component of animal cell membranes. It is a yellowish crystalline solid.\nCholesterol also serves as a precursor for the biosynthesis of steroid hormones, bile acid and vitamin D. Cholesterol is the principal sterol synthesized by all animals. In vertebrates, hepatic cells typically produce the greatest amounts. It is absent among prokaryotes (bacteria and archaea), although there are some exceptions, such as \"Mycoplasma\", which require cholesterol for growth.\nFran\u00e7ois Poulletier de la Salle first identified cholesterol in solid form in gallstones in 1769. However, it was not until 1815 that chemist Michel Eug\u00e8ne Chevreul named the compound \"cholesterine\".\nPhysiology.\nCholesterol is essential for all animal life, with each cell capable of synthesizing it by way of a complex 37-step process. This begins with the mevalonate or HMG-CoA reductase pathway, the target of statin drugs, which encompasses the first 18 steps. This is followed by 19 additional steps to convert the resulting lanosterol into cholesterol.\nA human male weighing 68\u00a0kg (150\u00a0lb) normally synthesizes about 1 gram (1,000\u00a0mg) of cholesterol per day, and his body contains about 35 g, mostly contained within the cell membranes. Typical daily cholesterol dietary intake for a man in the United States is 307\u00a0mg.\nMost ingested cholesterol is esterified, which causes it to be poorly absorbed by the gut. The body also compensates for absorption of ingested cholesterol by reducing its own cholesterol synthesis. For these reasons, cholesterol in food, seven to ten hours after ingestion, has little, if any effect on concentrations of cholesterol in the blood. However, during the first seven hours after ingestion of cholesterol, as absorbed fats are being distributed around the body within extracellular water by the various lipoproteins (which transport all fats in the water outside cells), the concentrations increase.\nPlants make cholesterol in very small amounts. In larger quantities they produce phytosterols, chemically similar substances which can compete with cholesterol for reabsorption in the intestinal tract, thus potentially reducing cholesterol reabsorption. When intestinal lining cells absorb phytosterols, in place of cholesterol, they usually excrete the phytosterol molecules back into the GI tract, an important protective mechanism. The intake of naturally occurring phytosterols, which encompass plant sterols and stanols, ranges between \u2248200\u2013300\u00a0mg/day depending on eating habits. Specially designed vegetarian experimental diets have been produced yielding upwards of 700\u00a0mg/day.\nFunction in cells.\nMembranes.\nCholesterol composes about 30% of all animal cell membranes. It is required to build and maintain membranes and modulates membrane fluidity over the range of physiological temperatures. The hydroxyl group of each cholesterol molecule interacts with water molecules surrounding the membrane, as do the polar heads of the membrane phospholipids and sphingolipids, while the bulky steroid and the hydrocarbon chain are embedded in the membrane, alongside the nonpolar fatty-acid chain of the other lipids. Through the interaction with the phospholipid fatty-acid chains, cholesterol increases membrane packing, which both alters membrane fluidity and maintains membrane integrity so that animal cells do not need to build cell walls (like plants and most bacteria). The membrane remains stable and durable without being rigid, allowing animal cells to change shape and animals to move.\nThe structure of the tetracyclic ring of cholesterol contributes to the fluidity of the cell membrane, as the molecule is in a \"trans\" conformation making all but the side chain of cholesterol rigid and planar. In this structural role, cholesterol also reduces the permeability of the plasma membrane to neutral solutes, hydrogen ions, and sodium ions.\nGates.\nWithin the cell membrane, cholesterol also functions in intracellular transport, cell signaling and nerve conduction. Cholesterol is essential for the structure and function of invaginated caveolae and clathrin-coated pits, including caveola-dependent and clathrin-dependent endocytosis. The role of cholesterol in endocytosis of these types can be investigated by using methyl beta cyclodextrin (M\u03b2CD) to remove cholesterol from the plasma membrane.\nSubstrate presentation.\nCholesterol regulates the biological process of substrate presentation and the enzymes that use substrate presentation as a mechanism of their activation. (PLD2) is a well-defined example of an enzyme activated by substrate presentation. The enzyme is palmitoylated causing the enzyme to traffic to cholesterol dependent lipid domains sometimes called \"lipid rafts\". The substrate of phospholipase D is phosphatidylcholine (PC) which is unsaturated and is of low abundance in lipid rafts. PC localizes to the disordered region of the cell along with the polyunsaturated lipid phosphatidylinositol 4,5-bisphosphate (PIP2). PLD2 has a PIP2 binding domain. When PIP2 concentration in the membrane increases, PLD2 leaves the cholesterol dependent domains and binds to PIP2 where it then gains access to its substrate PC and commences catalysis based on substrate presentation.\nSignaling.\nCholesterol is also implicated in cell signaling processes, assisting in the formation of lipid rafts in the plasma membrane, which brings receptor proteins in close proximity with high concentrations of second messenger molecules. In multiple layers, cholesterol and phospholipids, both electrical insulators, can facilitate speed of transmission of electrical impulses along nerve tissue. For many neuron fibers, a myelin sheath, rich in cholesterol since it is derived from compacted layers of Schwann cell membrane, provides insulation for more efficient conduction of impulses. Demyelination (loss of some of these Schwann cells) is believed to be part of the basis for multiple sclerosis.\nCholesterol binds to and affects the gating of a number of ion channels such as the nicotinic acetylcholine receptor, GABAA receptor, and the inward-rectifier potassium channel. Cholesterol also activates the estrogen-related receptor alpha (ERR\u03b1), and may be the endogenous ligand for the receptor. The constitutively active nature of the receptor may be explained by the fact that cholesterol is ubiquitous in the body. Inhibition of ERR\u03b1 signaling by reduction of cholesterol production has been identified as a key mediator of the effects of statins and bisphosphonates on bone, muscle, and macrophages. On the basis of these findings, it has been suggested that the ERR\u03b1 should be de-orphanized and classified as a receptor for cholesterol.\nChemical precursor.\nWithin cells, cholesterol is also a precursor molecule for several biochemical pathways. For example, it is the precursor molecule for the synthesis of vitamin D in the calcium metabolism and all steroid hormones, including the adrenal gland hormones cortisol and aldosterone, as well as the sex hormones progesterone, estrogens, and testosterone, and their derivatives.\nMetabolism.\nCholesterol is recycled in the body. The liver excretes cholesterol into biliary fluids, which are then stored in the gallbladder, which then excretes them in a non-esterified form (via bile) into the digestive tract. Typically, about 50% of the excreted cholesterol is reabsorbed by the small intestine back into the bloodstream.\nBiosynthesis and regulation.\nBiosynthesis.\nAll animal cells manufacture cholesterol, for both membrane structure and other uses, with relative production rates varying by cell type and organ function. About 80% of total daily cholesterol production occurs in the liver and the intestines; other sites of higher synthesis rates include the brain, the adrenal glands, and the reproductive organs.\nSynthesis within the body starts with the mevalonate pathway where two molecules of acetyl CoA condense to form acetoacetyl-CoA. This is followed by a second condensation between acetyl CoA and acetoacetyl-CoA to form 3-hydroxy-3-methylglutaryl CoA (HMG-CoA). \nThis molecule is then reduced to mevalonate by the enzyme HMG-CoA reductase. Production of mevalonate is the rate-limiting and irreversible step in cholesterol synthesis and is the site of action for statins (a class of cholesterol-lowering drugs).\nMevalonate is finally converted to isopentenyl pyrophosphate (IPP) through two phosphorylation steps and one decarboxylation step that requires ATP.\nThree molecules of isopentenyl pyrophosphate condense to form farnesyl pyrophosphate through the action of geranyl transferase.\nTwo molecules of farnesyl pyrophosphate then condense to form squalene by the action of squalene synthase in the endoplasmic reticulum. \nOxidosqualene cyclase then cyclizes squalene to form lanosterol.\nFinally, lanosterol is converted to cholesterol via either of two pathways, the Block pathway, or the Kandutsch-Russell pathway.\nThe final 19 steps to cholesterol contain NADPH and oxygen to help oxidize methyl groups for removal of carbons, mutases to move alkene groups, and NADH to help reduce ketones.\nKonrad Bloch and Feodor Lynen shared the Nobel Prize in Physiology or Medicine in 1964 for their discoveries concerning some of the mechanisms and methods of regulation of cholesterol and fatty acid metabolism.\nRegulation of cholesterol synthesis.\nBiosynthesis of cholesterol is directly regulated by the cholesterol levels present, though the homeostatic mechanisms involved are only partly understood. A higher intake from food leads to a net decrease in endogenous production, whereas lower intake from food has the opposite effect. The main regulatory mechanism is the sensing of intracellular cholesterol in the endoplasmic reticulum by the protein SREBP (sterol regulatory element-binding protein 1 and 2). In the presence of cholesterol, SREBP is bound to two other proteins: SCAP (SREBP cleavage-activating protein) and INSIG-1. When cholesterol levels fall, INSIG-1 dissociates from the SREBP-SCAP complex, which allows the complex to migrate to the Golgi apparatus. Here SREBP is cleaved by S1P and S2P (site-1 protease and site-2 protease), two enzymes that are activated by SCAP when cholesterol levels are low.\nThe cleaved SREBP then migrates to the nucleus, and acts as a transcription factor to bind to the sterol regulatory element (SRE), which stimulates the transcription of many genes. Among these are the low-density lipoprotein (LDL) receptor and HMG-CoA reductase. The LDL receptor scavenges circulating LDL from the bloodstream, whereas HMG-CoA reductase leads to an increase of endogenous production of cholesterol. A large part of this signaling pathway was clarified by Dr. Michael S. Brown and Dr. Joseph L. Goldstein in the 1970s. In 1985, they received the Nobel Prize in Physiology or Medicine for their work. Their subsequent work shows how the SREBP pathway regulates expression of many genes that control lipid formation and metabolism and body fuel allocation.\nCholesterol synthesis can also be turned off when cholesterol levels are high. HMG-CoA reductase contains both a cytosolic domain (responsible for its catalytic function) and a membrane domain. The membrane domain senses signals for its degradation. Increasing concentrations of cholesterol (and other sterols) cause a change in this domain's oligomerization state, which makes it more susceptible to destruction by the proteosome. This enzyme's activity can also be reduced by phosphorylation by an AMP-activated protein kinase. Because this kinase is activated by AMP, which is produced when ATP is hydrolyzed, it follows that cholesterol synthesis is halted when ATP levels are low.\nPlasma transport and regulation of absorption.\nAs an isolated molecule, cholesterol is only minimally soluble in water, or hydrophilic. Because of this, it dissolves in blood at exceedingly small concentrations. To be transported effectively, cholesterol is instead packaged within lipoproteins, complex discoidal particles with exterior amphiphilic proteins and lipids, whose outward-facing surfaces are water-soluble and inward-facing surfaces are lipid-soluble. This allows it to travel through the blood via emulsification. Unbound cholesterol, being amphipathic, is transported in the monolayer surface of the lipoprotein particle along with phospholipids and proteins. Cholesterol esters bound to fatty acid, on the other hand, are transported within the fatty hydrophilic core of the lipoprotein, along with triglyceride.\nThere are several types of lipoproteins in the blood. In order of increasing density, they are chylomicrons, very-low-density lipoprotein (VLDL), intermediate-density lipoprotein (IDL), low-density lipoprotein (LDL), and high-density lipoprotein (HDL). Lower protein/lipid ratios make for less dense lipoproteins. Cholesterol within different lipoproteins is identical, although some is carried as its native \"free\" alcohol form (the cholesterol-OH group facing the water surrounding the particles), while others as fatty acyl esters, known also as cholesterol esters, within the particles.\nLipoprotein particles are organized by complex apolipoproteins, typically 80\u2013100 different proteins per particle, which can be recognized and bound by specific receptors on cell membranes, directing their lipid payload into specific cells and tissues currently ingesting these fat transport particles. These surface receptors serve as unique molecular signatures, which then help determine fat distribution delivery throughout the body.\nChylomicrons, the least dense cholesterol transport molecules, contain apolipoprotein B-48, apolipoprotein C, and apolipoprotein E (the principal cholesterol carrier in the brain) in their shells. Chylomicrons carry fats from the intestine to muscle and other tissues in need of fatty acids for energy or fat production. Unused cholesterol remains in more cholesterol-rich chylomicron remnants, and taken up from here to the bloodstream by the liver.\nVLDL molecules are produced by the liver from triacylglycerol and cholesterol which was not used in the synthesis of bile acids. These molecules contain apolipoprotein B100 and apolipoprotein E in their shells, and can be degraded by lipoprotein lipase on the artery wall to IDL. This arterial wall cleavage allows absorption of triacylglycerol and increases concentration of circulating cholesterol. IDL molecules are then consumed in two processes: half is metabolized by HTGL and taken up by the LDL receptor on the liver cell surfaces, while the other half continues to lose triacylglycerols in the bloodstream until they become cholesterol laden LDL particles.\nLDL particles are the major blood cholesterol carriers. Each one contains approximately 1,500 molecules of cholesterol ester. LDL molecule shells contain just one molecule of apolipoprotein B100, recognized by LDL receptors in peripheral tissues. Upon binding of apolipoprotein B100, many LDL receptors concentrate in clathrin-coated pits. Both LDL and its receptor form vesicles within a cell via endocytosis. These vesicles then fuse with a lysosome, where the lysosomal acid lipase enzyme hydrolyzes the cholesterol esters. The cholesterol can then be used for membrane biosynthesis or esterified and stored within the cell, so as to not interfere with the cell membranes.\nLDL receptors are used up during cholesterol absorption, and its synthesis is regulated by SREBP, the same protein that controls the synthesis of cholesterol \"de novo\", according to its presence inside the cell. A cell with abundant cholesterol will have its LDL receptor synthesis blocked, to prevent new cholesterol in LDL molecules from being taken up. Conversely, LDL receptor synthesis proceeds when a cell is deficient in cholesterol.\nWhen this process becomes unregulated, LDL molecules without receptors begin to appear in the blood. These LDL molecules are oxidized and taken up by macrophages, which become engorged and form foam cells. These foam cells often become trapped in the walls of blood vessels and contribute to atherosclerotic plaque formation. Differences in cholesterol homeostasis affect the development of early atherosclerosis (carotid intima-media thickness). These plaques are the main causes of heart attacks, strokes, and other serious medical problems, leading to the association of so-called LDL cholesterol (actually a lipoprotein) with \"bad\" cholesterol.\nHDL particles are thought to transport cholesterol back to the liver, either for excretion or for other tissues that synthesize hormones, in a process known as reverse cholesterol transport (RCT). Large numbers of HDL particles correlates with better health outcomes, whereas low numbers of HDL particles is associated with atheromatous disease progression in the arteries.\nMetabolism, recycling and excretion.\nCholesterol is susceptible to oxidation and easily forms oxygenated derivatives called oxysterols. Three different mechanisms can form these: autoxidation, secondary oxidation to lipid peroxidation, and cholesterol-metabolizing enzyme oxidation. A great interest in oxysterols arose when they were shown to exert inhibitory actions on cholesterol biosynthesis. This finding became known as the \u201coxysterol hypothesis\u201d. Additional roles for oxysterols in human physiology include their participation in bile acid biosynthesis, function as transport forms of cholesterol, and regulation of gene transcription.\nIn biochemical experiments radiolabelled forms of cholesterol, such as tritiated-cholesterol are used. These derivatives undergo degradation upon storage and it is essential to purify cholesterol prior to use. Cholesterol can be purified using small Sephadex LH-20 columns.\nCholesterol is oxidized by the liver into a variety of bile acids. These, in turn, are conjugated with glycine, taurine, glucuronic acid, or sulfate. A mixture of conjugated and nonconjugated bile acids, along with cholesterol itself, is excreted from the liver into the bile. Approximately 95% of the bile acids are reabsorbed from the intestines, and the remainder are lost in the feces. The excretion and reabsorption of bile acids forms the basis of the enterohepatic circulation, which is essential for the digestion and absorption of dietary fats. Under certain circumstances, when more concentrated, as in the gallbladder, cholesterol crystallises and is the major constituent of most gallstones (lecithin and bilirubin gallstones also occur, but less frequently). Every day, up to 1 g of cholesterol enters the colon. This cholesterol originates from the diet, bile, and desquamated intestinal cells, and can be metabolized by the colonic bacteria. Cholesterol is converted mainly into coprostanol, a nonabsorbable sterol that is excreted in the feces.\nAlthough cholesterol is a steroid generally associated with mammals, the human pathogen \"Mycobacterium tuberculosis\" is able to completely degrade this molecule and contains a large number of genes that are regulated by its presence. Many of these cholesterol-regulated genes are homologues of fatty acid \u03b2-oxidation genes, but have evolved in such a way as to bind large steroid substrates like cholesterol.\nDietary sources.\nAnimal fats are complex mixtures of triglycerides, with lesser amounts of both the phospholipids and cholesterol molecules from which all animal (and human) cell membranes are constructed. Since all animal cells manufacture cholesterol, all animal-based foods contain cholesterol in varying amounts. Major dietary sources of cholesterol include red meat, egg yolks and whole eggs, liver, kidney, giblets, fish oil, and butter. Human breast milk also contains significant quantities of cholesterol.\nPlant cells synthesize cholesterol as a precursor for other compounds, such as phytosterols and steroidal glycoalkaloids, with cholesterol remaining in plant foods only in minor amounts or absent. Some plant foods, such as avocado, flax seeds and peanuts, contain phytosterols, which compete with cholesterol for absorption in the intestines, reduce the absorption of both dietary and bile cholesterol. A typical diet contributes on the order of 0.2 gram of phytosterols, which is not enough to have a significant impact on blocking cholesterol absorption. Phytosterols intake can be supplemented through the use of phytosterol-containing functional foods or dietary supplements that are recognized as having potential to reduce levels of LDL-cholesterol.\nMedical guidelines and recommendations.\nIn 2016, the United States Department of Agriculture Dietary Guidelines Advisory Committee recommended that Americans eat as little dietary cholesterol as possible. Most foods that are rich in cholesterol are also high in saturated fat and thereby may increase the risk of cardiovascular disease.\nSome supplemental guidelines have recommended doses of phytosterols in the 1.6\u20133.0\u00a0grams per day range (Health Canada, EFSA, ATP III, FDA). A recent meta-analysis demonstrating a 12% reduction in LDL-cholesterol at a mean dose of 2.1\u00a0grams per day. However, the benefits of a diet supplemented with phytosterols have also been questioned.\nClinical significance.\nHypercholesterolemia.\nAccording to the lipid hypothesis, elevated levels of cholesterol in the blood lead to atherosclerosis which may increase the risk of heart attack, stroke, and peripheral artery disease. Since higher blood LDL \u2013 especially higher LDL concentrations and smaller LDL particle size \u2013 contributes to this process more than the cholesterol content of the HDL particles, LDL particles are often termed \"bad cholesterol\". High concentrations of functional HDL, which can remove cholesterol from cells and atheromas, offer protection and are commonly referred to as \"good cholesterol\". These balances are mostly genetically determined, but can be changed by body composition, medications, diet, and other factors. A 2007 study demonstrated that blood total cholesterol levels have an exponential effect on cardiovascular and total mortality, with the association more pronounced in younger subjects. Because cardiovascular disease is relatively rare in the younger population, the impact of high cholesterol on health is larger in older people.\nElevated levels of the lipoprotein fractions, LDL, IDL and VLDL, rather than the total cholesterol level, correlate with the extent and progress of atherosclerosis. Conversely, the total cholesterol can be within normal limits, yet be made up primarily of small LDL and small HDL particles, under which conditions atheroma growth rates are high. A \"post hoc\" analysis of the IDEAL and the EPIC prospective studies found an association between high levels of HDL cholesterol (adjusted for apolipoprotein A-I and apolipoprotein B) and increased risk of cardiovascular disease, casting doubt on the cardioprotective role of \"good cholesterol\".\nAbout one in 250 individuals can have a genetic mutation for the LDL cholesterol receptor that causes them to have familial hypercholerolemia. Inherited high cholesterol can also include genetic mutations in the PCSK9 gene and the gene for apolipoprotein B.\nElevated cholesterol levels are treated with a strict diet consisting of low saturated fat, trans fat-free, low cholesterol foods, often followed by one of various hypolipidemic agents, such as statins, fibrates, cholesterol absorption inhibitors, nicotinic acid derivatives or bile acid sequestrants. There are several international guidelines on the treatment of hypercholesterolaemia.\nHuman trials using HMG-CoA reductase inhibitors, known as statins, have repeatedly confirmed that changing lipoprotein transport patterns from unhealthy to healthier patterns significantly lowers cardiovascular disease event rates, even for people with cholesterol values currently considered low for adults. Studies have shown that reducing LDL cholesterol levels by about 38.7\u00a0mg/dL with the use of statins can reduce cardiovascular disease and stroke risk by about 21%. Studies have also found that statins reduce atheroma progression. As a result, people with a history of cardiovascular disease may derive benefit from statins irrespective of their cholesterol levels (total cholesterol below 5.0\u00a0mmol/L [193\u00a0mg/dL]), and in men without cardiovascular disease, there is benefit from lowering abnormally high cholesterol levels (\"primary prevention\"). Primary prevention in women was originally practiced only by extension of the findings in studies on men, since, in women, none of the large statin trials conducted prior to 2007 demonstrated a significant reduction in overall mortality or in cardiovascular endpoints. Meta-analyses have demonstrated significant reductions in all-cause and cardiovascular mortality, without significant heterogeneity by sex.\nThe 1987 report of National Cholesterol Education Program, Adult Treatment Panels suggests the total blood cholesterol level should be: &lt; 200\u00a0mg/dL normal blood cholesterol, 200\u2013239\u00a0mg/dL borderline-high, &gt; 240\u00a0mg/dL high cholesterol. The American Heart Association provides a similar set of guidelines for total (fasting) blood cholesterol levels and risk for heart disease: Statins are effective in lowering LDL cholesterol and widely used for primary prevention in people at high risk of cardiovascular disease, as well as in secondary prevention for those who have developed cardiovascular disease.\nMore current testing methods determine LDL (\"bad\") and HDL (\"good\") cholesterol separately, allowing cholesterol analysis to be more nuanced. The desirable LDL level is considered to be less than 130\u00a0mg/dL (2.6 mmol/L), although a newer upper limit of 70\u00a0mg/dL (1.8\u00a0mmol/L) can be considered in higher-risk individuals based on some of the above-mentioned trials. A ratio of total cholesterol to HDL\u2014another useful measure\u2014of far less than 5:1 is thought to be healthier.\nTotal cholesterol is defined as the sum of HDL, LDL, and VLDL. Usually, only the total, HDL, and triglycerides are measured. For cost reasons, the VLDL is usually estimated as one-fifth of the triglycerides and the LDL is estimated using the Friedewald formula (or a variant): estimated LDL = [total cholesterol] \u2212 [total HDL] \u2212 [estimated VLDL]. VLDL can be calculated by dividing total triglycerides by five. Direct LDL measures are used when triglycerides exceed 400\u00a0mg/dL. The estimated VLDL and LDL have more error when triglycerides are above 400\u00a0mg/dL.\nIn the Framingham Heart Study, in subjects over 50 years of age, they found an 11% increase overall and 14% increase in cardiovascular disease mortality per 1\u00a0mg/dL per year drop in total cholesterol levels. The researchers attributed this phenomenon to the fact that people with severe chronic diseases or cancer tend to have below-normal cholesterol levels. This explanation is not supported by the Vorarlberg Health Monitoring and Promotion Programme, in which men of all ages and women over 50 with very low cholesterol were likely to die of cancer, liver diseases, and mental diseases. This result indicates the low-cholesterol effect occurs even among younger respondents, contradicting the previous assessment among cohorts of older people that this is a proxy or marker for frailty occurring with age.\nAlthough there is a link between cholesterol and atherosclerosis as discussed above, a 2014 review concluded there is insufficient evidence to support the recommendation of high consumption of polyunsaturated fatty acids and low consumption of total saturated fats for cardiovascular health. A 2016 review concluded that HDL cholesterol was inversely linked to mortality in people over age 60 years, and there was either no link between LDL and mortality, or that lower LDL was linked to a higher mortality risk, especially in older adults.\nHypocholesterolemia.\nAbnormally low levels of cholesterol are termed \"hypocholesterolemia\". Research into the causes of this state is relatively limited, but some studies suggest a link with depression, cancer, and cerebral hemorrhage. In general, the low cholesterol levels seem to be a consequence, rather than a cause, of an underlying illness. A genetic defect in cholesterol synthesis causes Smith\u2013Lemli\u2013Opitz syndrome, which is often associated with low plasma cholesterol levels. Hyperthyroidism, or any other endocrine disturbance which causes upregulation of the LDL receptor, may result in hypocholesterolemia.\nCholesterol testing.\nThe American Heart Association recommends testing cholesterol every 4\u20136 years for people aged 20 years or older. A separate set of American Heart Association guidelines issued in 2013 indicates that patients taking statin medications should have their cholesterol tested 4\u201312 weeks after their first dose and then every 3\u201312 months thereafter.\nA blood sample after 12-hour fasting is taken by a doctor, or a home cholesterol-monitoring device is used to measure a lipid profile, an approach used to estimate a person's lipoproteins, the vastly more important issue because lipoproteins have always been concordant with outcomes though the lipid profile is commonly discordant LDL Particle Number and Risk of Future Cardiovascular Disease in the Framingham Offspring Study.\nThe lipid profile measures: (a) total cholesterol, (b) cholesterol associated with HDL (i.e. Higher Density {than water} Lipids-transported-within-proteins) particles (\"which can regress arterial disease\"), (c) triglycerides and (d) (by a calculation and assumptions) cholesterol carried by LDL (i.e. Lower Density {than water} Lipids-transported-within-proteins) particles (\"which drive arterial disease\").\nIt is recommended to test cholesterol at least every five years if a person has total cholesterol of 5.2\u00a0mmol/L or more (200+\u00a0mg/dL), or if a man over age 45 or a woman over age 50 has HDL-C values less than 1\u00a0mmol/L (40\u00a0mg/dL), or there are other drivers heart disease and stroke. Additional drivers of heart disease include diabetes mellitus, hypertension (or use of anti-hypertensive medication), low HDL level, family history of coronary artery disease (CAD) and hypercholesterolemia, and cigarette smoking.\nCholesteric liquid crystals.\nSome cholesterol derivatives (among other simple cholesteric lipids) are known to generate the liquid crystalline \"cholesteric phase\". The cholesteric phase is, in fact, a chiral nematic phase, and it changes colour when its temperature changes. This makes cholesterol derivatives useful for indicating temperature in liquid-crystal display thermometers and in temperature-sensitive paints.\nStereoisomers.\nCholesterol has 256 stereoisomers that arise from its 8 stereocenters, although only two of the stereoisomers are of biochemical significance (\"nat\"-cholesterol and \"ent\"-cholesterol, for \"natural\" and \"enantiomer\", respectively), and only one occurs naturally (\"nat\"-cholesterol)."}
{"id": "6438", "revid": "37918255", "url": "https://en.wikipedia.org/wiki?curid=6438", "title": "Chromosome", "text": "A chromosome is a long DNA molecule with part or all of the genetic material of an organism. Most eukaryotic chromosomes include packaging proteins called histones which, aided by chaperone proteins, bind to and condense the DNA molecule to maintain its integrity. These chromosomes display a complex three-dimensional structure, which plays a significant role in transcriptional regulation.\nChromosomes are normally visible under a light microscope only during the metaphase of cell division (where all chromosomes are aligned in the center of the cell in their condensed form). Before this happens, each chromosome is duplicated (S phase), and both copies are joined by a centromere, resulting either in an X-shaped structure (pictured above), if the centromere is located equatorially, or a two-arm structure, if the centromere is located distally. The joined copies are now called sister chromatids. During metaphase the X-shaped structure is called a metaphase chromosome, which is highly condensed and thus easiest to distinguish and study. In animal cells, chromosomes reach their highest compaction level in anaphase during chromosome segregation.\nChromosomal recombination during meiosis and subsequent sexual reproduction play a significant role in genetic diversity. If these structures are manipulated incorrectly, through processes known as chromosomal instability and translocation, the cell may undergo mitotic catastrophe. Usually, this will make the cell initiate apoptosis leading to its own death, but sometimes mutations in the cell hamper this process and thus cause progression of cancer.\nSome use the term chromosome in a wider sense, to refer to the individualized portions of chromatin in cells, either visible or not under light microscopy. Others use the concept in a narrower sense, to refer to the individualized portions of chromatin during cell division, visible under light microscopy due to high condensation.\nEtymology.\nThe word \"chromosome\" () comes from the Greek (\"chroma\", \"colour\") and (\"soma\", \"body\"), describing their strong staining by particular dyes. The term was coined by the German anatomist Heinrich Wilhelm Waldeyer, referring to the term chromatin, which was introduced by Walther Flemming, the discoverer of cell division.\nSome of the early karyological terms have become outdated. For example, Chromatin (Flemming 1880) and Chromosom (Waldeyer 1888), both ascribe color to a non-colored state.\nHistory of discovery.\nThe German scientists Schleiden, Virchow and B\u00fctschli were among the first scientists who recognized the structures now familiar as chromosomes.\nIn a series of experiments beginning in the mid-1880s, Theodor Boveri gave definitive contributions to elucidating that chromosomes are the vectors of heredity, with two notions that became known as \u2018chromosome continuity\u2019 and \u2018chromosome individuality\u2019. \nWilhelm Roux suggested that each chromosome carries a different genetic configuration, and Boveri was able to test and confirm this hypothesis. Aided by the rediscovery at the start of the 1900s of Gregor Mendel's earlier work, Boveri was able to point out the connection between the rules of inheritance and the behaviour of the chromosomes. Boveri influenced two generations of American cytologists: Edmund Beecher Wilson, Nettie Stevens, Walter Sutton and Theophilus Painter were all influenced by Boveri (Wilson, Stevens, and Painter actually worked with him).\nIn his famous textbook \"The Cell in Development and Heredity\", Wilson linked together the independent work of Boveri and Sutton (both around 1902) by naming the chromosome theory of inheritance the Boveri\u2013Sutton chromosome theory (the names are sometimes reversed). Ernst Mayr remarks that the theory was hotly contested by some famous geneticists: William Bateson, Wilhelm Johannsen, Richard Goldschmidt and T.H. Morgan, all of a rather dogmatic turn of mind. Eventually, complete proof came from chromosome maps in Morgan's own lab.\nThe number of human chromosomes was published in 1923 by Theophilus Painter. By inspection through the microscope, he counted 24 pairs, which would mean 48 chromosomes. His error was copied by others and it was not until 1956 that the true number, 46, was determined by Indonesia-born cytogeneticist Joe Hin Tjio.\nProkaryotes.\nThe prokaryotes\u00a0\u2013 bacteria and archaea\u00a0\u2013 typically have a single circular chromosome, but many variations exist. The chromosomes of most bacteria, which some authors prefer to call genophores, can range in size from only 130,000 base pairs in the endosymbiotic bacteria \"Candidatus Hodgkinia cicadicola\" and \"Candidatus Tremblaya princeps\", to more than 14,000,000 base pairs in the soil-dwelling bacterium \"Sorangium cellulosum\". Spirochaetes of the genus \"Borrelia\" are a notable exception to this arrangement, with bacteria such as \"Borrelia burgdorferi\", the cause of Lyme disease, containing a single \"linear\" chromosome.\nStructure in sequences.\nProkaryotic chromosomes have less sequence-based structure than eukaryotes. Bacteria typically have a one-point (the origin of replication) from which replication starts, whereas some archaea contain multiple replication origins. The genes in prokaryotes are often organized in operons, and do not usually contain introns, unlike eukaryotes.\nDNA packaging.\nProkaryotes do not possess nuclei. Instead, their DNA is organized into a structure called the nucleoid. The nucleoid is a distinct structure and occupies a defined region of the bacterial cell. This structure is, however, dynamic and is maintained and remodeled by the actions of a range of histone-like proteins, which associate with the bacterial chromosome. In archaea, the DNA in chromosomes is even more organized, with the DNA packaged within structures similar to eukaryotic nucleosomes.\nCertain bacteria also contain plasmids or other extrachromosomal DNA. These are circular structures in the cytoplasm that contain cellular DNA and play a role in horizontal gene transfer. In prokaryotes (see nucleoids) and viruses, the DNA is often densely packed and organized; in the case of archaea, by homology to eukaryotic histones, and in the case of bacteria, by histone-like proteins.\nBacterial chromosomes tend to be tethered to the plasma membrane of the bacteria. In molecular biology application, this allows for its isolation from plasmid DNA by centrifugation of lysed bacteria and pelleting of the membranes (and the attached DNA).\nProkaryotic chromosomes and plasmids are, like eukaryotic DNA, generally supercoiled. The DNA must first be released into its relaxed state for access for transcription, regulation, and replication.\nEukaryotes.\nEach eukaryotic chromosome consists of a long linear DNA molecule associated with proteins, forming a compact complex of proteins and DNA called \"chromatin.\" Chromatin contains the vast majority of the DNA of an organism, but a small amount inherited maternally, can be found in the mitochondria. It is present in most cells, with a few exceptions, for example, red blood cells.\nHistones are responsible for the first and most basic unit of chromosome organization, the nucleosome.\nEukaryotes (cells with nuclei such as those found in plants, fungi, and animals) possess multiple large linear chromosomes contained in the cell's nucleus. Each chromosome has one centromere, with one or two arms projecting from the centromere, although, under most circumstances, these arms are not visible as such. In addition, most eukaryotes have a small circular mitochondrial genome, and some eukaryotes may have additional small circular or linear cytoplasmic chromosomes.\nIn the nuclear chromosomes of eukaryotes, the uncondensed DNA exists in a semi-ordered structure, where it is wrapped around histones (structural proteins), forming a composite material called chromatin.\nInterphase chromatin.\nThe packaging of DNA into nucleosomes causes a 10 nanometer fibre which may further condense up to 30\u00a0nm fibres Most of the euchromatin in interphase nuclei appears to be in the form of 30-nm fibers. Chromatin structure is the more decondensed state, i.e. the 10-nm conformation allows transcription.\nDuring interphase (the period of the cell cycle where the cell is not dividing), two types of chromatin can be distinguished:\nMetaphase chromatin and division.\nIn the early stages of mitosis or meiosis (cell division), the chromatin double helix become more and more condensed. They cease to function as accessible genetic material (transcription stops) and become a compact transportable form. The loops of 30-nm chromatin fibers are thought to fold upon themselves further to form the compact metaphase chromosomes of mitotic cells. The DNA is thus condense about 10,000 folds. \nChromosome scaffold, which is made of proteins such as condensin, TOP2A and KIF4, play an important role in holding the chromatin into compact chromosome. Loops of 30\u00a0nm structure further condense with scaffold into higher order structures. \nThis highly compact form makes the individual chromosomes visible, and they form the classic four arm structure, a pair of sister chromatids attached to each other at the centromere. The shorter arms are called \"p arms\" (from the French \"petit\", small) and the longer arms are called \"q arms\" (\"q\" follows \"p\" in the Latin alphabet; q-g \"grande\"; alternatively it is sometimes said q is short for \"queue\" meaning tail in French). This is the only natural context in which individual chromosomes are visible with an optical microscope.\nMitotic metaphase chromosomes are best described by a linearly organized longitudinally compressed array of consecutive chromatin loops.\nDuring mitosis, microtubules grow from centrosomes located at opposite ends of the cell and also attach to the centromere at specialized structures called kinetochores, one of which is present on each sister chromatid. A special DNA base sequence in the region of the kinetochores provides, along with special proteins, longer-lasting attachment in this region. The microtubules then pull the chromatids apart toward the centrosomes, so that each daughter cell inherits one set of chromatids. Once the cells have divided, the chromatids are uncoiled and DNA can again be transcribed. In spite of their appearance, chromosomes are structurally highly condensed, which enables these giant DNA structures to be contained within a cell nucleus.\nHuman chromosomes.\nChromosomes in humans can be divided into two types: autosomes (body chromosome(s)) and allosome (sex chromosome(s)). Certain genetic traits are linked to a person's sex and are passed on through the sex chromosomes. The autosomes contain the rest of the genetic hereditary information. All act in the same way during cell division. Human cells have 23 pairs of chromosomes (22 pairs of autosomes and one pair of sex chromosomes), giving a total of 46 per cell. In addition to these, human cells have many hundreds of copies of the mitochondrial genome. Sequencing of the human genome has provided a great deal of information about each of the chromosomes. Below is a table compiling statistics for the chromosomes, based on the Sanger Institute's human genome information in the Vertebrate Genome Annotation (VEGA) database. Number of genes is an estimate, as it is in part based on gene predictions. Total chromosome length is an estimate as well, based on the estimated size of unsequenced heterochromatin regions.\nNumber in various organisms.\nIn eukaryotes.\nThese tables give the total number of chromosomes (including sex chromosomes) in a cell nucleus. For example, most eukaryotes are diploid, like humans who have 22 different types of autosomes, each present as two homologous pairs, and two sex chromosomes. This gives 46 chromosomes in total. Other organisms have more than two copies of their chromosome types, such as bread wheat, which is \"hexaploid\" and has six copies of seven different chromosome types\u00a0\u2013 42 chromosomes in total.\nNormal members of a particular eukaryotic species all have the same number of nuclear chromosomes (see the table). Other eukaryotic chromosomes, i.e., mitochondrial and plasmid-like small chromosomes, are much more variable in number, and there may be thousands of copies per cell.\nAsexually reproducing species have one set of chromosomes that are the same in all body cells. However, asexual species can be either haploid or diploid.\nSexually reproducing species have somatic cells (body cells), which are diploid [2n] having two sets of chromosomes (23 pairs in humans with one set of 23 chromosomes from each parent), one set from the mother and one from the father. Gametes, reproductive cells, are haploid [n]: They have one set of chromosomes. Gametes are produced by meiosis of a diploid germ line cell. During meiosis, the matching chromosomes of father and mother can exchange small parts of themselves (crossover), and thus create new chromosomes that are not inherited solely from either parent. When a male and a female gamete merge (fertilization), a new diploid organism is formed.\nSome animal and plant species are polyploid [Xn]: They have more than two sets of homologous chromosomes. Plants important in agriculture such as tobacco or wheat are often polyploid, compared to their ancestral species. Wheat has a haploid number of seven chromosomes, still seen in some cultivars as well as the wild progenitors. The more-common pasta and bread wheat types are polyploid, having 28 (tetraploid) and 42 (hexaploid) chromosomes, compared to the 14 (diploid) chromosomes in the wild wheat.\nIn prokaryotes.\nProkaryote species generally have one copy of each major chromosome, but most cells can easily survive with multiple copies. For example, \"Buchnera\", a symbiont of aphids has multiple copies of its chromosome, ranging from 10\u2013400 copies per cell. However, in some large bacteria, such as \"Epulopiscium fishelsoni\" up to 100,000 copies of the chromosome can be present. Plasmids and plasmid-like small chromosomes are, as in eukaryotes, highly variable in copy number. The number of plasmids in the cell is almost entirely determined by the rate of division of the plasmid\u00a0\u2013 fast division causes high copy number.\nKaryotype.\nIn general, the karyotype is the characteristic chromosome complement of a eukaryote species. The preparation and study of karyotypes is part of cytogenetics.\nAlthough the replication and transcription of DNA is highly standardized in eukaryotes, the same cannot be said for their karyotypes, which are often highly variable. There may be variation between species in chromosome number and in detailed organization.\nIn some cases, there is significant variation within species. Often there is:\nAlso, variation in karyotype may occur during development from the fertilized egg.\nThe technique of determining the karyotype is usually called \"karyotyping\". Cells can be locked part-way through division (in metaphase) in vitro (in a reaction vial) with colchicine. These cells are then stained, photographed, and arranged into a \"karyogram\", with the set of chromosomes arranged, autosomes in order of length, and sex chromosomes (here X/Y) at the end.\nLike many sexually reproducing species, humans have special gonosomes (sex chromosomes, in contrast to autosomes). These are XX in females and XY in males. \nHistory and analysis techniques.\nInvestigation into the human karyotype took many years to settle the most basic question: \"How many chromosomes does a normal diploid human cell contain?\" In 1912, Hans von Winiwarter reported 47 chromosomes in spermatogonia and 48 in oogonia, concluding an XX/XO sex determination mechanism. Painter in 1922 was not certain whether the diploid number of man is 46 or 48, at first favouring 46. He revised his opinion later from 46 to 48, and he correctly insisted on humans having an XX/XY system.\nNew techniques were needed to definitively solve the problem:\nIt took until 1954 before the human diploid number was confirmed as 46. Considering the techniques of Winiwarter and Painter, their results were quite remarkable. Chimpanzees, the closest living relatives to modern humans, have 48 chromosomes as do the other great apes: in humans two chromosomes fused to form chromosome 2.\nAberrations.\nChromosomal aberrations are disruptions in the normal chromosomal content of a cell and are a major cause of genetic conditions in humans, such as Down syndrome, although most aberrations have little to no effect. Some chromosome abnormalities do not cause disease in carriers, such as translocations, or chromosomal inversions, although they may lead to a higher chance of bearing a child with a chromosome disorder. Abnormal numbers of chromosomes or chromosome sets, called aneuploidy, may be lethal or may give rise to genetic disorders. Genetic counseling is offered for families that may carry a chromosome rearrangement.\nThe gain or loss of DNA from chromosomes can lead to a variety of genetic disorders. Human examples include:\nSperm aneuploidy.\nExposure of males to certain lifestyle, environmental and/or occupational hazards may increase the risk of aneuploid spermatozoa. In particular, risk of aneuploidy is increased by tobacco smoking, and occupational exposure to benzene, insecticides, and perfluorinated compounds. Increased aneuploidy is often associated with increased DNA damage in spermatozoa."}
{"id": "6439", "revid": "4082870", "url": "https://en.wikipedia.org/wiki?curid=6439", "title": "Charge", "text": "Charge or charged may refer to:"}
{"id": "6440", "revid": "36043475", "url": "https://en.wikipedia.org/wiki?curid=6440", "title": "Colonna family", "text": "Colonna, also known as \"Sciarrillo\" or \"Sciarra\", is an Italian noble family, forming part of the papal nobility. It was powerful in medieval and Renaissance Rome, supplying one Pope (Martin V) and many other church and political leaders. The family is notable for its bitter feud with the Orsini family over influence in Rome, until it was stopped by Papal Bull in 1511. In 1571, the heads of both families married nieces of Pope Sixtus V. Thereafter, historians recorded that \"no peace had been concluded between the princes of Christendom, in which they had not been included by name\".\nHistory.\nOrigins.\nAccording to tradition, the Colonna family is a branch of the Counts of Tusculum \u2014 by Peter (1099\u20131151) son of Gregory III, called Peter \"de Columna\" from his property the Columna Castle in Colonna, in the Alban Hills. Further back, they trace their lineage past the Counts of Tusculum via Lombard and Italo-Roman nobles, merchants, and clergy through the Early Middle Ages \u2014 ultimately claiming origins from the Julio-Claudian dynasty.\nThe first cardinal from the family was appointed in 1206, when Giovanni Colonna di Carbognano was made Cardinal Deacon of SS. Cosma e Damiano. For many years, Cardinal Giovanni di San Paolo (elevated in 1193) was identified as a member of the Colonna family and therefore its first representative in the College of Cardinals, but modern scholars have established that this was based on false information from the beginning of the 16th century.\nGiovanni Colonna (born c. 1206) nephew of Cardinal Giovanni Colonna di Carbognano, made his solemn vows as a Dominican around 1228 and received his theological and philosophical training at the Roman \"studium\" of Santa Sabina, the forerunner of the Pontifical University of Saint Thomas Aquinas, \"Angelicum\". He served as the Provincial of the Roman province of the Dominican Order and led the provincial chapter of 1248 at Anagni. Colonna was appointed as Archbishop of Messina in 1255.\nMargherita Colonna (died 1248) was a member of the Franciscan Order. She was beatified by Pope Pius IX in 1848.\nAt this time, a rivalry began with the pro-papal Orsini family, leaders of the Guelph faction. This reinforced the pro-Emperor Ghibelline course that the Colonna family followed throughout the period of conflict between the Papacy and the Holy Roman Empire.\nColonna versus Papacy.\nIn 1297, Cardinal Jacopo (Giacomo Colonna) disinherited his brothers Ottone, Matteo, and Landolfo of their lands. The latter three appealed to Pope Boniface VIII, who ordered Jacopo to return the land, and furthermore hand over the family's strongholds of Colonna, Palestrina, and other towns to the Papacy. Jacopo refused; in May, Boniface removed him from the College of Cardinals and excommunicated him and his followers.\nThe Colonna family (aside from the three brothers allied with the Pope) declared that Boniface had been elected illegally following the unprecedented abdication of Pope Celestine V. The dispute led to open warfare, and in September, Boniface appointed Landolfo to the command of his army, to put down the revolt of Landolfo's own Colonna relatives. By the end of 1298, Landolfo had captured Colonna, Palestrina and other towns, and razed them to the ground. The family's lands were distributed among Landolfo and his loyal brothers; the rest of the family fled Italy.\nThe exiled Colonnas allied with the Pope's other great enemy, Philip IV of France, who in his youth had been tutored by Cardinal Egidio Colonna. In September 1303, Sciarra and Philipp's advisor, Guillaume de Nogaret, led a small force into Anagni to arrest Boniface VIII and bring him to France, where he was to stand trial. The two managed to apprehend the pope, and Sciarra reportedly slapped the pope in the face in the process, which was accordingly dubbed the \"Outrage of Anagni\". The attempt eventually failed after a few days, when locals freed the pope. However, Boniface VIII died on 11 October, allowing France to dominate his weaker successors during the Avignon papacy.\nLate Middle Ages.\nThe family remained at the centre of civic and religious life throughout the late Middle Ages. Cardinal Egidio Colonna died at the papal court in Avignon in 1314. An Augustinian, he had studied theology in Paris under St. Thomas of Aquinas to become one of the most authoritative thinkers of his time.\nIn the 14th century, the family sponsored the decoration of the Church of San Giovanni, most notably the floor mosaics.\nIn 1328, Louis IV of Germany marched into Italy for his coronation as Holy Roman Emperor. As Pope John XXII was residing in Avignon and had publicly declared that he would not crown Louis, the King decided to be crowned by a member of the Roman aristocracy, who proposed Sciarra Colonna. In honor of this event, the Colonna family was granted the privilege of using the imperial pointed crown on top of their coat of arms.\nThe celebrated poet Petrarch, was a great friend of the family, in particular of Giovanni Colonna and often lived in Rome as a guest of the family. He composed a number of sonnets for special occasions within the Colonna family, including \"Colonna the Glorious, the great Latin name upon which all our hopes rest\". In this period, the Colonna started claiming they were descendants of the Julio-Claudian dynasty.\nAt the Council of Constance, the Colonna finally succeeded in their papal ambitions when Oddone Colonna was elected on 14 November 1417. As Martin V, he reigned until his death on 20 February 1431.\nEarly modern period.\nVittoria Colonna became famous in the sixteenth century as a poet and a figure in literate circles.\nIn 1627 Anna Colonna, daughter of Filippo I Colonna, married Taddeo Barberini of the family Barberini; nephew of Pope Urban VIII.\nIn 1728, the Carbognano branch (Colonna di Sciarra) of the Colonna family added the name Barberini to its family name when Giulio Cesare Colonna di Sciarra married Cornelia Barberini, daughter of the last male Barberini to hold the name and granddaughter of Maffeo Barberini (son of Taddeo Barberini).\nCurrent status.\nThe Colonna family have been Prince Assistants to the Papal Throne since 1710, though their papal princely title only dates from 1854.\nThe family residence in Rome, the Palazzo Colonna, is open to the public every Saturday morning.\nThe main 'Colonna di Paliano' line is represented today by Prince Marcantonio Colonna di Paliano, Prince and Duke of Paliano (b. 1948), whose heir is Don Giovanni Andrea Colonna di Paliano (b. 1975), and by Don Prospero Colonna di Paliano, Prince of Avella (b. 1956), whose heir is Don Filippo Colonna di Paliano (b. 1995).\nThe 'Colonna di Stigliano' line is represented by Don Prospero Colonna di Stigliano, Prince of Stigliano (b. 1938), whose heir is his nephew Don Stefano Colonna di Stigliano (b. 1975)."}
