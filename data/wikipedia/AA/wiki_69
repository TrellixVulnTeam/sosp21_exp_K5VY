{"id": "8262", "revid": "7254364", "url": "https://en.wikipedia.org/wiki?curid=8262", "title": "Dominoes", "text": "Dominoes is a family of tile-based games played with gaming pieces, commonly known as dominoes. Each domino is a rectangular tile with a line dividing its face into two square \"ends\". Each end is marked with a number of spots (also called \"pips\" or \"dots\") or is blank. The backs of the tiles in a set are indistinguishable, either blank or having some common design. The gaming pieces make up a domino set, sometimes called a \"deck\" or \"pack\". The traditional European domino set consists of 28 tiles, also known as pieces, bones, rocks, stones, men, cards or just dominoes, featuring all combinations of spot counts between zero and six. A domino set is a generic gaming device, similar to playing cards or dice, in that a variety of games can be played with a set.\nThe earliest mention of dominoes is from Song dynasty China found in the text \"Former Events in Wulin\" by Zhou Mi (1232\u20131298). Modern dominoes first appeared in Italy during the 18th century, but they differ from Chinese dominoes in a number of respects, and there is no confirmed link between the two. European dominoes may have developed independently, or Italian missionaries in China may have brought the game to Europe.\nThe name \"domino\" is probably derived from the resemblance to a kind of carnival costume worn during the Venetian Carnival, often consisting of a black-hooded robe and a white mask. Despite the coinage of the word \"polyomino\" as a generalization, there is no connection between the word \"domino\" and the number 2 in any language.\nThe most commonly played domino games are Domino Whist, Matador, and Muggins (All Fives). Other popular forms include Texas 42, Chicken Foot, Concentration, Double Fives, and Mexican Train. In Britain, the most popular league and pub game is Fives and Threes.\nConstruction and composition of domino sets.\nEuropean-style dominoes are traditionally made of bone, silver lip ocean pearl oyster shell (mother of pearl), ivory, or a dark hardwood such as ebony, with contrasting black or white pips (inlaid or painted). Some sets feature the top half thickness in MOP, ivory, or bone, with the lower half in ebony. Alternatively, domino sets have been made from many different natural materials: stone (e.g., marble, granite or soapstone); other woods (e.g., ash, oak, redwood, and cedar); metals (e.g., brass or pewter); ceramic clay, or even frosted glass or crystal. These sets have a more novel look, and the often heavier weight makes them feel more substantial; also, such materials and the resulting products are usually much more expensive than polymer materials. \nModern commercial domino sets are usually made of synthetic materials, such as ABS or polystyrene plastics, or Bakelite and other phenolic resins; many sets approximate the look and feel of ivory while others use colored or even translucent plastics to achieve a more contemporary look. Modern sets also commonly use a different color for the dots of each different end value (one-spots might have black pips while two-spots might be green, three red, etc.) to facilitate finding matching ends. Occasionally, one may find a domino set made of card stock like that for playing cards. Such sets are lightweight, compact, and inexpensive, and like cards are more susceptible to minor disturbances such as a sudden breeze. Sometimes, the tiles have a metal pin (called a spinner or pivot) in the middle.\nThe traditional domino set contains one unique piece for each possible combination of two ends with zero to six spots, and is known as a double-six set because the highest-value piece has six pips on each end (the \"double six\"). The spots from one to six are generally arranged as they are on six-sided dice, but because blank ends having no spots are used, seven faces are possible, allowing 28 unique pieces in a double-six set.\nHowever, this is a relatively small number especially when playing with more than four people, so many domino sets are \"extended\" by introducing ends with greater numbers of spots, which increases the number of unique combinations of ends and thus of pieces. Each progressively larger set increases the maximum number of pips on an end by three, so the common extended sets are double-nine (55 tiles), double-12 (91 tiles), double-15 (136 tiles), and double-18 (190 tiles), which is the maximum in practice. Larger sets such as double-21 (253 tiles) could theoretically exist, but they seem to be extremely rare if nonexistent, as that would be far more than is normally necessary for most domino games even with eight players. As the set becomes larger, identifying the number of pips on each domino becomes more difficult, so some large domino sets use more readable Arabic numerals instead of pips.\nHistory.\nThe oldest confirmed written mention of dominoes in China comes from the \"Former Events in Wulin\" (i.e., the capital Hangzhou) written by the Yuan Dynasty (1271\u20131368) author Zhou Mi (1232\u20131298), who listed \"pupai\" (gambling plaques or tiles), as well as dice as items sold by peddlers during the reign of Emperor Xiaozong of Song (r. 1162\u20131189). Andrew Lo asserts that Zhou Mi meant dominoes when referring to \"pupai\", since the Ming author Lu Rong (1436\u20131494) explicitly defined \"pupai\" as dominoes (in regard to a story of a suitor who won a maiden's hand by drawing out four winning \"pupai\" from a set).\nThe earliest known manual written about dominoes is the \"(Manual of the Xuanhe Period)\" written by Qu You (1341\u20131437), but some Chinese scholars believe this manual is a forgery from a later time.\nIn the \"Encyclopedia of a Myriad of Treasures\", Zhang Pu (1602\u20131641) described the game of laying out dominoes as \"pupai\", although the character for \"pu\" had changed, yet retained the same pronunciation. Traditional Chinese domino games include \"Tien Gow, Pai Gow, Che Deng\", and others. The 32-piece Chinese domino set, made to represent each possible face of two thrown dice and thus have no blank faces, differs from the 28-piece domino set found in the West during the mid 18th century. Chinese dominoes with blank faces were known during the 17th century.\nMany different domino sets have been used for centuries in various parts of the world to play a variety of domino games. Each domino originally represented one of the 21 results of throwing two six-sided dice (2d6). One half of each domino is set with the pips from one die and the other half contains the pips from the second die. Chinese sets also introduce duplicates of some throws and divide the tiles into two suits: military and civil. Chinese dominoes are also longer than typical European ones.\nThe early 18th century saw the \"game of domino\" surfacing in Europe, appearing first in Italy, before rapidly spreading to Austria, southern Germany and France. From France, the game was introduced to England by the late 1700s, purportedly brought in French prisoners-of-war. It appears in American literature by the 1860s and variants soon spring up. In 1889, it was described as having spread worldwide, \"but nowhere is it more popular than in the caf\u00e9s of France and Belgium. From the outset, the European game was different from the Chinese one. European domino sets contain neither the military-civilian suit distinctions of Chinese dominoes nor the duplicates that went with them. Moreover, according to Dummett, in the Chinese games it is only the identity of the tile that matters; there is no concept of matching. Instead, the basic set of 28 unique tiles contains seven additional pieces, six of them representing the values that result from throwing a single die with the other half of the tile left blank, and the seventh domino representing the blank-blank (0\u20130) combination. Subsequently 45-piece (double eight) sets appeared in Austria and, in recent times, 55-piece (double nine) and 91-piece (double twelve) sets have been produced.\nThe earliest game rules in Europe describe a simple block game for two or four players. Later French rules add the variant of \"Domino \u00e0 la P\u00eache\" (\"Fishing Domino\"), an early draw game as well as a three-hand game with a pool. The first scoring game to be recorded was Fives, All Fives or Cribbage Dominoes which appeared in 1863 and borrowed the features of scoring for combinations as well as the cribbage board from the card game of Cribbage. In 1864, \"The American Hoyle\" describes three new variants: Muggins, simply Fives with the addition of another Cribbage feature, the 'muggins rule'; Bergen and Rounce; alongside the Block Game and Draw Game. All are still played today alongside games that have sprung up in the last 60 years such as Five Up, Mexican Train and Chicken Foot, the last two taking advantage of the larger domino sets available.\nTiles and suits.\nDominoes (also known as bones, cards, men, pieces or tiles), are normally twice as long as they are wide, which makes it easier to re-stack pieces after use. A domino usually features a line in the middle to divide it visually into two squares, also called ends. The value of either side is the number of spots or pips. In the most common variant (double-six), the values range from six pips down to none or blank. The sum of the two values, i.e. the total number of pips, may be referred to as the rank or weight of a tile; a tile may be described as \"heavier\" than a \"lighter\" one that has fewer (or no) pips.\nTiles are generally named after their two values. For instance, the following are descriptions of a tile bearing the values two and five:\nA tile that has the same pips-value on each end is called a double, and is typically referred to as double-zero, double-one, and so on. Conversely, a tile bearing different values is called a single.\nEvery tile which features a given number is a member of the suit of that number. A single tile is a member of two suits: for example, 0-3 belongs both to the suit of threes and the suit of blanks, or 0 suit.\nIn some versions the doubles can be treated as an additional suit of doubles. In these versions, the double-six belongs both to the suit of sixes and the suit of doubles. However, the dominant approach is that each double belongs to only one suit. \nThe most common domino sets commercially available are double six (with 28 tiles) and double nine (with 55 tiles). Larger sets exist and are popular for games involving several players or for players looking for long domino games.\nThe number of tiles in a double-n set obeys the following formula:\nThe total number of pips in a double-n set is found by:\nformula_2 i.e. the number of tiles multiplied by the maximum pip-count (n)\ne.g. a 6-6 set has (7 x 8) / 2 = 56/2 = 28 tiles, the average number of pips per tile is 6 (range is from 0 to 12), giving a total pip count of 6 x 28 = 168\nThis formula can be simplified a little bit when formula_3 is made equal to the \"total number of doubles in the domino set\":\nformula_4\nRules.\nThe most popular type of play are layout games, which fall into two main categories, blocking games and scoring games.\nBlocking game.\nThe most basic domino variant is for two players and requires a double-six set. The 28 tiles are shuffled face down and form the \"stock\" or \"boneyard\". Each player draws seven tiles from the stock. Once the players begin drawing tiles, they are typically placed on-edge in front of the players, so each player can see their own tiles, but none can see the value of other players' tiles. Every player can thus see how many tiles remain in the opponent's hands at all times during gameplay.\nOne player begins by downing (playing the first tile) one of their tiles. This tile starts the line of play, in which values of adjacent pairs of tile ends must match. The players alternately extend the line of play with one tile at one of its two ends; if a player is unable to place a valid tile, they must continue drawing tiles from the stock until they are able to place a tile. The game ends when one player wins by playing their last tile, or when the game is blocked because neither player can play. If that occurs, whoever caused the block receives all of the remaining player points not counting their own.\nScoring game.\nPlayers accrue points during game play for certain configurations, moves, or emptying one's hand. Most scoring games use variations of the draw game. If a player does not call \"domino\" before the tile is laid on the table, and another player says domino after the tile is laid, the first player must pick up an extra domino.\nDraw game.\nIn a draw game (blocking or scoring), players are additionally allowed to draw as many tiles as desired from the stock before playing a tile, and they are not allowed to pass before the stock is (nearly) empty. The score of a game is the number of pips in the losing player's hand plus the number of pips in the stock. Most rules prescribe that two tiles need to remain in the stock. The draw game is often referred to as simply \"dominoes\".\nAdaptations of both games can accommodate more than two players, who may play individually or in teams.\nLine of play.\nThe line of play is the configuration of played tiles on the table. It starts with a single tile and typically grows in two opposite directions when players add matching tiles. In practice, players often play tiles at right angles when the line of play gets too close to the edge of the table.\nThe rules for the line of play often differ from one variant to another. In many rules, the doubles serve as spinners, i.e., they can be played on all four sides, causing the line of play to branch. Sometimes, the first tile is required to be a double, which serves as the only spinner. In some games such as Chicken Foot, all sides of a spinner must be occupied before anybody is allowed to play elsewhere. Matador has unusual rules for matching. Bendomino uses curved tiles, so one side of the line of play (or both) may be blocked for geometrical reasons.\nIn Mexican Train and other train games, the game starts with a spinner from which various trains branch off. Most trains are owned by a player and in most situations players are allowed to extend only their own train.\nScoring.\nIn blocking games, scoring happens at the end of the game. After a player has emptied their hand, thereby winning the game for the team, the score consists of the total pip count of the losing team's hands. In some rules, the pip count of the remaining stock is added. If a game is blocked because no player can move, the winner is often determined by adding the pips in players' hands.\nIn scoring games, each individual can potentially add to the score. For example, in Bergen, players score two points whenever they cause a configuration in which both open ends have the same value and three points if additionally one open end is formed by a double. In Muggins, players score by ensuring the total pip count of the open ends is a multiple of a certain number. In variants of Muggins, the line of play may branch due to spinners.\nIn British public houses and social clubs, a scoring version of \"5s-and-3s\" is used. The game is normally played in pairs (two against two) and is played as a series of \"ends\". In each \"end\", the objective is for players to attach a domino from their hand to one end of those already played so that the sum of the end tiles is divisible by five or three. One point is scored for each time five or three can be divided into the sum of the two tiles, i.e. four at one end and five at the other makes nine, which is divisible by three three times, resulting in three points. Double five at one end and five at the other makes 15, which is divisible by three five times (five points) and divisible by five three times (three points) for a total of eight points.\nAn \"end\" stops when one of the players is out, i.e., has played all of their tiles. In the event no player is able to empty their hand, then the player with the lowest domino left in hand is deemed to be out and scores one point. A game consists of any number of ends with points scored in the ends accumulating towards a total. The game ends when one of the pair's total score exceeds a set number of points. A running total score is often kept on a cribbage board. 5s-and-3s is played in a number of competitive leagues in the British Isles.\nCard games using domino sets.\nApart from the usual blocking and scoring games, also domino games of a very different character are played, such as solitaire or trick-taking games. Most of these are adaptations of card games and were once popular in certain areas to circumvent religious proscriptions against playing cards.\nA very simple example is a Concentration variant played with a double-six set; two tiles are considered to match if their total pip count is 12.\nA popular domino game in Texas is 42. The game is similar to the card game spades. It is played with four players paired into teams. Each player draws seven tiles, and the tiles are played into tricks. Each trick counts as one point, and any domino with a multiple of five dots counts toward the total of the hand. These 35 points of \"five count\" and seven tricks equals 42 points, hence the name.\nCompetitive play.\nDominoes is played at a professional level, similar to poker. Numerous organisations and clubs of amateur domino players exist around the world. Some organizations organize international competitions.\nOther uses.\nBesides playing games, another use of domino tiles is the domino show, which involves standing them on end in long lines so that when the first tile is toppled, it topples the second, which topples the third, etc., resulting in all of the tiles falling. By analogy, the phenomenon of small events causing similar events leading to eventual catastrophe is called the domino effect.\nArrangements of millions of tiles have been made that have taken many minutes, even hours to fall. For large and elaborate arrangements, special blockages (also known as firebreaks) are employed at regular distances to prevent a premature toppling from undoing more than a section of the tiles while still being able to be removed without damage.\nThe phenomenon also has some theoretical relevance (amplifier, digital signal, information processing), and this amounts to the theoretical possibility of building domino computers. Dominoes are also commonly used as components in Rube Goldberg machines.\nThe Netherlands has hosted an annual domino-toppling exhibition called Domino Day since 1986. The event held on 18 November 2005 knocked over 4 million dominoes by a team from Weijers Domino Productions. On Domino Day 2008 (14 November 2008), the Weijers Domino Productions team attempted to set 10 records:\nThis record attempt was held in the WTC Expo hall in Leeuwarden. The artist who toppled the first stone was the Finnish acrobat Salima Peippo.\nAt one time, Pressman Toys manufactured a product called Domino Rally that contained tiles and mechanical devices for setting up toppling exhibits.\nIn Berlin on 9 November 2009, giant domino tiles were toppled in a 20th-anniversary commemoration of the fall of the Berlin Wall. Former Polish president and Solidarity leader Lech Wa\u0142\u0119sa set the toppling in motion.\nA 2-1 tile is used in the logo of pizza retailer Domino's Pizza.\nDominoes in Unicode.\nSince April 2008, the character encoding standard Unicode includes characters that represent the double-six domino tiles in various orientations. All combinations of blank through six pips on the left or right provides 49 glyphs, the same combinations vertically for another 49, and also a horizontal and a vertical \"back\" for a total of 100 glyphs. In this arrangement, both orientations are present: horizontally both tiles [1|6] and [6|1] exist, while a regular game set only has one such tile. The Unicode range for dominoes is U+1F030\u2013U+1F09F. The naming pattern in Unicode is, by example, . Few fonts are known to support these glyphs. While the complete domino set has only 28 tiles, for printing layout reasons, the Unicode set needs both horizontal and vertical forms for each tile, plus the 01-03 (plain) 03-01 (reversed) pairs, and generic backsides."}
{"id": "8263", "revid": "16630315", "url": "https://en.wikipedia.org/wiki?curid=8263", "title": "Dissociation constant", "text": "In chemistry, biochemistry, and pharmacology, a dissociation constant (formula_1) is a specific type of equilibrium constant that measures the propensity of a larger object to separate (dissociate) reversibly into smaller components, as when a complex falls apart into its component molecules, or when a salt splits up into its component ions. The dissociation constant is the inverse of the association constant. In the special case of salts, the dissociation constant can also be called an ionization constant.\nFor a general reaction:\n A_\\mathit{x} B_\\mathit{y} &lt;=&gt; \\mathit{x} A{} + \\mathit{y} B\n&lt;/chem&gt;\nin which a complex formula_2 breaks down into \"x\" A subunits and \"y\" B subunits, the dissociation constant is defined\nwhere [A], [B], and [AxBy] are the equilibrium concentrations of A, B, and the complex AxBy, respectively.\nOne reason for the popularity of the dissociation constant in biochemistry and pharmacology is that in the frequently encountered case where x=y=1, Kd has a simple physical interpretation: when formula_4, then formula_5 or equivalently formula_6\nDissociation constant of water.\nThe dissociation constant of water is denoted \"K\"w:\nThe concentration of water &lt;chem&gt;H2O&lt;/chem&gt; is omitted by convention, which means that the value of \"K\"w differs from the value of \"K\"eq that would be computed using that concentration.\nThe value of \"K\"w varies with temperature, as shown in the table below. This variation must be taken into account when making precise measurements of quantities such as pH."}
{"id": "8264", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=8264", "title": "Dumpster-diving", "text": ""}
{"id": "8266", "revid": "451287", "url": "https://en.wikipedia.org/wiki?curid=8266", "title": "DMCA", "text": ""}
{"id": "8267", "revid": "57939", "url": "https://en.wikipedia.org/wiki?curid=8267", "title": "Dimensional analysis", "text": "In engineering and science, dimensional analysis is the analysis of the relationships between different physical quantities by identifying their base quantities (such as length, mass, time, and electric charge) and units of measure (such as miles vs. kilometres, or pounds vs. kilograms) and tracking these dimensions as calculations or comparisons are performed. The conversion of units from one dimensional unit to another is often easier within the metric or SI system than in others, due to the regular 10-base in all units. Dimensional analysis, or more specifically the factor-label method, also known as the unit-factor method, is a widely used technique for such conversions using the rules of algebra.\n\"Commensurable\" physical quantities are of the same kind and have the same dimension, and can be directly compared to each other, even if they are originally expressed in differing units of measure, e.g. yards and metres, pounds(mass) and kilograms, seconds and years. \"Incommensurable\" physical quantities are of different kinds and have different dimensions, and can not be directly compared to each other, no matter what units they are originally expressed in, e.g. meters and kilograms, seconds and kilograms, meters and seconds. For example, asking whether a kilogram is larger than an hour is meaningless.\nAny physically meaningful equation, or inequality, \"must\" have the same dimensions on its left and right sides, a property known as \"dimensional homogeneity\". Checking for dimensional homogeneity is a common application of dimensional analysis, serving as a plausibility check on derived equations and computations. It also serves as a guide and constraint in deriving equations that may describe a physical system in the absence of a more rigorous derivation.\nThe concept of physical dimension, and of dimensional analysis, was introduced by Joseph Fourier in 1822.\nConcrete numbers and base units.\nMany parameters and measurements in the physical sciences and engineering are expressed as a concrete number\u2014a numerical quantity and a corresponding dimensional unit. Often a quantity is expressed in terms of several other quantities; for example, speed is a combination of length and time, e.g. 60\u00a0kilometres per hour or 1.4\u00a0kilometres per second. Compound relations with \"per\" are expressed with division, e.g. 60\u00a0km/1\u00a0h. Other relations can involve multiplication (often shown with a centered dot or juxtaposition), powers (like m2 for square metres), or combinations thereof.\nA set of base units for a system of measurement is a conventionally chosen set of units, none of which can be expressed as a combination of the others and in terms of which all the remaining units of the system can be expressed. For example, units for length and time are normally chosen as base units. Units for volume, however, can be factored into the base units of length (m3), thus they are considered derived or compound units.\nSometimes the names of units obscure the fact that they are derived units. For example, a newton (N) is a unit of force, which has units of mass (kg) times units of acceleration (m\u22c5s\u22122). The newton is defined as .\nPercentages and derivatives.\nPercentages are dimensionless quantities, since they are ratios of two quantities with the same dimensions. In other words, the % sign can be read as \"hundredths\", since .\nTaking a derivative with respect to a quantity adds the dimension of the variable one is differentiating with respect to, in the denominator. Thus:\nIn economics, one distinguishes between stocks and flows: a stock has units of \"units\" (say, widgets or dollars), while a flow is a derivative of a stock, and has units of \"units/time\" (say, dollars/year).\nIn some contexts, dimensional quantities are expressed as dimensionless quantities or percentages by omitting some dimensions. For example, debt-to-GDP ratios are generally expressed as percentages: total debt outstanding (dimension of currency) divided by annual GDP (dimension of currency)\u2014but one may argue that, in comparing a stock to a flow, annual GDP should have dimensions of currency/time (dollars/year, for instance) and thus Debt-to-GDP should have units of years, which indicates that Debt-to-GDP is the number of years needed for a constant GDP to pay the debt, if all GDP is spent on the debt and the debt is otherwise unchanged.\nConversion factor.\nIn dimensional analysis, a ratio which converts one unit of measure into another without changing the quantity is called a conversion factor. For example, kPa and bar are both units of pressure, and . The rules of algebra allow both sides of an equation to be divided by the same expression, so this is equivalent to . Since any quantity can be multiplied by 1 without changing it, the expression \"\" can be used to convert from bars to kPa by multiplying it with the quantity to be converted, including units. For example, because , and bar/bar cancels out, so .\nDimensional homogeneity.\nThe most basic rule of dimensional analysis is that of dimensional homogeneity. \nHowever, the dimensions form an abelian group under multiplication, so:\nFor example, it makes no sense to ask whether 1 hour is more, the same, or less than 1 kilometre, as these have different dimensions, nor to add 1 hour to 1 kilometre. However, it makes perfect sense to ask whether 1 mile is more, the same, or less than 1 kilometre being the same dimension of physical quantity even though the units are different. On the other hand, if an object travels 100\u00a0km in 2 hours, one may divide these and conclude that the object's average speed was 50\u00a0km/h.\nThe rule implies that in a physically meaningful \"expression\" only quantities of the same dimension can be added, subtracted, or compared. For example, if \"m\"man, \"m\"rat and \"L\"man denote, respectively, the mass of some man, the mass of a rat and the length of that man, the dimensionally homogeneous expression is meaningful, but the heterogeneous expression is meaningless. However, \"m\"man/\"L\"2man is fine. Thus, dimensional analysis may be used as a sanity check of physical equations: the two sides of any equation must be commensurable or have the same dimensions.\nThis has the implication that most mathematical functions, particularly the transcendental functions, must have a dimensionless quantity, a pure number, as the argument and must return a dimensionless number as a result. This is clear because many transcendental functions can be expressed as an infinite power series with dimensionless coefficients.\nAll powers of \"x\" must have the same dimension for the terms to be commensurable. But if \"x\" is not dimensionless, then the different powers of \"x\" will have different, incommensurable dimensions. However, power functions including root functions may have a dimensional argument and will return a result having dimension that is the same power applied to the argument dimension. This is because power functions and root functions are, loosely, just an expression of multiplication of quantities.\nEven when two physical quantities have identical dimensions, it may nevertheless be meaningless to compare or add them. For example, although torque and energy share the dimension , they are fundamentally different physical quantities.\nTo compare, add, or subtract quantities with the same dimensions but expressed in different units, the standard procedure is first to convert them all to the same units. For example, to compare 32 metres with 35 yards, use 1 yard = 0.9144\u00a0m to convert 35 yards to 32.004\u00a0m.\nA related principle is that any physical law that accurately describes the real world must be independent of the units used to measure the physical variables. For example, Newton's laws of motion must hold true whether distance is measured in miles or kilometres. This principle gives rise to the form that conversion factors must take between units that measure the same dimension: multiplication by a simple constant. It also ensures equivalence; for example, if two buildings are the same height in feet, then they must be the same height in metres.\nThe factor-label method for converting units.\nThe factor-label method is the sequential application of conversion factors expressed as fractions and arranged so that any dimensional unit appearing in both the numerator and denominator of any of the fractions can be cancelled out until only the desired set of dimensional units is obtained. For example, 10 miles per hour can be converted to meters per second by using a sequence of conversion factors as shown below:\nEach conversion factor is chosen based on the relationship between one of the original units and one of the desired units (or some intermediary unit), before being re-arranged to create a factor that cancels out the original unit. For example, as \"mile\" is the numerator in the original fraction and formula_3, \"mile\" will need to be the denominator in the conversion factor. Dividing both sides of the equation by 1 mile yields formula_4, which when simplified results in the dimensionless formula_5. Multiplying any quantity (physical quantity or not) by the dimensionless 1 does not change that quantity. Once this and the conversion factor for seconds per hour have been multiplied by the original fraction to cancel out the units \"mile\" and \"hour\", 10 miles per hour converts to 4.4704 meters per second.\nAs a more complex example, the concentration of nitrogen oxides (i.e., formula_6) in the flue gas from an industrial furnace can be converted to a mass flow rate expressed in grams per hour (i.e., g/h) of formula_7 by using the following information as shown below:\nAfter canceling out any dimensional units that appear both in the numerators and denominators of the fractions in the above equation, the NOx concentration of 10 ppmv converts to mass flow rate of 24.63\u00a0grams per hour.\nChecking equations that involve dimensions.\nThe factor-label method can also be used on any mathematical equation to check whether or not the dimensional units on the left hand side of the equation are the same as the dimensional units on the right hand side of the equation. Having the same units on both sides of an equation does not ensure that the equation is correct, but having different units on the two sides (when expressed in terms of base units) of an equation implies that the equation is wrong.\nFor example, check the Universal Gas Law equation of , when:\nAs can be seen, when the dimensional units appearing in the numerator and denominator of the equation's right hand side are cancelled out, both sides of the equation have the same dimensional units. Dimensional analysis can be used as a tool to construct equations that relate non-associated physico-chemical properties. The equations may reveal hitherto unknown or overlooked properties of matter, in the form of left-over dimensions \u2014 dimensional adjusters \u2014 that can then be assigned physical significance. It is important to point out that such 'mathematical manipulation' is neither without prior precedent, nor without considerable scientific significance. Indeed, the Planck's constant, a fundamental constant of the universe, was 'discovered' as a purely mathematical abstraction or representation that built on the Rayleigh-Jeans Equation for preventing the ultraviolet catastrophe. It was assigned and ascended to its quantum physical significance either in tandem or post mathematical dimensional adjustment \u2013 not earlier.\nLimitations.\nThe factor-label method can convert only unit quantities for which the units are in a linear relationship intersecting at 0. (Ratio scale in Stevens's typology) Most units fit this paradigm. An example for which it cannot be used is the conversion between degrees Celsius and kelvins (or degrees Fahrenheit). Between degrees Celsius and kelvins, there is a constant difference rather than a constant ratio, while between degrees Celsius and degrees Fahrenheit there is neither a constant difference nor a constant ratio. There is, however, an affine transform (formula_10, rather than a linear transform formula_11) between them.\nFor example, the freezing point of water is 0\u00a0\u00b0C and 32\u00a0\u00b0F, and a 5\u00a0\u00b0C change is the same as a 9\u00a0\u00b0F change. Thus, to convert from units of Fahrenheit to units of Celsius, one subtracts 32\u00a0\u00b0F (the offset from the point of reference), divides by 9\u00a0\u00b0F and multiplies by 5\u00a0\u00b0C (scales by the ratio of units), and adds 0\u00a0\u00b0C (the offset from the point of reference). Reversing this yields the formula for obtaining a quantity in units of Celsius from units of Fahrenheit; one could have started with the equivalence between 100\u00a0\u00b0C and 212\u00a0\u00b0F, though this would yield the same formula at the end.\nHence, to convert the numerical quantity value of a temperature \"T\"[F] in degrees Fahrenheit to a numerical quantity value \"T\"[C] in degrees Celsius, this formula may be used:\nTo convert \"T\"[C] in degrees Celsius to \"T\"[F] in degrees Fahrenheit, this formula may be used:\nApplications.\nDimensional analysis is most often used in physics and chemistry \u2013 and in the mathematics thereof \u2013 but finds some applications outside of those fields as well.\nMathematics.\nA simple application of dimensional analysis to mathematics is in computing the form of the volume of an \"n\"-ball (the solid ball in \"n\" dimensions), or the area of its surface, the \"n\"-sphere: being an \"n\"-dimensional figure, the volume scales as formula_12 while the surface area, being formula_13-dimensional, scales as formula_14 Thus the volume of the \"n\"-ball in terms of the radius is formula_15 for some constant formula_16 Determining the constant takes more involved mathematics, but the form can be deduced and checked by dimensional analysis alone.\nFinance, economics, and accounting.\nIn finance, economics, and accounting, dimensional analysis is most commonly referred to in terms of the distinction between stocks and flows. More generally, dimensional analysis is used in interpreting various financial ratios, economics ratios, and accounting ratios.\nFluid mechanics.\nIn fluid mechanics, dimensional analysis is performed in order to obtain dimensionless pi terms or groups. According to the principles of dimensional analysis, any prototype can be described by a series of these terms or groups that describe the behaviour of the system. Using suitable pi terms or groups, it is possible to develop a similar set of pi terms for a model that has the same dimensional relationships. In other words, pi terms provide a shortcut to developing a model representing a certain prototype. Common dimensionless groups in fluid mechanics include:\nHistory.\nThe origins of dimensional analysis have been disputed by historians. \nThe first written application of dimensional analysis has been credited to an article of Fran\u00e7ois Daviet at the Turin Academy of Science. Daviet had the master Lagrange as teacher. \nHis fundamental works are contained in acta of the Academy dated 1799.\nThis led to the conclusion that meaningful laws must be homogeneous equations in their various units of measurement, a result which was eventually later formalized in the Buckingham \u03c0 theorem.\nSimeon Poisson also treated the same problem of the parallelogram law by Daviet, in his treatise of 1811 and 1833 (vol I, p.39). In the second edition of 1833, Poisson explicitly introduces the term \"dimension\" instead of the Daviet \"homogeneity\".\nIn 1822, the important Napoleonic scientist Joseph Fourier made the first credited important contributions based on the idea that physical laws like should be independent of the units employed to measure the physical variables.\nMaxwell played a major role in establishing modern use of dimensional analysis by distinguishing mass, length, and time as fundamental units, while referring to other units as derived. Although Maxwell defined length, time and mass to be \"the three fundamental units\", he also noted that gravitational mass can be derived from length and time by assuming a form of Newton's law of universal gravitation in which the gravitational constant \"G\" is taken as unity, thereby defining . By assuming a form of Coulomb's law in which Coulomb's constant \"k\"e is taken as unity, Maxwell then determined that the dimensions of an electrostatic unit of charge were , which, after substituting his equation for mass, results in charge having the same dimensions as mass, viz. .\nDimensional analysis is also used to derive relationships between the physical quantities that are involved in a particular phenomenon that one wishes to understand and characterize. It was used for the first time in this way in 1872 by Lord Rayleigh, who was trying to understand why the sky is blue. Rayleigh first published the technique in his 1877 book \"The Theory of Sound\".\nThe original meaning of the word \"dimension\", in Fourier's \"Theorie de la Chaleur\", was the numerical value of the exponents of the base units. For example, acceleration was considered to have the dimension 1 with respect to the unit of length, and the dimension \u22122 with respect to the unit of time. This was slightly changed by Maxwell, who said the dimensions of acceleration are LT\u22122, instead of just the exponents.\nMathematical formulation.\nThe Buckingham \u03c0 theorem describes how every physically meaningful equation involving \"n\" variables can be equivalently rewritten as an equation of dimensionless parameters, where \"m\" is the rank of the dimensional matrix. Furthermore, and most importantly, it provides a method for computing these dimensionless parameters from the given variables.\nA dimensional equation can have the dimensions reduced or eliminated through nondimensionalization, which begins with dimensional analysis, and involves scaling quantities by characteristic units of a system or natural units of nature. This gives insight into the fundamental properties of the system, as illustrated in the examples below.\nDefinition.\nThe dimension of a physical quantity can be expressed as a product of the basic physical dimensions such as length, mass and time, each raised to a rational power. The \"dimension\" of a physical quantity is more fundamental than some \"scale\" unit used to express the amount of that physical quantity. For example, \"mass\" is a dimension, while the kilogram is a particular scale unit chosen to express a quantity of mass. Except for natural units, the choice of scale is cultural and arbitrary.\nThere are many possible choices of basic physical dimensions. The SI standard recommends the usage of the following dimensions and corresponding symbols: length (L), mass (M), time (T), electric current (I), absolute temperature (\u0398), amount of substance (N) and luminous intensity (J). The symbols are by convention usually written in roman sans serif typeface. Mathematically, the dimension of the quantity \"Q\" is given by \nwhere \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\" are the dimensional exponents. Other physical quantities could be defined as the base quantities, as long as they form a linearly independent basis. For instance, one could replace the dimension of electric current (I) of the SI basis with a dimension of electric charge (Q), since Q = IT.\nAs examples, the dimension of the physical quantity speed \"v\" is\nand the dimension of the physical quantity force \"F\" is\nThe unit chosen to express a physical quantity and its dimension are related, but not identical concepts. The units of a physical quantity are defined by convention and related to some standard; e.g., length may have units of metres, feet, inches, miles or micrometres; but any length always has a dimension of L, no matter what units of length are chosen to express it. Two different units of the same physical quantity have conversion factors that relate them. For example, 1\u00a0in = 2.54\u00a0cm; in this case (2.54\u00a0cm/in) is the conversion factor, which is itself dimensionless. Therefore, multiplying by that conversion factor does not change the dimensions of a physical quantity.\nThere are also physicists that have cast doubt on the very existence of incompatible fundamental dimensions of physical quantity, although this does not invalidate the usefulness of dimensional analysis.\nMathematical properties.\nThe dimensions that can be formed from a given collection of basic physical dimensions, such as M, L, and T, form an abelian group: The identity is written as 1; , and the inverse to L is 1/L or L\u22121. L raised to any rational power \"p\" is a member of the group, having an inverse of L\u2212\"p\" or 1/Lp. The operation of the group is multiplication, having the usual rules for handling exponents ().\nThis group can be described as a vector space over the rational numbers, with for example dimensional symbol M\"i\"L\"j\"T\"k\" corresponding to the vector . When physical measured quantities (be they like-dimensioned or unlike-dimensioned) are multiplied or divided by one other, their dimensional units are likewise multiplied or divided; this corresponds to addition or subtraction in the vector space. When measurable quantities are raised to a rational power, the same is done to the dimensional symbols attached to those quantities; this corresponds to scalar multiplication in the vector space.\nA basis for such a vector space of dimensional symbols is called a set of base quantities, and all other vectors are called derived units. As in any vector space, one may choose different bases, which yields different systems of units (e.g., choosing whether the unit for charge is derived from the unit for current, or vice versa).\nThe group identity 1, the dimension of dimensionless quantities, corresponds to the origin in this vector space.\nThe set of units of the physical quantities involved in a problem correspond to a set of vectors (or a matrix). The nullity describes some number (e.g., \"m\") of ways in which these vectors can be combined to produce a zero vector. These correspond to producing (from the measurements) a number of dimensionless quantities, {\u03c01, ..., \u03c0\"m\"}. (In fact these ways completely span the null subspace of another different space, of powers of the measurements.) Every possible way of multiplying (and exponentiating) together the measured quantities to produce something with the same units as some derived quantity \"X\" can be expressed in the general form\nConsequently, every possible commensurate equation for the physics of the system can be rewritten in the form\nKnowing this restriction can be a powerful tool for obtaining new insight into the system.\nMechanics.\nThe dimension of physical quantities of interest in mechanics can be expressed in terms of base dimensions M, L, and T \u2013 these form a 3-dimensional vector space. This is not the only valid choice of base dimensions, but it is the one most commonly used. For example, one might choose force, length and mass as the base dimensions (as some have done), with associated dimensions F, L, M; this corresponds to a different basis, and one may convert between these representations by a change of basis. The choice of the base set of dimensions is thus a convention, with the benefit of increased utility and familiarity. The choice of base dimensions is not entirely arbitrary, because they must form a basis: they must span the space, and be linearly independent.\nFor example, F, L, M form a set of fundamental dimensions because they form a basis that is equivalent to M, L, T: the former can be expressed as [F = ML/T2], L, M, while the latter can be expressed as M, L, [T = (ML/F)1/2].\nOn the other hand, length, velocity and time do not form a set of base dimensions for mechanics, for two reasons:\nOther fields of physics and chemistry.\nDepending on the field of physics, it may be advantageous to choose one or another extended set of dimensional symbols. In electromagnetism, for example, it may be useful to use dimensions of M, L, T, and Q, where Q represents the dimension of electric charge. In thermodynamics, the base set of dimensions is often extended to include a dimension for temperature, \u0398. In chemistry, the amount of substance (the number of molecules divided by the Avogadro constant, \u2248 ) is defined as a base dimension, N, as well.\nIn the interaction of relativistic plasma with strong laser pulses, a dimensionless relativistic similarity parameter, connected with the symmetry properties of the collisionless Vlasov equation, is constructed from the plasma-, electron- and critical-densities in addition to the electromagnetic vector potential. The choice of the dimensions or even the number of dimensions to be used in different fields of physics is to some extent arbitrary, but consistency in use and ease of communications are common and necessary features.\nPolynomials and transcendental functions.\nScalar arguments to transcendental functions such as exponential, trigonometric and logarithmic functions, or to inhomogeneous polynomials, must be dimensionless quantities. (Note: this requirement is somewhat relaxed in Siano's orientational analysis described below, in which the square of certain dimensioned quantities are dimensionless.)\nWhile most mathematical identities about dimensionless numbers translate in a straightforward manner to dimensional quantities, care must be taken with logarithms of ratios: the identity log(a/b) = log a \u2212 log b, where the logarithm is taken in any base, holds for dimensionless numbers a and b, but it does \"not\" hold if a and b are dimensional, because in this case the left-hand side is well-defined but the right-hand side is not.\nSimilarly, while one can evaluate monomials (\"x\"\"n\") of dimensional quantities, one cannot evaluate polynomials of mixed degree with dimensionless coefficients on dimensional quantities: for \"x\"2, the expression (3\u00a0m)2\u00a0=\u00a09\u00a0m2 makes sense (as an area), while for \"x\"2\u00a0+\u00a0\"x\", the expression (3\u00a0m)2\u00a0+\u00a03\u00a0m\u00a0=\u00a09\u00a0m2\u00a0+\u00a03\u00a0m does not make sense.\nHowever, polynomials of mixed degree can make sense if the coefficients are suitably chosen physical quantities that are not dimensionless. For example,\nThis is the height to which an object rises in time\u00a0\"t\" if the acceleration of gravity is 9.8\u00a0meter\u00a0per\u00a0second\u00a0per\u00a0second and the initial upward speed is 500\u00a0meter\u00a0per\u00a0second. It is not necessary for \"t\" to be in \"seconds\". For example, suppose \"t\"\u00a0=\u00a00.01\u00a0minutes. Then the first term would be\nIncorporating units.\nThe value of a dimensional physical quantity \"Z\" is written as the product of a unit [\"Z\"] within the dimension and a dimensionless numerical factor, \"n\".\nWhen like-dimensioned quantities are added or subtracted or compared, it is convenient to express them in consistent units so that the numerical values of these quantities may be directly added or subtracted. But, in concept, there is no problem adding quantities of the same dimension expressed in different units. For example, 1 meter added to 1 foot is a length, but one cannot derive that length by simply adding 1 and 1. A conversion factor, which is a ratio of like-dimensioned quantities and is equal to the dimensionless unity, is needed:\nThe factor formula_31 is identical to the dimensionless 1, so multiplying by this conversion factor changes nothing. Then when adding two quantities of like dimension, but expressed in different units, the appropriate conversion factor, which is essentially the dimensionless 1, is used to convert the quantities to identical units so that their numerical values can be added or subtracted.\nOnly in this manner is it meaningful to speak of adding like-dimensioned quantities of differing units.\nPosition vs displacement.\nSome discussions of dimensional analysis implicitly describe all quantities as mathematical vectors. (In mathematics scalars are considered a special case of vectors; vectors can be added to or subtracted from other vectors, and, inter alia, multiplied or divided by scalars. If a vector is used to define a position, this assumes an implicit point of reference: an origin. While this is useful and often perfectly adequate, allowing many important errors to be caught, it can fail to model certain aspects of physics. A more rigorous approach requires distinguishing between position and displacement (or moment in time versus duration, or absolute temperature versus temperature change).\nConsider points on a line, each with a position with respect to a given origin, and distances among them. Positions and displacements all have units of length, but their meaning is not interchangeable:\nThis illustrates the subtle distinction between \"affine\" quantities (ones modeled by an affine space, such as position) and \"vector\" quantities (ones modeled by a vector space, such as displacement).\nProperly then, positions have dimension of \"affine\" length, while displacements have dimension of \"vector\" length. To assign a number to an \"affine\" unit, one must not only choose a unit of measurement, but also a point of reference, while to assign a number to a \"vector\" unit only requires a unit of measurement.\nThus some physical quantities are better modeled by vectorial quantities while others tend to require affine representation, and the distinction is reflected in their dimensional analysis.\nThis distinction is particularly important in the case of temperature, for which the numeric value of absolute zero is not the origin 0 in some scales. For absolute zero,\nwhere the symbol \u2258 means \"corresponds to\", since although these values on the respective temperature scales correspond, they represent distinct quantities in the same way that the distances from distinct starting points to the same end point are distinct quantities, and cannot in general be equated.\nFor temperature differences,\n(Here \u00b0R refers to the Rankine scale, not the R\u00e9aumur scale).\nUnit conversion for temperature differences is simply a matter of multiplying by, e.g., 1\u00a0\u00b0F / 1\u00a0K (although the ratio is not a constant value). But because some of these scales have origins that do not correspond to absolute zero, conversion from one temperature scale to another requires accounting for that. As a result, simple dimensional analysis can lead to errors if it is ambiguous whether 1\u00a0K means the absolute temperature equal to \u2212272.15\u00a0\u00b0C, or the temperature difference equal to 1\u00a0\u00b0C.\nOrientation and frame of reference.\nSimilar to the issue of a point of reference is the issue of orientation: a displacement in 2 or 3 dimensions is not just a length, but is a length together with a \"direction\". (This issue does not arise in 1 dimension, or rather is equivalent to the distinction between positive and negative.) Thus, to compare or combine two dimensional quantities in a multi-dimensional space, one also needs an orientation: they need to be compared to a frame of reference.\nThis leads to the extensions discussed below, namely Huntley's directed dimensions and Siano's orientational analysis.\nExamples.\nA simple example: period of a harmonic oscillator.\nWhat is the period of oscillation of a mass attached to an ideal linear spring with spring constant suspended in gravity of strength ? That period is the solution for of some dimensionless equation in the variables , , , and .\nThe four quantities have the following dimensions: [T]; [M]; [M/T2]; and [L/T2]. From these we can form only one dimensionless product of powers of our chosen variables, formula_32 = formula_33 , and putting formula_34 for some dimensionless constant gives the dimensionless equation sought. The dimensionless product of powers of variables is sometimes referred to as a dimensionless group of variables; here the term \"group\" means \"collection\" rather than mathematical group. They are often called dimensionless numbers as well.\nNote that the variable does not occur in the group. It is easy to see that it is impossible to form a dimensionless product of powers that combines with , , and , because is the only quantity that involves the dimension L. This implies that in this problem the is irrelevant. Dimensional analysis can sometimes yield strong statements about the \"irrelevance\" of some quantities in a problem, or the need for additional parameters. If we have chosen enough variables to properly describe the problem, then from this argument we can conclude that the period of the mass on the spring is independent of : it is the same on the earth or the moon. The equation demonstrating the existence of a product of powers for our problem can be written in an entirely equivalent way: formula_35, for some dimensionless constant \u03ba (equal to formula_36 from the original dimensionless equation).\nWhen faced with a case where dimensional analysis rejects a variable (, here) that one intuitively expects to belong in a physical description of the situation, another possibility is that the rejected variable is in fact relevant, but that some other relevant variable has been omitted, which might combine with the rejected variable to form a dimensionless quantity. That is, however, not the case here.\nWhen dimensional analysis yields only one dimensionless group, as here, there are no unknown functions, and the solution is said to be \"complete\" \u2013 although it still may involve unknown dimensionless constants, such as .\nA more complex example: energy of a vibrating wire.\nConsider the case of a vibrating wire of length \"\u2113\" (L) vibrating with an amplitude \"A\" (L). The wire has a linear density \"\u03c1\" (M/L) and is under tension \"s\" (ML/T2), and we want to know the energy \"E\" (ML2/T2) in the wire. Let \"\u03c0\"1 and \"\u03c0\"2 be two dimensionless products of powers of the variables chosen, given by\nThe linear density of the wire is not involved. The two groups found can be combined into an equivalent form as an equation\nwhere \"F\" is some unknown function, or, equivalently as\nwhere \"f\" is some other unknown function. Here the unknown function implies that our solution is now incomplete, but dimensional analysis has given us something that may not have been obvious: the energy is proportional to the first power of the tension. Barring further analytical analysis, we might proceed to experiments to discover the form for the unknown function \"f\". But our experiments are simpler than in the absence of dimensional analysis. We'd perform none to verify that the energy is proportional to the tension. Or perhaps we might guess that the energy is proportional to \"\u2113\", and so infer that . The power of dimensional analysis as an aid to experiment and forming hypotheses becomes evident.\nThe power of dimensional analysis really becomes apparent when it is applied to situations, unlike those given above, that are more complicated, the set of variables involved are not apparent, and the underlying equations hopelessly complex. Consider, for example, a small pebble sitting on the bed of a river. If the river flows fast enough, it will actually raise the pebble and cause it to flow along with the water. At what critical velocity will this occur? Sorting out the guessed variables is not so easy as before. But dimensional analysis can be a powerful aid in understanding problems like this, and is usually the very first tool to be applied to complex problems where the underlying equations and constraints are poorly understood. In such cases, the answer may depend on a dimensionless number such as the Reynolds number, which may be interpreted by dimensional analysis.\nA third example: demand versus capacity for a rotating disc.\nConsider the case of a thin, solid, parallel-sided rotating disc of axial thickness \"t\" (L) and radius \"R\" (L). The disc has a density \"\u03c1\" (M/L3), rotates at an angular velocity \"\u03c9\" (T\u22121) and this leads to a stress \"S\" (ML\u22121T\u22122) in the material. There is a theoretical linear elastic solution, given by Lame, to this problem when the disc is thin relative to its radius, the faces of the disc are free to move axially, and the plane stress constitutive relations can be assumed to be valid. As the disc becomes thicker relative to the radius then the plane stress solution breaks down. If the disc is restrained axially on its free faces then a state of plane strain will occur. However, if this is not the case then the state of stress may only be determined though consideration of three-dimensional elasticity and there is no known theoretical solution for this case. An engineer might, therefore, be interested in establishing a relationship between the five variables. Dimensional analysis for this case leads to the following (5\u00a0\u2212\u00a03\u00a0=\u00a02) non-dimensional groups:\nThrough the use of numerical experiments using, for example, the finite element method, the nature of the relationship between the two non-dimensional groups can be obtained as shown in the figure. As this problem only involves two non-dimensional groups, the complete picture is provided in a single plot and this can be used as a design/assessment chart for rotating discs\nExtensions.\nHuntley's extension: directed dimensions and quantity of matter.\nHuntley has pointed out that a dimensional analysis can become more powerful by discovering new independent dimensions in the quantities under consideration, thus increasing the rank formula_40 of the dimensional matrix. He introduced two approaches to doing so:\nAs an example of the usefulness of the first approach, suppose we wish to calculate the distance a cannonball travels when fired with a vertical velocity component formula_41 and a horizontal velocity component formula_42, assuming it is fired on a flat surface. Assuming no use of directed lengths, the quantities of interest are then formula_42, formula_41, both dimensioned as LT\u22121, , the distance travelled, having dimension L, and the downward acceleration of gravity, with dimension LT\u22122.\nWith these four quantities, we may conclude that the equation for the range may be written:\nOr dimensionally\nfrom which we may deduce that formula_47 and formula_48, which leaves one exponent undetermined. This is to be expected since we have two fundamental dimensions L and T, and four parameters, with one equation.\nIf, however, we use directed length dimensions, then formula_42 will be dimensioned as LT\u22121, formula_41 as LT\u22121, as L and as LT\u22122. The dimensional equation becomes:\nand we may solve completely as formula_52, formula_53 and formula_54. The increase in deductive power gained by the use of directed length dimensions is apparent.\nIn his second approach, Huntley holds that it is sometimes useful (e.g., in fluid mechanics and thermodynamics) to distinguish between mass as a measure of inertia (inertial mass), and mass as a measure of the quantity of matter. Quantity of matter is defined by Huntley as a quantity (a) proportional to inertial mass, but (b) not implicating inertial properties. No further restrictions are added to its definition.\nFor example, consider the derivation of Poiseuille's Law. We wish to find the rate of mass flow of a viscous fluid through a circular pipe. Without drawing distinctions between inertial and substantial mass we may choose as the relevant variables\nThere are three fundamental variables so the above five equations will yield two dimensionless variables which we may take to be formula_57 and formula_58 and we may express the dimensional equation as\nwhere and are undetermined constants. If we draw a distinction between inertial mass with dimension formula_60 and quantity of matter with dimension formula_61, then mass flow rate and density will use quantity of matter as the mass parameter, while the pressure gradient and coefficient of viscosity will use inertial mass. We now have four fundamental parameters, and one dimensionless constant, so that the dimensional equation may be written:\nwhere now only is an undetermined constant (found to be equal to formula_63 by methods outside of dimensional analysis). This equation may be solved for the mass flow rate to yield Poiseuille's law.\nHuntley's recognition of quantity of matter as an independent quantity dimension is evidently successful in the problems where it is applicable, but his definition of quantity of matter is open to interpretation, as it lacks specificity beyond the two requirements (a) and (b) he postulated for it. For a given substance, the SI dimension amount of substance, with unit mole, does satisfy Huntley's two requirements as a measure of quantity of matter, and could be used as a quantity of matter in any problem of dimensional analysis where Huntley's concept is applicable.\nHuntley's concept of directed length dimensions however has some serious limitations:\nIt also is often quite difficult to assign the L, L, L, L, symbols to the physical variables involved in the problem of interest. He invokes a procedure that involves the \"symmetry\" of the physical problem. This is often very difficult to apply reliably: It is unclear as to what parts of the problem that the notion of \"symmetry\" is being invoked. Is it the symmetry of the physical body that forces are acting upon, or to the points, lines or areas at which forces are being applied? What if more than one body is involved with different symmetries?\nConsider the spherical bubble attached to a cylindrical tube, where one wants the flow rate of air as a function of the pressure difference in the two parts. What are the Huntley extended dimensions of the viscosity of the air contained in the connected parts? What are the extended dimensions of the pressure of the two parts? Are they the same or different? These difficulties are responsible for the limited application of Huntley's directed length dimensions to real problems.\nSiano's extension: orientational analysis.\nAngles are, by convention, considered to be dimensionless quantities. As an example, consider again the projectile problem in which a point mass is launched from the origin at a speed and angle above the \"x\"-axis, with the force of gravity directed along the negative \"y\"-axis. It is desired to find the range , at which point the mass returns to the \"x\"-axis. Conventional analysis will yield the dimensionless variable , but offers no insight into the relationship between and .\n has suggested that the directed dimensions of Huntley be replaced by using \"orientational symbols\" to denote vector directions, and an orientationless symbol 10. Thus, Huntley's L becomes L1 with L specifying the dimension of length, and specifying the orientation. Siano further shows that the orientational symbols have an algebra of their own. Along with the requirement that , the following multiplication table for the orientation symbols results:\nNote that the orientational symbols form a group (the Klein four-group or \"Viergruppe\"). In this system, scalars always have the same orientation as the identity element, independent of the \"symmetry of the problem\". Physical quantities that are vectors have the orientation expected: a force or a velocity in the z-direction has the orientation of . For angles, consider an angle that lies in the z-plane. Form a right triangle in the z-plane with being one of the acute angles. The side of the right triangle adjacent to the angle then has an orientation and the side opposite has an orientation . Since (using to indicate orientational equivalence) we conclude that an angle in the xy-plane must have an orientation , which is not unreasonable. Analogous reasoning forces the conclusion that has orientation while has orientation 10. These are different, so one concludes (correctly), for example, that there are no solutions of physical equations that are of the form , where and are real scalars. Note that an expression such as formula_65 is not dimensionally inconsistent since it is a special case of the sum of angles formula and should properly be written:\nwhich for formula_67 and formula_68 yields formula_69. Siano distinguishes between geometric angles, which have an orientation in 3-dimensional space, and phase angles associated with time-based oscillations, which have no spatial orientation, i.e. the orientation of a phase angle is formula_70.\nThe assignment of orientational symbols to physical quantities and the requirement that physical equations be orientationally homogeneous can actually be used in a way that is similar to dimensional analysis to derive a little more information about acceptable solutions of physical problems. In this approach one sets up the dimensional equation and solves it as far as one can. If the lowest power of a physical variable is fractional, both sides of the solution is raised to a power such that all powers are integral. This puts it into \"normal form\". The orientational equation is then solved to give a more restrictive condition on the unknown powers of the orientational symbols, arriving at a solution that is more complete than the one that dimensional analysis alone gives. Often the added information is that one of the powers of a certain variable is even or odd.\nAs an example, for the projectile problem, using orientational symbols, , being in the xy-plane will thus have dimension and the range of the projectile will be of the form:\nDimensional homogeneity will now correctly yield and , and orientational homogeneity requires that formula_72. In other words, that must be an odd integer. In fact the required function of theta will be which is a series consisting of odd powers of .\nIt is seen that the Taylor series of and are orientationally homogeneous using the above multiplication table, while expressions like and are not, and are (correctly) deemed unphysical.\nSiano's orientational analysis is compatible with the conventional conception of angular quantities as being dimensionless, and within orientational analysis, the radian may still be considered a dimensionless unit. The orientational analysis of a quantity equation is carried out separately from the ordinary dimensional analysis, yielding information that supplements the dimensional analysis.\nDimensionless concepts.\nConstants.\nThe dimensionless constants that arise in the results obtained, such as the C in the Poiseuille's Law problem and the formula_73 in the spring problems discussed above, come from a more detailed analysis of the underlying physics and often arise from integrating some differential equation. Dimensional analysis itself has little to say about these constants, but it is useful to know that they very often have a magnitude of order unity. This observation can allow one to sometimes make \"back of the envelope\" calculations about the phenomenon of interest, and therefore be able to more efficiently design experiments to measure it, or to judge whether it is important, etc.\nFormalisms.\nParadoxically, dimensional analysis can be a useful tool even if all the parameters in the underlying theory are dimensionless, e.g., lattice models such as the Ising model can be used to study phase transitions and critical phenomena. Such models can be formulated in a purely dimensionless way. As we approach the critical point closer and closer, the distance over which the variables in the lattice model are correlated (the so-called correlation length, formula_74 ) becomes larger and larger. Now, the correlation length is the relevant length scale related to critical phenomena, so one can, e.g., surmise on \"dimensional grounds\" that the non-analytical part of the free energy per lattice site should be formula_75 where formula_76 is the dimension of the lattice.\nIt has been argued by some physicists, e.g., M. J. Duff, that the laws of physics are inherently dimensionless. The fact that we have assigned incompatible dimensions to Length, Time and Mass is, according to this point of view, just a matter of convention, borne out of the fact that before the advent of modern physics, there was no way to relate mass, length, and time to each other. The three independent dimensionful constants: \"c\", \"\u0127\", and \"G\", in the fundamental equations of physics must then be seen as mere conversion factors to convert Mass, Time and Length into each other.\nJust as in the case of critical properties of lattice models, one can recover the results of dimensional analysis in the appropriate scaling limit; e.g., dimensional analysis in mechanics can be derived by reinserting the constants \"\u0127\", \"c\", and \"G\" (but we can now consider them to be dimensionless) and demanding that a nonsingular relation between quantities exists in the limit formula_77, formula_78 and formula_79. In problems involving a gravitational field the latter limit should be taken such that the field stays finite.\nDimensional equivalences.\nFollowing are tables of commonly occurring expressions in physics, related to the dimensions of energy, momentum, and force.\nNatural units.\nIf , where \"c\" is the speed of light and \"\u0127\" is the reduced Planck constant, and a suitable fixed unit of energy is chosen, then all quantities of length \"L\", mass \"M\" and time \"T\" can be expressed (dimensionally) as a power of energy \"E\", because length, mass and time can be expressed using speed \"v\", action \"S\", and energy \"E\":\nthough speed and action are dimensionless ( and ) \u2013 so the only remaining quantity with dimension is energy. In terms of powers of dimensions:\nThis is particularly useful in particle physics and high energy physics, in which case the energy unit is the electron volt (eV). Dimensional checks and estimates become very simple in this system.\nHowever, if electric charges and currents are involved, another unit to be fixed is for electric charge, normally the electron charge \"e\" though other choices are possible.\nSee also.\nProgramming languages.\nDimensional correctness as part of type checking has been studied since 1977.\nImplementations for Ada and C++ were described in 1985 and 1988.\nKennedy's 1996 thesis describes an implementation in Standard ML, and later in F#. There are implementations for Haskell, OCaml, and Rust, Python, and a code checker for Fortran.\nGriffioen's 2019 thesis extended Kennedy's Hindley\u2013Milner type system to support Hart's matrices."}
{"id": "8269", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=8269", "title": "Discrete math", "text": ""}
{"id": "8270", "revid": "2278355", "url": "https://en.wikipedia.org/wiki?curid=8270", "title": "December 25", "text": ""}
{"id": "8271", "revid": "60840", "url": "https://en.wikipedia.org/wiki?curid=8271", "title": "Digital television", "text": "Digital television (DTV) is the transmission of television audiovisual signals using digital encoding, in contrast to the earlier analog television technology which used analog signals. At the time of its development it was considered an innovative advancement and represented the first significant evolution in television technology since color television in the 1950s. Modern digital television is transmitted in high definition (HDTV) with greater resolution than analog TV. It typically uses a widescreen aspect ratio (commonly 16:9) in contrast to the narrower format of analog TV. It makes more economical use of scarce radio spectrum space; it can transmit up to seven channels in the same bandwidth as a single analog channel, and provides many new features that analog television cannot. A transition from analog to digital broadcasting began around 2000. Different digital television broadcasting standards have been adopted in different parts of the world; below are the more widely used standards:\nHistory.\nBackground.\nDigital television's roots have been tied very closely to the availability of inexpensive, high performance computers. It was not until the 1990s that digital TV became a real possibility. Digital television was previously not practically feasible due to the impractically high bandwidth requirements of uncompressed digital video, requiring around 200Mbit/s (25MB/s) bit-rate for a standard-definition television (SDTV) signal, and over 1Gbit/s for high-definition television (HDTV).\nDigital TV became practically feasible in the early 1990s due to a major technological development, discrete cosine transform (DCT) video compression. DCT coding is a lossy compression technique that was first proposed for image compression by Nasir Ahmed in 1972, and was later adapted into a motion-compensated DCT video coding algorithm, for video coding standards such as the H.26x formats from 1988 onwards and the MPEG formats from 1991 onwards. Motion-compensated DCT video compression significantly reduced the amount of bandwidth required for a digital TV signal. DCT coding compressed down the bandwidth requirements of digital television signals to about 34Mpps bit-rate for SDTV and around 70140 Mbit/s for HDTV while maintaining near-studio-quality transmission, making digital television a practical reality in the 1990s.\nDevelopment.\nA digital TV service was proposed in 1986 by Nippon Telegraph and Telephone (NTT) and the Ministry of Posts and Telecommunication (MPT) in Japan, where there were plans to develop an \"Integrated Network System\" service. However, it was not possible to practically implement such a digital TV service until the adoption of discrete cosine transform (DCT) video compression technology made it possible in the early 1990s.\nIn the mid-1980s, as Japanese consumer electronics firms forged ahead with the development of HDTV technology, and as the MUSE analog format was proposed by Japan's public broadcaster NHK as a worldwide standard, Japanese advancements were seen as pacesetters that threatened to eclipse U.S. electronics companies. Until June 1990, the Japanese MUSE standard\u2014based on an analog system\u2014was the front-runner among the more than 23 different technical concepts under consideration.\nBetween 1988 and 1991, several European organizations were working on DCT-based digital video coding standards for both SDTV and HDTV. The EU 256 project by the CMTT and ETSI, along with research by Italian broadcaster RAI, developed a DCT video codec that broadcast SDTV at 34Mbit/s bit-rate and near-studio-quality HDTV at about 70140 Mbit/s bit-rate. RAI demonstrated this with a 1990 FIFA World Cup broadcast in March 1990. An American company, General Instrument, also demonstrated the feasibility of a digital television signal in 1990. This led to the FCC being persuaded to delay its decision on an ATV standard until a digitally based standard could be developed.\nIn March 1990, when it became clear that a digital standard was feasible, the FCC made a number of critical decisions. First, the Commission declared that the new TV standard must be more than an enhanced analog signal, but be able to provide a genuine HDTV signal with at least twice the resolution of existing television images. Then, to ensure that viewers who did not wish to buy a new digital television set could continue to receive conventional television broadcasts, it dictated that the new ATV standard must be capable of being \"simulcast\" on different channels. The new ATV standard also allowed the new DTV signal to be based on entirely new design principles. Although incompatible with the existing NTSC standard, the new DTV standard would be able to incorporate many improvements.\nThe final standard adopted by the FCC did not require a single standard for scanning formats, aspect ratios, or lines of resolution. This outcome resulted from a dispute between the consumer electronics industry (joined by some broadcasters) and the computer industry (joined by the film industry and some public interest groups) over which of the two scanning processes\u2014interlaced or progressive\u2014is superior. Interlaced scanning, which is used in televisions worldwide, scans even-numbered lines first, then odd-numbered ones. Progressive scanning, which is the format used in computers, scans lines in sequences, from top to bottom. The computer industry argued that progressive scanning is superior because it does not \"flicker\" in the manner of interlaced scanning. It also argued that progressive scanning enables easier connections with the Internet, and is more cheaply converted to interlaced formats than vice versa. The film industry also supported progressive scanning because it offers a more efficient means of converting filmed programming into digital formats. For their part, the consumer electronics industry and broadcasters argued that interlaced scanning was the only technology that could transmit the highest quality pictures then (and currently) feasible, i.e., 1,080 lines per picture and 1,920 pixels per line. Broadcasters also favored interlaced scanning because their vast archive of interlaced programming is not readily compatible with a progressive format.\nInaugural launches.\nDirecTV in the U.S. launched the first commercial digital satellite platform in May 1994, using the Digital Satellite System (DSS) standard. Digital cable broadcasts were tested and launched in the U.S. in 1996 by TCI and Time Warner. The first digital terrestrial platform was launched in November 1998 as ONdigital in the United Kingdom, using the DVB-T standard.\nTechnical information.\nFormats and bandwidth.\nDigital television supports many different picture formats defined by the broadcast television systems which are a combination of size and aspect ratio (width to height ratio).\nWith digital terrestrial television (DTT) broadcasting, the range of formats can be broadly divided into two categories: high definition television (HDTV) for the transmission of high-definition video and standard-definition television (SDTV). These terms by themselves are not very precise, and many subtle intermediate cases exist.\nOne of several different HDTV formats that can be transmitted over DTV is: 1280\u00a0\u00d7\u00a0720 pixels in progressive scan mode (abbreviated \"720p\") or 1920\u00a0\u00d7\u00a01080 pixels in interlaced video mode (\"1080i\"). Each of these uses a aspect ratio. HDTV cannot be transmitted over analog television channels because of channel capacity issues.\nSDTV, by comparison, may use one of several different formats taking the form of various aspect ratios depending on the technology used in the country of broadcast. In terms of rectangular pixels, NTSC countries can deliver a 640\u00a0\u00d7\u00a0480 resolution in 4:3 and 854\u00a0\u00d7\u00a0480 in , while PAL can give 768\u00a0\u00d7\u00a0576 in and 1024\u00a0\u00d7\u00a0576 in . However, broadcasters may choose to reduce these resolutions to reduce bit rate (e.g., many DVB-T channels in the United Kingdom use a horizontal resolution of 544 or 704 pixels per line).\nEach commercial broadcasting terrestrial television DTV channel in North America is permitted to be broadcast at a bit rate up to 19 megabits per second. However, the broadcaster does not need to use this entire bandwidth for just one broadcast channel. Instead the broadcast can use the channel to include PSIP and can also subdivide across several video subchannels (a.k.a. feeds) of varying quality and compression rates, including non-video datacasting services that allow one-way high-bit-rate streaming of data to computers like National Datacast.\nA broadcaster may opt to use a standard-definition (SDTV) digital signal instead of an HDTV signal, because current convention allows the bandwidth of a DTV channel (or \"multiplex\") to be subdivided into multiple digital subchannels, (similar to what most FM radio stations offer with HD Radio), providing multiple feeds of entirely different television programming on the same channel. This ability to provide either a single HDTV feed or multiple lower-resolution feeds is often referred to as distributing one's \"bit budget\" or multicasting. This can sometimes be arranged automatically, using a statistical multiplexer (or \"stat-mux\"). With some implementations, image resolution may be less directly limited by bandwidth; for example in DVB-T, broadcasters can choose from several different modulation schemes, giving them the option to reduce the transmission bit rate and make reception easier for more distant or mobile viewers.\nReceiving digital signal.\nThere are several different ways to receive digital television. One of the oldest means of receiving DTV (and TV in general) is from terrestrial transmitters using an antenna (known as an \"aerial\" in some countries). This way is known as Digital terrestrial television (DTT). With DTT, viewers are limited to channels that have a terrestrial transmitter in range of their antenna.\nOther ways have been devised to receive digital television. Among the most familiar to people are digital cable and digital satellite. In some countries where transmissions of TV signals are normally achieved by microwaves, digital MMDS is used. Other standards, such as Digital multimedia broadcasting (DMB) and DVB-H, have been devised to allow handheld devices such as mobile phones to receive TV signals. Another way is IPTV, that is receiving TV via Internet Protocol, relying on digital subscriber line (DSL) or optical cable line. Finally, an alternative way is to receive digital TV signals via the open Internet (Internet television), whether from a central streaming service or a P2P (peer-to-peer) system.\nSome signals carry encryption and specify use conditions (such as \"may not be recorded\" or \"may not be viewed on displays larger than 1 m in diagonal measure\") backed up with the force of law under the World Intellectual Property Organization Copyright Treaty (WIPO Copyright Treaty) and national legislation implementing it, such as the U.S. Digital Millennium Copyright Act. Access to encrypted channels can be controlled by a removable smart card, for example via the Common Interface (DVB-CI) standard for Europe and via Point Of Deployment (POD) for IS or named differently CableCard.\nProtection parameters for terrestrial DTV broadcasting.\nDigital television signals must not interfere with each other, and they must also coexist with analog television until it is phased out.\nThe following table gives allowable signal-to-noise and signal-to-interference ratios for various interference scenarios. This table is a crucial regulatory tool for controlling the placement and power levels of stations. Digital TV is more tolerant of interference than analog TV, and this is the reason a smaller range of channels can carry an all-digital set of television stations.\nInteraction.\nPeople can interact with a DTV system in various ways. One can, for example, browse the electronic program guide. Modern DTV systems sometimes use a return path providing feedback from the end user to the broadcaster. This is possible with a coaxial or fiber optic cable, a dialup modem, or Internet connection but is not possible with a standard antenna.\nSome of these systems support video on demand using a communication channel localized to a neighborhood rather than a city (terrestrial) or an even larger area (satellite).\n1-segment broadcasting.\n1seg (1-segment) is a special form of ISDB. Each channel is further divided into 13 segments. The 12 segments of them are allocated for HDTV and remaining segment, the 13th, is used for narrow-band receivers such as mobile television or cell phone.\nComparison of analog vs digital.\nDTV has several advantages over analog TV, the most significant being that digital channels take up less bandwidth, and the bandwidth needs are continuously variable, at a corresponding reduction in image quality depending on the level of compression as well as the resolution of the transmitted image. This means that digital broadcasters can provide more digital channels in the same space, provide high-definition television service, or provide other non-television services such as multimedia or interactivity. DTV also permits special services such as multiplexing (more than one program on the same channel), electronic program guides and additional languages (spoken or subtitled). The sale of non-television services may provide an additional revenue source.\nDigital and analog signals react to interference differently. For example, common problems with analog television include ghosting of images, noise from weak signals, and many other potential problems which degrade the quality of the image and sound, although the program material may still be watchable. With digital television, the audio and video must be synchronized digitally, so reception of the digital signal must be very nearly complete; otherwise, neither audio nor video will be usable. Short of this complete failure, \"blocky\" video is seen when the digital signal experiences interference.\nAnalog TV began with monophonic sound, and later developed multichannel television sound with two independent audio signal channels. DTV allows up to 5 audio signal channels plus a subwoofer bass channel, with broadcasts similar in quality to movie theaters and DVDs.\nDigital TV signals require less transmission power than analog TV signals to be broadcast and received satisfactorily.\nCompression artifacts, picture quality monitoring, and allocated bandwidth.\nDTV images have some picture defects that are not present on analog television or motion picture cinema, because of present-day limitations of bit rate and compression algorithms such as MPEG-2. This defect is sometimes referred to as \"mosquito noise\".\nBecause of the way the human visual system works, defects in an image that are localized to particular features of the image or that come and go are more perceptible than defects that are uniform and constant. However, the DTV system is designed to take advantage of other limitations of the human visual system to help mask these flaws, e.g. by allowing more compression artifacts during fast motion where the eye cannot track and resolve them as easily and, conversely, minimizing artifacts in still backgrounds that may be closely examined in a scene (since time allows).\nBroadcast, cable, satellite, and Internet DTV operators control the picture quality of television signal encodes using sophisticated, neuroscience-based algorithms, such as the structural similarity (SSIM) video quality measurement tool, which was accorded each of its inventors a Primetime Emmy because of its global use. Another tool, called Visual Information Fidelity (VIF), is a top-performing algorithm at the core of the Netflix VMAF video quality monitoring system, which accounts for about 35% of all U.S. bandwidth consumption.\nEffects of poor reception.\nChanges in signal reception from factors such as degrading antenna connections or changing weather conditions may gradually reduce the quality of analog TV. The nature of digital TV results in a perfectly decodable video initially, until the receiving equipment starts picking up interference that overpowers the desired signal or if the signal is too weak to decode. Some equipment will show a garbled picture with significant damage, while other devices may go directly from perfectly decodable video to no video at all or lock up. This phenomenon is known as the digital cliff effect.\nBlock error may occur when transmission is done with compressed images. A block error in a single frame often results in black boxes in several subsequent frames, making viewing difficult.\nFor remote locations, distant channels that, as analog signals, were previously usable in a snowy and degraded state may, as digital signals, be perfectly decodable or may become completely unavailable. The use of higher frequencies will add to these problems, especially in cases where a clear line-of-sight from the receiving antenna to the transmitter is not available, because usually higher frquency signals can't pass through obstacles as easily.\nEffect on old analog technology.\nTelevision sets with only analog tuners cannot decode digital transmissions. When analog broadcasting over the air ceases, users of sets with analog-only tuners may use other sources of programming (e.g. cable, recorded media) or may purchase set-top converter boxes to tune in the digital signals. In the United States, a government-sponsored coupon was available to offset the cost of an external converter box. Analog switch-off (of full-power stations) took place on December 11, 2006 in The Netherlands, June 12, 2009 in the United States for full-power stations, and later for Class-A Stations on September 1, 2016, July 24, 2011 in Japan, August 31, 2011 in Canada, February 13, 2012 in Arab states, May 1, 2012 in Germany, October 24, 2012 in the United Kingdom and Ireland, October 31, 2012 in selected Indian cities, and December 10, 2013 in Australia. Completion of analog switch-off is scheduled for December 31, 2017 in the whole of India, December 2018 in Costa Rica and around 2020 for the Philippines.\nDisappearance of TV-audio receivers.\nPrior to the conversion to digital TV, analog television broadcast audio for TV channels on a separate FM carrier signal from the video signal. This FM audio signal could be heard using standard radios equipped with the appropriate tuning circuits.\nHowever, after the transition of many countries to digital TV, no portable radio manufacturer has yet developed an alternative method for portable radios to play just the audio signal of digital TV channels; DTV radio is not the same thing.\nEnvironmental issues.\nThe adoption of a broadcast standard incompatible with existing analog receivers has created the problem of large numbers of analog receivers being discarded during digital television transition. One superintendent of public works was quoted in 2009 saying; \"some of the studies I\u2019ve read in the trade magazines say up to a quarter of American households could be throwing a TV out in the next two years following the regulation change\". In 2009, an estimated 99 million analog TV receivers were sitting unused in homes in the US alone and, while some obsolete receivers are being retrofitted with converters, many more are simply dumped in landfills where they represent a source of toxic metals such as lead as well as lesser amounts of materials such as barium, cadmium and chromium.\nAccording to one campaign group, a CRT computer monitor or TV contains an average of of lead. According to another source, the lead in glass of a CRT varies from 1.08\u00a0lb to 11.28\u00a0lb, depending on screen size and type, but the lead is in the form of \"stable and immobile\" lead oxide mixed into the glass. It is claimed that the lead can have long-term negative effects on the environment if dumped as landfill. However, the glass envelope can be recycled at suitably equipped facilities. Other portions of the receiver may be subject to disposal as hazardous material.\nLocal restrictions on disposal of these materials vary widely; in some cases second-hand stores have refused to accept working color television receivers for resale due to the increasing costs of disposing of unsold TVs. Those thrift stores which are still accepting donated TVs have reported significant increases in good-condition working used television receivers abandoned by viewers who often expect them not to work after digital transition.\nIn Michigan in 2009, one recycler estimated that as many as one household in four would dispose of or recycle a TV set in the following year. The digital television transition, migration to high-definition television receivers and the replacement of CRTs with flatscreens are all factors in the increasing number of discarded analog CRT-based television receivers."}
{"id": "8272", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=8272", "title": "Danforth Quayle", "text": ""}
{"id": "8273", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=8273", "title": "James Danforth Quayle", "text": ""}
{"id": "8274", "revid": "19089174", "url": "https://en.wikipedia.org/wiki?curid=8274", "title": "Declaration of Arbroath", "text": " \nThe Declaration of Arbroath (; ; ) is the name usually given to a letter, dated 6 April 1320 at Arbroath, written by Scottish barons and addressed to Pope John XXII. It constituted King Robert I's response to his excommunication for disobeying the pope's demand in 1317 for a truce in the First War of Scottish Independence. The letter asserted the antiquity of the independence of the Kingdom of Scotland, denouncing English attempts to subjugate it.\nGenerally believed to have been written in Arbroath Abbey by Bernard of Kilwinning (or of Linton), then Chancellor of Scotland and Abbot of Arbroath, and sealed by fifty-one magnates and nobles, the letter is the sole survivor of three created at the time. The others were a letter from the King of Scots, Robert I, and a letter from four Scottish bishops which all made similar points. The \"Declaration\" was intended to assert Scotland's status as an independent, sovereign state and defend Scotland's right to use military action when unjustly attacked.\nSubmitted in Latin, the \"Declaration\" was little known until the late 17th century and is unmentioned by any of Scotland's major 16th century historians. In the 1680s, the Latin text was printed for the first time and translated into English in the wake of the Glorious Revolution, after which time it was sometimes described as a declaration of independence.\nOverview.\nThe \"Declaration\" was part of a broader diplomatic campaign, which sought to assert Scotland's position as an independent kingdom, rather than its being a feudal land controlled by England's Norman kings, as well as lift the excommunication of Robert the Bruce. The pope had recognised Edward I of England's claim to overlordship of Scotland in 1305 and Bruce was excommunicated by the Pope for murdering John Comyn before the altar at Greyfriars Church in Dumfries in 1306. This excommunication was lifted in 1308; subsequently the pope threatened Robert with excommunication again if Avignon's demands in 1317 for peace with England were ignored. Warfare continued, and in 1320 John XXII again excommunicated Robert I. In reply, the \"Declaration\" was composed and signed and, in response, the papacy rescinded King Robert Bruce's excommunication and thereafter addressed him using his royal title.\nThe wars of Scottish independence began as a result of the deaths of King Alexander III of Scotland in 1286 and his heir the \"Maid of Norway\" in 1290, which left the throne of Scotland vacant and the subsequent succession crisis of 1290-1296 ignited a struggle among the Competitors for the Crown of Scotland, chiefly between the House of Comyn, the House of Balliol, and the House of Bruce who all claimed the crown. After July 1296's deposition of King John Balliol by Edward of England and then February 1306's killing of John Comyn III, Robert Bruce's rivals to the throne of Scotland were gone, and Robert was crowned king at Scone that year. Edward I, the \"Hammer of Scots\", died in 1307; his son and successor Edward II did not renew his father's campaigns in Scotland. In 1309 a parliament held at St Andrews acknowledged Robert's right to rule, received emissaries from the Kingdom of France recognising the Bruce's title, and proclaimed the independence of the kingdom from England.\nBy 1314 only Edinburgh, Berwick-upon-Tweed, Roxburgh, and Stirling remained in English hands. In June 1314 the Battle of Bannockburn had secured Robert Bruce's position as King of Scots; Stirling, the Central Belt, and much of Lothian came under Robert's control while the defeated Edward II's power on escaping to England via Berwick weakened under the sway of his cousin Henry, Earl of Lancaster. King Robert was thus able to consolidate his power, and sent his brother Edward Bruce to claim the Kingdom of Ireland in 1315 with an army landed in Ulster the previous year with the help of Gaelic lords from the Isles. Edward Bruce died in 1318 without achieving success, but the Scots campaigns in Ireland and in northern England were intended to press for the recognition of Robert's crown by King Edward. At the same time, it undermined the House of Plantagenet's claims to overlordship of the British Isles and halted the Plantagenets' effort to absorb Scotland as had been done in Ireland and Wales. Thus were the Scots nobles confident in their letters to Pope John of the distinct and independent nature of Scotland's kingdom; the \"Declaration of Arbroath\" was one such. According to historian David Crouch, \"The two nations were mutually hostile kingdoms and peoples, and the ancient idea of Britain as an informal empire of peoples under the English king's presidency was entirely dead.\"\nThe text makes claims about the ancient history of Scotland and especially the \"Scoti\", forbears of the Scots, who the \"Declaration\" claims originated in \"Scythia Major\" and migrated via Spain to Britain, dating their migration to \"1,200 years from the Israelite people's crossing of the Red Sea\". The \"Declaration\" describes how the Scots had \"thrown out the Britons and completely destroyed the Picts\", resisted the invasions of \"the Norse, the Danes and the English\", and \"held itself ever since, free from all slavery\". It then claims that in the Kingdom of Scotland, \"one hundred and thirteen kings have reigned of their own Blood Royal, without interruption by foreigners\". The text compares Robert Bruce with the Biblical warriors Judas Maccabeus and Joshua.\nThe \"Declaration\" made a number of points: that Edward I of England had unjustly attacked Scotland and perpetrated atrocities; that Robert the Bruce had delivered the Scottish nation from this peril; and, most controversially, that the independence of Scotland was the prerogative of the Scottish people, rather than the King of Scots. (However, this should be taken in the context of the time - \u2018Scottish People\u2019 refers to the Scottish nobility, rather than commoners.) In fact it stated that the nobility would choose someone else to be king if Bruce proved to be unfit in maintaining Scotland's independence.\nDebates.\nSome have interpreted this last point as an early expression of 'popular sovereignty' \u2013 that government is contractual and that kings can be chosen by the community rather than by God alone. It has been considered to be the first statement of the contractual theory of monarchy underlying modern constitutionalism. \nSome point to the \u201cDeclaration\" as evidence of the long-term persistence of the Scots as a distinct national community, giving a very early date for the emergence of nationalism. \nIt has also been argued that the \"Declaration\" was not a statement of popular sovereignty (and that its signatories would have had no such concept) but a statement of royal propaganda supporting Bruce's faction. A justification had to be given for the rejection of King John Balliol in whose name William Wallace and Andrew de Moray had rebelled in 1297. The reason given in the \"Declaration\" is that Bruce was able to defend Scotland from English aggression whereas, by implication, King John could not.\nWhatever the true motive, the idea of a contract between King and people was advanced to the Pope as a justification for Bruce's coronation whilst John de Balliol still lived in Papal custody.\nText.\nFor the full text in Latin and a translation in English, See on WikiSource.\nSignatories.\nThere are 39 names\u2014eight earls and thirty-one barons\u2014at the start of the document, all of whom may have had their seals appended, probably over the space of some weeks and months, with nobles sending in their seals to be used. On the extant copy of the \"Declaration\" there are only 19 seals, and of those 19 people only 12 are named within the document. It is thought likely that at least 11 more seals than the original 39 might have been appended. The \"Declaration\" was then taken to the papal court at Avignon by Bishop Kininmund, Sir Adam Gordon and Sir Odard de Maubuisson.\nThe Pope heeded the arguments contained in the \"Declaration\", influenced by the offer of support from the Scots for his long-desired crusade if they no longer had to fear English invasion. He exhorted Edward II in a letter to make peace with the Scots, but the following year was again persuaded by the English to take their side and issued six bulls to that effect.\nEight years later, on 1 March 1328, the new English king, Edward III, signed a peace treaty between Scotland and England, the Treaty of Edinburgh\u2013Northampton. In this treaty, which was in effect for until 1333, Edward renounced all English claims to Scotland. In October 1328, the interdict on Scotland, and the excommunication of its king, were removed by the Pope.\nManuscript.\nThe original copy of the \"Declaration\" that was sent to Avignon is lost. The only existing manuscript copy of the \"Declaration\" survives among Scotland's state papers, measuring 540mm wide by 675mm long (including the seals), it is held by the National Archives of Scotland in Edinburgh, a part of the National Records of Scotland. \nThe most widely known English language translation was made by Sir James Fergusson, formerly Keeper of the Records of Scotland, from text that he reconstructed using this extant copy and early copies of the original draft. \nG. W. S. Barrow has shown that one passage in particular, often quoted from the Fergusson translation, was carefully written using different parts of \"The Conspiracy of Catiline\" by the Roman author, Sallust (86\u201335 BC) as the direct source:\nList of signatories.\nListed below are the signatories of the Declaration of Arbroath in 1320.\nThe letter itself is written in Latin. It uses the Latin versions of the signatories' titles, and in some cases, the spelling of names has changed over the years. This list generally uses the titles of the signatories' Wikipedia biographies.\nIn addition, the names of the following do not appear in the document's text, but their names are written on seal tags and their seals are present:\nLegacy.\nIn 1998 former majority leader Trent Lott succeeded in instituting an annual \"National Tartan Day\" on 6 April by resolution of the United States Senate. US Senate Resolution 155 of 10 November 1997 states that \"the Declaration of Arbroath, the Scottish Declaration of Independence, was signed on April 6, 1320 and the American Declaration of Independence was modeled [sic] on that inspirational document\". However, although this influence is accepted by some historians, it is disputed by others. \nIn 2016 the Declaration of Arbroath was placed on the UK Memory of the World Register, part of UNESCO's Memory of the World Programme.\n2020 is the 700th anniversary of the Declaration of Arbroath's composition; an \"Arbroath 2020\" festival was arranged but postponed due to the COVID-19 pandemic. The National Museum of Scotland in Edinburgh planned to display the document to the public for the first time in fifteen years."}
{"id": "8276", "revid": "1011686065", "url": "https://en.wikipedia.org/wiki?curid=8276", "title": "Digital data", "text": "Digital data, in information theory and information systems, is the discrete, discontinuous representation of information or works. Numbers and letters are commonly used representations.\nDigital data can be contrasted with analog signals which behave in a continuous manner, and with continuous functions such as sounds, images, and other measurements.\nThe word \"digital\" comes from the same source as the words digit and \"digitus\" (the Latin word for \"finger\"), as fingers are often used for counting. Mathematician George Stibitz of Bell Telephone Laboratories used the word \"digital\" in reference to the fast electric pulses emitted by a device designed to aim and fire anti-aircraft guns in 1942. The term is most commonly used in computing and electronics, especially where real-world information is converted to binary numeric form as in digital audio and digital photography.\nSymbol to digital conversion.\nSince symbols (for example, alphanumeric characters) are not continuous, representing symbols digitally is rather simpler than conversion of continuous or analog information to digital. Instead of sampling and quantization as in analog-to-digital conversion, such techniques as polling and encoding are used.\nA symbol input device usually consists of a group of switches that are polled at regular intervals to see which switches are switched. Data will be lost if, within a single polling interval, two switches are pressed, or a switch is pressed, released, and pressed again. This polling can be done by a specialized processor in the device to prevent burdening the main CPU. When a new symbol has been entered, the device typically sends an interrupt, in a specialized format, so that the CPU can read it.\nFor devices with only a few switches (such as the buttons on a joystick), the status of each can be encoded as bits (usually 0 for released and 1 for pressed) in a single word. This is useful when combinations of key presses are meaningful, and is sometimes used for passing the status of modifier keys on a keyboard (such as shift and control). But it does not scale to support more keys than the number of bits in a single byte or word.\nDevices with many switches (such as a computer keyboard) usually arrange these switches in a scan matrix, with the individual switches on the intersections of x and y lines. When a switch is pressed, it connects the corresponding x and y lines together. Polling (often called scanning in this case) is done by activating each x line in sequence and detecting which y lines then have a signal, thus which keys are pressed. When the keyboard processor detects that a key has changed state, it sends a signal to the CPU indicating the scan code of the key and its new state. The symbol is then encoded or converted into a number based on the status of modifier keys and the desired character encoding.\nA custom encoding can be used for a specific application with no loss of data. However, using a standard encoding such as ASCII is problematic if a symbol such as '\u00df' needs to be converted but is not in the standard.\nIt is estimated that in the year 1986 less than 1% of the world's technological capacity to store information was digital and in 2007 it was already 94%. The year 2002 is assumed to be the year when humankind was able to store more information in digital than in analog format (the \"beginning of the digital age\").\nStates.\nDigital data come in these three states: data at rest, data in transit and data in use. The confidentiality, integrity and availability have to be managed during the entire lifecycle from 'birth' to the destruction of the data.\nProperties of digital information.\nAll digital information possesses common properties that distinguish it from analog data with respect to communications:\nHistorical digital systems.\nEven though digital signals are generally associated with the binary electronic digital systems used in modern electronics and computing, digital systems are actually ancient, and need not be binary or electronic."}
{"id": "8277", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=8277", "title": "Di George's syndrome", "text": ""}
{"id": "8278", "revid": "41329389", "url": "https://en.wikipedia.org/wiki?curid=8278", "title": "Deduction", "text": "Deduction may refer to:\nPhilosophy.\nDeductions are a conclusion you come to through reasoning."}
{"id": "8280", "revid": "20110590", "url": "https://en.wikipedia.org/wiki?curid=8280", "title": "Demon", "text": "A demon is a supernatural being, typically associated with evil, prevalent historically in religion, occultism, literature, fiction, mythology, and folklore; as well as in media such as comics, video games, movies, anime, and television series.\nThe original Greek word \"daimon\" does not carry negative connotations. The Ancient Greek word \"daim\u014dn\" denotes a spirit or divine power, much like the Latin \"genius\" or \"numen\". The Greek conception of a \"daim\u014dn\" notably appears in the works of Plato, where it describes the divine inspiration of Socrates.\nIn Ancient Near Eastern religions and in the Abrahamic traditions, including ancient and medieval Christian demonology, a demon is considered a harmful spiritual entity which may cause demonic possession, calling for an exorcism. In Western occultism and Renaissance magic, which grew out of an amalgamation of Greco-Roman magic, Jewish Aggadah and Christian demonology, a demon is believed to be a spiritual entity that may be conjured and controlled.\nEtymology.\nThe Ancient Greek word \"daemon\" denotes a spirit or divine power, much like the Latin \"genius\" or \"numen\". \"Daim\u014dn\" most likely came from the Greek verb \"daiesthai\" (to divide, distribute). The Greek conception of a \"daim\u014dn\" notably appears in the works of Plato, where it describes the divine inspiration of Socrates. The original Greek word \"daimon\" does not carry the negative connotation initially understood by implementation of the Koine (\"daimonion\"), and later ascribed to any cognate words sharing the root.\nThe Greek terms do not have any connotations of evil or malevolence. In fact, \"eudaimonia\", (literally good-spiritedness) means happiness. By the early Roman Empire, cult statues were seen, by pagans and their Christian neighbors alike, as inhabited by the numinous presence of the gods: \"Like pagans, Christians still sensed and saw the gods and their power, and as something, they had to assume, lay behind it, by an easy traditional shift of opinion they turned these pagan \"daimones\" into malevolent 'demons', the troupe of Satan... Far into the Byzantine period Christians eyed their cities' old pagan statuary as a seat of the demons' presence. It was no longer beautiful, it was infested.\" The term had first acquired its negative connotations in the Septuagint translation of the Hebrew Bible into Greek, which drew on the mythology of ancient Semitic religions. This was then inherited by the Koine text of the New Testament. The Western medieval and neo-medieval conception of a \"demon\" derives seamlessly from the ambient popular culture of Late Antiquity. The Hellenistic \"daemon\" eventually came to include many Semitic and Near Eastern gods as evaluated by Christianity.\nThe supposed existence of demons remains an important concept in many modern religions and occultist traditions. Demons are still feared largely due to their alleged power to possess living creatures. In the contemporary Western occultist tradition (perhaps epitomized by the work of Aleister Crowley), a demon (such as Choronzon, which is Crowley's interpretation of the so-called 'Demon of the Abyss') is a useful metaphor for certain inner psychological processes (inner demons), though some may also regard it as an objectively real phenomenon. Some scholars believe that large portions of the demonology (see Asmodai) of Judaism, a key influence on Christianity and Islam, originated from a later form of Zoroastrianism, and were transferred to Judaism during the Persian era.\nAncient Egypt.\nBoth deities and demons can act as intermediaries to deliver messages to humans. Thus they share some resemblance to the Greek daimonion. The exact definition of \"demon\" in Egyptology posed a major problem for modern scholarship, since the borders between a deity and a demon are sometimes blurred and the ancient Egyptian language lacks a term for the modern English \"demon\". However, magical writings indicate that ancient Egyptians acknowledged the existence of malevolent demons by highlighting the demon names with red ink. Demons in this culture appeared to be subordinative and related to a specific deity, yet they may have occasionally acted independently of the divine will. The existence of demons can be related to the realm of chaos, beyond the created world. But even this negative connotation cannot be denied in light of the magical texts. The role of demons in relation to the human world remains ambivalent and largely depends on context.\nAncient Egyptian demons can be divided into two classes: \"guardians\" and \"wanderers.\" \"Guardians\" are tied to a specific place; their demonic activity is topographically defined and their function can be benevolent towards those who have the secret knowledge to face them. Demons protecting the underworld may prevent human souls from entering paradise. Only by knowing right charms is the deceased able to enter the \"Halls of Osiris\". Here, the aggressive nature of the guardian demons is motivated by the need to protect their abodes and not by their evil essence. Accordingly, demons guarded sacred places or the gates to the netherworld. During the Ptolemaic and Roman period, the guardians shifted towards the role of Genius loci and they were the focus of local and private cults.\nThe \"wanderers\" are associated with possession, mental illness, death and plagues. Many of them serve as executioners for the major deities, such as Ra or Osiris, when ordered to punish humans on earth or in the netherworld. Wanderers can also be agents of chaos, arising from the world beyond creation to bring about misfortune and suffering without any divine instructions, led only by evil motivations. The influences of the wanderers can be warded off and kept at the borders on the human world by the use of magic, but they can never be destroyed. A sub-category of \"wanderers\" are nightmare demons, which were believed to cause nightmares by entering a human body.\nMesopotamia.\nThe ancient Mesopotamians believed that the underworld was home to many demons, which are sometimes referred to as \"offspring of \"arali\"\". These demons could sometimes leave the underworld and terrorize mortals on earth. One class of demons that were believed to reside in the underworld were known as \"galla\"; their primary purpose appears to have been to drag unfortunate mortals back to Kur. They are frequently referenced in magical texts, and some texts describe them as being seven in number. Several extant poems describe the \"galla\" dragging the god Dumuzid into the underworld. Like other demons, however, \"galla\" could also be benevolent and, in a hymn from King Gudea of Lagash ( 2144 \u2013 2124 BCE), a minor god named Ig-alima is described as \"the great \"galla\" of Girsu\".\nLamashtu was a demonic goddess with the \"head of a lion, the teeth of a donkey, naked breasts, a hairy body, hands stained (with blood?), long fingers and fingernails, and the feet of Anz\u00fb.\" She was believed to feed on the blood of human infants and was widely blamed as the cause of miscarriages and cot deaths. Although Lamashtu has traditionally been identified as a demoness, the fact that she could cause evil on her own without the permission of other deities strongly indicates that she was seen as a goddess in her own right. Mesopotamian peoples protected against her using amulets and talismans. She was believed to ride in her boat on the river of the underworld and she was associated with donkeys. She was believed to be the daughter of An.\nPazuzu is a demonic god who was well known to the Babylonians and Assyrians throughout the first millennium BCE. He is shown with \"a rather canine face with abnormally bulging eyes, a scaly body, a snake-headed penis, the talons of a bird and usually wings.\" He was believed to be the son of the god Hanbi. He was usually regarded as evil, but he could also sometimes be a beneficent entity who protected against winds bearing pestilence and he was thought to be able to force Lamashtu back to the underworld. Amulets bearing his image were positioned in dwellings to protect infants from Lamashtu and pregnant women frequently wore amulets with his head on them as protection from her.\n\u0160ul-pa-e's name means \"youthful brilliance\", but he was not envisioned as youthful god. According to one tradition, he was the consort of Ninhursag, a tradition which contradicts the usual portrayal of Enki as Ninhursag's consort. In one Sumerian poem, offerings made to \u0160hul-pa-e in the underworld and, in later mythology, he was one of the demons of the underworld.\nAccording to the Jewish Encyclopedia, \"In Chaldean mythology the seven evil deities were known as \"shedu\", storm-demons, represented in ox-like form.\" They were represented as winged bulls, derived from the colossal bulls used as protective jinn of royal palaces.\nAbrahamic religions.\nJudaism.\nAs referring to the existence or non-existence of demons (\"shedim\" or \"Se'irim\") there are converse opinions in Judaism. There are \"practically nil\" roles assigned to demons in the Hebrew Bible. In Judaism today, beliefs in \"demons\" or \"evil spirits\" are either \"midot hasidut\" (Hebr. for \"customs of the pious\"), and therefore not halachah, or notions based on a superstition that are non-essential, non-binding parts of Judaism, and therefore not normative Jewish practice. That is to say, Jews are not obligated to believe in the existence of \"shedim\", as posek rabbi David Bar-Hayim points out.\nTanakh.\nThe Tanakh mentions two classes of demonic spirits, the \"se'irim\" and the \"shedim\". The word \"shedim\" appears in two places in the Tanakh (, ). The \"se'irim\" are mentioned once in , probably a re-calling of Assyrian demons in shape of goats. The \"shedim\" in return are not pagan demigods, but the foreign gods themselves. Both entities appear in a scriptural context of animal or child sacrifice to \"non-existent\" false gods.\nFrom Chaldea, the term \"shedu\" traveled to the Israelites. The writers of the Tanach applied the word as a dialogism to Canaanite deities.\nThere are indications that demons in popular Hebrew mythology were believed to come from the nether world. Various diseases and ailments were ascribed to them, particularly those affecting the brain and those of internal nature. Examples include catalepsy, headache, epilepsy and nightmares. There also existed a demon of blindness, \"Shabriri\" (lit. \"dazzling glare\") who rested on uncovered water at night and blinded those who drank from it.\nDemons supposedly entered the body and caused the disease while overwhelming or \"seizing\" the victim. To cure such diseases, it was necessary to draw out the evil demons by certain incantations and talismanic performances, at which the Essenes excelled. Josephus, who spoke of demons as \"spirits of the wicked which enter into men that are alive and kill them\", but which could be driven out by a certain root, witnessed such a performance in the presence of the Emperor Vespasian and ascribed its origin to King Solomon. In mythology, there were few defences against Babylonian demons. The mythical mace Sharur had the power to slay demons such as Asag, a legendary gallu or edimmu of hideous strength.\nSecond Temple period texts.\nTo the Qumran community during the Second Temple period this apotropaic prayer was assigned, stating: \"And, I the Sage, declare the grandeur of his radiance in order to frighten and terri[fy] all the spirits of the ravaging angels and the bastard spirits, demons, Liliths, owls\" (\"Dead Sea Scrolls\", \"Songs of the Sage,\" Lines 4\u20135).\nIn the Dead Sea Scrolls, there exists a fragment entitled \"Curses of Belial\" (\"Curses of Belial (Dead Sea Scrolls, 394, 4Q286(4Q287, fr. 6)=4QBerakhot)\"). This fragment holds much rich language that reflects the sentiment shared between the Qumran towards Belial. In many ways this text shows how these people thought Belial influenced sin through the way they address him and speak of him. By addressing \"Belial and all his guilty lot,\" (4Q286:2) they make it clear that he is not only impious, but also guilty of sins. Informing this state of uncleanliness are both his \"hostile\" and \"wicked design\" (4Q286:3,4). Through this design, Belial poisons the thoughts of those who are not necessarily sinners. Thus a dualism is born from those inclined to be wicked and those who aren't. It is clear that Belial directly influences sin by the mention of \"abominable plots\" and \"guilty inclination\" (4Q286:8,9). These are both mechanisms by which Belial advances his evil agenda that the Qumran have exposed and are calling upon God to protect them from. There is a deep sense of fear that Belial will \"establish in their heart their evil devices\" (4Q286:11,12). This sense of fear is the stimulus for this prayer in the first place. Without the worry and potential of falling victim to Belial's demonic sway, the Qumran people would never feel impelled to craft a curse. This very fact illuminates the power Belial was believed to hold over mortals, and the fact that sin proved to be a temptation that must stem from an impure origin.\nIn Jubilees 1:20, Belial's appearance continues to support the notion that sin is a direct product of his influence. Moreover, Belial's presence acts as a placeholder for all negative influences or those that would potentially interfere with God's will and a pious existence. Similarly to the \"gentiles ... [who] cause them to sin against you\" (Jubilees 1:19), Belial is associated with a force that drives one away from God. Coupled in this plea for protection against foreign rule, in this case the Egyptians, is a plea for protection from \"the spirit of Belial\" (Jubilees 1:19). Belial's tendency is to \"ensnare [you] from every path of righteousness\" (Jubilees 1:19). This phrase is intentionally vague, allowing room for interpretation. Everyone, in one way or another, finds themselves straying from the path of righteousness and by pawning this transgression off on Belial, he becomes a scapegoat for all misguidance, no matter what the cause. By associating Belial with all sorts of misfortune and negative external influence, the Qumran people are henceforth allowed to be let off for the sins they commit. \nBelial's presence is found throughout the War Scrolls, located in the Dead Sea Scrolls, and is established as the force occupying the opposite end of the spectrum of God. In Col. I, verse 1, the first line of the document, it is stated that \"the first attack of the Sons of Light shall be undertaken against the forces of the Sons of Darkness, the army of Belial\" (1Q33;1:1). This dichotomy sheds light on the negative connotations that Belial held at the time. Where God and his Sons of Light are forces that protect and promote piety, Belial and his Sons of Darkness cater to the opposite, instilling the desire to sin and encouraging destruction. This opposition is only reinforced later in the document; it continues to read that the \"holy ones\" will \"strike a blow at wickedness\", ultimately resulting in the \"annihilation of the Sons of Darkness\" (1Q33:1:13). This epic battle between good and evil described in such abstract terms, however it is also applicable to everyday life and serves as a lens through which the Qumran see the world. Every day is the Sons of Light battle evil and call upon God to help them overcome evil in ways small and large.\nBelial's influence is not taken lightly. In Col. XI, verse 8, the text depicts God conquering the \"hordes of Belial\" (1Q33;11:8). This defeat is indicative of God's power over Belial and his forces of temptation. However the fact that Belial is the leader of hordes is a testament to how persuasive he can be. If Belial was obviously an arbiter of wrongdoing and was blatantly in the wrong, he wouldn't be able to amass an army. This fact serves as a warning message, reasserting God's strength, while also making it extremely clear the breadth of Belial's prowess. Belial's \"council is to condemn and convict\", so the Qumran feel strongly that their people are not only aware of his purpose, but also equipped to combat his influence (1Q33;13:11).\nIn the Damascus Document, Belial also makes a prominent appearance, being established as a source of evil and an origin of several types of sin. In Column 4, the first mention of Belial reads: \"Belial shall be unleashed against Israel\" (4Q266). This phrase is able to be interpreted myriad different ways. Belial is characterized in a wild and uncontrollable fashion, making him seem more dangerous and unpredictable. The notion of being unleashed is such that once he is free to roam; he is unstoppable and able to carry out his agenda uninhibited. The passage then goes to enumerate the \"three nets\" (4Q266;4:16) by which Belial captures his prey and forces them to sin. \"Fornication ..., riches ..., [and] the profanation of the temple\" (4Q266;4:17,18) make up the three nets. These three temptations were three agents by which people were driven to sin, so subsequently, the Qumran people crafted the nets of Belial to rationalize why these specific temptations were so toxic. Later in Column 5, Belial is mentioned again as one of \"the removers of bound who led Israel astray\" (4Q266;5:20). This statement is a clear display of Belial's influence over man regarding sin. The passage goes on to state: \"they preached rebellion against ... God\" (4Q266;5:21,22). Belial's purpose is to undermine the teachings of God, and he achieves this by imparting his nets on humans, or the incentive to sin.\nIn the \"War of the Sons of Light Against the Sons of Darkness\", Belial controls scores of demons, which are specifically allotted to him by God for the purpose of performing evil. Belial, despite his malevolent disposition, is considered an angel.\nTalmudic tradition.\nIn the Jerusalem Talmud notions of \"shedim\" (\"demons\" or \"spirits\") are almost unknown or occur only very rarely, whereas in the Babylon Talmud there are many references to \"shedim\" and magical incantations. The existence of \"shedim\" in general was not questioned by most of the Babylonian Talmudists. As a consequence of the rise of influence of the Babylonian Talmud over that of the Jerusalem Talmud, late rabbis in general took as fact the existence of \"shedim\", nor did most of the medieval thinkers question their reality. However, rationalists like Maimonides, Saadia Gaon and Abraham ibn Ezra and others explicitly denied their existence, and completely rejected concepts of demons, evil spirits, negative spiritual influences, attaching and possessing spirits. Their point of view eventually became mainstream Jewish understanding.\nKabbalah.\nIn Kabbalah demons are regarded a necessary part of the divine emanation in the material world and a byproduct of human sin (Qliphoth). However spirits such as the \"shedim\" may also be benevolent and were used in kabbalistic ceremonies (as with the \"golem\" of Rabbi Yehuda Loevy) and malevolent \"shedim\" (\"Mazikin\", from the root meaning \"to damage\") were often credited with possession.\nAggadah.\nAggadic tales from the Persian tradition describe the \"shedim\", the \" mazzi\u1e33im\" (\"harmers\"), and the \" ru\u1e25in\" (\"spirits\"). There were also \"lilin\" (\"night spirits\"), \" \u1e6delane\" (\"shade\", or \"evening spirits\"), \" \u1e6diharire\" (\"midday spirits\"), and \" \u1e93afrire\" (\"morning spirits\"), as well as the \"demons that bring famine\" and \"such as cause storm and earthquake\". According to some aggadic stories, demons were under the dominion of a king or chief, either Asmodai or, in the older Aggadah, Samael (\"the angel of death\"), who killed via poison. Stories in the fashion of this kind of folklore never became an essential feature of Jewish theology. Although occasionally an angel is called \"satan\" in the Babylon Talmud, this does not refer to a demon: \"Stand not in the way of an ox when coming from the pasture, for Satan dances between his horns\".\nChristianity.\nOld Testament.\nDemonic entities in the Old Testament of the Christian Bible are of two classes: the \"satyrs\" or \"shaggy goats\" (from Hebr. \"se'irim\" \"hairy beings\", \"he-goats\" or \"fauns\"; , ) and the \"demons\" (from Hebr. \"shedim\" first translated as \"daimonion\", \"daemon\"; , ).\nNew Testament.\nThe term \"demon\" (from the Koine Greek \u03b4\u03b1\u03b9\u03bc\u03cc\u03bd\u03b9\u03bf\u03bd \"daimonion\") appears 63 times in the New Testament of the Christian Bible, mostly if not all relating to occurrences of possession of individuals and exorcism by Jesus.\nThe King James Version kept it translated as \"devil\". The word \"devil\" by itself is the translation word for the Greek \"diabolos\" which occurs 38 times in the New Testament. The Tyndale Bible (1526 CE), a precursor of KJV, translated it all as \"devyl\", including Act 17:18 as \"newe devyls\".\nPseudepigrapha and deuterocanonical books.\nDemons are included into biblical interpretation. In the story of Passover, the Bible tells the story as \"the Lord struck down all the firstborn in Egypt\" (Exodus 12:21\u201329). In the Book of Jubilees, which is considered canonical only by the Ethiopian Orthodox Church, this same event is told slightly differently: \"All the powers of [the demon] Mastema had been let loose to slay all the first-born in the land of Egypt...And the powers of the Lord did everything according as the Lord commanded them\" (Jubilees 49:2\u20134).\nIn the Genesis flood narrative the author explains how God was noticing \"how corrupt the earth had become, for all the people on earth had corrupted their ways\" (Genesis 6:12). In Jubilees the sins of man are attributed to \"the unclean demons [who] began to lead astray the children of the sons of Noah, and to make to err and destroy them\" (Jubilees 10:1). In Jubilees Mastema questions the loyalty of Abraham and tells God to \"bid him offer him as a burnt offering on the altar, and Thou wilt see if he will do this command\" (Jubilees 17:16). The discrepancy between the story in Jubilees and the story in Genesis 22 exists with the presence of Mastema. In Genesis, God tests the will of Abraham merely to determine whether he is a true follower, however; in Jubilees Mastema has an agenda behind promoting the sacrifice of Abraham's son, \"an even more demonic act than that of the Satan in Job.\" In Jubilees, where Mastema, an angel tasked with the tempting of mortals into sin and iniquity, requests that God give him a tenth of the spirits of the children of the watchers, demons, in order to aid the process. These demons are passed into Mastema's authority, where once again, an angel is in charge of demonic spirits.\nThe sources of demonic influence were thought to originate from the Watchers or Nephilim, who are first mentioned in Genesis 6 and are the focus of 1 Enoch Chapters 1\u201316, and also in Jubilees 10. The Nephilim were seen as the source of the sin and evil on earth because they are referenced in Genesis 6:4 before the story of the Flood. In Genesis 6:5, God sees evil in the hearts of men. The passage states, \"the wickedness of humankind on earth was great\", and that \"Every inclination of the thoughts of their hearts was only continually evil\" (Genesis 5). The mention of the Nephilim in the preceding sentence connects the spread of evil to the Nephilim. Enoch is a very similar story to Genesis 6:4\u20135, and provides further description of the story connecting the Nephilim to the corruption of humans. In Enoch, sin originates when angels descend from heaven and fornicate with women, birthing giants as tall as 300 cubits. The giants and the angels' departure of Heaven and mating with human women are also seen as the source of sorrow and sadness on Earth. The book of Enoch shows that these fallen angels can lead humans to sin through direct interaction or through providing forbidden knowledge. In Enoch, Semyaz leads the angels to mate with women. Angels mating with humans is against God's commands and is a cursed action, resulting in the wrath of God coming upon Earth. Azazel indirectly influences humans to sin by teaching them divine knowledge not meant for humans. Asael brings down the \"stolen mysteries\" (Enoch 16:3). Asael gives the humans weapons, which they use to kill each other. Humans are also taught other sinful actions such as beautification techniques, alchemy, astrology and how to make medicine (considered forbidden knowledge at the time). Demons originate from the evil spirits of the giants that are cursed by God to wander the earth. These spirits are stated in Enoch to \"corrupt, fall, be excited, and fall upon the earth, and cause sorrow\" (Enoch 15:11).\nThe Book of Jubilees conveys that sin occurs when Cainan accidentally transcribes astrological knowledge used by the Watchers (Jubilees 8). This differs from Enoch in that it does not place blame on the Angels. However, in Jubilees 10:4 the evil spirits of the Watchers are discussed as evil and still remain on earth to corrupt the humans. God binds only 90 percent of the Watchers and destroys them, leaving 10 percent to be ruled by Mastema. Because the evil in humans is great, only 10 percent would be needed to corrupt and lead humans astray. These spirits of the giants also referred to as \"the bastards\" in the Apotropaic prayer Songs of the Sage, which lists the names of demons the narrator hopes to expel.\nChristian demonology.\nIn Christianity, demons are corrupted spirits carrying the execution of Satan's desires. They are generally regarded as three different types of spirits:\nOften deities of other religions are interpreted or identified as such \"demons\" (from the Greek Old Testament \u03b4\u03b1\u03b9\u03bc\u03cc\u03bd\u03b9\u03bf\u03bd \"daimonion\"). The evolution of the Christian Devil and pentagram are examples of early rituals and images that showcase evil qualities, as seen by the Christian churches.\nSince Early Christianity, demonology has developed from a simple acceptance of demons to a complex study that has grown from the original ideas taken from Jewish demonology and Christian scriptures. Christian demonology is studied in depth within the Roman Catholic Church, although many other Christian churches affirm and discuss the existence of demons.\nBuilding upon the few references to \"daemons\" in the New Testament, especially the poetry of the Book of Revelation, Christian writers of apocrypha from the 2nd century onwards created a more complicated tapestry of beliefs about \"demons\" that was largely independent of Christian scripture.\nThe contemporary Roman Catholic Church unequivocally teaches that angels and demons are real beings rather than just symbolic devices. The Catholic Church has a cadre of officially sanctioned exorcists which perform many exorcisms each year. The exorcists of the Catholic Church teach that demons attack humans continually but that afflicted persons can be effectively healed and protected either by the formal rite of exorcism, authorized to be performed only by bishops and those they designate, or by prayers of deliverance, which any Christian can offer for themselves or others.\nAt various times in Christian history, attempts have been made to classify demons according to various proposed demonic hierarchies.\nIn the Gospels, particularly the Gospel of Mark, Jesus cast out many demons from those afflicted with various ailments. He also lent this power to some of his disciples ().\nIslam.\n\"Shayatin\" is the usual term for demons in Islamic belief. In Islam demons try to lead humans astray from God, by tempting them to sin, teaching them sorcery and cause mischief among humans. Occult practises albeit not forbidden per se, may include conjuring demons, which requires acts against God's laws and are therefore forbidden, such as illicit blood-sacrifices, abandoning prayer and rejecting fasting. Based on the Islamic view on Solomon, who is widely believed to have been a ruler over genies and demons, Islam has a rich tradition about conjuring demons. Among the demons are the \"shayatin\" (devils) and the \"div\" (fiends). Both are believed to have worked for Solomon as slaves. While the shayatin usually appear within a Judeo-Christian background, the div frequently feature in beliefs of Persian and Indian origin. But it is to be noted that in Islam both angels and demons are considered to be the creatures of God and so God has ultimate power over all of them. \nAccording to exegisis of the Quran the devils are the offspring of Iblis (Satan). They are said to live until the world ceases to exist, always lurking on humans (and jinn) to assault them with whisperings into their \"hearts\" (\"wasw\u0101s\") to lead them astray. When they succeed, their victim would follow their commands. Prayers are used to ward off their attacks, dissolving them temporarily. As the counterpart of the angels, they try to go against God's will and their abode (here: hell) is pre-destined. They lack free-will and are bound to evil. The ifrit and marid are more powerful classes of shayatin. It is necessary to note that in Islam Jinns are different than shayatin unlike shayatin they have free will and not all of them are wrongdoers.\nThe Muslim Persians identified the evil spirits of the Quran with div. While some argue the shayatin have been created good, but turned evil by Iblis' act of arrogance, the div have been created as vicious creatures and embodiment of evil. When Iblis was still among the angels, he led an army against the spirits on the earth. Among them have been the div, who formed two orders; one of them sided with the jinn and have been banished along them, damned to roam the earth, the other treacherous div joined Iblis during battle, but have been sentened to hell with him. The div are often depicted as sorcerers whose misdeeds are not bound to temptation only. They could cause sickness, mental illnesses, or even turn humans to stone by touching. While the shayatin frequently appear to ordinary humans to tempt them into everything disapproved by society, the div usually appear to specific heroes.\nBah\u00e1\u02bc\u00ed Faith.\nIn the Bah\u00e1\u02bc\u00ed Faith, demons are not regarded as independent evil spirits as they are in some faiths. Rather, evil spirits described in various faiths' traditions, such as Satan, fallen angels, demons and jinn, are metaphors for the base character traits a human being may acquire and manifest when he turns away from God and follows his lower nature. Belief in the existence of ghosts and earthbound spirits is rejected and considered to be the product of superstition.\nCeremonial magic.\nWhile some people fear demons, or attempt to exorcise them, others willfully attempt to summon them for knowledge, assistance, or power. The ceremonial magician usually consults a grimoire, which gives the names and abilities of demons as well as detailed instructions for conjuring and controlling them. Grimoires are not limited to demons \u2013 some give the names of angels or spirits which can be called, a process called theurgy. The use of ceremonial magic to call demons is also known as goetia, the name taken from a section in the famous grimoire known as the \"Lesser Key of Solomon\".\nHinduism.\nHindu beliefs include numerous varieties of spirits such as Vetalas, Bhutas and Pishachas. Rakshasas and Asuras are demons\nAsuras.\n\"Asura\", in the earliest hymns of the Rigveda, originally meant any supernatural spirit, either good or bad. Since the /s/ of the Indic linguistic branch is cognate with the /h/ of the Early Iranian languages, the word \"Asura\", representing a category of celestial beings. Ancient Hinduism tells that Devas (also called \"suras\") and Asuras are half-brothers, sons of the same father Kashyapa; although some of the Devas, such as Varuna, are also called Asuras. Later, during Puranic age, Asura and Rakshasa came to exclusively mean any of a race of anthropomorphic, powerful, possibly evil beings. Daitya (lit. sons of the mother \"Diti\"), Maya Danava, Rakshasa (lit. from \"harm to be guarded against\"), and Asura are incorrectly translated into English as \"demon\".\nIn post-Vedic Hindu scriptures, pious, highly enlightened Asuras, such as Prahlada and Vibhishana, are not uncommon. The Asura are not fundamentally against the gods, nor do they tempt humans to fall. Many people metaphorically interpret the Asura as manifestations of the ignoble passions in the human mind and as symbolic devices. There were also cases of power-hungry Asuras challenging various aspects of the gods, but only to be defeated eventually and seek forgiveness.\nEvil spirits.\nHinduism advocates the reincarnation and transmigration of souls according to one's karma. Souls (Atman) of the dead are adjudged by the Yama and are accorded various purging punishments before being reborn. Humans that have committed extraordinary wrongs are condemned to roam as lonely, often mischief mongers, spirits for a length of time before being reborn. Many kinds of such spirits (Vetalas, Pishachas, Bh\u016bta) are recognized in the later Hindu texts.\nIranian demons.\nZoroastrianism.\nEvil spirits are the creation of the evil principle Ahriman in Zoroastrian cosmology, commonly referred to as Daeva. The first six archdemons are produced by Ahriman in direct opposition to the holy immortals created by Ahura Mazda the principle of good. This six archdemons (or seven if Ahriman is included) give existence to uncountable malevolent daeva; the Zorastrian demons. They are the embodiment of evil, causing moral imperfection, destroy, kill and torment the wicked souls in the afterlife. Some demons are related to specific vices. Humans in the state of such sin might be possessed by a corresponding demon:\nManichaeism.\nIn Manichaean mythology demons had a real existence, as they derived from the Kingdom of Darkness, they were not metaphors expressing the absence of good nor are they fallen angels, that means they are not originally good, but entities purely evil. The demons came into the world after the Prince of Darkness assaulted the Realm of Light. The demons ultimately failed their attack and ended up imprisoned in the structures and matter of the contemporary world. Lacking virtues and being in constant conflict with both the divine creatures and themselves, they are inferior to the divine entities and overcome by the divine beings at the end of time. They are not sophisticated or inventive creatures, but only driven by their urges.\nSimultaneously, the Manichaean concept of demons remains abstract and is closely linked to ethical aspects of evil that many of them appear as personified evil qualities such as:\nThe Watcher, another group of demonic entities, known from the Enochian writings, appear in the canonical Book of Giants. The Watchers came into existence after the demons were chained up in the sky by Living Spirit. Later, outwitted by Third Messenger, they fall to earth, there they had intercourse with human women and beget the monstrous Nephilim. Thereupon they establish a tyrannical rule on earth, suppressing mankind, until they are defeated by the angels of punishment, setting an end to their rule.\nNative North American demons.\nWendigo.\nThe Algonquian people traditionally believe in a spirit called a wendigo. The spirit is believed to possess people who then become cannibals. In Athabaskan folklore, there is a belief in wechuge, a similar cannibal sprit. \nWicca.\nAccording to Rosemary Ellen Guiley, \"Demons are not courted or worshipped in contemporary Wicca and Paganism. The existence of negative energies is acknowledged.\"\nModern interpretations.\nPsychologist Wilhelm Wundt remarked that \"among the activities attributed by myths all over the world to demons, the harmful predominate, so that in popular belief bad demons are clearly older than good ones.\" Sigmund Freud developed this idea and claimed that the concept of demons was derived from the important relation of the living to the dead: \"The fact that demons are always regarded as the spirits of those who have died \"recently\" shows better than anything the influence of mourning on the origin of the belief in demons.\"\nM. Scott Peck, an American psychiatrist, wrote two books on the subject, \"People of the Lie: The Hope For Healing Human Evil\" and \"Glimpses of the Devil: A Psychiatrist's Personal Accounts of Possession, Exorcism, and Redemption\". Peck describes in some detail several cases involving his patients. In \"People of the Lie\" he provides identifying characteristics of an evil person, whom he classified as having a character disorder. In \"Glimpses of the Devil\" Peck goes into significant detail describing how he became interested in exorcism in order to debunk the \"myth\" of possession by evil spirits \u2013 only to be convinced otherwise after encountering two cases which did not fit into any category known to psychology or psychiatry. Peck came to the conclusion that possession was a rare phenomenon related to evil and that possessed people are not actually evil; rather, they are doing battle with the forces of evil.\nAlthough Peck's earlier work was met with widespread popular acceptance, his work on the topics of evil and possession has generated significant debate and derision. Much was made of his association with (and admiration for) the controversial Malachi Martin, a Roman Catholic priest and a former Jesuit, despite the fact that Peck consistently called Martin a liar and a manipulator. Richard Woods, a Roman Catholic priest and theologian, has claimed that Dr. Peck misdiagnosed patients based upon a lack of knowledge regarding dissociative identity disorder (formerly known as multiple personality disorder) and had apparently transgressed the boundaries of professional ethics by attempting to persuade his patients into accepting Christianity. Father Woods admitted that he has never witnessed a genuine case of demonic possession in all his years.\nAccording to S. N. Chiu, God is shown sending a demon against Saul in 1 Samuel 16 and 18 in order to punish him for the failure to follow God's instructions, showing God as having the power to use demons for his own purposes, putting the demon under his divine authority. According to the \"Britannica Concise Encyclopedia\", demons, despite being typically associated with evil, are often shown to be under divine control, and not acting of their own devices."}
{"id": "8282", "revid": "28438", "url": "https://en.wikipedia.org/wiki?curid=8282", "title": "Dmitry Ivanovich Mendeleev", "text": ""}
{"id": "8285", "revid": "991806087", "url": "https://en.wikipedia.org/wiki?curid=8285", "title": "Dense", "text": ""}
{"id": "8286", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=8286", "title": "Domino effect", "text": "A domino effect or chain reaction is the cumulative effect produced when one event sets off a chain of similar events. The term is best known as a mechanical effect and is used as an analogy to a falling row of dominoes. It typically refers to a linked sequence of events where the time between successive events is relatively small. It can be used literally (an observed series of actual collisions) or metaphorically (causal linkages within systems such as global finance or politics). The term \"domino effect\" is used both to imply that an event is inevitable or highly likely (as it has already started to happen), and conversely to imply that an event is impossible or highly unlikely (the one domino left standing).\nDemonstration of the effect.\nThe domino effect can easily be visualized by placing a row of dominoes upright, each separated by a small distance. Upon pushing the first domino, the next domino in line will be knocked over, and so on, thus firing a linear chain in which each domino's fall is triggered by the domino immediately preceding it. The effect is the same regardless of the length of the chain. The energy used in this chain reaction is the potential energy of the dominoes due to them being in a meta-stable state; when the first domino is toppled, the energy transferred by the fall is greater than the energy needed to knock over the following domino, and so on.\nThe domino effect is exploited in Rube Goldberg machines.\nSee also.\nRelevant physical theory:\nMathematical theory\nPolitical theory\nSocial"}
{"id": "8288", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=8288", "title": "Dinosaurs", "text": ""}
{"id": "8291", "revid": "39899811", "url": "https://en.wikipedia.org/wiki?curid=8291", "title": "Dinosauria", "text": ""}
{"id": "8292", "revid": "16847332", "url": "https://en.wikipedia.org/wiki?curid=8292", "title": "Delphi programming language", "text": ""}
{"id": "8293", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=8293", "title": "Diffusion pump", "text": "Diffusion pumps use a high speed jet of vapor to direct gas molecules in the pump throat down into the bottom of the pump and out the exhaust. They were the first type of high vacuum pumps operating in the regime of free molecular flow, where the movement of the gas molecules can be better understood as diffusion than by conventional fluid dynamics. Invented in 1915 by Wolfgang Gaede, he named it a \"diffusion pump\" since his design was based on the finding that gas cannot diffuse against the vapor stream, but will be carried with it to the exhaust. However, the principle of operation might be more precisely described as gas-jet pump, since diffusion plays a role also in other high vacuum pumps. In modern textbooks, the diffusion pump is categorized as a momentum transfer pump.\nThe diffusion pump is widely used in both industrial and research applications. Most modern diffusion pumps use silicone oil or polyphenyl ethers as the working fluid.\nHistory.\nIn the late 19th century, most vacuums were creating using a Sprengel pump, which had the advantage of being very simple to operate, and capable of achieving quite good vacuum given enough time. Compared to later pumps, however, the pumping speed was very slow and the vapor pressure of the mercury limited the ultimate vacuum.\nFollowing his invention of the molecular pump, the diffusion pump was invented in 1915 by Wolfgang Gaede, and originally used elemental mercury as the working fluid. After its invention, the design was quickly commercialized by Leybold.\nIt was then improved by Irving Langmuir and W. Crawford. Cecil Reginald Burch discovered the possibility of using silicone oil in 1928.\nOil diffusion pumps.\nAn oil diffusion pump is used to achieve higher vacuum (lower pressure) than is possible by use of positive displacement pumps alone. Although its use has been mainly associated within the high-vacuum range (down to 10\u22129 mbar), diffusion pumps today can produce pressures approaching 10\u221210 mbar when properly used with modern fluids and accessories. The features that make the diffusion pump attractive for high and ultra-high vacuum use are its high pumping speed for all gases and low cost per unit pumping speed when compared with other types of pump used in the same vacuum range. Diffusion pumps cannot discharge directly into the atmosphere, so a mechanical forepump is typically used to maintain an outlet pressure around 0.1 mbar.\nThe oil diffusion pump is operated with an oil of low vapor pressure. The high speed jet is generated by boiling the fluid and directing the vapor through a jet assembly. Note that the oil is gaseous when entering the nozzles. Within the nozzles, the flow changes from laminar to supersonic and molecular. Often, several jets are used in series to enhance the pumping action. The outside of the diffusion pump is cooled using either air flow, water lines or a water-filled jacket. As the vapor jet hits the outer cooled shell of the diffusion pump, the working fluid condenses and is recovered and directed back to the boiler. The pumped gases continue flowing to the base of the pump at increased pressure, flowing out through the diffusion pump outlet, where they are compressed to ambient pressure by the secondary mechanical forepump and exhausted.\nUnlike turbomolecular pumps and cryopumps, diffusion pumps have no moving parts and as a result are quite durable and reliable. They can function over pressure ranges of 10\u221210 to 10\u22122 mbar. They are driven only by convection and thus have a very low energy efficiency.\nOne major disadvantage of diffusion pumps is the tendency to backstream oil into the vacuum chamber. This oil can contaminate surfaces inside the chamber or upon contact with hot filaments or electrical discharges may result in carbonaceous or siliceous deposits. Due to backstreaming, oil diffusion pumps are not suitable for use with highly sensitive analytical equipment or other applications which require an extremely clean vacuum environment, but mercury diffusion pumps may be in the case of ultra high vacuum chambers used for metal deposition. Often cold traps and baffles are used to minimize backstreaming, although this results in some loss of pumping speed.\nThe oil of a diffusion pump cannot be exposed to the atmosphere when hot. If this occurs, the oil will oxidise and has to be replaced, if a fire occurs the smoke and residue may contaminate other parts of the system.\nOil types.\nThe least expensive diffusion pump oils are based on hydrocarbons which have been purified by double-distillation. Compared with the other fluids, they have higher vapor pressure, so are usually limited to a pressure of 1 x 10\u22126 Torr. They are also the most likely to burn or explode if exposed to oxidizers.\nThe most common silicone oils used in diffusion pumps are trisiloxanes, which contain the chemical group Si-O-Si-O-Si, to which various phenyl groups or methyl groups are attached. These are available as the so called 702 and 703 blends, which were formerly manufactured by Dow Corning. These can be further separated into 704 and 705 oils, which are made up of the isomers of tetraphenyl tetramethyl trisiloxane and pentaphenyl trimethyl trisiloxane respectively.\nFor pumping reactive species, usually a polyphenyl ether based oil is used. These oils are the most chemical and heat resistant type of diffusion pump oil.\nSteam ejectors.\n \nThe steam ejector is a popular form of pump for vacuum distillation and freeze-drying. A jet of steam entrains the vapour that must be removed from the vacuum chamber. Steam ejectors can have single or multiple stages, with and without condensers in between the stages. While both steam ejectors and diffusion pumps use jets of vapor to entrain gas, they work on fundamentally different principles - steam ejectors rely on viscous flow and mixing to pump gas, whereas diffusion pumps use molecular diffusion. This has several consequences. In diffusion pumps, the inlet pressure can be much lower than the static pressure of jet, whereas in steam ejectors the two pressures are about the same. Also, diffusion pumps are capable of much higher compression ratios, and cannot discharge directly to atmosphere."}
{"id": "8295", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=8295", "title": "Declarative memory", "text": ""}
{"id": "8298", "revid": "19382112", "url": "https://en.wikipedia.org/wiki?curid=8298", "title": "Descartes", "text": ""}
{"id": "8299", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=8299", "title": "Domenico Alberti", "text": "Domenico Alberti (c. 1710\u00a0\u2013 14 October 1740 or 1746) was an Italian singer, harpsichordist, and composer.\nAlberti was born in Venice and studied music with Antonio Lotti. He wrote operas, songs, and sonatas for keyboard instruments, for which he is best known today. These sonatas frequently employ arpeggiated accompaniment in the left hand in one of several patterns that are now collectively known as \"Alberti bass\". Alberti was one of the earliest composers to use these patterns, but was not the first or only. The most well-known of these patterns consists of regular broken chords, with the lowest note sounding first, then the highest, then the middle and then the highest again. This pattern is repeated. Today, Alberti is regarded as a minor composer, and his works are played or recorded only irregularly. The Alberti bass was used by many later composers, and it became an important element in much keyboard music of the Classical music era.\nAn example of Alberti bass (Mozart's \"Piano Sonata, K 545\"):\nIn his own lifetime, Alberti was known as a singer. He often used to accompany himself on the harpsichord. In 1736, he served as a page for Pietro Andrea Cappello, the Venetian ambassador to Spain. While at the Spanish court, the famous castrato singer Farinelli heard him sing. Farinelli was said to have been impressed, although Alberti was an amateur.\nAlberti's best known pieces are his keyboard sonatas, although even they are very rarely performed. It is thought he wrote around 36 sonatas, of which 14 have survived. They all have two movements, each in binary form.\nIt is probable that Mozart's first violin sonatas, written at the age of seven, were modeled on Alberti's work.\nAlberti died in 1740 or 1746 in Rome."}
{"id": "8300", "revid": "14703151", "url": "https://en.wikipedia.org/wiki?curid=8300", "title": "Doris Day", "text": "Doris Day (born Doris Mary Anne Kappelhoff; April 3, 1922\u00a0\u2013 May 13, 2019) was an American actress, singer, and animal welfare activist. She began her career as a big band singer in 1939, achieving commercial success in 1945 with two No. 1 recordings, \"Sentimental Journey\" and \"My Dreams Are Getting Better All the Time\" with Les Brown &amp; His Band of Renown. She left Brown to embark on a solo career and recorded more than 650 songs from 1947 to 1967.\nDay was one of the biggest film stars in the 1950s\u20131960s era. Day's film career began during the Golden Age of Hollywood with the film \"Romance on the High Seas\" (1948). She starred in films of many genres, including musicals, comedies, dramas, and thrillers. She played the title role in \"Calamity Jane\" (1953) and starred in Alfred Hitchcock's \"The Man Who Knew Too Much\" (1956) with James Stewart. Her best-known films are those in which she co-starred with Rock Hudson, chief among them 1959's \"Pillow Talk\", for which she was nominated for the Academy Award for Best Actress. She also worked with James Garner on both \"Move Over, Darling\" (1963) and \"The Thrill of It All\" (1963), and starred alongside Clark Gable, Cary Grant, James Cagney, David Niven, Ginger Rogers, Jack Lemmon, Frank Sinatra, Kirk Douglas, Lauren Bacall, and Rod Taylor in various movies. After ending her film career in 1968, only briefly removed from the height of her popularity, she starred in her own sitcom \"The Doris Day Show\" (1968\u20131973).\nIn 1989, she was awarded the Golden Globe Cecil B. DeMille Award for lifetime achievement in motion pictures. In 2004, she was awarded the Presidential Medal of Freedom. In 2008, she received the Grammy Lifetime Achievement Award as well as a Legend Award from the Society of Singers. In 2011, she was awarded the Los Angeles Film Critics Association's Career Achievement Award. Also in 2011, she released her 29th studio album \"My Heart\" which contained new material and became a UK Top 10 album. As of 2020, she was one of eight record performers to have been the top box-office earner in the United States four times.\nEarly life.\nDay was born Doris Mary Anne Kappelhoff on April 3, 1922 in Cincinnati, Ohio, the daughter of Alma Sophia (\"n\u00e9e\" Welz; 1895\u20131976) and William Joseph Kappelhoff (1892\u20131967). Her mother was a homemaker, and her father was a music teacher and choirmaster. Doris was named after actress Doris Kenyon. Her maternal and paternal grandparents were German; her paternal grandfather Franz Joseph Wilhelm Kappelhoff immigrated to the United States in 1875 and settled in Cincinnati which had a large German community with its own churches, clubs, and German-language newspapers. For most of her life, Day stated she was born in 1924; it was not until her 95th birthday\u00a0\u2013 when the Associated Press found her birth certificate, showing a 1922 date of birth\u00a0\u2013 that she stated otherwise. It was common among actresses in Hollywood to state an age younger than they actually were in reality because youth was everything when it came to casting.\nThe youngest of three siblings, she had two older brothers: Richard (who died before her birth) and Paul, two to three years older. Due to her father's alleged infidelity, her parents separated. She developed an early interest in dance, and in the mid-1930s formed a dance duo with Jerry Doherty that performed locally in Cincinnati. A car accident on October 13, 1937 injured her right leg and curtailed her prospects as a professional dancer.\nCareer.\nEarly career (1938\u20131947).\nWhile recovering from her car accident, Kappelhoff started to sing along with the radio and discovered a talent she did not know she had. \"During this long, boring period, I used to while away a lot of time listening to the radio, sometimes singing along with the likes of Benny Goodman, Duke Ellington, Tommy Dorsey, and Glenn Miller\", she told A. E. Hotchner, one of Day's biographers. \"But the one radio voice I listened to above others belonged to Ella Fitzgerald. There was a quality to her voice that fascinated me, and I'd sing along with her, trying to catch the subtle ways she shaded her voice, the casual yet clean way she sang the words.\"\nObserving her daughter sing rekindled Alma's interest in show business, and she decided Doris must have singing lessons. She engaged a teacher, Grace Raine. After three lessons, Raine told Alma that young Doris had \"tremendous potential\"; Raine was so impressed that she gave Doris three lessons a week for the price of one. Years later, Day said that Raine had the biggest effect on her singing style and career.\nDuring the eight months she was taking singing lessons, Kappelhoff had her first professional jobs as a vocalist, on the WLW radio program \"Carlin's Carnival\", and in a local restaurant, Charlie Yee's Shanghai Inn. During her radio performances, she first caught the attention of Barney Rapp, who was looking for a female vocalist and asked if she would like to audition for the job. According to Rapp, he had auditioned about 200 singers when Kappelhoff got the job.\nWhile working for Rapp in 1939, she adopted the stage surname \"Day\", at Rapp's suggestion. Rapp felt that \"Kappelhoff\" was too long for marquees, and he admired her rendition of the song \"Day After Day\". After working with Rapp, Day worked with bandleaders Jimmy James, Bob Crosby, and Les Brown. In 1941, Day appeared as a singer in three Soundies with the Les Brown band.\nWhile working with Brown, Day recorded her first hit recording, \"Sentimental Journey\", released in early 1945. It soon became an anthem of the desire of World War II demobilizing troops to return home. The song continues to be associated with Day, and she re-recorded it on several occasions, including a version in her 1971 television special. During 1945\u201346, Day (as vocalist with the Les Brown Band) had six other top ten hits on the \"Billboard\" chart: \"My Dreams Are Getting Better All the Time\", Tain't Me\", \"Till The End of Time\", \"You Won't Be Satisfied (Until You Break My Heart)\", \"The Whole World is Singing My Song\", and \"I Got the Sun in the Mornin. Les Brown said, \"As a singer Doris belongs in the company of Bing Crosby and Frank Sinatra.\" (Aljean Harmetz (2019). \"Wholesome Box-Office Star and Golden Voice of 'Que Sera, Sera' \". \"The New York Times.\" p.\u00a01 )\nEarly film career (1948\u20131954).\nWhile singing with the Les Brown band and for nearly two years on Bob Hope's weekly radio program, she toured extensively across the United States.\nHer performance of the song \"Embraceable You\" impressed songwriter Jule Styne and his partner, Sammy Cahn, and they recommended her for a role in \"Romance on the High Seas\" (1948). Day was cast for the role after auditioning for director Michael Curtiz. She was shocked at being offered the role in the film, and admitted to Curtiz that she was a singer without acting experience. But he said he liked that \"she was honest\", not afraid to admit it, and he wanted someone who \"looked like the All-American Girl\". Day was the discovery of which Curtiz was proudest during his career.\nThe film provided her with a hit recording as a soloist, \"It's Magic\", which followed by two months her first hit (\"Love Somebody\" in 1948) recorded as a duet with Buddy Clark. Day recorded \"Someone Like You\", before the film \"My Dream Is Yours\" (1949), which featured the song. In 1950, U.S. servicemen in Korea voted her their favorite star.\nShe continued to make minor and frequently nostalgic period musicals such as \"On Moonlight Bay\" (1951), \"By the Light of the Silvery Moon\" (1953), and \"Tea For Two\" (1950) for Warner Brothers.\nHer most commercially successful film for Warner was \"I'll See You in My Dreams\" (1951), which broke box-office records of 20 years. The film is a musical biography of lyricist Gus Kahn. It was Day's fourth film directed by Curtiz. Day appeared as the title character in the comedic western-themed musical, \"Calamity Jane\" (1953). A song from the film, \"Secret Love\", won the Academy Award for Best Original Song and became Day's fourth No. 1 hit single in the United States.\nBetween 1950 and 1953, the albums from six of her movie musicals charted in the Top 10, three of them at No. 1. After filming \"Lucky Me\" (1954) with Bob Cummings and \"Young at Heart\" (1955) with Frank Sinatra, Day chose not to renew her contract with Warner Brothers.\nDuring this period, Day also had her own radio program, \"The Doris Day Show\". It was broadcast on CBS in 1952\u20131953.\nBreakthrough (1955\u20131958).\nHaving become primarily recognized as a musical-comedy actress, Day gradually took on more dramatic roles to broaden her range. Her dramatic star turn as singer Ruth Etting in \"Love Me or Leave Me\" (1955), with top billing above James Cagney, received critical and commercial success, becoming Day's biggest hit thus far. Cagney said she had \"the ability to project the simple, direct statement of a simple, direct idea without cluttering it\", comparing her to Laurette Taylor's Broadway performance in \"The Glass Menagerie\" (1945), one of the greatest performances by an American actor. Day said it was her best film performance. Producer Joe Pasternak said, \"I was stunned that Doris did not get an Oscar nomination.\" The soundtrack album from that movie was a No. 1 hit.\nDay starred in Alfred Hitchcock's suspense film \"The Man Who Knew Too Much\" (1956) with James Stewart. She sang two songs in the film, \"Que Sera, Sera (Whatever Will Be, Will Be)\" which won an Academy Award for Best Original Song, and \"We'll Love Again\". The film was Day's 10th movie to be in the Top 10 at the box office. Day played the title role in the thriller/noir \"Julie\" (also 1956) with Louis Jourdan.\nAfter three successive dramatic films, Day returned to her musical/comedic roots in \"The Pajama Game\" (1957) with John Raitt. The film was based on the Broadway play of the same name. She worked with Paramount Pictures for the comedy \"Teacher's Pet\" (1958), alongside Clark Gable and Gig Young. She co-starred with Richard Widmark and Gig Young in the romantic comedy film \"The Tunnel of Love\" (also 1958), but found scant success opposite Jack Lemmon in \"It Happened to Jane\" (1959).\n\"Billboard\" annual nationwide poll of disc jockeys had ranked Day as the No. 1 female vocalist nine times in ten years (1949 through 1958), but her success and popularity as a singer was now being overshadowed by her box-office appeal.\nBox-office success (1959\u20131968).\nIn 1959, Day entered her most successful phase as a film actress with a series of romantic comedies. This success began with \"Pillow Talk\" (1959), co-starring Rock Hudson who became a lifelong friend, and Tony Randall. Day received a nomination for an Academy Award for Best Actress. It was the only Oscar nomination she received in her career. Day, Hudson, and Randall made two more films together, \"Lover Come Back\" (1961) and \"Send Me No Flowers\" (1964).\nAlong with David Niven and Janis Paige, Day starred in \"Please Don't Eat the Daisies\" (1960) and with Cary Grant in the comedy \"That Touch of Mink\" (1962). During 1960 and the 1962 to 1964 period, she ranked number one at the box office, the second woman to be number one four times, an accomplishment equalled by no other actress except Shirley Temple. She set a record that has yet to be equaled, receiving seven consecutive Laurel Awards as the top female box office star.\nDay teamed up with James Garner starting with \"The Thrill of It All\", followed by \"Move Over, Darling\" (both 1963). The film's theme song, \"Move Over Darling\", co-written by her son, reached in the UK. In between these comedic roles, Day co-starred with Rex Harrison in the movie thriller \"Midnight Lace\" (1960), an updating of the stage thriller \"Gaslight\".\nBy the late 1960s, the sexual revolution of the baby boomer generation had refocused public attitudes about sex. Times changed, but Day's films did not. Day's next film \"Do Not Disturb\" (1965) was popular with audiences, but her popularity soon waned. Critics and comics dubbed Day \"The World's Oldest Virgin\", and audiences began to shy away from her films. As a result, she slipped from the list of top box-office stars, last appearing in the top ten with the hit film \"The Glass Bottom Boat\" (1966). One of the roles she turned down was that of Mrs. Robinson in \"The Graduate\", a role that eventually went to Anne Bancroft. In her published memoirs, Day said she had rejected the part on moral grounds: she found the script \"vulgar and offensive\".\nShe starred in the western film \"The Ballad of Josie\" (1967). That same year, Day recorded \"The Love Album\", although it was not released until 1994. The following year (1968), she starred in the comedy film \"Where Were You When the Lights Went Out?\" which centers on the Northeast blackout of November 9, 1965. Her final feature, the comedy \"With Six You Get Eggroll\", was released in 1968.\nFrom 1959 to 1970, Day received nine Laurel Award nominations (and won four times) for best female performance in eight comedies and one drama. From 1959 through 1969, she received six Golden Globe nominations for best female performance in three comedies, one drama (\"Midnight Lace\"), one musical (\"Jumbo\"), and her television series.\nBankruptcy and television career.\nAfter her third husband Martin Melcher died on April 20, 1968, a shocked Day discovered that Melcher and his business partner and \"adviser\" Jerome Bernard Rosenthal had squandered her earnings, leaving her deeply in debt. Rosenthal had been her attorney since 1949, when he represented her in her uncontested divorce action against her second husband, saxophonist George W. Weidler. Day filed suit against Rosenthal in February 1969, won a successful decision in 1974, but did not receive compensation until a settlement in 1979.\nDay also learned to her displeasure that Melcher had committed her to a television series, which became \"The Doris Day Show\".\nDay hated the idea of performing on television, but felt obligated to do it. The first episode of \"The Doris Day Show\" aired on September 24, 1968, and, from 1968 to 1973, employed \"Que Sera, Sera\" as its theme song. Day persevered (she needed the work to help pay off her debts), but only after CBS ceded creative control to her and her son. The successful show enjoyed a five-year run, and functioned as a curtain raiser for the \"Carol Burnett Show\". It is remembered today for its abrupt season-to-season changes in casting and premise.\nBy the end of its run in 1973, public tastes had changed, as had those of the television industry, and her firmly established persona was regarded as pass\u00e9. She largely retired from acting after \"The Doris Day Show\", but did complete two television specials, \"The Doris Mary Anne Kappelhoff Special\" (1971) and \"Doris Day Today\" (1975), and was a guest on various shows in the 1970s.\nIn the 1985\u201386 season, Day hosted her own television talk show, \"Doris Day's Best Friends\", on the Christian Broadcasting Network (CBN). The network canceled the show after 26 episodes, despite the worldwide publicity it received. Much of that attention came from the episode featuring Rock Hudson, in which Hudson was showing the first public symptoms of AIDS including severe weight loss and admitted fatigue; Hudson would die from the disease a year later. Day later said, \"He was very sick. But I just brushed that off and I came out and put my arms around him and said, 'Am I glad to see you'.\"\n1980s and 1990s.\nDay's husband and agent, Martin Melcher, had Beverly Hills lawyer Jerome Rosenthal handle his wife's money since the 1940s. \"During that period, Rosenthal committed breaches of professional ethics that are difficult to exaggerate\", as one court put it.\nIn October 1985, the California Supreme Court rejected Rosenthal's appeal of the multimillion-dollar judgment against him for legal malpractice, and upheld conclusions of a trial court and a Court of Appeal that Rosenthal acted improperly. In April 1986, the U.S. Supreme Court refused to review the lower court's judgment. In June 1987, Rosenthal filed a $30\u00a0million lawsuit against lawyers he claimed cheated him out of millions of dollars in real estate investments. He named Day as a co-defendant, describing her as an \"unwilling, involuntary plaintiff whose consent cannot be obtained\". Rosenthal claimed that millions of dollars Day lost were in real estate sold after Melcher died in 1968, in which Rosenthal asserted that the attorneys gave Day bad advice, telling her to sell, at a loss, three hotels, in Palo Alto, California, Dallas, Texas, and Atlanta, Georgia, plus some oil leases in Kentucky and Ohio. He claimed he had made the investments under a long-term plan, and did not intend to sell them until they appreciated in value. Two of the hotels sold in 1970 for about $7\u00a0million, and their estimated worth in 1986 was $50\u00a0million.\nTerry Melcher stated that his adoptive father's premature death saved Day from financial ruin. It remains unresolved whether Martin Melcher had himself also been duped. Day stated publicly that she believed her husband innocent of any deliberate wrongdoing, stating that he \"simply trusted the wrong person\". According to Day's autobiography, as told to A. E. Hotchner, the usually athletic and healthy Martin Melcher had an enlarged heart. Most of the interviews on the subject given to Hotchner (and included in Day's autobiography) paint an unflattering portrait of Melcher. Author David Kaufman asserts that one of Day's costars, actor Louis Jourdan, maintained that Day herself disliked her husband, but Day's public statements regarding Melcher appear to contradict that assertion.\nDay was scheduled to present, along with Patrick Swayze and Marvin Hamlisch, the Best Original Score Oscar at the 61st Academy Awards in March 1989 but she suffered a deep leg cut and was unable to attend. She had been walking through the gardens of her hotel when she cut her leg on a sprinkler. The cut required stitches.\nDay was inducted into the Ohio Women's Hall of Fame in 1981 and received the Cecil B. DeMille Award for career achievement in 1989. In 1994, Day's \"Greatest Hits\" album became another entry into the British charts. Her cover of \"Perhaps, Perhaps, Perhaps\" was included in the soundtrack of the Australian film \"Strictly Ballroom.\"\n2000s.\nDay participated in interviews and celebrations of her birthday with an annual Doris Day music marathon. In July 2008, she appeared on the Southern California radio show of longtime friend and newscaster George Putnam.\nDay turned down a tribute offer from the American Film Institute and from the Kennedy Center Honors because they require attendance in person. In 2004, she was awarded the Presidential Medal of Freedom by President George W. Bush for her achievements in the entertainment industry and for her work on behalf of animals. President Bush stated:\nColumnist Liz Smith and film critic Rex Reed mounted vigorous campaigns to gather support for an Honorary Academy Award for Day to herald her film career and her status as the top female box-office star of all time. According to \"The Hollywood Reporter\" in 2015, the Academy offered her the Honorary Oscar multiple times, but she declined as she saw the film industry as a part of her past life. Day received a Grammy for Lifetime Achievement in Music in 2008, albeit again in absentia.\nShe received three Grammy Hall of Fame Awards, in 1998, 1999 and 2012, for her recordings of \"Sentimental Journey\", \"Secret Love\", and \"Que Sera, Sera\", respectively. Day was inducted into the Hit Parade Hall of Fame in 2007, and in 2010 received the first Legend Award ever presented by the Society of Singers.\n2010s.\nDay, aged 89, released \"My Heart\" in the United Kingdom on September 5, 2011, her first new album in nearly two decades since the release of \"The Love Album\", which, although recorded in 1967, was not released until 1994. The album is a compilation of previously unreleased recordings produced by Day's son, Terry Melcher, before his death in 2004. Tracks include the 1970s Joe Cocker hit \"You Are So Beautiful\", the Beach Boys' \"Disney Girls\" and jazz standards such as \"My Buddy\", which Day originally sang in the film \"I'll See You in My Dreams\" (1951).\nAfter the disc was released in the United States it soon climbed to No. 12 on Amazon's bestseller list, and helped raise funds for the Doris Day Animal League. Day became the oldest artist to score a UK Top 10 with an album featuring new material.\nIn January 2012, the Los Angeles Film Critics Association presented Day with a Lifetime Achievement Award.\nIn April 2014, Day made an unexpected public appearance to attend the annual Doris Day Animal Foundation benefit. The benefit raises money for her Animal Foundation.\nClint Eastwood offered Day a role in a film he was planning to direct in 2015. Although she reportedly was in talks with Eastwood, her neighbor in Carmel, about a role in the film, she eventually declined.\nDay granted ABC a telephone interview on her birthday in 2016, which was accompanied by photos of her life and career.\nIn a rare interview with \"The Hollywood Reporter\" on April 4, 2019, the day after her 97th birthday, Day talked about her work on the Doris Day Animal Foundation, founded in 1978. On the question of what her favorite film was, she answered \"Calamity Jane\": \"I was such a tomboy growing up, and she was such a fun character to play. Of course, the music was wonderful, too\u2014'Secret Love,' especially, is such a beautiful song.\"\nTo commemorate her birthday, her fans gathered each year to take part in a three-day party in her hometown of Carmel, California, in late March. The event was also a fundraiser for her Animal Foundation. During the 2019 event, there was a special screening of her film \"Pillow Talk\" (1959) to celebrate its 60th anniversary. About the film, Day stated in the same interview that she \"had such fun working with my pal, Rock. We laughed our way through three films we made together and remained great friends. I miss him.\"\nAnimal welfare activism.\nDay's interest in animal welfare and related issues apparently dated to her teen years. While recovering from an automobile accident, she took her dog Tiny for a walk without a leash. Tiny ran into the street and was killed by a passing car. Day later expressed guilt and loneliness about Tiny's untimely death. In 1971, she co-founded Actors and Others for Animals, and appeared in a series of newspaper advertisements denouncing the wearing of fur, alongside Mary Tyler Moore, Angie Dickinson, and Jayne Meadows.\nIn 1978, Day founded the Doris Day Pet Foundation, now the Doris Day Animal Foundation (DDAF). A non-profit 501(c)(3) grant-giving public charity, DDAF funds other non-profit causes throughout the US that share DDAF's mission of helping animals and the people who love them. The DDAF continues to operate independently.\nTo complement the Doris Day Animal Foundation, Day formed the Doris Day Animal League (DDAL) in 1987, a national non-profit citizens' lobbying organization whose mission is to reduce pain and suffering, and protect animals through legislative initiatives. Day actively lobbied the United States Congress in support of legislation designed to safeguard animal welfare on a number of occasions, and in 1995 she originated the annual Spay Day USA. The DDAL merged into The Humane Society of the United States (HSUS) in 2006. The HSUS now manages World Spay Day, the annual one-day spay/neuter event that Day originated.\nA facility bearing her name, the Doris Day Horse Rescue and Adoption Center, which helps abused and neglected horses, opened in 2011 in Murchison, Texas, on the grounds of an animal sanctuary started by her late friend, author Cleveland Amory. Day contributed $250,000 toward the founding of the center.\nA posthumous auction of 1,100 of Day's possessions in April 2020 generated $3 million for the Doris Day Animal Foundation.\nPersonal life.\nAfter her retirement from films, Day lived in Carmel-by-the-Sea, California. She had many pets and adopted stray animals. She was a lifelong Republican. Her only child was music producer and songwriter Terry Melcher, who had a hit in the 1960s with \"Hey Little Cobra\" under the name The Rip Chords. before becoming a successful producer whose acts included The Byrds, Paul Revere &amp; the Raiders, and---in the late 1980s---The Beach Boys; he died of melanoma in November 2004. Since the 1980s Day owned a hotel in Carmel-by-the-Sea called the Cypress Inn which she originally co-owned with her son. It was an early pet\u2013friendly hotel and was featured in \"Architectural Digest\" in 1999.\nMarriages.\nDay was married four times. From March 1941 to February 1943, she was married to trombonist Al Jorden (1917\u20131967), whom she met in Barney Rapp's Band. Jorden was a violent schizophrenic who later took his own life. When Day became pregnant and refused to have an abortion, he beat her in an attempt to force a miscarriage. Their son, Terrence \"Terry\" Paul Jorden, was born in 1942, and changed his name to Terrence Paul Melcher when he was adopted by Day's third husband.\nHer second marriage was to George William Weidler (1926\u20131989) from March 30, 1946, to May 31, 1949, a saxophonist and the brother of actress Virginia Weidler. Weidler and Day met again several years later during a brief reconciliation, and he introduced her to Christian Science.\nDay married American film producer Martin Melcher (1915\u20131968) on April 3, 1951, her 29th birthday, and this marriage lasted until he died in April 1968. Melcher adopted Day's son Terry, who became a successful musician and record producer under the name Terry Melcher. Martin Melcher produced many of Day's movies. They were both Christian Scientists, resulting in her not seeing a doctor for some time for symptoms which suggested cancer.\nDay's fourth marriage was to Barry Comden (1935\u20132009) from April 14, 1976, until April 2, 1982. He was the \"ma\u00eetre d'h\u00f4tel\" at one of Day's favorite restaurants. He knew of her great love of dogs and endeared himself to her by giving her a bag of meat scraps and bones on her way out of the restaurant. He later complained that she cared more for her \"animal friends\" than she did for him.\nDeath.\nDay died on May 13, 2019, at the age of 97, after having contracted pneumonia. Her death was announced by her charity, the Doris Day Animal Foundation. Per Day's requests, the Foundation announced that there would be no funeral services, grave marker, or other public memorials. She was cremated.\nDiscography.\nStudio albums.\n\"Source\""}
{"id": "8301", "revid": "1013075010", "url": "https://en.wikipedia.org/wiki?curid=8301", "title": "Distillation", "text": "Distillation, or classical distillation, is the process of separating the components or substances from a liquid mixture by using selective boiling and condensation. Dry distillation is the heating of solid materials to produce gaseous products (which may condense into liquids or solids). Dry distillation may involve chemical changes such as destructive distillation or cracking and is not discussed under this article. Distillation may result in essentially complete separation (nearly pure components), or it may be a partial separation that increases the concentration of selected components in the mixture. In either case, the process exploits differences in the relative volatility of the mixture's components. In industrial applications, distillation is a unit operation of practically universal importance, but it is a physical separation process, not a chemical reaction.\nDistillation has many applications. For example:\nAn installation used for distillation, especially of distilled beverages, is a distillery. The distillation equipment itself is a still.\nHistory.\nEarly evidence of distillation was found on Akkadian tablets dated c. 1200 BCE describing perfumery operations. The tablets provided textual evidence that an early primitive form of distillation was known to the Babylonians of ancient Mesopotamia. Early evidence of distillation was also found related to alchemists working in Alexandria in Roman Egypt in the 1st century CE. \nDistilled water has been in use since at least c. 200 CE, when Alexander of Aphrodisias described the process. Work on distilling other liquids continued in early Byzantine Egypt under Zosimus of Panopolis in the 3rd century. Distillation was practiced in the ancient Indian subcontinent, which is evident from baked clay retorts and receivers found at Taxila, Shaikhan Dheri, and Charsadda in modern Pakistan, dating to the early centuries of the Common Era. These \"Gandhara stills\" were only capable of producing very weak liquor, as there was no efficient means of collecting the vapors at low heat. \nDistillation in China may have begun during the Eastern Han dynasty (1st\u20132nd centuries CE), but the distillation of beverages began in the Jin (12th\u201313th centuries) and Southern Song (10th\u201313th centuries) dynasties, according to archaeological evidence.\nMedieval Muslim chemists such as J\u0101bir ibn \u1e24ayy\u0101n (Latin: Geber, ninth century) and Ab\u016b Bakr al-R\u0101z\u012b (Latin: Rhazes, 854\u2013925) experimented extensively with the distillation of various substances. The distillation of wine is attested in Arabic works attributed to al-Kind\u012b (c. 801\u2013873 CE) and to al-F\u0101r\u0101b\u012b (c. 872\u2013950), and in the 28th book of al-Zahr\u0101w\u012b's (Latin: Abulcasis, 936\u20131013) \"Kit\u0101b al-Ta\u1e63r\u012bf\" (later translated into Latin as \"Liber servatoris\"). In the twelfth century, recipes for the production of \"aqua ardens\" (\"burning water\", i.e., ethanol) by distilling wine with salt started to appear in a number of Latin works, and by the end of the thirteenth century it had become a widely known substance among Western European chemists. Fractional distillation was developed by Tadeo Alderotti in the 13th century.\nA still was found in an archaeological site in Qinglong, Hebei province, in China, dating back to the 12th century. Distilled beverages were common during the Yuan dynasty (13th\u201314th centuries).\nIn 1500, German alchemist Hieronymus Braunschweig published \"Liber de arte destillandi\" (\"The Book of the Art of Distillation\"), the first book solely dedicated to the subject of distillation, followed in 1512 by a much expanded version. In 1651, John French published \"The Art of Distillation\", the first major English compendium on the practice, but it has been claimed that much of it derives from Braunschweig's work. This includes diagrams with people in them showing the industrial rather than bench scale of the operation.\nAs alchemy evolved into the science of chemistry, vessels called retorts became used for distillations. Both alembics and retorts are forms of glassware with long necks pointing to the side at a downward angle to act as air-cooled condensers to condense the distillate and let it drip downward for collection. Later, copper alembics were invented. Riveted joints were often kept tight by using various mixtures, for instance a dough made of rye flour. These alembics often featured a cooling system around the beak, using cold water, for instance, which made the condensation of alcohol more efficient. These were called pot stills. Today, the retorts and pot stills have been largely supplanted by more efficient distillation methods in most industrial processes. However, the pot still is still widely used for the elaboration of some fine alcohols, such as cognac, Scotch whisky, Irish whiskey, tequila, rum, and some vodkas. Pot stills made of various materials (wood, clay, stainless steel) are also used by bootleggers in various countries. Small pot stills are also sold for use in the domestic production of flower water or essential oils.\nEarly forms of distillation involved batch processes using one vaporization and one condensation. Purity was improved by further distillation of the condensate. Greater volumes were processed by simply repeating the distillation. Chemists reportedly carried out as many as 500 to 600 distillations in order to obtain a pure compound.\nIn the early 19th century, the basics of modern techniques, including pre-heating and reflux, were developed. In 1822, Anthony Perrier developed one of the first continuous stills, and then, in 1826, Robert Stein improved that design to make his patent still. In 1830, Aeneas Coffey got a patent for improving the design even further. Coffey's continuous still may be regarded as the archetype of modern petrochemical units. The French engineer Armand Savalle developed his steam regulator around 1846. In 1877, Ernest Solvay was granted a U.S. Patent for a tray column for ammonia distillation, and the same and subsequent years saw developments in this theme for oils and spirits.\nWith the emergence of chemical engineering as a discipline at the end of the 19th century, scientific rather than empirical methods could be applied. The developing petroleum industry in the early 20th century provided the impetus for the development of accurate design methods, such as the McCabe\u2013Thiele method by Ernest Thiele and the Fenske equation. The first industrial plant in the United States to use distillation as a means of ocean desalination opened in Freeport, Texas in 1961 with the hope of bringing water security to the region.\nThe availability of powerful computers has allowed direct computer simulations of distillation columns.\nApplications of distillation.\nThe application of distillation can roughly be divided into four groups: laboratory scale, industrial distillation, distillation of herbs for perfumery and medicinals (herbal distillate), and food processing. The latter two are distinctively different from the former two in that distillation is not used as a true purification method but more to transfer all volatiles from the source materials to the distillate in the processing of beverages and herbs.\nThe main difference between laboratory scale distillation and industrial distillation are that laboratory scale distillation is often performed on a batch basis, whereas industrial distillation often occurs continuously. In batch distillation, the composition of the source material, the vapors of the distilling compounds, and the distillate change during the distillation. In batch distillation, a still is charged (supplied) with a batch of feed mixture, which is then separated into its component fractions, which are collected sequentially from most volatile to less volatile, with the bottoms \u2013 remaining least or non-volatile fraction \u2013 removed at the end. The still can then be recharged and the process repeated.\nIn continuous distillation, the source materials, vapors, and distillate are kept at a constant composition by carefully replenishing the source material and removing fractions from both vapor and liquid in the system. This results in a more detailed control of the separation process.\nIdealized distillation model.\nThe boiling point of a liquid is the temperature at which the vapor pressure of the liquid equals the pressure around the liquid, enabling bubbles to form without being crushed. A special case is the normal boiling point, where the vapor pressure of the liquid equals the ambient atmospheric pressure.\nIt is a misconception that in a liquid mixture at a given pressure, each component boils at the boiling point corresponding to the given pressure, allowing the vapors of each component to collect separately and purely. However, this does not occur, even in an idealized system. Idealized models of distillation are essentially governed by Raoult's law and Dalton's law and assume that vapor\u2013liquid equilibria are attained.\nRaoult's law states that the vapor pressure of a solution is dependent on 1) the vapor pressure of each chemical component in the solution and 2) the fraction of solution each component makes up, a.k.a. the mole fraction. This law applies to ideal solutions, or solutions that have different components but whose molecular interactions are the same as or very similar to pure solutions.\nDalton's law states that the total pressure is the sum of the partial pressures of each individual component in the mixture. When a multi-component liquid is heated, the vapor pressure of each component will rise, thus causing the total vapor pressure to rise. When the total vapor pressure reaches the pressure surrounding the liquid, boiling occurs and liquid turns to gas throughout the bulk of the liquid. A mixture with a given composition has one boiling point at a given pressure when the components are mutually soluble. A mixture of constant composition does not have multiple boiling points.\nAn implication of one boiling point is that lighter components never cleanly \"boil first\". At boiling point, all volatile components boil, but for a component, its percentage in the vapor is the same as its percentage of the total vapor pressure. Lighter components have a higher partial pressure and, thus, are concentrated in the vapor, but heavier volatile components also have a (smaller) partial pressure and necessarily vaporize also, albeit at a lower concentration in the vapor. Indeed, batch distillation and fractionation succeed by varying the composition of the mixture. In batch distillation, the batch vaporizes, which changes its composition; in fractionation, liquid higher in the fractionation column contains more lights and boils at lower temperatures. Therefore, starting from a given mixture, it appears to have a boiling range instead of a boiling point, although this is because its composition changes: each intermediate mixture has its own, singular boiling point.\nThe idealized model is accurate in the case of chemically similar liquids, such as benzene and toluene. In other cases, severe deviations from Raoult's law and Dalton's law are observed, most famously in the mixture of ethanol and water. These compounds, when heated together, form an azeotrope, which is when the vapor phase and liquid phase contain the same composition. Although there are computational methods that can be used to estimate the behavior of a mixture of arbitrary components, the only way to obtain accurate vapor\u2013liquid equilibrium data is by measurement.\nIt is not possible to completely purify a mixture of components by distillation, as this would require each component in the mixture to have a zero partial pressure. If ultra-pure products are the goal, then further chemical separation must be applied. When a binary mixture is vaporized and the other component, e.g., a salt, has zero partial pressure for practical purposes, the process is simpler.\nBatch or differential distillation.\nHeating an ideal mixture of two volatile substances, A and B, with A having the higher volatility, or lower boiling point, in a batch distillation setup (such as in an apparatus depicted in the opening figure) until the mixture is boiling results in a vapor above the liquid that contains a mixture of A and B. The ratio between A and B in the vapor will be different from the ratio in the liquid. The ratio in the liquid will be determined by how the original mixture was prepared, while the ratio in the vapor will be enriched in the more volatile compound, A (due to Raoult's Law, see above). The vapor goes through the condenser and is removed from the system. This, in turn, means that the ratio of compounds in the remaining liquid is now different from the initial ratio (i.e., more enriched in B than in the starting liquid).\nThe result is that the ratio in the liquid mixture is changing, becoming richer in component B. This causes the boiling point of the mixture to rise, which results in a rise in the temperature in the vapor, which results in a changing ratio of A : B in the gas phase (as distillation continues, there is an increasing proportion of B in the gas phase). This results in a slowly changing ratio of A : B in the distillate.\nIf the difference in vapour pressure between the two components A and B is large \u2013 generally expressed as the difference in boiling points \u2013 the mixture in the beginning of the distillation is highly enriched in component A, and when component A has distilled off, the boiling liquid is enriched in component B.\nContinuous distillation.\nContinuous distillation is an ongoing distillation in which a liquid mixture is continuously (without interruption) fed into the process and separated fractions are removed continuously as output streams occur over time during the operation. Continuous distillation produces a minimum of two output fractions, including at least one volatile distillate fraction, which has boiled and been separately captured as a vapor and then condensed to a liquid. There is always a bottoms (or residue) fraction, which is the least volatile residue that has not been separately captured as a condensed vapor.\nContinuous distillation differs from batch distillation in the respect that concentrations should not change over time. Continuous distillation can be run at a steady state for an arbitrary amount of time. For any source material of specific composition, the main variables that affect the purity of products in continuous distillation are the reflux ratio and the number of theoretical equilibrium stages, in practice determined by the number of trays or the height of packing. Reflux is a flow from the condenser back to the column, which generates a recycle that allows a better separation with a given number of trays. Equilibrium stages are ideal steps where compositions achieve vapor\u2013liquid equilibrium, repeating the separation process and allowing better separation given a reflux ratio. A column with a high reflux ratio may have fewer stages, but it refluxes a large amount of liquid, giving a wide column with a large holdup. Conversely, a column with a low reflux ratio must have a large number of stages, thus requiring a taller column.\nGeneral improvements.\nBoth batch and continuous distillations can be improved by making use of a fractionating column on top of the distillation flask. The column improves separation by providing a larger surface area for the vapor and condensate to come into contact. This helps it remain at equilibrium for as long as possible. The column can even consist of small subsystems ('trays' or 'dishes') which all contain an enriched, boiling liquid mixture, all with their own vapor\u2013liquid equilibrium.\nThere are differences between laboratory-scale and industrial-scale fractionating columns, but the principles are the same. Examples of laboratory-scale fractionating columns (in increasing efficiency) include\nLaboratory scale distillation.\nLaboratory scale distillations are almost exclusively run as batch distillations. The device used in distillation, sometimes referred to as a \"still\", consists at a minimum of a reboiler or \"pot\" in which the source material is heated, a condenser in which the heated vapor is cooled back to the liquid state, and a receiver in which the concentrated or purified liquid, called the distillate, is collected. Several laboratory scale techniques for distillation exist (see also ).\nA completely sealed distillation apparatus could experience extreme and rapidly varying internal pressure, which could cause it to burst open at the joints. Therefore, some path is usually left open (for instance, at the receiving flask) to allow the internal pressure to equalize with atmospheric pressure. Alternatively, a vacuum pump may be used to keep the apparatus at a lower than atmospheric pressure. If the substances involved are air- or moisture-sensitive, the connection to the atmosphere can be made through one or more drying tubes packed with materials that scavenge the undesired air components, or through bubblers that provide a movable liquid barrier. Finally, the entry of undesired air components can be prevented by pumping a low but steady flow of suitable inert gas, like nitrogen, into the apparatus.\nSimple distillation.\nIn simple distillation, the vapor is immediately channeled into a condenser. Consequently, the distillate is not pure but rather its composition is identical to the composition of the vapors at the given temperature and pressure. That concentration follows Raoult's law.\nAs a result, simple distillation is effective only when the liquid boiling points differ greatly (rule of thumb is 25\u00a0\u00b0C) or when separating liquids from non-volatile solids or oils. For these cases, the vapor pressures of the components are usually different enough that the distillate may be sufficiently pure for its intended purpose.\nA cutaway schematic of a simple distillation operation is shown at right. The starting liquid 15 in the boiling flask 2 is heated by a combined hotplate and magnetic stirrer 13 via a silicone oil bath (orange, 14). The vapor flows through a short Vigreux column 3, then through a Liebig condenser 5, is cooled by water (blue) that circulates through ports 6 and 7. The condensed liquid drips into the receiving flask 8, sitting in a cooling bath (blue, 16). The adapter 10 has a connection 9 that may be fitted to a vacuum pump. The components are connected by ground glass joints (gray).\nFractional distillation.\nFor many cases, the boiling points of the components in the mixture will be sufficiently close that Raoult's law must be taken into consideration. Therefore, fractional distillation must be used in order to separate the components by repeated vaporization-condensation cycles within a packed fractionating column. This separation, by successive distillations, is also referred to as rectification.\nAs the solution to be purified is heated, its vapors rise to the fractionating column. As it rises, it cools, condensing on the condenser walls and the surfaces of the packing material. Here, the condensate continues to be heated by the rising hot vapors; it vaporizes once more. However, the composition of the fresh vapors are determined once again by Raoult's law. Each vaporization-condensation cycle (called a \"theoretical plate\") will yield a purer solution of the more volatile component. In reality, each cycle at a given temperature does not occur at exactly the same position in the fractionating column; \"theoretical plate\" is thus a concept rather than an accurate description.\nMore theoretical plates lead to better separations. A spinning band distillation system uses a spinning band of Teflon or metal to force the rising vapors into close contact with the descending condensate, increasing the number of theoretical plates.\nSteam distillation.\nLike vacuum distillation, steam distillation is a method for distilling compounds which are heat-sensitive. The temperature of the steam is easier to control than the surface of a heating element, and allows a high rate of heat transfer without heating at a very high temperature. This process involves bubbling steam through a heated mixture of the raw material. By Raoult's law, some of the target compound will vaporize (in accordance with its partial pressure). The vapor mixture is cooled and condensed, usually yielding a layer of oil and a layer of water.\nSteam distillation of various aromatic herbs and flowers can result in two products; an essential oil as well as a watery herbal distillate. The essential oils are often used in perfumery and aromatherapy while the watery distillates have many applications in aromatherapy, food processing and skin care.\nVacuum distillation.\nSome compounds have very high boiling points. To boil such compounds, it is often better to lower the pressure at which such compounds are boiled instead of increasing the temperature. Once the pressure is lowered to the vapor pressure of the compound (at the given temperature), boiling and the rest of the distillation process can commence. This technique is referred to as vacuum distillation and it is commonly found in the laboratory in the form of the rotary evaporator.\nThis technique is also very useful for compounds which boil beyond their decomposition temperature at atmospheric pressure and which would therefore be decomposed by any attempt to boil them under atmospheric pressure.\nShort path and molecular distillation.\nMolecular distillation is vacuum distillation below the pressure of 0.01 torr. 0.01 torr is one order of magnitude above high vacuum, where fluids are in the free molecular flow regime, i.e. the mean free path of molecules is comparable to the size of the equipment. The gaseous phase no longer exerts significant pressure on the substance to be evaporated, and consequently, rate of evaporation no longer depends on pressure. That is, because the continuum assumptions of fluid dynamics no longer apply, mass transport is governed by molecular dynamics rather than fluid dynamics. Thus, a short path between the hot surface and the cold surface is necessary, typically by suspending a hot plate covered with a film of feed next to a cold plate with a line of sight in between. Molecular distillation is used industrially for purification of oils.\nShort path distillation is a distillation technique that involves the distillate travelling a short distance, often only a few centimeters, and is normally done at reduced pressure. A classic example would be a distillation involving the distillate travelling from one glass bulb to another, without the need for a condenser separating the two chambers. This technique is often used for compounds which are unstable at high temperatures or to purify small amounts of compound. The advantage is that the heating temperature can be considerably lower (at reduced pressure) than the boiling point of the liquid at standard pressure, and the distillate only has to travel a short distance before condensing. A short path ensures that little compound is lost on the sides of the apparatus. The Kugelrohr is a kind of a short path distillation apparatus which often contain multiple chambers to collect distillate fractions.\nAir-sensitive vacuum distillation.\nSome compounds have high boiling points as well as being air sensitive. A simple vacuum distillation system as exemplified above can be used, whereby the vacuum is replaced with an inert gas after the distillation is complete. However, this is a less satisfactory system if one desires to collect fractions under a reduced pressure. To do this a \"cow\" or \"pig\" adaptor can be added to the end of the condenser, or for better results or for very air sensitive compounds a Perkin triangle apparatus can be used.\nThe Perkin triangle, has means via a series of glass or Teflon taps to allows fractions to be isolated from the rest of the still, without the main body of the distillation being removed from either the vacuum or heat source, and thus can remain in a state of reflux. To do this, the sample is first isolated from the vacuum by means of the taps, the vacuum over the sample is then replaced with an inert gas (such as nitrogen or argon) and can then be stoppered and removed. A fresh collection vessel can then be added to the system, evacuated and linked back into the distillation system via the taps to collect a second fraction, and so on, until all fractions have been collected.\nZone distillation.\nZone distillation is a distillation process in long container with partial melting of refined matter in moving liquid zone and condensation of vapor in the solid phase at condensate pulling in cold area. The process is worked in theory. When zone heater is moving from the top to the bottom of the container then solid condensate with irregular impurity distribution is forming. Then most pure part of the condensate may be extracted as product. The process may be iterated many times by moving (without turnover) the received condensate to the bottom part of the container on the place of refined matter. The irregular impurity distribution in the condensate (that is efficiency of purification) increases with the number of iterations.\nZone distillation is the distillation analog of zone recrystallization. Impurity distribution in the condensate is described by known equations of zone recrystallization \u2013 with the replacement of the distribution co-efficient k of crystallization - for the separation factor \u03b1 of distillation.\nOther types.\nThe unit process of evaporation may also be called \"distillation\":\nOther uses:\nAzeotropic distillation.\nInteractions between the components of the solution create properties unique to the solution, as most processes entail nonideal mixtures, where Raoult's law does not hold. Such interactions can result in a constant-boiling azeotrope which behaves as if it were a pure compound (i.e., boils at a single temperature instead of a range). At an azeotrope, the solution contains the given component in the same proportion as the vapor, so that evaporation does not change the purity, and distillation does not effect separation. For example, ethyl alcohol and water form an azeotrope of 95.6% at 78.1\u00a0\u00b0C.\nIf the azeotrope is not considered sufficiently pure for use, there exist some techniques to break the azeotrope to give a pure distillate. This set of techniques are known as azeotropic distillation. Some techniques achieve this by \"jumping\" over the azeotropic composition (by adding another component to create a new azeotrope, or by varying the pressure). Others work by chemically or physically removing or sequestering the impurity. For example, to purify ethanol beyond 95%, a drying agent (or desiccant, such as potassium carbonate) can be added to convert the soluble water into insoluble water of crystallization. Molecular sieves are often used for this purpose as well.\nImmiscible liquids, such as water and toluene, easily form azeotropes. Commonly, these azeotropes are referred to as a low boiling azeotrope because the boiling point of the azeotrope is lower than the boiling point of either pure component. The temperature and composition of the azeotrope is easily predicted from the vapor pressure of the pure components, without use of Raoult's law. The azeotrope is easily broken in a distillation set-up by using a liquid\u2013liquid separator (a decanter) to separate the two liquid layers that are condensed overhead. Only one of the two liquid layers is refluxed to the distillation set-up.\nHigh boiling azeotropes, such as a 20 percent by weight mixture of hydrochloric acid in water, also exist. As implied by the name, the boiling point of the azeotrope is greater than the boiling point of either pure component.\nTo break azeotropic distillations and cross distillation boundaries, such as in the DeRosier Problem, it is necessary to increase the composition of the light key in the distillate.\nBreaking an azeotrope with unidirectional pressure manipulation.\nThe boiling points of components in an azeotrope overlap to form a band. By exposing an azeotrope to a vacuum or positive pressure, it's possible to bias the boiling point of one component away from the other by exploiting the differing vapor pressure curves of each; the curves may overlap at the azeotropic point, but are unlikely to be remain identical further along the pressure axis either side of the azeotropic point. When the bias is great enough, the two boiling points no longer overlap and so the azeotropic band disappears.\nThis method can remove the need to add other chemicals to a distillation, but it has two potential drawbacks.\nUnder negative pressure, power for a vacuum source is needed and the reduced boiling points of the distillates requires that the condenser be run cooler to prevent distillate vapors being lost to the vacuum source. Increased cooling demands will often require additional energy and possibly new equipment or a change of coolant.\nAlternatively, if positive pressures are required, standard glassware can not be used, energy must be used for pressurization and there is a higher chance of side reactions occurring in the distillation, such as decomposition, due to the higher temperatures required to effect boiling.\nA unidirectional distillation will rely on a pressure change in one direction, either positive or negative.\nPressure-swing distillation.\nPressure-swing distillation is essentially the same as the unidirectional distillation used to break azeotropic mixtures, but here both positive and negative pressures may be employed.\nThis improves the selectivity of the distillation and allows a chemist to optimize distillation by avoiding extremes of pressure and temperature that waste energy. This is particularly important in commercial applications.\nOne example of the application of pressure-swing distillation is during the industrial purification of ethyl acetate after its catalytic synthesis from ethanol.\nIndustrial distillation.\nLarge scale industrial distillation applications include both batch and continuous fractional, vacuum, azeotropic, extractive, and steam distillation. The most widely used industrial applications of continuous, steady-state fractional distillation are in petroleum refineries, petrochemical and chemical plants and natural gas processing plants.\nTo control and optimize such industrial distillation, a standardized laboratory method, ASTM D86, is established. This test method extends to the atmospheric distillation of petroleum products using a laboratory batch distillation unit to quantitatively determine the boiling range characteristics of petroleum products.\nIndustrial distillation is typically performed in large, vertical cylindrical columns known as distillation towers or distillation columns with diameters ranging from about 65\u00a0centimeters to 16\u00a0meters and heights ranging from about 6\u00a0meters to 90\u00a0meters or more. When the process feed has a diverse composition, as in distilling crude oil, liquid outlets at intervals up the column allow for the withdrawal of different \"fractions\" or products having different boiling points or boiling ranges. The \"lightest\" products (those with the lowest boiling point) exit from the top of the columns and the \"heaviest\" products (those with the highest boiling point) exit from the bottom of the column and are often called the bottoms.\nIndustrial towers use reflux to achieve a more complete separation of products. Reflux refers to the portion of the condensed overhead liquid product from a distillation or fractionation tower that is returned to the upper part of the tower as shown in the schematic diagram of a typical, large-scale industrial distillation tower. Inside the tower, the downflowing reflux liquid provides cooling and condensation of the upflowing vapors thereby increasing the efficiency of the distillation tower. The more reflux that is provided for a given number of theoretical plates, the better the tower's separation of lower boiling materials from higher boiling materials. Alternatively, the more reflux that is provided for a given desired separation, the fewer the number of theoretical plates required. Chemical engineers must choose what combination of reflux rate and number of plates is both economically and physically feasible for the products purified in the distillation column.\nSuch industrial fractionating towers are also used in cryogenic air separation, producing liquid oxygen, liquid nitrogen, and high purity argon. Distillation of chlorosilanes also enables the production of high-purity silicon for use as a semiconductor.\nDesign and operation of a distillation tower depends on the feed and desired products. Given a simple, binary component feed, analytical methods such as the McCabe\u2013Thiele method or the Fenske equation can be used. For a multi-component feed, simulation models are used both for design and operation. Moreover, the efficiencies of the vapor\u2013liquid contact devices (referred to as \"plates\" or \"trays\") used in distillation towers are typically lower than that of a theoretical 100% efficient equilibrium stage. Hence, a distillation tower needs more trays than the number of theoretical vapor\u2013liquid equilibrium stages. A variety of models have been postulated to estimate tray efficiencies.\nIn modern industrial uses, a packing material is used in the column instead of trays when low pressure drops across the column are required. Other factors that favor packing are: vacuum systems, smaller diameter columns, corrosive systems, systems prone to foaming, systems requiring low liquid holdup, and batch distillation. Conversely, factors that favor plate columns are: presence of solids in feed, high liquid rates, large column diameters, complex columns, columns with wide feed composition variation, columns with a chemical reaction, absorption columns, columns limited by foundation weight tolerance, low liquid rate, large turn-down ratio and those processes subject to process surges.\nThis packing material can either be random dumped packing (1\u20133\" wide) such as Raschig rings or structured sheet metal. Liquids tend to wet the surface of the packing and the vapors pass across this wetted surface, where mass transfer takes place. Unlike conventional tray distillation in which every tray represents a separate point of vapor\u2013liquid equilibrium, the vapor\u2013liquid equilibrium curve in a packed column is continuous. However, when modeling packed columns, it is useful to compute a number of \"theoretical stages\" to denote the separation efficiency of the packed column with respect to more traditional trays. Differently shaped packings have different surface areas and void space between packings. Both of these factors affect packing performance.\nAnother factor in addition to the packing shape and surface area that affects the performance of random or structured packing is the liquid and vapor distribution entering the packed bed. The number of theoretical stages required to make a given separation is calculated using a specific vapor to liquid ratio. If the liquid and vapor are not evenly distributed across the superficial tower area as it enters the packed bed, the liquid to vapor ratio will not be correct in the packed bed and the required separation will not be achieved. The packing will appear to not be working properly. The height equivalent to a theoretical plate (HETP) will be greater than expected. The problem is not the packing itself but the mal-distribution of the fluids entering the packed bed. Liquid mal-distribution is more frequently the problem than vapor. The design of the liquid distributors used to introduce the feed and reflux to a packed bed is critical to making the packing perform to it maximum efficiency. Methods of evaluating the effectiveness of a liquid distributor to evenly distribute the liquid entering a packed bed can be found in references. Considerable work has been done on this topic by Fractionation Research, Inc. (commonly known as FRI).\nMulti-effect distillation.\nThe goal of multi-effect distillation is to increase the energy efficiency of the process, for use in desalination, or in some cases one stage in the production of ultrapure water. The number of effects is inversely proportional to the kW\u00b7h/m3 of water recovered figure, and refers to the volume of water recovered per unit of energy compared with single-effect distillation. One effect is roughly 636\u00a0kW\u00b7h/m3.\nThere are many other types of multi-effect distillation processes, including one referred to as simply multi-effect distillation (MED), in which multiple chambers, with intervening heat exchangers, are employed.\nDistillation in food processing.\nDistilled beverages.\nCarbohydrate-containing plant materials are allowed to ferment, producing a dilute solution of ethanol in the process. Spirits such as whiskey and rum are prepared by distilling these dilute solutions of ethanol. Components other than ethanol, including water, esters, and other alcohols, are collected in the condensate, which account for the flavor of the beverage. Some of these beverages are then stored in barrels or other containers to acquire more flavor compounds and characteristic flavors."}
{"id": "8302", "revid": "30746614", "url": "https://en.wikipedia.org/wiki?curid=8302", "title": "David Hilbert", "text": "David Hilbert (; ; 23 January 1862 \u2013 14 February 1943) was a German mathematician and one of the most influential mathematicians of the 19th and early 20th centuries. Hilbert discovered and developed a broad range of fundamental ideas in many areas, including invariant theory, the calculus of variations, commutative algebra, algebraic number theory, the foundations of geometry, spectral theory of operators and its application to integral equations, mathematical physics, and the foundations of mathematics (particularly proof theory).\nHilbert adopted and defended Georg Cantor's set theory and transfinite numbers. In 1900, he presented a collection of problems that set the course for much of the mathematical research of the 20th century.\nHilbert and his students contributed significantly to establishing rigor and developed important tools used in modern mathematical physics. Hilbert is known as one of the founders of proof theory and mathematical logic.\nLife.\nEarly life and education.\nHilbert, the first of two children and only son of Otto and Maria Therese (Erdtmann) Hilbert, was born in the Province of Prussia, Kingdom of Prussia, either in K\u00f6nigsberg (according to Hilbert's own statement) or in Wehlau (known since 1946 as Znamensk) near K\u00f6nigsberg where his father worked at the time of his birth.\nIn late 1872, Hilbert entered the Friedrichskolleg Gymnasium (\"Collegium fridericianum\", the same school that Immanuel Kant had attended 140 years before); but, after an unhappy period, he transferred to (late 1879) and graduated from (early 1880) the more science-oriented Wilhelm Gymnasium. Upon graduation, in autumn 1880, Hilbert enrolled at the University of K\u00f6nigsberg, the \"Albertina\". In early 1882, Hermann Minkowski (two years younger than Hilbert and also a native of K\u00f6nigsberg but had gone to Berlin for three semesters), returned to K\u00f6nigsberg and entered the university. Hilbert developed a lifelong friendship with the shy, gifted Minkowski.\nCareer.\nIn 1884, Adolf Hurwitz arrived from G\u00f6ttingen as an Extraordinarius (i.e., an associate professor). An intense and fruitful scientific exchange among the three began, and Minkowski and Hilbert especially would exercise a reciprocal influence over each other at various times in their scientific careers. Hilbert obtained his doctorate in 1885, with a dissertation, written under Ferdinand von Lindemann, titled \"\u00dcber invariante Eigenschaften spezieller bin\u00e4rer Formen, insbesondere der Kugelfunktionen\" (\"On the invariant properties of special binary forms, in particular the spherical harmonic functions\").\nHilbert remained at the University of K\u00f6nigsberg as a \"Privatdozent\" (senior lecturer) from 1886 to 1895. In 1895, as a result of intervention on his behalf by Felix Klein, he obtained the position of Professor of Mathematics at the University of G\u00f6ttingen. During the Klein and Hilbert years, G\u00f6ttingen became the preeminent institution in the mathematical world. He remained there for the rest of his life.\nG\u00f6ttingen school.\nAmong Hilbert's students were Hermann Weyl, chess champion Emanuel Lasker, Ernst Zermelo, and Carl Gustav Hempel. John von Neumann was his assistant. At the University of G\u00f6ttingen, Hilbert was surrounded by a social circle of some of the most important mathematicians of the 20th century, such as Emmy Noether and Alonzo Church.\nAmong his 69 Ph.D. students in G\u00f6ttingen were many who later became famous mathematicians, including (with date of thesis): Otto Blumenthal (1898), Felix Bernstein (1901), Hermann Weyl (1908), Richard Courant (1910), Erich Hecke (1910), Hugo Steinhaus (1911), and Wilhelm Ackermann (1925). Between 1902 and 1939 Hilbert was editor of the \"Mathematische Annalen\", the leading mathematical journal of the time.\nPersonal life.\nIn 1892, Hilbert married K\u00e4the Jerosch (1864\u20131945), who was the daughter of a K\u00f6nigsberg merchant, an outspoken young lady with an independence of mind that matched [Hilbert's].\" While at K\u00f6nigsberg they had their one child, Franz Hilbert (1893\u20131969).\nFranz suffered throughout his life from an undiagnosed mental illness. His inferior intellect was a terrible disappointment to his father and this misfortune was a matter of distress to the mathematicians and students at G\u00f6ttingen.\nHilbert considered the mathematician Hermann Minkowski to be his \"best and truest friend\".\nHilbert was baptized and raised a Calvinist in the Prussian Evangelical Church. He later left the Church and became an agnostic. He also argued that mathematical truth was independent of the existence of God or other \"a priori\" assumptions. When Galileo Galilei was criticized for failing to stand up for his convictions on the Heliocentric theory, Hilbert objected: \"But [Galileo] was not an idiot. Only an idiot could believe that scientific truth needs martyrdom; that may be necessary in religion, but scientific results prove themselves in due time.\"\nLater years.\nAround 1925, Hilbert developed pernicious anemia, a then-untreatable vitamin deficiency whose primary symptom is exhaustion; his assistant Eugene Wigner described him as subject to \"enormous fatigue\" and how he \"seemed quite old\", and that even after eventually being diagnosed and treated, he \"was hardly a scientist after 1925, and certainly not a Hilbert.\"\nHilbert lived to see the Nazis purge many of the prominent faculty members at University of G\u00f6ttingen in 1933. Those forced out included Hermann Weyl (who had taken Hilbert's chair when he retired in 1930), Emmy Noether and Edmund Landau. One who had to leave Germany, Paul Bernays, had collaborated with Hilbert in mathematical logic, and co-authored with him the important book \"Grundlagen der Mathematik\" (which eventually appeared in two volumes, in 1934 and 1939). This was a sequel to the Hilbert\u2013Ackermann book \"Principles of Mathematical Logic\" from 1928. Hermann Weyl's successor was Helmut Hasse.\nAbout a year later, Hilbert attended a banquet and was seated next to the new Minister of Education, Bernhard Rust. Rust asked whether \"the \"Mathematical Institute\" really suffered so much because of the departure of the Jews\". Hilbert replied,\n\"Suffered? It doesn't exist any longer, does it!\"\nDeath.\nBy the time Hilbert died in 1943, the Nazis had nearly completely restaffed the university, as many of the former faculty had either been Jewish or married to Jews. Hilbert's funeral was attended by fewer than a dozen people, only two of whom were fellow academics, among them Arnold Sommerfeld, a theoretical physicist and also a native of K\u00f6nigsberg. News of his death only became known to the wider world six months after he died.\nThe epitaph on his tombstone in G\u00f6ttingen consists of the famous lines he spoke at the conclusion of his retirement address to the Society of German Scientists and Physicians on 8 September 1930. The words were given in response to the Latin maxim: \"Ignoramus et ignorabimus\" or \"We do not know, we shall not know\":\nIn English:\nThe day before Hilbert pronounced these phrases at the 1930 annual meeting of the Society of German Scientists and Physicians, Kurt G\u00f6del\u2014in a round table discussion during the Conference on Epistemology held jointly with the Society meetings\u2014tentatively announced the first expression of his incompleteness theorem. G\u00f6del's incompleteness theorems show that even elementary axiomatic systems such as Peano arithmetic are either self-contradicting or contain logical propositions that are impossible to prove or disprove.\nContributions to mathematics and physics.\nHilbert solves Gordan's Problem.\nHilbert's first work on invariant functions led him to the demonstration in 1888 of his famous \"finiteness theorem\". Twenty years earlier, Paul Gordan had demonstrated the theorem of the finiteness of generators for binary forms using a complex computational approach. Attempts to generalize his method to functions with more than two variables failed because of the enormous difficulty of the calculations involved. To solve what had become known in some circles as \"Gordan's Problem\", Hilbert realized that it was necessary to take a completely different path. As a result, he demonstrated \"Hilbert's basis theorem\", showing the existence of a finite set of generators, for the invariants of quantics in any number of variables, but in an abstract form. That is, while demonstrating the existence of such a set, it was not a constructive proof \u2014 it did not display \"an object\" \u2014 but rather, it was an existence proof and relied on use of the law of excluded middle in an infinite extension.\nHilbert sent his results to the \"Mathematische Annalen\". Gordan, the house expert on the theory of invariants for the \"Mathematische Annalen\", could not appreciate the revolutionary nature of Hilbert's theorem and rejected the article, criticizing the exposition because it was insufficiently comprehensive. His comment was:\nKlein, on the other hand, recognized the importance of the work, and guaranteed that it would be published without any alterations. Encouraged by Klein, Hilbert extended his method in a second article, providing estimations on the maximum degree of the minimum set of generators, and he sent it once more to the \"Annalen\". After having read the manuscript, Klein wrote to him, saying:\nLater, after the usefulness of Hilbert's method was universally recognized, Gordan himself would say:\nFor all his successes, the nature of his proof created more trouble than Hilbert could have imagined. Although Kronecker had conceded, Hilbert would later respond to others' similar criticisms that \"many different constructions are subsumed under one fundamental idea\" \u2014 in other words (to quote Reid): \"Through a proof of existence, Hilbert had been able to obtain a construction\"; \"the proof\" (i.e. the symbols on the page) \"was\" \"the object\". Not all were convinced. While Kronecker would die soon afterwards, his constructivist philosophy would continue with the young Brouwer and his developing intuitionist \"school\", much to Hilbert's torment in his later years. Indeed, Hilbert would lose his \"gifted pupil\" Weyl to intuitionism \u2014 \"Hilbert was disturbed by his former student's fascination with the ideas of Brouwer, which aroused in Hilbert the memory of Kronecker\". Brouwer the intuitionist in particular opposed the use of the Law of Excluded Middle over infinite sets (as Hilbert had used it). Hilbert responded:\nAxiomatization of geometry.\nThe text \"Grundlagen der Geometrie\" (tr.: \"Foundations of Geometry\") published by Hilbert in 1899 proposes a formal set, called Hilbert's axioms, substituting for the traditional axioms of Euclid. They avoid weaknesses identified in those of Euclid, whose works at the time were still used textbook-fashion. It is difficult to specify the axioms used by Hilbert without referring to the publication history of the \"Grundlagen\" since Hilbert changed and modified them several times. The original monograph was quickly followed by a French translation, in which Hilbert added V.2, the Completeness Axiom. An English translation, authorized by Hilbert, was made by E.J. Townsend and copyrighted in 1902. This translation incorporated the changes made in the French translation and so is considered to be a translation of the 2nd edition. Hilbert continued to make changes in the text and several editions appeared in German. The 7th edition was the last to appear in Hilbert's lifetime. New editions followed the 7th, but the main text was essentially not revised.\nHilbert's approach signaled the shift to the modern axiomatic method. In this, Hilbert was anticipated by Moritz Pasch's work from 1882. Axioms are not taken as self-evident truths. Geometry may treat \"things\", about which we have powerful intuitions, but it is not necessary to assign any explicit meaning to the undefined concepts. The elements, such as point, line, plane, and others, could be substituted, as Hilbert is reported to have said to Schoenflies and K\u00f6tter, by tables, chairs, glasses of beer and other such objects. It is their defined relationships that are discussed.\nHilbert first enumerates the undefined concepts: point, line, plane, lying on (a relation between points and lines, points and planes, and lines and planes), betweenness, congruence of pairs of points (line segments), and congruence of angles. The axioms unify both the plane geometry and solid geometry of Euclid in a single system.\nThe 23 problems.\nHilbert put forth a most influential list of 23 unsolved problems at the International Congress of Mathematicians in Paris in 1900. This is generally reckoned as the most successful and deeply considered compilation of open problems ever to be produced by an individual mathematician.\nAfter re-working the foundations of classical geometry, Hilbert could have extrapolated to the rest of mathematics. His approach differed, however, from the later 'foundationalist' Russell\u2013Whitehead or 'encyclopedist' Nicolas Bourbaki, and from his contemporary Giuseppe Peano. The mathematical community as a whole could enlist in problems, which he had identified as crucial aspects of the areas of mathematics he took to be key.\nThe problem set was launched as a talk \"The Problems of Mathematics\" presented during the course of the Second International Congress of Mathematicians held in Paris. The introduction of the speech that Hilbert gave said:\nHe presented fewer than half the problems at the Congress, which were published in the acts of the Congress. In a subsequent publication, he extended the panorama, and arrived at the formulation of the now-canonical 23 Problems of Hilbert. See also Hilbert's twenty-fourth problem. The full text is important, since the exegesis of the questions still can be a matter of inevitable debate, whenever it is asked how many have been solved.\nSome of these were solved within a short time. Others have been discussed throughout the 20th century, with a few now taken to be unsuitably open-ended to come to closure. Some even continue to this day to remain a challenge for mathematicians.\nFormalism.\nIn an account that had become standard by the mid-century, Hilbert's problem set was also a kind of manifesto, that opened the way for the development of the formalist school, one of three major schools of mathematics of the 20th century. According to the formalist, mathematics is manipulation of symbols according to agreed upon formal rules. It is therefore an autonomous activity of thought. There is, however, room to doubt whether Hilbert's own views were simplistically formalist in this sense.\nHilbert's program.\nIn 1920 he proposed explicitly a research project (in \"metamathematics\", as it was then termed) that became known as Hilbert's program. He wanted mathematics to be formulated on a solid and complete logical foundation. He believed that in principle this could be done, by showing that:\nHe seems to have had both technical and philosophical reasons for formulating this proposal. It affirmed his dislike of what had become known as the \"ignorabimus\", still an active issue in his time in German thought, and traced back in that formulation to Emil du Bois-Reymond.\nThis program is still recognizable in the most popular philosophy of mathematics, where it is usually called \"formalism\". For example, the Bourbaki group adopted a watered-down and selective version of it as adequate to the requirements of their twin projects of (a) writing encyclopedic foundational works, and (b) supporting the axiomatic method as a research tool. This approach has been successful and influential in relation with Hilbert's work in algebra and functional analysis, but has failed to engage in the same way with his interests in physics and logic.\nHilbert wrote in 1919:\nHilbert published his views on the foundations of mathematics in the 2-volume work Grundlagen der Mathematik.\nG\u00f6del's work.\nHilbert and the mathematicians who worked with him in his enterprise were committed to the project. His attempt to support axiomatized mathematics with definitive principles, which could banish theoretical uncertainties, ended in failure.\nG\u00f6del demonstrated that any non-contradictory formal system, which was comprehensive enough to include at least arithmetic, cannot demonstrate its completeness by way of its own axioms. In 1931 his incompleteness theorem showed that Hilbert's grand plan was impossible as stated. The second point cannot in any reasonable way be combined with the first point, as long as the axiom system is genuinely finitary.\nNevertheless, the subsequent achievements of proof theory at the very least \"clarified\" consistency as it relates to theories of central concern to mathematicians. Hilbert's work had started logic on this course of clarification; the need to understand G\u00f6del's work then led to the development of recursion theory and then mathematical logic as an autonomous discipline in the 1930s. The basis for later theoretical computer science, in the work of Alonzo Church and Alan Turing, also grew directly out of this 'debate'.\nFunctional analysis.\nAround 1909, Hilbert dedicated himself to the study of differential and integral equations; his work had direct consequences for important parts of modern functional analysis. In order to carry out these studies, Hilbert introduced the concept of an infinite dimensional Euclidean space, later called Hilbert space. His work in this part of analysis provided the basis for important contributions to the mathematics of physics in the next two decades, though from an unanticipated direction.\nLater on, Stefan Banach amplified the concept, defining Banach spaces. Hilbert spaces are an important class of objects in the area of functional analysis, particularly of the spectral theory of self-adjoint linear operators, that grew up around it during the 20th century.\nPhysics.\nUntil 1912, Hilbert was almost exclusively a \"pure\" mathematician. When planning a visit from Bonn, where he was immersed in studying physics, his fellow mathematician and friend Hermann Minkowski joked he had to spend 10\u00a0days in quarantine before being able to visit Hilbert. In fact, Minkowski seems responsible for most of Hilbert's physics investigations prior to 1912, including their joint seminar on the subject in 1905.\nIn 1912, three years after his friend's death, Hilbert turned his focus to the subject almost exclusively. He arranged to have a \"physics tutor\" for himself. He started studying kinetic gas theory and moved on to elementary radiation theory and the molecular theory of matter. Even after the war started in 1914, he continued seminars and classes where the works of Albert Einstein and others were followed closely.\nBy 1907, Einstein had framed the fundamentals of the theory of gravity, but then struggled for nearly 8\u00a0years with a confounding problem of putting the theory into final form. By early summer\u00a01915, Hilbert's interest in physics had focused on general relativity, and he invited Einstein to G\u00f6ttingen to deliver a week of lectures on the subject. Einstein received an enthusiastic reception at G\u00f6ttingen. Over the summer, Einstein learned that Hilbert was also working on the field equations and redoubled his own efforts. During November\u00a01915, Einstein published several papers culminating in \"The Field Equations of Gravitation\" (see Einstein field equations). Nearly simultaneously, David Hilbert published \"The Foundations of Physics\", an axiomatic derivation of the field equations (see Einstein\u2013Hilbert action). Hilbert fully credited Einstein as the originator of the theory, and no public priority dispute concerning the field equations ever arose between the two men during their lives. See more at priority.\nAdditionally, Hilbert's work anticipated and assisted several advances in the mathematical formulation of quantum mechanics. His work was a key aspect of Hermann Weyl and John von Neumann's work on the mathematical equivalence of Werner Heisenberg's matrix mechanics and Erwin Schr\u00f6dinger's wave equation, and his namesake Hilbert space plays an important part in quantum theory. In 1926, von\u00a0Neumann showed that, if quantum states were understood as vectors in Hilbert space, they would correspond with both Schr\u00f6dinger's wave function theory and Heisenberg's matrices.\nThroughout this immersion in physics, Hilbert worked on putting rigor into the mathematics of physics. While highly dependent on higher mathematics, physicists tended to be \"sloppy\" with it. To a \"pure\" mathematician like Hilbert, this was both ugly, and difficult to understand. As he began to understand physics and how physicists were using mathematics, he developed a coherent mathematical theory for what he found \u2013 most importantly in the area of integral equations. When his colleague Richard Courant wrote the now classic \"Methoden der mathematischen Physik\" [\"Methods of Mathematical Physics\"] including some of Hilbert's ideas, he added Hilbert's name as author even though Hilbert had not directly contributed to the writing. Hilbert said \"Physics is too hard for physicists\", implying that the necessary mathematics was generally beyond them; the Courant-Hilbert book made it easier for them.\nNumber theory.\nHilbert unified the field of algebraic number theory with his 1897 treatise \"Zahlbericht\" (literally \"report on numbers\"). He also resolved a significant number-theory problem formulated by Waring in 1770. As with the finiteness theorem, he used an existence proof that shows there must be solutions for the problem rather than providing a mechanism to produce the answers. He then had little more to publish on the subject; but the emergence of Hilbert modular forms in the dissertation of a student means his name is further attached to a major area.\nHe made a series of conjectures on class field theory. The concepts were highly influential, and his own contribution lives on in the names of the Hilbert class field and of the Hilbert symbol of local class field theory. Results were mostly proved by 1930, after work by Teiji Takagi.\nHilbert did not work in the central areas of analytic number theory, but his name has become known for the Hilbert\u2013P\u00f3lya conjecture, for reasons that are anecdotal.\nWorks.\nHis collected works (\"Gesammelte Abhandlungen\") have been published several times. The original versions of his papers contained \"many technical errors of varying degree\"; when the collection was first published, the errors were corrected and it was found that this could be done without major changes in the statements of the theorems, with one exception\u2014a claimed proof of the continuum hypothesis. The errors were nonetheless so numerous and significant that it took Olga Taussky-Todd three years to make the corrections."}
{"id": "8303", "revid": "40502578", "url": "https://en.wikipedia.org/wiki?curid=8303", "title": "Down syndrome", "text": "Down syndrome or Down's syndrome, also known as trisomy 21, is a genetic disorder caused by the presence of all or part of a third copy of chromosome 21. It is usually associated with physical growth delays, mild to moderate intellectual disability, and characteristic facial features. The average IQ of a young adult with Down syndrome is 50, equivalent to the mental ability of an eight- or nine-year-old child, but this can vary widely.\nThe parents of the affected individual are usually genetically normal. The probability increases from less than 0.1% in 20-year-old mothers to 3% in those of age 45. The extra chromosome is believed to occur by chance, with no known behavioral activity or environmental factor that changes the probability. Down syndrome can be identified during pregnancy by prenatal screening followed by diagnostic testing or after birth by direct observation and genetic testing. Since the introduction of screening, Down syndrome pregnancies are often aborted. Regular screening for health problems common in Down syndrome is recommended throughout the person's life.\nThere is no cure for Down syndrome. Education and proper care have been shown to improve quality of life. Some children with Down syndrome are educated in typical school classes, while others require more specialized education. Some individuals with Down syndrome graduate from high school, and a few attend post-secondary education. In adulthood, about 20% in the United States do paid work in some capacity, with many requiring a sheltered work environment. Support in financial and legal matters is often needed. Life expectancy is around 50 to 60\u00a0years in the developed world with proper health care.\nDown syndrome is one of the most common chromosome abnormalities in humans. It occurs in about 1 in 1,000 babies born each year. In 2015, Down syndrome was present in 5.4 million individuals globally and resulted in 27,000 deaths, down from 43,000 deaths in 1990. It is named after British doctor John Langdon Down, who fully described the syndrome in 1866. Some aspects of the condition were described earlier by French psychiatrist Jean-\u00c9tienne Dominique Esquirol in 1838 and French physician \u00c9douard S\u00e9guin in 1844. The genetic cause of Down syndrome was discovered in 1959.\nSigns and symptoms.\nThose with Down syndrome nearly always have physical and intellectual disabilities. As adults, their mental abilities are typically similar to those of an 8- or 9-year-old. They also typically have poor immune function and generally reach developmental milestones at a later age. They have an increased risk of a number of other health problems, including congenital heart defect, epilepsy, leukemia, thyroid diseases, and mental disorders.\nPhysical.\nPeople with Down syndrome may have some or all of these physical characteristics: a small chin, slanted eyes, poor muscle tone, a flat nasal bridge, a single crease of the palm, and a protruding tongue due to a small mouth and relatively large tongue. These airway changes lead to obstructive sleep apnea in around half of those with Down syndrome. Other common features include: a flat and wide face, a short neck, excessive joint flexibility, extra space between big toe and second toe, abnormal patterns on the fingertips and short fingers. Instability of the atlantoaxial joint occurs in about 20% and may lead to spinal cord injury in 1\u20132%. Hip dislocations may occur without trauma in up to a third of people with Down syndrome.\nGrowth in height is slower, resulting in adults who tend to have short stature\u2014the average height for men is 154\u00a0cm (5\u00a0ft 1\u00a0in) and for women is 142\u00a0cm (4\u00a0ft 8\u00a0in). Individuals with Down syndrome are at increased risk for obesity as they age. Growth charts have been developed specifically for children with Down syndrome.\nNeurological.\nThis syndrome causes about a third of cases of intellectual disability. Many developmental milestones are delayed with the ability to crawl typically occurring around 8\u00a0months rather than 5\u00a0months and the ability to walk independently typically occurring around 21\u00a0months rather than 14\u00a0months.\nMost individuals with Down syndrome have mild (IQ: 50\u201369) or moderate (IQ: 35\u201350) intellectual disability with some cases having severe (IQ: 20\u201335) difficulties. Those with mosaic Down syndrome typically have IQ scores 10\u201330 points higher. As they age, people with Down syndrome typically perform worse than their same-age peers.\nCommonly, individuals with Down syndrome have better language understanding than ability to speak. Between 10 and 45% have either a stutter or rapid and irregular speech, making it difficult to understand them. After reaching 30\u00a0years of age, some may lose their ability to speak.\nThey typically do fairly well with social skills. Behavior problems are not generally as great an issue as in other syndromes associated with intellectual disability. In children with Down syndrome, mental illness occurs in nearly 30% with autism occurring in 5\u201310%. People with Down syndrome experience a wide range of emotions. While people with Down syndrome are generally happy, symptoms of depression and anxiety may develop in early adulthood.\nChildren and adults with Down syndrome are at increased risk of epileptic seizures, which occur in 5\u201310% of children and up to 50% of adults. This includes an increased risk of a specific type of seizure called infantile spasms. Many (15%) who live 40 years or longer develop Alzheimer\u2019s disease. In those who reach 60\u00a0years of age, 50\u201370% have the disease.\nSenses.\nHearing and vision disorders occur in more than half of people with Down syndrome. \nVision problems occur in 38 to 80%. Between 20 and 50% have strabismus, in which the two eyes do not move together. Cataracts (cloudiness of the lens of the eye) occur in 15%, and may be present at birth. Keratoconus (a thin, cone-shaped cornea) and glaucoma (increased eye pressure) are also more common, as are refractive errors requiring glasses or contacts. Brushfield spots (small white or grayish/brown spots on the outer part of the iris) are present in 38 to 85% of individuals.\nHearing problems are found in 50\u201390% of children with Down syndrome. This is often the result of otitis media with effusion which occurs in 50\u201370% and chronic ear infections which occur in 40 to 60%. Ear infections often begin in the first year of life and are partly due to poor eustachian tube function. Excessive ear wax can also cause hearing loss due to obstruction of the outer ear canal. Even a mild degree of hearing loss can have negative consequences for speech, language understanding, and academics. Additionally, it is important to rule out hearing loss as a factor in social and cognitive deterioration. Age-related hearing loss of the sensorineural type occurs at a much earlier age and affects 10\u201370% of people with Down syndrome.\nHeart.\nThe rate of congenital heart disease in newborns with Down syndrome is around 40%. Of those with heart disease, about 80% have an atrioventricular septal defect or ventricular septal defect with the former being more common. Mitral valve problems become common as people age, even in those without heart problems at birth. Other problems that may occur include tetralogy of Fallot and patent ductus arteriosus. People with Down syndrome have a lower risk of hardening of the arteries.\nCancer.\nAlthough the overall risk of cancer in Down syndrome is not changed, the risk of testicular cancer and certain blood cancers, including acute lymphoblastic leukemia (ALL) and acute megakaryoblastic leukemia (AMKL) is increased while the risk of other non-blood cancers is decreased. People with Down syndrome are believed to have an increased risk of developing cancers derived from germ cells whether these cancers are blood- or non-blood-related.\nBlood cancers.\nLeukemia is 10 to 15 times more common in children with Down syndrome. In particular, acute lymphoblastic leukemia is 20 times more common and the megakaryoblastic form of acute myeloid leukemia (acute megakaryoblastic leukemia), is 500 times more common. Acute megakaryoblastic leukemia (AMKL) is a leukemia of megakaryoblasts, the precursors cells to megakaryocytes which form blood platelets. Acute lymphoblastic leukemia in Down syndrome accounts for 1\u20133% of all childhood cases of ALL. It occurs most often in those older than nine years or having a white blood cell count greater than 50,000 per microliter and is rare in those younger than one year old. ALL in Down syndrome tends to have poorer outcomes than other cases of ALL in people without Down syndrome.\nIn Down syndrome, AMKL is typically preceded by transient myeloproliferative disease (TMD), a disorder of blood cell production in which non-cancerous megakaryoblasts with a mutation in the \"GATA1\" gene rapidly divide during the later period of pregnancy. The condition affects 3\u201310% of babies with Down. While it often spontaneously resolves within three months of birth, it can cause serious blood, liver, or other complications. In about 10% of cases, TMD progresses to AMKL during the three months to five years following its resolution.\nNon-blood cancers.\nPeople with Down syndrome have a lower risk of all major solid cancers, including those of lung, breast, and cervix, with the lowest relative rates occurring in those aged 50 years or older. This low risk is thought due to an increase in the expression of tumor suppressor genes present on chromosome 21. One exception is testicular germ cell cancer which occurs at a higher rate in Down syndrome.\nEndocrine.\nProblems of the thyroid gland occur in 20\u201350% of individuals with Down syndrome. Low thyroid is the most common form, occurring in almost half of all individuals. Thyroid problems can be due to a poorly or nonfunctioning thyroid at birth (known as congenital hypothyroidism) which occurs in 1% or can develop later due to an attack on the thyroid by the immune system resulting in Graves' disease or autoimmune hypothyroidism. Type 1 diabetes mellitus is also more common.\nGastrointestinal.\nConstipation occurs in nearly half of people with Down syndrome and may result in changes in behavior. One potential cause is Hirschsprung's disease, occurring in 2\u201315%, which is due to a lack of nerve cells controlling the colon. Other frequent congenital problems include duodenal atresia, pyloric stenosis, Meckel diverticulum, and imperforate anus. Celiac disease affects about 7\u201320% and gastroesophageal reflux disease is also more common.\nTeeth.\nPeople with Down syndrome tend to be more susceptible to gingivitis as well as early, severe periodontal disease, necrotising ulcerative gingivitis, and early tooth loss, especially in the lower front teeth. While plaque and poor oral hygiene are contributing factors, the severity of these periodontal diseases cannot be explained solely by external factors. Research suggests that the severity is likely a result of a weakened immune system. The weakened immune system also contributes to increased incidence of yeast infections in the mouth (from \"Candida albicans\").\nPeople with Down syndrome also tend to have a more alkaline saliva resulting in a greater resistance to tooth decay, despite decreased quantities of saliva, less effective oral hygiene habits, and higher plaque indexes.\nHigher rates of tooth wear and bruxism are also common. Other common oral manifestations of Down syndrome include enlarged hypotonic tongue, crusted and hypotonic lips, mouth breathing, narrow palate with crowded teeth, class III malocclusion with an underdeveloped maxilla and posterior crossbite, delayed exfoliation of baby teeth and delayed eruption of adult teeth, shorter roots on teeth, and often missing and malformed (usually smaller) teeth. Less common manifestations include cleft lip and palate and enamel hypocalcification (20% prevalence).\nTaurodontism, an elongation of the pulp chamber, has a high prevalence in people with DS.\nFertility.\nMales with Down syndrome usually do not father children, while females have lower rates of fertility relative to those who are unaffected. Fertility is estimated to be present in 30\u201350% of females. Menopause usually occurs at an earlier age. The poor fertility in males is thought to be due to problems with sperm development; however, it may also be related to not being sexually active. As of 2006, three instances of males with Down syndrome fathering children and 26 cases of females having children have been reported. Without assisted reproductive technologies, around half of the children of someone with Down syndrome will also have the syndrome.\nCause.\nDown syndrome is caused by having three copies of the genes on chromosome 21, rather than the usual two. The parents of the affected individual are typically genetically normal. Those who have one child with Down syndrome have about a 1% risk of having a second child with the syndrome, if both parents are found to have normal karyotypes.\nThe extra chromosome content can arise through several different ways. The most common cause (about 92\u201395% of cases) is a complete extra copy of chromosome 21, resulting in trisomy 21. In 1.0 to 2.5% of cases, some of the cells in the body are normal and others have trisomy 21, known as mosaic Down syndrome. The other common mechanisms that can give rise to Down syndrome include: a Robertsonian translocation, isochromosome, or ring chromosome. These contain additional material from chromosome 21 and occur in about 2.5% of cases. An isochromosome results when the two long arms of a chromosome separate together rather than the long and short arm separating together during egg or sperm development.\nTrisomy 21.\nTrisomy 21 (also known by the karyotype 47,XX,+21 for females and 47,XY,+21 for males) is caused by a failure of the 21st chromosome to separate during egg or sperm development (nondisjunction). As a result, a sperm or egg cell is produced with an extra copy of chromosome 21; this cell thus has 24 chromosomes. When combined with a normal cell from the other parent, the baby has 47 chromosomes, with three copies of chromosome 21. About 88% of cases of trisomy 21 result from nonseparation of the chromosomes in the mother, 8% from nonseparation in the father, and 3% after the egg and sperm have merged.\nTranslocation.\nThe extra chromosome 21 material may also occur due to a Robertsonian translocation in 2\u20134% of cases. In this situation, the long arm of chromosome 21 is attached to another chromosome, often chromosome 14. In a male affected with Down syndrome, it results in a karyotype of 46XY,t(14q21q). This may be a new mutation or previously present in one of the parents. The parent with such a translocation is usually normal physically and mentally; however, during production of egg or sperm cells, a higher chance of creating reproductive cells with extra chromosome 21 material exists. This results in a 15% chance of having a child with Down syndrome when the mother is affected and a less than 5% probability if the father is affected. The probability of this type of Down syndrome is not related to the mother's age. Some children without Down syndrome may inherit the translocation and have a higher probability of having children of their own with Down syndrome. In this case it is sometimes known as familial Down syndrome.\nMechanism.\nThe extra genetic material present in Down syndrome results in overexpression of a portion of the 310 genes located on chromosome 21. This overexpression has been estimated at around 50%, due to the third copy of the chromosome present. Some research has suggested the Down syndrome critical region is located at bands 21q22.1\u2013q22.3, with this area including genes for the amyloid precursor protein, superoxide dismutase, and likely the ETS2 proto oncogene. Other research, however, has not confirmed these findings. microRNAs are also proposed to be involved.\nThe dementia that occurs in Down syndrome is due to an excess of amyloid beta peptide produced in the brain and is similar to Alzheimer's disease, which also involves amyloid beta build-up. Amyloid beta is processed from amyloid precursor protein, the gene for which is located on chromosome 21. Senile plaques and neurofibrillary tangles are present in nearly all by 35\u00a0years of age, though dementia may not be present. Those with Down syndrome also lack a normal number of lymphocytes and produce less antibodies which contributes to their increased risk of infection.\nEpigenetics.\nDown syndrome is associated with an increased risk of many chronic diseases that are typically associated with older age such as Alzheimer's disease. The accelerated aging suggest that trisomy 21 increases the biological age of tissues, but molecular evidence for this hypothesis is sparse. According to a biomarker of tissue age known as epigenetic clock, trisomy 21 increases the age of blood and brain tissue (on average by 6.6 years).\nDiagnosis.\nBefore birth.\nWhen screening tests predict a high risk of Down syndrome, a more invasive diagnostic test (amniocentesis or chorionic villus sampling) is needed to confirm the diagnosis. The false-positive rate with screening is about 2\u20135% (see section Screening below). Amniocentesis and chorionic villus sampling are more reliable tests, but they increase the risk of miscarriage between 0.5 and 1%. The risk of limb problems may be increased in the offspring if chorionic villus sampling is performed before 10 weeks. The risk from the procedure is greater the earlier it is performed, thus amniocentesis is not recommended before 15 weeks gestational age and chorionic villus sampling before 10 weeks gestational age.\nAbortion rates.\nAbout 92% of pregnancies in Europe with a diagnosis of Down syndrome are terminated. As a result, there is almost no one with Down's in Iceland and Denmark, where screening is commonplace. In the United States, the termination rate after diagnosis is around 75%, but varies from 61% to 93% depending on the population surveyed. Rates are lower among women who are younger and have decreased over time. When asked if they would have a termination if their fetus tested positive, 23\u201333% said yes, when high-risk pregnant women were asked, 46\u201386% said yes, and when women who screened positive are asked, 89\u201397% say yes.\nAfter birth.\nThe diagnosis can often be suspected based on the child's physical appearance at birth. An analysis of the child's chromosomes is needed to confirm the diagnosis, and to determine if a translocation is present, as this may help determine the risk of the child's parents having further children with Down syndrome. Parents generally wish to know the possible diagnosis once it is suspected and do not wish pity.\nScreening.\nGuidelines recommend screening for Down syndrome to be offered to all pregnant women, regardless of age. A number of tests are used, with varying levels of accuracy. They are typically used in combination to increase the detection rate. None can be definitive, thus if screening is positive, either amniocentesis or chorionic villus sampling is required to confirm the diagnosis. Screening in both the first and second trimesters is better than just screening in the first trimester. The different screening techniques in use are able to pick up 90\u201395% of cases, with a false-positive rate of 2\u20135%. If Down syndrome occurs in one in 500 pregnancies and the test used has a 5% false-positive rate, this means, of 26 women who test positive on screening, only one will have Down syndrome confirmed. If the screening test has a 2% false-positive rate, this means one of eleven who test positive on screening have a fetus with Down syndrome.\nUltrasound.\nUltrasound imaging can be used to screen for Down syndrome. Findings that indicate increased risk when seen at 14 to 24 weeks of gestation include a small or no nasal bone, large ventricles, nuchal fold thickness, and an abnormal right subclavian artery, among others. The presence or absence of many markers is more accurate. Increased fetal nuchal translucency (NT) indicates an increased risk of Down syndrome picking up 75\u201380% of cases and being falsely positive in 6%.\nBlood tests.\nSeveral blood markers can be measured to predict the risk of Down syndrome during the first or second trimester. Testing in both trimesters is sometimes recommended and test results are often combined with ultrasound results. In the second trimester, often two or three tests are used in combination with two or three of: \u03b1-fetoprotein, unconjugated estriol, total hCG, and free \u03b2hCG detecting about 60\u201370% of cases.\nTesting of the mother's blood for fetal DNA is being studied and appears promising in the first trimester. The International Society for Prenatal Diagnosis considers it a reasonable screening option for those women whose pregnancies are at a high risk for trisomy 21. Accuracy has been reported at 98.6% in the first trimester of pregnancy. Confirmatory testing by invasive techniques (amniocentesis, CVS) is still required to confirm the screening result.\nManagement.\nEfforts such as early childhood intervention, screening for common problems, medical treatment where indicated, a good family environment, and work-related training can improve the development of children with Down syndrome. Education and proper care can improve quality of life. Raising a child with Down syndrome is more work for parents than raising an unaffected child. Typical childhood vaccinations are recommended.\nHealth screening.\nA number of health organizations have issued recommendations for screening those with Down syndrome for particular diseases. This is recommended to be done systematically.\nAt birth, all children should get an electrocardiogram and ultrasound of the heart. Surgical repair of heart problems may be required as early as three months of age. Heart valve problems may occur in young adults, and further ultrasound evaluation may be needed in adolescents and in early adulthood. Due to the elevated risk of testicular cancer, some recommend checking the person's testicles yearly.\nCognitive development.\nHearing aids or other amplification devices can be useful for language learning in those with hearing loss. Speech therapy may be useful and is recommended to be started around nine months of age. As those with Down syndrome typically have good hand-eye coordination, learning sign language may be possible. Augmentative and alternative communication methods, such as pointing, body language, objects, or pictures, are often used to help with communication. Behavioral issues and mental illness are typically managed with counseling or medications.\nEducation programs before reaching school age may be useful. School-age children with Down syndrome may benefit from inclusive education (whereby students of differing abilities are placed in classes with their peers of the same age), provided some adjustments are made to the curriculum. Evidence to support this, however, is not very strong. In the United States, the Individuals with Disabilities Education Act of 1975 requires public schools generally to allow attendance by students with Down syndrome.\nIndividuals with Down syndrome may learn better visually. Drawing may help with language, speech, and reading skills. Children with Down syndrome still often have difficulty with sentence structure and grammar, as well as developing the ability to speak clearly. Several types of early intervention can help with cognitive development. Efforts to develop motor skills include physical therapy, speech and language therapy, and occupational therapy. Physical therapy focuses specifically on motor development and teaching children to interact with their environment. Speech and language therapy can help prepare for later language. Lastly, occupational therapy can help with skills needed for later independence.\nOther.\nTympanostomy tubes are often needed and often more than one set during the person's childhood. Tonsillectomy is also often done to help with sleep apnea and throat infections. Surgery, however, does not always address the sleep apnea and a continuous positive airway pressure (CPAP) machine may be useful. Physical therapy and participation in physical education may improve motor skills. Evidence to support this in adults, however, is not very good.\nEfforts to prevent respiratory syncytial virus (RSV) infection with human monoclonal antibodies should be considered, especially in those with heart problems. In those who develop dementia there is no evidence for memantine, donepezil, rivastigmine, or galantamine.\nPlastic surgery has been suggested as a method of improving the appearance and thus the acceptance of people with Down syndrome. It has also been proposed as a way to improve speech. Evidence, however, does not support a meaningful difference in either of these outcomes. Plastic surgery on children with Down syndrome is uncommon, and continues to be controversial. The U.S. National Down Syndrome Society views the goal as one of mutual respect and acceptance, not appearance.\nMany alternative medical techniques are used in Down syndrome; however, they are poorly supported by evidence. These include: dietary changes, massage, animal therapy, chiropractic and naturopathy, among others. Some proposed treatments may also be harmful.\nPrognosis.\nBetween 5 and 15% of children with Down syndrome in Sweden attend regular school. Some graduate from high school; however, most do not. Of those with intellectual disability in the United States who attended high school about 40% graduated. Many learn to read and write and some are able to do paid work. In adulthood about 20% in the United States do paid work in some capacity. In Sweden, however, less than 1% have regular jobs. Many are able to live semi-independently, but they often require help with financial, medical, and legal matters. Those with mosaic Down syndrome usually have better outcomes.\nIndividuals with Down syndrome have a higher risk of early death than the general population. This is most often from heart problems or infections. Following improved medical care, particularly for heart and gastrointestinal problems, the life expectancy has increased. This increase has been from 12 years in 1912, to 25 years in the 1980s, to 50 to 60\u00a0years in the developed world in the 2000s. Currently between 4 and 12% die in the first year of life. The probability of long-term survival is partly determined by the presence of heart problems. In those with congenital heart problems, 60% survive to 10\u00a0years and 50% survive to 30\u00a0years of age. In those without heart problems, 85% survive to 10\u00a0years and 80% survive to 30\u00a0years of age. About 10% live to 70 years of age. The National Down Syndrome Society provide information regarding raising a child with Down syndrome.\nEpidemiology.\nDown syndrome is the most common chromosomal abnormality in humans. Globally, , Down syndrome occurs in about 1 per 1,000 births and results in about 17,000 deaths. More children are born with Down syndrome in countries where abortion is not allowed and in countries where pregnancy more commonly occurs at a later age. About 1.4 per 1,000 live births in the United States and 1.1 per 1,000 live births in Norway are affected. In the 1950s, in the United States, it occurred in 2 per 1000 live births with the decrease since then due to prenatal screening and abortions. The number of pregnancies with Down syndrome is more than two times greater with many spontaneously aborting. It is the cause of 8% of all congenital disorders.\nMaternal age affects the chances of having a pregnancy with Down syndrome. At age 20, the chance is 1 in 1,441; at age 30, it is 1 in 959; at age 40, it is 1 in 84; and at age 50 it is 1 in 44. Although the probability increases with maternal age, 70% of children with Down syndrome are born to women 35 years of age and younger, because younger people have more children. The father's older age is also a risk factor in women older than 35, but not in women younger than 35, and may partly explain the increase in risk as women age.\nHistory.\nEnglish physician John Langdon Down first described Down syndrome in 1862, recognizing it as a distinct type of mental disability, and again in a more widely published report in 1866. \u00c9douard S\u00e9guin described it as separate from cretinism in 1844. By the 20th century, Down syndrome had become the most recognizable form of mental disability.\nIn antiquity, many infants with disabilities were either killed or abandoned. \nIn June 2020, the earliest incidence of Down syndrome was found in genomic evidence from an infant that was buried before 3200 BC at Poulnabrone dolmen in Ireland.\nResearchers believe that a number of historical pieces of art portray Down syndrome, including pottery from the pre-Columbian Tumaco-La Tolita culture in present-day Colombia and Ecuador, and the 16th-century painting \"The Adoration of the Christ Child\".\nIn the 20th century, many individuals with Down syndrome were institutionalized, few of the associated medical problems were treated, and most people died in infancy or early adulthood. With the rise of the eugenics movement, 33 of the then 48 U.S. states and several countries began programs of forced sterilization of individuals with Down syndrome and comparable degrees of disability. Action T4 in Nazi Germany made public policy of a program of systematic involuntary euthanization.\nWith the discovery of karyotype techniques in the 1950s it became possible to identify abnormalities of chromosomal number or shape. In 1959 J\u00e9r\u00f4me Lejeune reported the discovery that Down syndrome resulted from an extra chromosome. However, Lejeune's claim to the discovery has been disputed, and in 2014 the Scientific Council of the French Federation of Human Genetics unanimously awarded its Grand Prize to his colleague Marthe Gautier for her role in this discovery. The discovery took place in the laboratory of Raymond Turpin at the H\u00f4pital Trousseau in Paris, France. J\u00e9r\u00f4me Lejeune and Marthe Gautier were both his students.\nAs a result of this discovery, the condition became known as trisomy\u00a021. Even before the discovery of its cause, the presence of the syndrome in all races, its association with older maternal age, and its rarity of recurrence had been noticed. Medical texts had assumed it was caused by a combination of inheritable factors that had not been identified. Other theories had focused on injuries sustained during birth.\nSociety and culture.\nName.\nDue to his perception that children with Down syndrome shared facial similarities with those of Blumenbach's Mongolian race, John Langdon Down used the term \"mongoloid\". He felt that the existence of Down syndrome confirmed that all peoples were genetically related. In the 1950s with discovery of the underlying cause as being related to chromosomes, concerns about the race-based nature of the name increased.\nIn 1961, a group of nineteen scientists suggested that \"mongolism\" had \"misleading connotations\" and had become \"an embarrassing term\". The World Health Organization (WHO) dropped the term in 1965 after a request by the delegation from the Mongolian People's Republic. While the term mongoloid (also mongolism, Mongolian imbecility or idiocy) continued to be used until the early 1980s, it is now considered unacceptable and is no longer in common use.\nIn 1975, the United States National Institutes of Health (NIH) convened a conference to standardize the naming and recommended replacing the possessive form, \"Down's syndrome\" with \"Down syndrome\". However, both the possessive and nonpossessive forms remain in use by the general population. The term \"trisomy 21\" is also commonly used.\nEthics.\nMost obstetricians argue that not offering screening for Down syndrome is unethical. As it is a medically reasonable procedure, per informed consent, people should at least be given information about it. It will then be the woman's choice, based on her personal beliefs, how much or how little screening she wishes. When results from testing become available, it is also considered unethical not to give the results to the person in question.\nSome bioethicists deem it reasonable for parents to select a child who would have the highest well-being. One criticism of this reasoning is that it often values those with disabilities less. Some parents argue that Down syndrome should not be prevented or cured and that eliminating Down syndrome amounts to genocide. The disability rights movement does not have a position on screening, although some members consider testing and abortion discriminatory. Some in the United States who are anti-abortion support abortion if the fetus is disabled, while others do not. Of a group of 40 mothers in the United States who have had one child with Down syndrome, half agreed to screening in the next pregnancy.\nWithin the US, some Protestant denominations see abortion as acceptable when a fetus has Down syndrome while Orthodox Christianity and Roman Catholicism do not. Some of those against screening refer to it as a form of \"eugenics\". Disagreement exists within Islam regarding the acceptability of abortion in those carrying a fetus with Down syndrome. Some Islamic countries allow abortion, while others do not. Parents may be stigmatized whichever decision they make.\nAdvocacy groups.\nAdvocacy groups for individuals with Down syndrome began to be formed after the Second World War. These were organizations advocating for the inclusion of people with Down syndrome into the general school system and for a greater understanding of the condition among the general population, as well as groups providing support for families with children living with Down syndrome. Before this individuals with Down syndrome were often placed in mental hospitals or asylums. Organizations included the Royal Society for Handicapped Children and Adults founded in the UK in 1946 by Judy Fryd, Kobato Kai founded in Japan in 1964, the National Down Syndrome Congress founded in the United States in 1973 by Kathryn McGee and others, and the National Down Syndrome Society founded in 1979 in the United States. The first Roman Catholic order of nuns for women with Down Syndrome, Little Sisters Disciples of the Lamb, was founded in 1985 in France.\nThe first World Down Syndrome Day was held on 21 March 2006. The day and month were chosen to correspond with 21 and trisomy, respectively. It was recognized by the United Nations General Assembly in 2011.\nResearch.\nEfforts are underway to determine how the extra chromosome 21 material causes Down syndrome, as currently this is unknown, and to develop treatments to improve intelligence in those with the syndrome. Two efforts being studied are the use stem cells and gene therapy. Other methods being studied include the use of antioxidants, gamma secretase inhibition, adrenergic agonists, and memantine. Research is often carried out on an animal model, the Ts65Dn mouse.\nOther hominids.\nDown syndrome may also occur in hominids other than humans. In great apes chromosome 22 corresponds to the human chromosome 21 and thus trisomy 22 causes Down syndrome in apes. The condition was observed in a common chimpanzee in 1969 and a Bornean orangutan in 1979, but neither lived very long. The common chimpanzee Kanako (born around 1993, in Japan) has become the longest-lived known example of this condition. Kanako has some of the same symptoms that are common in human Down syndrome. It is unknown how common this condition is in chimps but it is plausible it could be roughly as common as Down syndrome is in humans."}
{"id": "8305", "revid": "40840686", "url": "https://en.wikipedia.org/wiki?curid=8305", "title": "Dyslexia", "text": "Dyslexia, also known as reading disorder, is characterized by trouble with reading despite normal intelligence. Different people are affected to different degrees. Problems may include difficulties in spelling words, reading quickly, writing words, \"sounding out\" words in the head, pronouncing words when reading aloud and understanding what one reads. Often these difficulties are first noticed at school. When someone who previously could read loses their ability, it is known as \"alexia\". The difficulties are involuntary and people with this disorder have a normal desire to learn. People with dyslexia have higher rates of attention deficit hyperactivity disorder (ADHD), developmental language disorders, and difficulties with numbers.\nDyslexia is believed to be caused by the interaction of genetic and environmental factors. Some cases run in families. Dyslexia that develops due to a traumatic brain injury, stroke, or dementia is called \"acquired dyslexia\". The underlying mechanisms of dyslexia are problems within the brain's language processing. Dyslexia is diagnosed through a series of tests of memory, vision, spelling, and reading skills. Dyslexia is separate from reading difficulties caused by hearing or vision problems or by insufficient teaching or opportunity to learn.\nTreatment involves adjusting teaching methods to meet the person's needs. While not curing the underlying problem, it may decrease the degree or impact of symptoms. Treatments targeting vision are not effective. Dyslexia is the most common learning disability and occurs in all areas of the world. It affects 3\u20137% of the population, however, up to 20% of the general population may have some degree of symptoms. While dyslexia is more often diagnosed in men, it has been suggested that it affects men and women equally. Some believe that dyslexia should be best considered as a different way of learning, with both benefits and downsides.\nClassification.\nDyslexia is divided into developmental and acquired forms. This article is primarily about \"developmental dyslexia\", i.e., dyslexia that begins in early childhood. Acquired dyslexia occurs subsequent to neurological insult, such as traumatic brain injury or stroke. People with acquired dyslexia exhibit some of the signs or symptoms of the developmental disorder, but requiring different assessment strategies and treatment approaches.\nSigns and symptoms.\nIn early childhood, symptoms that correlate with a later diagnosis of dyslexia include delayed onset of speech and a lack of phonological awareness. A common myth closely associates dyslexia with mirror writing and reading letters or words backwards. These behaviors are seen in many children as they learn to read and write, and are not considered to be defining characteristics of dyslexia.\nSchool-age children with dyslexia may exhibit signs of difficulty in identifying or generating rhyming words, or counting the number of syllables in words\u2013both of which depend on phonological awareness. They may also show difficulty in segmenting words into individual sounds or may blend sounds when producing words, indicating reduced phonemic awareness. Difficulties with word retrieval or naming things is also associated with dyslexia. People with dyslexia are commonly poor spellers, a feature sometimes called dysorthographia or dysgraphia, which depends on orthographic coding.\nProblems persist into adolescence and adulthood and may include difficulties with summarizing stories, memorization, reading aloud, or learning foreign languages. Adults with dyslexia can often read with good comprehension, though they tend to read more slowly than others without a learning difficulty and perform worse in spelling tests or when reading nonsense words\u2013a measure of phonological awareness.\nAssociated conditions.\nDyslexia often co-occurs with other learning disorders, but the reasons for this comorbidity have not been clearly identified. These associated disabilities include:\nCauses.\nResearchers have been trying to find the neurobiological basis of dyslexia since the condition was first identified in 1881. For example, some have tried to associate the common problem among people with dyslexia of not being able to see letters clearly to abnormal development of their visual nerve cells.\nNeuroanatomy.\nNeuroimaging techniques, such as functional magnetic resonance imaging (fMRI) and positron emission tomography (PET), have shown a correlation between both functional and structural differences in the brains of children with reading difficulties. Some people with dyslexia show less electrical activation in parts of the left hemisphere of the brain involved with reading, such as the inferior frontal gyrus, inferior parietal lobule, and the middle and ventral temporal cortex. Over the past decade, brain activation studies using PET to study language have produced a breakthrough in the understanding of the neural basis of language. Neural bases for the visual lexicon and for auditory verbal short-term memory components have been proposed, with some implication that the observed neural manifestation of developmental dyslexia is task-specific (i.e., functional rather than structural). fMRIs of people with dyslexia indicate an interactive role of the cerebellum and cerebral cortex as well as other brain structures in reading.\nThe cerebellar theory of dyslexia proposes that impairment of cerebellum-controlled muscle movement affects the formation of words by the tongue and facial muscles, resulting in the fluency problems that some people with dyslexia experience. The cerebellum is also involved in the automatization of some tasks, such as reading. The fact that some children with dyslexia have motor task and balance impairments could be consistent with a cerebellar role in their reading difficulties. However, the cerebellar theory has not been supported by controlled research studies.\nGenetics.\nResearch into potential genetic causes of dyslexia has its roots in post-autopsy examination of the brains of people with dyslexia. Observed anatomical differences in the language centers of such brains include microscopic cortical malformations known as ectopias, and more rarely, vascular micro-malformations, and microgyrus\u2014a smaller than usual size for the gyrus. The previously cited studies and others suggest that abnormal cortical development, presumed to occur before or during the sixth month of fetal brain development, may have caused the abnormalities. Abnormal cell formations in people with dyslexia have also been reported in non-language cerebral and subcortical brain structures. Several genes have been associated with dyslexia, including DCDC2 and KIAA0319 on chromosome 6, and DYX1C1 on chromosome 15.\nGene\u2013environment interaction.\nThe contribution of gene\u2013environment interaction to reading disability has been intensely studied using twin studies, which estimate the proportion of variance associated with a person's environment and the proportion associated with their genes. Both environmental and genetic factors appear to contribute to reading development. Studies examining the influence of environmental factors such as parental education and teaching quality have determined that genetics have greater influence in supportive, rather than less optimal, environments. However, more optimal conditions may just allow those genetic risk factors to account for more of the variance in outcome because the environmental risk factors have been minimized.\nAs environment plays a large role in learning and memory, it is likely that epigenetic modifications play an important role in reading ability. Measures of gene expression, histone modifications, and methylation in the human periphery are used to study epigenetic processes; however, all of these have limitations in the extrapolation of results for application to the human brain.\nLanguage.\nThe orthographic complexity of a language directly affects how difficult it is to learn to read it. English and French have comparatively \"deep\" phonemic orthographies within the Latin alphabet writing system, with complex structures employing spelling patterns on several levels: letter-sound correspondence, syllables, and morphemes. Languages such as Spanish, Italian and Finnish have mostly alphabetic orthographies, which primarily employ letter-sound correspondence\u2014so-called \"shallow\" orthographies\u2014which makes them easier to learn for people with dyslexia. Logographic writing systems, such as Chinese characters, have extensive symbol use; and these also pose problems for dyslexic learners.\nPathophysiology.\nMost people who are right-hand dominant have the left hemisphere of their brain specialize more in language processing. In terms of the mechanism of dyslexia, fMRI studies suggest that this specialization may be less pronounced or even absent in cases with dyslexia. Additionally, anatomical differences in the corpus callosum, the bundle of nerve fibers that connects the left and right hemispheres, have been linked to dyslexia via different studies.\nData via diffusion tensor MRI indicate changes in connectivity or in gray matter density in areas related to reading/language. Finally, the left inferior frontal gyrus has shown differences in phonological processing in people with dyslexia. Neurophysiological and imaging procedures are being used to ascertain phenotypic characteristics in people with dyslexia thus identifying the effects of certain genes.\nDual route theory.\nThe dual-route theory of reading aloud was first described in the early 1970s. This theory suggests that two separate mental mechanisms, or cognitive routes, are involved in reading aloud. One mechanism is the lexical route, which is the process whereby skilled readers can recognize known words by sight alone, through a \"dictionary\" lookup procedure. The other mechanism is the nonlexical or sublexical route, which is the process whereby the reader can \"sound out\" a written word. This is done by identifying the word's constituent parts (letters, phonemes, graphemes) and applying knowledge of how these parts are associated with each other, for example, how a string of neighboring letters sound together. The dual-route system could explain the different rates of dyslexia occurrence between different languages (e.g., the consistency of phonological rules in the Spanish language could account for the fact that Spanish-speaking children show a higher level of performance in non-word reading, when compared to English-speakers).\nDiagnosis.\nDyslexia is a heterogeneous, dimensional learning disorder that impairs accurate and fluent word reading and spelling. Typical\u2014but not universal\u2014features include difficulties with phonological awareness; inefficient and often inaccurate processing of sounds in oral language (\"phonological processing\"); and verbal working memory deficits.\nDyslexia is a neurodevelopmental disorder, subcategorized in diagnostic guides as a \"learning disorder with impairment in reading\" (ICD-11 prefixes \"developmental\" to \"learning disorder\"; DSM-5 uses \"specific\"). Dyslexia is not a problem with intelligence. Emotional problems often arise secondary to learning difficulties. The National Institute of Neurological Disorders and Stroke describes dyslexia as \"difficulty with phonological processing (the manipulation of sounds), spelling, and/or rapid visual-verbal responding\".\nThe British Dyslexia Association defines dyslexia as \"a learning difficulty that primarily affects the skills involved in accurate and fluent word reading and spelling\" and is characterized by \"difficulties in phonological awareness, verbal memory and verbal processing speed\". \"Phonological awareness\" enables one to identify, discriminate, remember (working memory), and mentally manipulate the sound structures of language\u2014phonemes, onsite-rime segments, syllables, and words.\nAssessment.\nAssessment tests.\nThere is a wide range of tests that are used in clinical and educational settings to evaluate the possibility that a person might have dyslexia. If initial testing suggests that a person might have dyslexia, such tests are often followed up with a full diagnostic assessment to determine the extent and nature of the disorder. Some tests can be administered by a teacher or computer; others require specialized training and are given by psychologists. Some test results indicate how to carry out teaching strategies. Because a variety of different cognitive, behavioral, emotional, and environmental factors all could contribute to difficultly learning to read, a comprehensive evaluation should consider these different possibilities. These tests and observations can include:\nScreening.\nScreening procedures seek to identify children who show signs of possible dyslexia. In the preschool years, a family history of dyslexia, particularly in biological parents and siblings, predicts an eventual dyslexia diagnosis better than any test. In primary school (ages 5\u20137), the ideal screening procedure consist of training primary school teachers to carefully observe and record their pupils' progress through the phonics curriculum, and thereby identify children progressing slowly. When teachers identify such students they can supplement their observations with screening tests such as the \"Phonics screening check\" used by United Kingdom schools during Year one.\nIn the medical setting, child and adolescent psychiatrist M. S. Thambirajah emphasizes that \"[g]iven the high prevalence of developmental disorders in school-aged children, all children seen in clinics should be systematically screened for developmental disorders irrespective of the presenting problem/s.\" Thambirajah recommends screening for developmental disorders, including dyslexia, by conducting a brief developmental history, a preliminary psychosocial developmental examination, and obtaining a school report regarding academic and social functioning.\nManagement.\nThrough the use of compensation strategies, therapy and educational support, individuals with dyslexia can learn to read and write. There are techniques and technical aids that help to manage or conceal symptoms of the disorder. Reducing stress and anxiety can sometimes improve written comprehension. For dyslexia intervention with alphabet-writing systems, the fundamental aim is to increase a child's awareness of correspondences between graphemes (letters) and phonemes (sounds), and to relate these to reading and spelling by teaching how sounds blend into words. Reinforced collateral training focused on reading and spelling may yield longer-lasting gains than oral phonological training alone. Early intervention can be successful in reducing reading failure.\nResearch does not suggest that specially-tailored fonts (such as Dyslexie and OpenDyslexic) help with reading. Children with dyslexia read text set in a regular font such as Times New Roman and Arial just as quickly, and they show a preference for regular fonts over specially-tailored fonts. Some research has pointed to increased letter-spacing being beneficial.\nThere is currently no evidence showing that music education significantly improves the reading skills of adolescents with dyslexia.\nPrognosis.\nDyslexic children require special instruction for word analysis and spelling from an early age. The prognosis, generally speaking, is positive for individuals who are identified in childhood and receive support from friends and family. The New York educational system (NYED) indicates \"a daily uninterrupted 90-minute block of instruction in reading\", furthermore \"instruction in phonemic awareness, phonics, vocabulary development, reading fluency\" so as to improve the individual's reading ability.\nEpidemiology.\nThe percentage of people with dyslexia is unknown, but it has been estimated to be as low as 5% and as high as 17% of the population. While it is diagnosed more often in males, some believe that it affects males and females equally.\nThere are different definitions of dyslexia used throughout the world, but despite significant differences in writing systems, dyslexia occurs in different populations. Dyslexia is not limited to difficulty in converting letters to sounds, and Chinese people with dyslexia may have difficulty converting Chinese characters into their meanings. The Chinese vocabulary uses logographic, monographic, non-alphabet writing where one character can represent an individual phoneme.\nThe phonological-processing hypothesis attempts to explain why dyslexia occurs in a wide variety of languages. Furthermore, the relationship between phonological capacity and reading appears to be influenced by orthography.\nHistory.\nDyslexia was clinically described by Oswald Berkhan in 1881, but the term \"dyslexia\" was coined in 1883 by Rudolf Berlin, an ophthalmologist in Stuttgart. He used the term to refer to the case of a young boy who had severe difficulty learning to read and write, despite showing typical intelligence and physical abilities in all other respects. In 1896, W. Pringle Morgan, a British physician from Seaford, East Sussex, published a description of a reading-specific learning disorder in a report to the \"British Medical Journal\" titled \"Congenital Word Blindness\". The distinction between phonological versus surface types of dyslexia is only descriptive, and without any etiological assumption as to the underlying brain mechanisms. However, studies have alluded to potential differences due to variation in performance.\nSociety and culture.\nAs is the case with any disorder, society often makes an assessment based on incomplete information. Before the 1980s, dyslexia was thought to be a consequence of education, rather than a neurological disability. As a result, society often misjudges those with the disorder. There is also sometimes a workplace stigma and negative attitude towards those with dyslexia. If the instructors of a person with dyslexia lack the necessary training to support a child with the condition, there is often a negative effect on the student's learning participation.\nSince at least the 1960s in the UK, the children diagnosed with developmental dyslexia have consistently been from privileged families. Although half of prisoners in the UK have significant reading difficulties, very few have ever been evaluated for dyslexia. Access to some special educational resources and funding is contingent upon having a diagnosis of dyslexia. As a result, when Staffordshire and Warwickshire proposed in 2018 to teach reading to all children with reading difficulties, using techniques proven to be successful for most children with a diagnosis of dyslexia, without first requiring the families to obtain an official diagnosis, dyslexia advocates and parents of children with dyslexia were fearful that they were losing a privileged status.\nResearch.\nMost dyslexia research relates to alphabetic writing systems, and especially to European languages. However, substantial research is also available regarding people with dyslexia who speak Arabic, Chinese, Hebrew, or other languages. The outward expression of individuals with reading disability and regular poor readers is the same in some respects."}
{"id": "8307", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=8307", "title": "Dyslectic", "text": ""}
{"id": "8308", "revid": "89336", "url": "https://en.wikipedia.org/wiki?curid=8308", "title": "Delft", "text": "Delft () is a city and municipality in the province of South Holland, Netherlands. It is located between Rotterdam, to the southeast, and The Hague, to the northwest. Together with them, it is part of both Rotterdam\u2013The Hague metropolitan area and the Randstad.\nDelft is a popular tourist destination in the Netherlands, famous for its historical connections with the reigning House of Orange-Nassau, for its blue pottery, for being home to the painter Jan Vermeer, and for hosting Delft University of Technology (TU Delft). Historically, Delft played a highly influential role in the Dutch Golden Age. In terms of science and technology, thanks to the pioneering contributions of Antonie van Leeuwenhoek and Martinus Beijerinck, Delft can be considered to be the birthplace of microbiology.\nHistory.\nEarly history.\nThe city of Delft came into being beside a canal, the 'Delf', which comes from the word \"delven\", meaning to delve or dig, and this led to the name Delft. At the elevated place where this 'Delf' crossed the creek wall of the silted up river Gantel, a Count established his manor, probably around 1075. Partly because of this, Delft became an important market town, the evidence for which can be seen in the size of its central market square.\nHaving been a rural village in the early Middle Ages, Delft developed into a city, and on 15 April 1246, Count Willem II granted Delft its city charter. Trade and industry flourished. In 1389 the Delfshavensche Schie canal was dug through to the river Maas, where the port of Delfshaven was built, connecting Delft to the sea.\nUntil the 17th century, Delft was one of the major cities of the then county (and later province) of Holland. In 1400, for example, the city had 6,500 inhabitants, making it the third largest city after Dordrecht (8,000) and Haarlem (7,000). In 1560, Amsterdam, with 28,000 inhabitants, had become the largest city, followed by Delft, Leiden and Haarlem, which each had around 14,000 inhabitants.\nIn 1536, a large part of the city was destroyed by the great fire of Delft.\nThe town's association with the House of Orange started when William of Orange (Willem van Oranje), nicknamed William the Silent (Willem de Zwijger), took up residence in 1572 in the former Saint-Agatha convent (subsequently called the Prinsenhof). At the time he was the leader of growing national Dutch resistance against Spanish occupation, known as the Eighty Years' War. By then Delft was one of the leading cities of Holland and it was equipped with the necessary city walls to serve as a headquarters. In October 1573, an attack by Spanish forces was repelled in the Battle of Delft.\nAfter the Act of Abjuration was proclaimed in 1581, Delft became the \"de facto\" capital of the newly independent Netherlands, as the seat of the Prince of Orange.\nWhen William was shot dead on 10 July 1584 by Balthazar Gerards in the hall of the Prinsenhof (now the Prinsenhof Museum), the family's traditional burial place in Breda was still in the hands of the Spanish. Therefore, he was buried in the Delft Nieuwe Kerk (New Church), starting a tradition for the House of Orange that has continued to the present day.\nAround this time, Delft also occupied a prominent position in the field of printing.\nA number of Italian glazed earthenware makers settled in the city and introduced a new style. The tapestry industry also flourished when famous manufacturer Fran\u00e7ois Spierincx moved to the city. In the 17th century, Delft experienced a new heyday, thanks to the presence of an office of the Dutch East India Company (VOC) (opened in 1602) and the manufacture of Delft Blue china.\nA number of notable artists based themselves in the city, including Leonard Bramer, Carel Fabritius, Pieter de Hoogh, Gerard Houckgeest, Emanuel de Witte, Jan Steen, and Johannes Vermeer.\nReinier de Graaf and Antonie van Leeuwenhoek received international attention for their scientific research.\nDelft Explosion.\nThe Delft Explosion, also known in history as the Delft Thunderclap, occurred on 12 October 1654 when a gunpowder store exploded, destroying much of the city. Over a hundred people were killed and thousands were injured.\nAbout of gunpowder were stored in barrels in a magazine in a former Clarist convent in the Doelenkwartier district, where the Paardenmarkt is now located. Cornelis Soetens, the keeper of the magazine, opened the store to check a sample of the powder and a huge explosion followed. Luckily, many citizens were away, visiting a market in Schiedam or a fair in The Hague.\nToday, the explosion is primarily remembered for killing Rembrandt's most promising pupil, Carel Fabritius, and destroying almost all of his works.\nDelft artist Egbert van der Poel painted several pictures of Delft showing the devastation.\nThe gunpowder store was subsequently re-housed, a 'cannonball's distance away', outside the city, in a new building designed by architect Pieter Post.\nSights.\nThe city centre retains a large number of monumental buildings, while in many streets there are canals of which the banks are connected by typical bridges, altogether making this city a notable tourist destination.\nHistorical buildings and other sights of interest include:\nCulture.\nDelft is well known for the Delft pottery ceramic products which were styled on the imported Chinese porcelain of the 17th century. The city had an early start in this area since it was a home port of the Dutch East India Company. It can still be seen at the pottery factories De Koninklijke Porceleyne Fles (or Royal Delft) and De Delftse Pauw, while new ceramics and ceramic art can be found at the Gallery Terra Delft.\nThe painter Johannes Vermeer (1632\u20131675) was born in Delft. Vermeer used Delft streets and home interiors as the subject or background in his paintings.\nSeveral other famous painters lived and worked in Delft at that time, such as Pieter de Hoogh, Carel Fabritius, Nicolaes Maes, Gerard Houckgeest and Hendrick Cornelisz. van Vliet. They were all members of the Delft School. The Delft School is known for its images of domestic life and views of households, church interiors, courtyards, squares and the streets of Delft. The painters also produced pictures showing historic events, flowers, portraits for patrons and the court as well as decorative pieces of art.\nDelft supports creative arts companies. From 2001 the , a building that had been disused since 1951, began to house small companies in the creative arts sector. However, demolition of the building started in December 2009, making way for the construction of the new railway tunnel in Delft. The occupants of the building, as well as the name 'Bacinol', moved to another building in the city. The name Bacinol relates to Dutch penicillin research during WWII.\nEducation.\nDelft University of Technology (TU Delft) is one of four universities of technology in the Netherlands. It was founded as an academy for civil engineering in 1842 by King William II. Today well over 21,000 students are enrolled.\nThe UNESCO-IHE Institute for Water Education, providing postgraduate education for people from developing countries, draws on the strong tradition in water management and hydraulic engineering of the Delft university.\nEconomy.\nIn the local economic field essential elements are:\nNature and recreation.\nEast of Delft lies a relatively large nature and recreation area called the \"Delftse Hout\" (\"Delft Wood\"). Through the forest lie bike, horse-riding and footpaths. It also includes a vast lake (suitable for swimming and windsurfing), narrow beaches, a restaurant, and community gardens, plus camping ground and other recreational and sports facilities. (There is also a facility for renting bikes from the station.)\nInside the city, apart from a central park, there are several smaller town parks, including \"Nieuwe Plantage\", \"Agnetapark\", \"Kalverbos\".\nThere is also the Botanical Garden of the TU and an arboretum in Delftse Hout.\nNotable people.\nDelft was the birthplace of:\nInternational relations.\nTwin towns \u2014 Sister cities.\nDelft is twinned with:\nTransport.\nTrains stopping at these stations connect Delft with, among others, the nearby cities of Rotterdam and The Hague, as often as every five minutes, for most of the day.\nThere are several bus routes from Delft to similar destinations. Trams frequently travel between Delft and The Hague via special double tracks crossing the city."}
{"id": "8309", "revid": "1535071", "url": "https://en.wikipedia.org/wiki?curid=8309", "title": "Duesberg hypothesis", "text": "The Duesberg hypothesis is the claim, associated with University of California, Berkeley professor Peter Duesberg, that various noninfectious factors such as but not limited to, recreational and pharmaceutical drug use are the cause of AIDS, and that HIV (human immunodeficiency virus) is merely a harmless passenger virus. The scientific consensus is that the Duesberg hypothesis is incorrect and that HIV is the cause of AIDS. The most prominent supporters of this hypothesis are Duesberg himself, biochemist vitamin proponent David Rasnick, and journalist Celia Farber. The scientific community contends that Duesberg's arguments are the result of cherry-picking predominantly outdated scientific data and selectively ignoring evidence in favor of HIV's role in AIDS.\nRole of legal and illegal drug use.\nDuesberg argues that there is a statistical correlation between trends in recreational drug use and trends in AIDS cases. He argues that the epidemic of AIDS cases in the 1980s corresponds to a supposed epidemic of recreational drug use in the United States and Europe during the same time frame.\nThese claims are not supported by epidemiologic data. The average yearly increase in opioid-related deaths from 1990 to 2002 was nearly three times the yearly increase from 1979\u201390, with the greatest increase in 2000\u201302, yet AIDS cases and deaths fell dramatically during the mid-to-late-1990s. Duesberg's claim that recreational drug use, rather than HIV, was the cause of AIDS has been specifically examined and found to be false. Cohort studies have found that only HIV-positive drug users develop opportunistic infections; HIV-negative drug users do not develop such infections, indicating that HIV rather than drug use is the cause of AIDS.\nDuesberg has also argued that nitrite inhalants were the cause of the epidemic of Kaposi sarcoma (KS) in gay men. However, this argument has been described as an example of the fallacy of a statistical confounding effect; it is now known that a herpesvirus, potentiated by HIV, is responsible for AIDS-associated KS.\nMoreover, in addition to recreational drugs, Duesberg argues that anti-HIV drugs such as zidovudine (AZT) can cause AIDS. Duesberg's claim that antiviral medication causes AIDS is regarded as disproven by the scientific community. Placebo-controlled studies have found that AZT as a single agent produces modest and short-lived improvements in survival and delays the development of opportunistic infections; it certainly did not cause AIDS, which develops in both treated and untreated study patients. With the subsequent development of protease inhibitors and highly active antiretroviral therapy, numerous studies have documented the fact that anti-HIV drugs prevent the development of AIDS and substantially prolong survival, further disproving the claim that these drugs \"cause\" AIDS.\nScientific study and rejection of Duesberg's risk-AIDS hypothesis.\nSeveral studies have specifically addressed Duesberg's claim that recreational drug abuse or sexual promiscuity were responsible for the manifestations of AIDS. An early study of his claims, published in \"Nature\" in 1993, found Duesberg's drug abuse-AIDS hypothesis to have \"no basis in fact.\"\nA large prospective study followed a group of 715 homosexual men in the Vancouver, Canada, area; approximately half were HIV-seropositive or became so during the follow-up period, and the remainder were HIV-seronegative. After more than 8 years of follow-up, despite similar rates of drug use, sexual contact, and other supposed risk factors in both groups, only the HIV-positive group suffered from opportunistic infections. Similarly, CD4 counts dropped in the patients who were HIV-infected, but remained stable in the HIV-negative patients, despite similar rates of risk behavior. The authors concluded that \"the risk-AIDS hypothesis ... is clearly rejected by our data,\" and that \"the evidence supports the hypothesis that HIV-1 has an integral role in the CD4 depletion and progressive immune dysfunction that characterise AIDS.\"\nSimilarly, the Multicenter AIDS Cohort Study (MACS) and the Women's Interagency HIV Study (WIHS)\u2014which between them observed more than 8,000 Americans\u2014demonstrated that \"the presence of HIV infection is the only factor that is strongly and consistently associated with the conditions that define AIDS.\" A 2008 study found that recreational drug use (including cannabis, cocaine, poppers, and amphetamines) had no effect on CD4 or CD8 T-cell counts, providing further evidence against a role of recreational drugs as a cause of AIDS.\nCurrent AIDS definitions.\nDuesberg argued in 1989 that a significant number of AIDS victims had died without proof of HIV infection. However, with the use of modern culture techniques and polymerase chain reaction testing, HIV can be demonstrated in virtually all patients with AIDS. Since AIDS is now defined partially by the presence of HIV, Duesberg claims it is impossible by definition to offer evidence that AIDS doesn't require HIV. However, the first definitions of AIDS mentioned no cause and the first AIDS diagnoses were made before HIV was discovered. The addition of HIV positivity to surveillance criteria as an absolutely necessary condition for case reporting occurred only in 1993, after a scientific consensus was established that HIV caused AIDS.\nAIDS in Africa.\nAccording to the Duesberg hypothesis, AIDS is not found in Africa. What Duesberg calls \"the myth of an African AIDS epidemic,\" among people\" exists for several reasons, including:\nDuesberg states that African AIDS cases are \"a collection of long-established, indigenous diseases, such as chronic fevers, weight loss, alias \"slim disease,\" diarrhea, and tuberculosis\" that result from malnutrition and poor sanitation. African AIDS cases, though, have increased in the last three decades as HIV's prevalence has increased but as malnutrition percentages and poor sanitation have declined in many African regions. In addition, while HIV and AIDS are more prevalent in urban than in rural settings in Africa, malnutrition and poor sanitation are found more commonly in rural than in urban settings.\nAccording to Duesberg, common diseases are easily misdiagnosed as AIDS in Africa because \"the diagnosis of African AIDS is arbitrary\" and does not include HIV testing. A definition of AIDS agreed upon in 1985 by the World Health Organization in Bangui did not require a positive HIV test, but since 1985, many African countries have added positive HIV tests to the Bangui criteria for AIDS or changed their definitions to match those of the U.S. Centers for Disease Control. One of the reasons for using more HIV tests despite their expense is that, rather than overestimating AIDS as Duesberg suggests, the Bangui definition alone excluded nearly half of African AIDS patients.\"\nDuesberg notes that diseases associated with AIDS differ between African and Western populations, concluding that the causes of immunodeficiency must be different. Tuberculosis is much more commonly diagnosed among AIDS patients in Africa than in Western countries, while PCP conforms to the opposite pattern. Tuberculosis, though, had higher prevalence in Africa than in the West before the spread of HIV. In Africa and the United States, HIV has spurred a similar percentage increase in tuberculosis cases. PCP may be underestimated in Africa: since machinery \"required for accurate testing is relatively rare in many resource-poor areas, including large parts of Africa, PCP is likely to be underdiagnosed in Africa. Consistent with this hypothesis, studies that report the highest rates of PCP in Africa are those that use the most advanced diagnostic methods\" Duesberg also claims that Kaposi's Sarcoma is \"exclusively diagnosed in male homosexual risk groups using nitrite inhalants and other psychoactive drugs as aphrodisiacs\", but the cancer is fairly common among heterosexuals in some parts of Africa, and is found in heterosexuals in the United States as well.\nBecause reported AIDS cases in Africa and other parts of the developing world include a larger proportion of people who do not belong to Duesberg's preferred risk groups of drug addicts and male homosexuals, Duesberg writes on his website that \"There are no risk groups in Africa, like drug addicts and homosexuals.\" However, many studies have addressed the issue of risk groups in Africa and concluded that the risk of AIDS is not equally distributed. In addition, AIDS in Africa largely kills sexually active working-age adults.\nSouth African president Thabo Mbeki accepted Duesberg's hypothesis and, through the mid-2000s, rejected offers of medical assistance to fight HIV infection, a policy of inaction that cost over 300,000 lives.\nDuesberg claims that retroviruses like HIV must be harmless to survive.\nDuesberg argues that retroviruses like HIV must be harmless to survive: they do not kill cells and they do not cause cancer, he maintains. Duesberg writes, \"retroviruses do not kill cells because they depend on viable cells for the replication of their RNA from viral DNA integrated into cellular DNA.\" Duesberg elsewhere states that \"the typical virus reproduces by entering a living cell and commandeering the cell's resources in order to make new virus particles, a process that ends with the disintegration of the dead cell.\"\nDuesberg also rejects the involvement of retroviruses and other viruses in cancer. To him, virus-associated cancers are \"freak accidents of nature\" that do not warrant research programs such as the war on cancer. Duesberg rejects a role in cancer for numerous viruses, including leukemia viruses, Epstein\u2013Barr virus, human papilloma virus, hepatitis B, feline leukemia virus, and human T-lymphotropic virus.\nDuesberg claims that the supposedly innocuous nature of all retroviruses is supported by what he considers to be their normal mode of proliferation: infection from mother to child \"in utero\". Duesberg does not suggest that HIV is an endogenous retrovirus, a virus integrated into the germline and genetically heritable:\nScientific response to the Duesberg hypothesis.\nThe consensus in the scientific community is that the Duesberg hypothesis has been refuted by a large and growing mass of evidence showing that HIV causes AIDS, that the amount of virus in the blood correlates with disease progression, that a plausible mechanism for HIV's action has been proposed, and that anti-HIV medication decreases mortality and opportunistic infection in people with AIDS.\nIn the 9 December 1994 issue of \"Science\" (Vol. 266, No. 5191), Duesberg's methods and claims were evaluated in a group of articles. The authors concluded that\nEffectiveness of antiretroviral medication.\nThe vast majority of people with AIDS have never received antiretroviral drugs, including those in developed countries prior to the licensure of AZT (zidovudine) in 1987, and people in developing countries today where very few individuals have access to these medications.\nThe NIAID reports that \"in the mid-1980s, clinical trials enrolling patients with AIDS found that AZT given as single-drug therapy conferred a modest survival advantage compared [with] placebo. Among HIV-infected patients who had not yet developed AIDS, placebo-controlled trials found that AZT given as single-drug therapy delayed, for a year or two, the onset of AIDS-related illnesses. Significantly, long-term follow-up of these trials did not show a prolonged benefit of AZT, but also did not indicate that the drug increased disease progression or mortality. The lack of excess AIDS cases and death in the AZT arms of these placebo-controlled trials in effect counters the argument that AZT causes AIDS. Subsequent clinical trials found that patients receiving two-drug combinations had up to 50 percent improvements in time to progression to AIDS and in survival when compared with people receiving single-drug therapy. In more recent years, three-drug combination therapies have produced another 50 to 80 percent improvement in progression to AIDS and in survival when compared with two-drug regimens in clinical trials.\" \"Use of potent anti-HIV combination therapies has contributed to dramatic reductions in the incidence of AIDS and AIDS-related deaths in populations where these drugs are widely available, an effect which clearly would not be seen if antiretroviral drugs caused AIDS.\"\nOpponents claim that nearly all HIV-positive people will develop AIDS.\nDuesberg claims as support for his idea that many drug-free HIV-positive people have not yet developed AIDS; HIV/AIDS scientists note that many drug-free HIV-positive people have developed AIDS, and that, in the absence of medical treatment or rare genetic factors postulated to delay disease progression, it is very likely that nearly all HIV-positive people will eventually develop AIDS. Scientists also note that HIV-negative drug users do not suffer from immune system collapse."}
{"id": "8310", "revid": "952495450", "url": "https://en.wikipedia.org/wiki?curid=8310", "title": "DSL (disambiguation)", "text": "DSL or digital subscriber line is a family of technologies that provide digital data transmission over the wires of a local telephone network.\nDSL may also refer to:"}
{"id": "8311", "revid": "37179761", "url": "https://en.wikipedia.org/wiki?curid=8311", "title": "Dinosaur", "text": "Dinosaurs are a diverse group of reptiles of the clade Dinosauria. They first appeared during the Triassic period, between 243 and 233.23\u00a0million years ago, although the exact origin and timing of the evolution of dinosaurs is the subject of active research. They became the dominant terrestrial vertebrates after the Triassic\u2013Jurassic extinction event 201.3\u00a0million years ago; their dominance continued throughout the Jurassic and Cretaceous periods. The fossil record shows that birds are modern feathered dinosaurs, having evolved from earlier theropods during the Late Jurassic epoch, and are the only dinosaur lineage to survive the Cretaceous\u2013Paleogene extinction event approximately 66\u00a0million years ago. Dinosaurs can therefore be divided into avian dinosaurs, or birds; and the extinct non-avian dinosaurs, which are all dinosaurs other than birds.\nDinosaurs are a varied group of animals from taxonomic, morphological and ecological standpoints. Birds, at over 10,700 living species, are among the most diverse group of vertebrates. Using fossil evidence, paleontologists have identified over 900 distinct genera and more than 1,000 different species of non-avian dinosaurs. Dinosaurs are represented on every continent by both extant species (birds) and fossil remains. Through the first half of the 20th century, before birds were recognized as dinosaurs, most of the scientific community believed dinosaurs to have been sluggish and cold-blooded. Most research conducted since the 1970s, however, has indicated that dinosaurs were active animals with elevated metabolisms and numerous adaptations for social interaction. Some were herbivorous, others carnivorous. Evidence suggests that all dinosaurs were egg-laying; and that nest-building was a trait shared by many dinosaurs, both avian and non-avian.\nWhile dinosaurs were ancestrally bipedal, many extinct groups included quadrupedal species, and some were able to shift between these stances. Elaborate display structures such as horns or crests are common to all dinosaur groups, and some extinct groups developed skeletal modifications such as bony armor and spines. While the dinosaurs' modern-day surviving avian lineage (birds) are generally small due to the constraints of flight, many prehistoric dinosaurs (non-avian and avian) were large-bodied\u2014the largest sauropod dinosaurs are estimated to have reached lengths of and heights of and were the largest land animals of all time. The misconception that non-avian dinosaurs were uniformly gigantic is based in part on preservation bias, as large, sturdy bones are more likely to last until they are fossilized. Many dinosaurs were quite small, some measuring about in length.\nThe first dinosaur fossils were recognized in the early 19th century, with the name \"dinosaur\" (meaning \"terrible lizard\") having been coined by Sir Richard Owen in 1841 to refer to these \"great fossil lizards\". Since then, mounted fossil dinosaur skeletons have been major attractions at museums worldwide, and dinosaurs have become an enduring part of popular culture. The large sizes of some dinosaurs, as well as their seemingly monstrous and fantastic nature, have ensured their regular appearance in best-selling books and films, such as \"Jurassic Park\". Persistent public enthusiasm for the animals has resulted in significant funding for dinosaur science, and new discoveries are regularly covered by the media.\nDefinition.\nUnder phylogenetic nomenclature, dinosaurs are usually defined as the group consisting of the most recent common ancestor (MRCA) of \"Triceratops\" and modern birds (Neornithes), and all its descendants. It has also been suggested that Dinosauria be defined with respect to the MRCA of \"Megalosaurus\" and \"Iguanodon\", because these were two of the three genera cited by Richard Owen when he recognized the Dinosauria. Both definitions result in the same set of animals being defined as dinosaurs: \"Dinosauria = Ornithischia + Saurischia\". This definition includes major groups such as ankylosaurians (armored herbivorous quadrupeds), stegosaurians (plated herbivorous quadrupeds), ceratopsians (bipedal or quadrupedal herbivores with neck frills), pachycephalosaurians (bipedal herbivores with thick skulls), ornithopods (bipedal or quadrupedal herbivores including \"duck-bills\"), theropods (mostly bipedal carnivores and birds), and sauropodomorphs (mostly large herbivorous quadrupeds with long necks and tails).\nBirds are now recognized as being the sole surviving lineage of theropod dinosaurs. In traditional taxonomy, birds were considered a separate class that had evolved from dinosaurs, a distinct superorder. However, a majority of contemporary paleontologists concerned with dinosaurs reject the traditional style of classification in favor of phylogenetic taxonomy; this approach requires that, for a group to be natural, all descendants of members of the group must be included in the group as well. Birds are thus considered to be dinosaurs and dinosaurs are, therefore, not extinct. Birds are classified as belonging to the subgroup Maniraptora, which are coelurosaurs, which are theropods, which are saurischians, which are dinosaurs.\nResearch by Matthew G. Baron, David B. Norman, and Paul M. Barrett in 2017 suggested a radical revision of dinosaurian systematics. Phylogenetic analysis by Baron \"et al.\" recovered the Ornithischia as being closer to the Theropoda than the Sauropodomorpha, as opposed to the traditional union of theropods with sauropodomorphs. They resurrected the clade Ornithoscelida to refer to the group containing Ornithischia and Theropoda. Dinosauria itself was re-defined as the last common ancestor of \"Triceratops horridus\", \"Passer domesticus\" and \"Diplodocus carnegii\", and all of its descendants, to ensure that sauropods and kin remain included as dinosaurs.\nGeneral description.\nUsing one of the above definitions, dinosaurs can be generally described as archosaurs with hind limbs held erect beneath the body. Other prehistoric animals, including pterosaurs, mosasaurs, ichthyosaurs, plesiosaurs, and \"Dimetrodon\", while often popularly conceived of as dinosaurs, are not taxonomically classified as dinosaurs. Pterosaurs are distantly related to dinosaurs, being members of the clade Ornithodira. The other groups mentioned are, like dinosaurs and pterosaurs, members of Sauropsida (the reptile and bird clade), except \"Dimetrodon\" (which is a synapsid). None of them had the erect hind limb posture characteristic of true dinosaurs. \nDinosaurs were the dominant terrestrial vertebrates of the Mesozoic Era, especially the Jurassic and Cretaceous periods. Other groups of animals were restricted in size and niches; mammals, for example, rarely exceeded the size of a domestic cat, and were generally rodent-sized carnivores of small prey. They have always been recognized as an extremely varied group of animals; over 900 non-avian dinosaur genera have been identified with certainty as of 2018, and the total number of genera preserved in the fossil record has been estimated at around 1850, nearly 75% of which remain to be discovered, and 1124 species by 2016. A 1995 study predicted that about 3,400 dinosaur genera ever existed, including many that would not have been preserved in the fossil record.\nIn 2016, the estimated number of dinosaur species that existed in the Mesozoic was 1,543\u20132,468. In 2021, the number of modern-day birds (avian dinosaurs) was estimated to be at 10,806 species. Some are herbivorous, others carnivorous, including seed-eaters, fish-eaters, insectivores, and omnivores. While dinosaurs were ancestrally bipedal (as are all modern birds), some prehistoric species were quadrupeds, and others, such as \"Anchisaurus\" and \"Iguanodon\", could walk just as easily on two or four legs. Cranial modifications like horns and crests are common dinosaurian traits, and some extinct species had bony armor. Although known for large size, many Mesozoic dinosaurs were human-sized or smaller, and modern birds are generally small in size. Dinosaurs today inhabit every continent, and fossils show that they had achieved global distribution by at least the Early Jurassic epoch. Modern birds inhabit most available habitats, from terrestrial to marine, and there is evidence that some non-avian dinosaurs (such as \"Microraptor\") could fly or at least glide, and others, such as spinosaurids, had semiaquatic habits.\nDistinguishing anatomical features.\nWhile recent discoveries have made it more difficult to present a universally agreed-upon list of their distinguishing features, nearly all dinosaurs discovered so far share certain modifications to the ancestral archosaurian skeleton, or are clearly descendants of older dinosaurs showing these modifications. Although some later groups of dinosaurs featured further modified versions of these traits, they are considered typical for Dinosauria; the earliest dinosaurs had them and passed them on to their descendants. Such modifications, originating in the most recent common ancestor of a certain taxonomic group, are called the synapomorphies of such a group.\nA detailed assessment of archosaur interrelations by Sterling Nesbitt confirmed or found the following twelve unambiguous synapomorphies, some previously known:\nNesbitt found a number of further potential synapomorphies and discounted a number of synapomorphies previously suggested. Some of these are also present in silesaurids, which Nesbitt recovered as a sister group to Dinosauria, including a large anterior trochanter, metatarsals II and IV of subequal length, reduced contact between ischium and pubis, the presence of a cnemial crest on the tibia and of an ascending process on the astragalus, and many others.\nA variety of other skeletal features are shared by dinosaurs. However, because they are either common to other groups of archosaurs or were not present in all early dinosaurs, these features are not considered to be synapomorphies. For example, as diapsids, dinosaurs ancestrally had two pairs of Infratemporal fenestrae (openings in the skull behind the eyes), and as members of the diapsid group Archosauria, had additional openings in the snout and lower jaw. Additionally, several characteristics once thought to be synapomorphies are now known to have appeared before dinosaurs, or were absent in the earliest dinosaurs and independently evolved by different dinosaur groups. These include an elongated scapula, or shoulder blade; a sacrum composed of three or more fused vertebrae (three are found in some other archosaurs, but only two are found in \"Herrerasaurus\"); and a perforate acetabulum, or hip socket, with a hole at the center of its inside surface (closed in \"Saturnalia tupiniquim\", for example). Another difficulty of determining distinctly dinosaurian features is that early dinosaurs and other archosaurs from the Late Triassic epoch are often poorly known and were similar in many ways; these animals have sometimes been misidentified in the literature.\nDinosaurs stand with their hind limbs erect in a manner similar to most modern mammals, but distinct from most other reptiles, whose limbs sprawl out to either side. This posture is due to the development of a laterally facing recess in the pelvis (usually an open socket) and a corresponding inwardly facing distinct head on the femur. Their erect posture enabled early dinosaurs to breathe easily while moving, which likely permitted stamina and activity levels that surpassed those of \"sprawling\" reptiles. Erect limbs probably also helped support the evolution of large size by reducing bending stresses on limbs. Some non-dinosaurian archosaurs, including rauisuchians, also had erect limbs but achieved this by a \"pillar-erect\" configuration of the hip joint, where instead of having a projection from the femur insert on a socket on the hip, the upper pelvic bone was rotated to form an overhanging shelf.\nHistory of study.\nPre-scientific history.\nDinosaur fossils have been known for millennia, although their true nature was not recognized. The Chinese considered them to be dragon bones and documented them as such. For example, \"Huayang Guo Zhi\"\u00a0(), a gazetteer compiled by Chang Qu\u00a0() during the Western Jin Dynasty (265\u2013316), reported the discovery of dragon bones at Wucheng in Sichuan Province. Villagers in central China have long unearthed fossilized \"dragon bones\" for use in traditional medicines. In Europe, dinosaur fossils were generally believed to be the remains of giants and other biblical creatures.\nEarly dinosaur research.\nScholarly descriptions of what would now be recognized as dinosaur bones first appeared in the late 17th century in England. Part of a bone, now known to have been the femur of a \"Megalosaurus\", was recovered from a limestone quarry at Cornwell near Chipping Norton, Oxfordshire, in 1676. The fragment was sent to Robert Plot, Professor of Chemistry at the University of Oxford and first curator of the Ashmolean Museum, who published a description in his \"The Natural History of Oxford-shire\" (1677). He correctly identified the bone as the lower extremity of the femur of a large animal, and recognized that it was too large to belong to any known species. He, therefore, concluded it to be the femur of a huge human, perhaps a Titan or another type of giant featured in legends. Edward Lhuyd, a friend of Sir Isaac Newton, published \"Lithophylacii Britannici ichnographia\" (1699), the first scientific treatment of what would now be recognized as a dinosaur when he described and named a sauropod tooth, \"Rutellum impicatum\", that had been found in Caswell, near Witney, Oxfordshire.\nBetween 1815 and 1824, the Rev William Buckland, the first Reader of Geology at the University of Oxford, collected more fossilized bones of \"Megalosaurus\" and became the first person to describe a non-avian dinosaur in a scientific journal. The second non-avian dinosaur genus to be identified, \"Iguanodon\", was discovered in 1822 by Mary Ann Mantell\u00a0\u2013 the wife of English geologist Gideon Mantell. Gideon Mantell recognized similarities between his fossils and the bones of modern iguanas. He published his findings in 1825.\nThe study of these \"great fossil lizards\" soon became of great interest to European and American scientists, and in 1841 the English paleontologist Sir Richard Owen coined the term \"dinosaur\", using it to refer to the \"distinct tribe or sub-order of Saurian Reptiles\" that were then being recognized in England and around the world. The term is derived . Though the taxonomic name has often been interpreted as a reference to dinosaurs' teeth, claws, and other fearsome characteristics, Owen intended it to also evoke their size and majesty. Owen recognized that the remains that had been found so far, \"Iguanodon\", \"Megalosaurus\" and \"Hylaeosaurus\", shared a number of distinctive features, and so decided to present them as a distinct taxonomic group. With the backing of Prince Albert, the husband of Queen Victoria, Owen established the Natural History Museum, London, to display the national collection of dinosaur fossils and other biological and geological exhibits.\nDiscoveries in North America.\nIn 1858, William Parker Foulke discovered the first known American dinosaur, in marl pits in the small town of Haddonfield, New Jersey. (Although fossils had been found before, their nature had not been correctly discerned.) The creature was named \"Hadrosaurus foulkii\". It was an extremely important find: \"Hadrosaurus\" was one of the first nearly complete dinosaur skeletons found (the first was in 1834, in Maidstone, England), and it was clearly a bipedal creature. This was a revolutionary discovery as, until that point, most scientists had believed dinosaurs walked on four feet, like other lizards. Foulke's discoveries sparked a wave of interests in dinosaurs in the United States, known as dinosaur mania.\nDinosaur mania was exemplified by the fierce rivalry between Edward Drinker Cope and Othniel Charles Marsh, both of whom raced to be the first to find new dinosaurs in what came to be known as the Bone Wars. This fight between the two scientists lasted for over 30 years, ending in 1897 when Cope died after spending his entire fortune on the dinosaur hunt. Unfortunately, many valuable dinosaur specimens were damaged or destroyed due to the pair's rough methods: for example, their diggers often used dynamite to unearth bones. Modern paleontologists would find such methods crude and unacceptable, since blasting easily destroys fossil and stratigraphic evidence. Despite their unrefined methods, the contributions of Cope and Marsh to paleontology were vast: Marsh unearthed 86 new species of dinosaur and Cope discovered 56, a total of 142 new species. Cope's collection is now at the American Museum of Natural History, while Marsh's is at the Peabody Museum of Natural History at Yale University.\n\"Dinosaur renaissance\" and beyond.\nThe field of dinosaur research has enjoyed a surge in activity that began in the 1970s and is ongoing. This was triggered, in part, by John Ostrom's discovery and 1969 description of \"Deinonychus\", an active predator that may have been warm-blooded, in marked contrast to the then-prevailing image of dinosaurs as sluggish and cold-blooded. Vertebrate paleontology has become a global science. Major new dinosaur discoveries have been made by paleontologists working in previously unexploited regions, including India, South America, Madagascar, Antarctica, and most significantly China (the well-preserved feathered dinosaurs in China have further consolidated the link between dinosaurs and their living descendants, modern birds). The widespread application of cladistics, which rigorously analyzes the relationships between biological organisms, has also proved tremendously useful in classifying dinosaurs. Cladistic analysis, among other modern techniques, helps to compensate for an often incomplete and fragmentary fossil record.\nSoft tissue and DNA.\nOne of the best examples of soft-tissue impressions in a fossil dinosaur was discovered in the Pietraroia Plattenkalk in southern Italy. The discovery was reported in 1998, and described the specimen of a small, juvenile coelurosaur, \"Scipionyx samniticus\". The fossil includes portions of the intestines, colon, liver, muscles, and windpipe of this dinosaur.\nIn the March 2005 issue of \"Science\", the paleontologist Mary Higby Schweitzer and her team announced the discovery of flexible material resembling actual soft tissue inside a 68-million-year-old \"Tyrannosaurus rex\" leg bone from the Hell Creek Formation in Montana. After recovery, the tissue was rehydrated by the science team. When the fossilized bone was treated over several weeks to remove mineral content from the fossilized bone-marrow cavity (a process called demineralization), Schweitzer found evidence of intact structures such as blood vessels, bone matrix, and connective tissue (bone fibers). Scrutiny under the microscope further revealed that the putative dinosaur soft tissue had retained fine structures (microstructures) even at the cellular level. The exact nature and composition of this material, and the implications of Schweitzer's discovery, are not yet clear.\nIn 2009, a team including Schweitzer announced that, using even more careful methodology, they had duplicated their results by finding similar soft tissue in a duck-billed dinosaur, \"Brachylophosaurus canadensis\", found in the Judith River Formation of Montana. This included even more detailed tissue, down to preserved bone cells that seem to have visible remnants of nuclei and what seem to be red blood cells. Among other materials found in the bone was collagen, as in the \"Tyrannosaurus\" bone. The type of collagen an animal has in its bones varies according to its DNA and, in both cases, this collagen was of the same type found in modern chickens and ostriches.\nThe extraction of ancient DNA from dinosaur fossils has been reported on two separate occasions; upon further inspection and peer review, however, neither of these reports could be confirmed. However, a functional peptide involved in the vision of a theoretical dinosaur has been inferred using analytical phylogenetic reconstruction methods on gene sequences of related modern species such as reptiles and birds. In addition, several proteins, including hemoglobin, have putatively been detected in dinosaur fossils.\nIn 2015, researchers reported finding structures similar to blood cells and collagen fibers, preserved in the bone fossils of six Cretaceous dinosaur specimens, which are approximately 75\u00a0million years old.\nEvolutionary history.\nOrigins and early evolution.\nDinosaurs diverged from their archosaur ancestors during the Middle to Late Triassic epochs, roughly 20\u00a0million years after the devastating Permian\u2013Triassic extinction event wiped out an estimated 96% of all marine species and 70% of terrestrial vertebrate species approximately 252\u00a0million years ago. Radiometric dating of the Ischigualasto Formation of Argentina where the early dinosaur genus \"Eoraptor\" was found date it as 231.4\u00a0million years old. \"Eoraptor\" is thought to resemble the common ancestor of all dinosaurs; if this is true, its traits suggest that the first dinosaurs were small, bipedal predators. The discovery of primitive, dinosaur-like ornithodirans such as \"Lagosuchus\" and \"Lagerpeton\" in Argentina in the Carnian epoch of the Triassic, around 233\u00a0million years ago, supports this view; analysis of recovered fossils suggests that these animals were indeed small, bipedal predators. Dinosaurs may have appeared as early as the Anisian epoch of the Triassic, 245\u00a0million years ago, as evidenced by remains of the genus \"Nyasasaurus\" from that period. However, its known fossils are too fragmentary to tell if it was a dinosaur or only a close relative. Paleontologist Max C. Langer \"et al.\" (2018) determined that \"Staurikosaurus\" from the Santa Maria Formation dates to 233.23\u00a0million years ago, making it older in geologic age than \"Eoraptor\".\nWhen dinosaurs appeared, they were not the dominant terrestrial animals. The terrestrial habitats were occupied by various types of archosauromorphs and therapsids, like cynodonts and rhynchosaurs. Their main competitors were the pseudosuchians, such as aetosaurs, ornithosuchids and rauisuchians, which were more successful than the dinosaurs. Most of these other animals became extinct in the Triassic, in one of two events. First, at about 215\u00a0million years ago, a variety of basal archosauromorphs, including the protorosaurs, became extinct. This was followed by the Triassic\u2013Jurassic extinction event (about 201\u00a0million years ago), that saw the end of most of the other groups of early archosaurs, like aetosaurs, ornithosuchids, phytosaurs, and rauisuchians. Rhynchosaurs and dicynodonts survived (at least in some areas) at least as late as early\u200a\u2013mid Norian and late Norian or earliest Rhaetian stages, respectively, and the exact date of their extinction is uncertain. These losses left behind a land fauna of crocodylomorphs, dinosaurs, mammals, pterosaurians, and turtles. The first few lines of early dinosaurs diversified through the Carnian and Norian stages of the Triassic, possibly by occupying the niches of the groups that became extinct. Also notably, there was a heightened rate of extinction during the Carnian Pluvial Event.\nEvolution and paleobiogeography.\nDinosaur evolution after the Triassic followed changes in vegetation and the location of continents. In the Late Triassic and Early Jurassic, the continents were connected as the single landmass Pangaea, and there was a worldwide dinosaur fauna mostly composed of coelophysoid carnivores and early sauropodomorph herbivores. Gymnosperm plants (particularly conifers), a potential food source, radiated in the Late Triassic. Early sauropodomorphs did not have sophisticated mechanisms for processing food in the mouth, and so must have employed other means of breaking down food farther along the digestive tract. The general homogeneity of dinosaurian faunas continued into the Middle and Late Jurassic, where most localities had predators consisting of ceratosaurians, megalosauroids, and allosauroids, and herbivores consisting of stegosaurian ornithischians and large sauropods. Examples of this include the Morrison Formation of North America and Tendaguru Beds of Tanzania. Dinosaurs in China show some differences, with specialized metriacanthosaurid theropods and unusual, long-necked sauropods like \"Mamenchisaurus\". Ankylosaurians and ornithopods were also becoming more common, but primitive sauropodomorphs had become extinct. Conifers and pteridophytes were the most common plants. Sauropods, like earlier sauropodomorphs, were not oral processors, but ornithischians were evolving various means of dealing with food in the mouth, including potential cheek-like organs to keep food in the mouth, and jaw motions to grind food. Another notable evolutionary event of the Jurassic was the appearance of true birds, descended from maniraptoran coelurosaurians.\nBy the Early Cretaceous and the ongoing breakup of Pangaea, dinosaurs were becoming strongly differentiated by landmass. The earliest part of this time saw the spread of ankylosaurians, iguanodontians, and brachiosaurids through Europe, North America, and northern Africa. These were later supplemented or replaced in Africa by large spinosaurid and carcharodontosaurid theropods, and rebbachisaurid and titanosaurian sauropods, also found in South America. In Asia, maniraptoran coelurosaurians like dromaeosaurids, troodontids, and oviraptorosaurians became the common theropods, and ankylosaurids and early ceratopsians like \"Psittacosaurus\" became important herbivores. Meanwhile, Australia was home to a fauna of basal ankylosaurians, hypsilophodonts, and iguanodontians. The stegosaurians appear to have gone extinct at some point in the late Early Cretaceous or early Late Cretaceous. A major change in the Early Cretaceous, which would be amplified in the Late Cretaceous, was the evolution of flowering plants. At the same time, several groups of dinosaurian herbivores evolved more sophisticated ways to orally process food. Ceratopsians developed a method of slicing with teeth stacked on each other in batteries, and iguanodontians refined a method of grinding with dental batteries, taken to its extreme in hadrosaurids. Some sauropods also evolved tooth batteries, best exemplified by the rebbachisaurid \"Nigersaurus\".\nThere were three general dinosaur faunas in the Late Cretaceous. In the northern continents of North America and Asia, the major theropods were tyrannosaurids and various types of smaller maniraptoran theropods, with a predominantly ornithischian herbivore assemblage of hadrosaurids, ceratopsians, ankylosaurids, and pachycephalosaurians. In the southern continents that had made up the now-splitting supercontinent Gondwana, abelisaurids were the common theropods, and titanosaurian sauropods the common herbivores. Finally, in Europe, dromaeosaurids, rhabdodontid iguanodontians, nodosaurid ankylosaurians, and titanosaurian sauropods were prevalent. Flowering plants were greatly radiating, with the first grasses appearing by the end of the Cretaceous. Grinding hadrosaurids and shearing ceratopsians became very diverse across North America and Asia. Theropods were also radiating as herbivores or omnivores, with therizinosaurians and ornithomimosaurians becoming common.\nThe Cretaceous\u2013Paleogene extinction event, which occurred approximately 66\u00a0million years ago at the end of the Cretaceous, caused the extinction of all dinosaur groups except for the neornithine birds. Some other diapsid groups, such as crocodilians, sebecosuchians, turtles, lizards, snakes, sphenodontians, and choristoderans, also survived the event.\nThe surviving lineages of neornithine birds, including the ancestors of modern ratites, ducks and chickens, and a variety of waterbirds, diversified rapidly at the beginning of the Paleogene period, entering ecological niches left vacant by the extinction of Mesozoic dinosaur groups such as the arboreal enantiornithines, aquatic hesperornithines, and even the larger terrestrial theropods (in the form of \"Gastornis\", eogruiids, bathornithids, ratites, geranoidids, mihirungs, and \"terror birds\"). It is often stated that mammals out-competed the neornithines for dominance of most terrestrial niches but many of these groups co-existed with rich mammalian faunas for most of the Cenozoic Era. Terror birds and bathornithids occupied carnivorous guilds alongside predatory mammals, and ratites are still fairly successful as mid-sized herbivores; eogruiids similarly lasted from the Eocene to Pliocene, only becoming extinct very recently after over 20\u00a0million years of co-existence with many mammal groups.\nClassification.\nDinosaurs belong to a group known as archosaurs, which also includes modern crocodilians. Within the archosaur group, dinosaurs are differentiated most noticeably by their gait. Dinosaur legs extend directly beneath the body, whereas the legs of lizards and crocodilians sprawl out to either side.\nCollectively, dinosaurs as a clade are divided into two primary branches, Saurischia and Ornithischia. Saurischia includes those taxa sharing a more recent common ancestor with birds than with Ornithischia, while Ornithischia includes all taxa sharing a more recent common ancestor with \"Triceratops\" than with Saurischia. Anatomically, these two groups can be distinguished most noticeably by their pelvic structure. Early saurischians\u2014\"lizard-hipped\", from the Greek \"sauros\" (\u03c3\u03b1\u1fe6\u03c1\u03bf\u03c2) meaning \"lizard\" and \"ischion\" (\u1f30\u03c3\u03c7\u03af\u03bf\u03bd) meaning \"hip joint\"\u2014retained the hip structure of their ancestors, with a pubis bone directed cranially, or forward. This basic form was modified by rotating the pubis backward to varying degrees in several groups (\"Herrerasaurus\", therizinosauroids, dromaeosaurids, and birds). Saurischia includes the theropods (exclusively bipedal and with a wide variety of diets) and sauropodomorphs (long-necked herbivores which include advanced, quadrupedal groups).\nBy contrast, ornithischians\u2014\"bird-hipped\", from the Greek \"ornitheios\" (\u1f40\u03c1\u03bd\u03af\u03b8\u03b5\u03b9\u03bf\u03c2) meaning \"of a bird\" and \"ischion\" (\u1f30\u03c3\u03c7\u03af\u03bf\u03bd) meaning \"hip joint\"\u2014had a pelvis that superficially resembled a bird's pelvis: the pubic bone was oriented caudally (rear-pointing). Unlike birds, the ornithischian pubis also usually had an additional forward-pointing process. Ornithischia includes a variety of species that were primarily herbivores. Despite the terms \"bird hip\" and \"lizard hip\", birds are not part of Ornithischia, but rather Saurischia\u2014birds evolved from earlier dinosaurs with \"lizard hips\".\nTaxonomy.\nThe following is a simplified classification of dinosaur groups based on their evolutionary relationships, and organized based on the list of Mesozoic dinosaur species provided by Holtz (2007). A more detailed version can be found at Dinosaur classification.\nThe dagger (\u2020) is used to signify groups with no living members.\nPaleobiology.\nKnowledge about dinosaurs is derived from a variety of fossil and non-fossil records, including fossilized bones, feces, trackways, gastroliths, feathers, impressions of skin, internal organs and other soft tissues. Many fields of study contribute to our understanding of dinosaurs, including physics (especially biomechanics), chemistry, biology, and the Earth sciences (of which paleontology is a sub-discipline). Two topics of particular interest and study have been dinosaur size and behavior.\nSize.\nCurrent evidence suggests that dinosaur average size varied through the Triassic, Early Jurassic, Late Jurassic and Cretaceous. Predatory theropod dinosaurs, which occupied most terrestrial carnivore niches during the Mesozoic, most often fall into the category when sorted by estimated weight into categories based on order of magnitude, whereas recent predatory carnivoran mammals peak in the category. The mode of Mesozoic dinosaur body masses is between . This contrasts sharply with the average size of Cenozoic mammals, estimated by the National Museum of Natural History as about .\nThe sauropods were the largest and heaviest dinosaurs. For much of the dinosaur era, the smallest sauropods were larger than anything else in their habitat, and the largest was an order of magnitude more massive than anything else that has since walked the Earth. Giant prehistoric mammals such as \"Paraceratherium\" (the largest land mammal ever) were dwarfed by the giant sauropods, and only modern whales approach or surpass them in size. There are several proposed advantages for the large size of sauropods, including protection from predation, reduction of energy use, and longevity, but it may be that the most important advantage was dietary. Large animals are more efficient at digestion than small animals, because food spends more time in their digestive systems. This also permits them to subsist on food with lower nutritive value than smaller animals. Sauropod remains are mostly found in rock formations interpreted as dry or seasonally dry, and the ability to eat large quantities of low-nutrient browse would have been advantageous in such environments.\nLargest and smallest.\nScientists will probably never be certain of the largest and smallest dinosaurs to have ever existed. This is because only a tiny percentage of animals were ever fossilized and most of these remain buried in the earth. Few of the specimens that are recovered are complete skeletons, and impressions of skin and other soft tissues are rare. Rebuilding a complete skeleton by comparing the size and morphology of bones to those of similar, better-known species is an inexact art, and reconstructing the muscles and other organs of the living animal is, at best, a process of educated guesswork.\nThe tallest and heaviest dinosaur known from good skeletons is \"Giraffatitan brancai\" (previously classified as a species of \"Brachiosaurus\"). Its remains were discovered in Tanzania between 1907 and 1912. Bones from several similar-sized individuals were incorporated into the skeleton now mounted and on display at the Museum f\u00fcr Naturkunde in Berlin; this mount is tall and long, and would have belonged to an animal that weighed between and \u00a0kilograms ( and \u00a0lb). The longest complete dinosaur is the long \"Diplodocus\", which was discovered in Wyoming in the United States and displayed in Pittsburgh's Carnegie Museum of Natural History in 1907. The longest dinosaur known from good fossil material is the \"Patagotitan\": the skeleton mount in the American Museum of Natural History in New York is long. The Museo Municipal Carmen Funes in Plaza Huincul, Argentina, has an \"Argentinosaurus\" reconstructed skeleton mount that is long.\nThere were larger dinosaurs, but knowledge of them is based entirely on a small number of fragmentary fossils. Most of the largest herbivorous specimens on record were discovered in the 1970s or later, and include the massive \"Argentinosaurus\", which may have weighed to \u00a0kilograms (90 to 110\u00a0short tons) and reached lengths of ; some of the longest were the long \"Diplodocus hallorum\" (formerly \"Seismosaurus\"), the long \"Supersaurus\", and long \"Patagotitan\"; and the tallest, the tall \"Sauroposeidon\", which could have reached a sixth-floor window. The heaviest and longest dinosaur may have been \"Maraapunisaurus\", known only from a now lost partial vertebral neural arch described in 1878. Extrapolating from the illustration of this bone, the animal may have been long and weighed kg ( lb). However, as no further evidence of sauropods of this size has been found, and the discoverer, Cope, had made typographic errors before, it is likely to have been an extreme overestimation.\nThe largest carnivorous dinosaur was \"Spinosaurus\", reaching a length of , and weighing . Other large carnivorous theropods included \"Giganotosaurus\", \"Carcharodontosaurus\" and \"Tyrannosaurus\". \"Therizinosaurus\" and \"Deinocheirus\" were among the tallest of the theropods. The largest ornithischian dinosaur was probably the hadrosaurid \"Shantungosaurus giganteus\" which measured . The largest individuals may have weighed as much as .\nThe smallest dinosaur known is the bee hummingbird, with a length of only and mass of around . The smallest known non-avialan dinosaurs were about the size of pigeons and were those theropods most closely related to birds. For example, \"Anchiornis huxleyi\" is currently the smallest non-avialan dinosaur described from an adult specimen, with an estimated weight of and a total skeletal length of . The smallest herbivorous non-avialan dinosaurs included \"Microceratus\" and \"Wannanosaurus\", at about long each.\nBehavior.\nMany modern birds are highly social, often found living in flocks. There is general agreement that some behaviors that are common in birds, as well as in crocodiles (closest living relatives of birds), were also common among extinct dinosaur groups. Interpretations of behavior in fossil species are generally based on the pose of skeletons and their habitat, computer simulations of their biomechanics, and comparisons with modern animals in similar ecological niches.\nThe first potential evidence for herding or flocking as a widespread behavior common to many dinosaur groups in addition to birds was the 1878 discovery of 31\u00a0\"Iguanodon\", ornithischians that were then thought to have perished together in Bernissart, Belgium, after they fell into a deep, flooded sinkhole and drowned. Other mass-death sites have been discovered subsequently. Those, along with multiple trackways, suggest that gregarious behavior was common in many early dinosaur species. Trackways of hundreds or even thousands of herbivores indicate that duck-billed (hadrosaurids) may have moved in great herds, like the American bison or the African Springbok. Sauropod tracks document that these animals traveled in groups composed of several different species, at least in Oxfordshire, England, although there is no evidence for specific herd structures. Congregating into herds may have evolved for defense, for migratory purposes, or to provide protection for young. There is evidence that many types of slow-growing dinosaurs, including various theropods, sauropods, ankylosaurians, ornithopods, and ceratopsians, formed aggregations of immature individuals. One example is a site in Inner Mongolia that has yielded remains of over 20 \"Sinornithomimus\", from one to seven years old. This assemblage is interpreted as a social group that was trapped in mud. The interpretation of dinosaurs as gregarious has also extended to depicting carnivorous theropods as pack hunters working together to bring down large prey. However, this lifestyle is uncommon among modern birds, crocodiles, and other reptiles, and the taphonomic evidence suggesting mammal-like pack hunting in such theropods as \"Deinonychus\" and \"Allosaurus\" can also be interpreted as the results of fatal disputes between feeding animals, as is seen in many modern diapsid predators.\nThe crests and frills of some dinosaurs, like the marginocephalians, theropods and lambeosaurines, may have been too fragile to be used for active defense, and so they were likely used for sexual or aggressive displays, though little is known about dinosaur mating and territorialism. Head wounds from bites suggest that theropods, at least, engaged in active aggressive confrontations.\nFrom a behavioral standpoint, one of the most valuable dinosaur fossils was discovered in the Gobi Desert in 1971. It included a \"Velociraptor\" attacking a \"Protoceratops\", providing evidence that dinosaurs did indeed attack each other. Additional evidence for attacking live prey is the partially healed tail of an \"Edmontosaurus\", a hadrosaurid dinosaur; the tail is damaged in such a way that shows the animal was bitten by a tyrannosaur but survived. Cannibalism amongst some species of dinosaurs was confirmed by tooth marks found in Madagascar in 2003, involving the theropod \"Majungasaurus\".\nComparisons between the scleral rings of dinosaurs and modern birds and reptiles have been used to infer daily activity patterns of dinosaurs. Although it has been suggested that most dinosaurs were active during the day, these comparisons have shown that small predatory dinosaurs such as dromaeosaurids, \"Juravenator\", and \"Megapnosaurus\" were likely nocturnal. Large and medium-sized herbivorous and omnivorous dinosaurs such as ceratopsians, sauropodomorphs, hadrosaurids, ornithomimosaurs may have been cathemeral, active during short intervals throughout the day, although the small ornithischian \"Agilisaurus\" was inferred to be diurnal.\nBased on fossil evidence from dinosaurs such as \"Oryctodromeus\", some ornithischian species seem to have led a partially fossorial (burrowing) lifestyle. Many modern birds are arboreal (tree climbing), and this was also true of many Mesozoic birds, especially the enantiornithines. While some early bird-like species may have already been arboreal as well (including dromaeosaurids] such as \"Microraptor\") most non-avialan dinosaurs seem to have relied on land-based locomotion. A good understanding of how dinosaurs moved on the ground is key to models of dinosaur behavior; the science of biomechanics, pioneered by Robert McNeill Alexander, has provided significant insight in this area. For example, studies of the forces exerted by muscles and gravity on dinosaurs' skeletal structure have investigated how fast dinosaurs could run, whether diplodocids could create sonic booms via whip-like tail snapping, and whether sauropods could float.\nCommunication.\nModern birds are known to communicate using visual and auditory signals, and the wide diversity of visual display structures among fossil dinosaur groups, such as horns, frills, crests, sails, and feathers, suggests that visual communication has always been important in dinosaur biology. Reconstruction of the plumage color of \"Anchiornis\", suggest the importance of color in visual communication in non-avian dinosaurs. The evolution of dinosaur vocalization is less certain. Paleontologist Phil Senter has suggested that non-avian dinosaurs relied mostly on visual displays and possibly non-vocal acoustic sounds like hissing, jaw grinding or clapping, splashing and wing beating (possible in winged maniraptoran dinosaurs). He states they were unlikely to have been capable of vocalizing since their closest relatives, crocodilians and birds, use different means to vocalize, the former via the larynx and the latter through the unique syrinx, suggesting they evolved independently and their common ancestor was mute.\nThe earliest remains of a syrinx, which has enough mineral content for fossilization, was found in a specimen of the duck-like \"Vegavis iaai\" dated 69\u200a\u201366\u00a0million years ago, and this organ is unlikely to have existed in non-avian dinosaurs. However, in contrast to Senter, other researchers have suggested that dinosaurs could vocalize and that the syrinx-based vocal system of birds evolved from a larynx-based one, rather than the two systems evolving independently. A 2016 study suggests that dinosaurs produced closed mouth vocalizations like cooing, which occur in both crocodilians and birds as well as other reptiles. Such vocalizations evolved independently in extant archosaurs numerous times, following increases in body size. The crests of the Lambeosaurini and nasal chambers of ankylosaurids have been suggested to have functioned in vocal resonance, though Senter stated that the presence of resonance chambers in some dinosaurs is not necessarily evidence of vocalization as modern snakes have such chambers which intensify their hisses.\nReproductive biology.\nAll dinosaurs laid amniotic eggs with hard shells made mostly of calcium carbonate. Dinosaur eggs were usually laid in a nest. Most species create somewhat elaborate nests which can be cups, domes, plates, beds scrapes, mounds, or burrows. Some species of modern bird have no nests; the cliff-nesting common guillemot lays its eggs on bare rock, and male emperor penguins keep eggs between their body and feet. Primitive birds and many non-avialan dinosaurs often lay eggs in communal nests, with males primarily incubating the eggs. While modern birds have only one functional oviduct and lay one egg at a time, more primitive birds and dinosaurs had two oviducts, like crocodiles. Some non-avialan dinosaurs, such as \"Troodon\", exhibited iterative laying, where the adult might lay a pair of eggs every one or two days, and then ensured simultaneous hatching by delaying brooding until all eggs were laid.\nWhen laying eggs, females grow a special type of bone between the hard outer bone and the marrow of their limbs. This medullary bone, which is rich in calcium, is used to make eggshells. A discovery of features in a \"Tyrannosaurus\" skeleton provided evidence of medullary bone in extinct dinosaurs and, for the first time, allowed paleontologists to establish the sex of a fossil dinosaur specimen. Further research has found medullary bone in the carnosaur \"Allosaurus\" and the ornithopod \"Tenontosaurus\". Because the line of dinosaurs that includes \"Allosaurus\" and \"Tyrannosaurus\" diverged from the line that led to \"Tenontosaurus\" very early in the evolution of dinosaurs, this suggests that the production of medullary tissue is a general characteristic of all dinosaurs.\nAnother widespread trait among modern birds (but see below in regards to fossil groups and extant megapodes) is parental care for young after hatching. Jack Horner's 1978 discovery of a \"Maiasaura\" (\"good mother lizard\") nesting ground in Montana demonstrated that parental care continued long after birth among ornithopods. A specimen of the oviraptorid \"Citipati osmolskae\" was discovered in a chicken-like brooding position in 1993, which may indicate that they had begun using an insulating layer of feathers to keep the eggs warm. An embryo of the basal sauropodomorph \"Massospondylus\" was found without teeth, indicating that some parental care was required to feed the young dinosaurs. Trackways have also confirmed parental behavior among ornithopods from the Isle of Skye in northwestern Scotland.\nHowever, there is ample evidence of precociality or superprecociality among many dinosaur species, particularly theropods. For instance, non-ornithuromorph birds have been abundantly demonstrated to have had slow growth rates, megapode-like egg burying behavior and the ability to fly soon after birth. Both \"Tyrannosaurus\" and \"Troodon\" had juveniles with clear superprecociality and likely occupying different ecological niches than the adults. Superprecociality has been inferred for sauropods.\nGenital structures are unlikely to fossilize as they lack scales that may allow preservation via pigmentation or residual calcium phosphate salts. In 2021, the best preserved specimen of a dinosaur's cloacal vent exterior was described for \"Psittacosaurus\", demonstrating lateral swellings similar to crocodylian musk glands used in social displays by both sexes and pigmented regions which could also reflect a signalling function. However, this specimen on its own does not offer enough information to determine whether this dinosaur had sexual signalling functions; it only supports the possibility. Cloacal visual signalling can occur in either males or females in living birds, making it unlikely to be useful to determine sex for extinct dinosaurs.\nPhysiology.\nBecause both modern crocodilians and birds have four-chambered hearts (albeit modified in crocodilians), it is likely that this is a trait shared by all archosaurs, including all dinosaurs. While all modern birds have high metabolisms and are endothermic (\"warm-blooded\"), a vigorous debate has been ongoing since the 1960s regarding how far back in the dinosaur lineage this trait extended. Various researchers have supported dinosaurs as being endothermic, ectothermic (\"cold-blooded\"), or somewhere in between. An emerging consensus among researchers is that, while different lineages of dinosaurs would have had different metabolisms, most of them had higher metabolic rates than other reptiles but lower than living birds and mammals, which is termed mesothermy by some. Evidence from crocodiles and their extinct relatives suggests that such elevated metabolisms could have developed in the earliest archosaurs, which were the common ancestors of dinosaurs and crocodiles.\nAfter non-avian dinosaurs were discovered, paleontologists first posited that they were ectothermic. This was used to imply that the ancient dinosaurs were relatively slow, sluggish organisms, even though many modern reptiles are fast and light-footed despite relying on external sources of heat to regulate their body temperature. The idea of dinosaurs as ectothermic remained a prevalent view until Robert T. Bakker, an early proponent of dinosaur endothermy, published an influential paper on the topic in 1968. Bakker specifically used anatomical and ecological evidence to argue that sauropods, which had hitherto been depicted as sprawling aquatic animals with their tails dragging on the ground, were endotherms that lived vigorous, terrestrial lives. In 1972, Bakker expanded on his arguments based on energy requirements and predator-prey ratios. This was one of the seminal results that led to the Dinosaur Renaissance (see ).\nOne of the greatest contributions to the modern understanding of dinosaur physiology has been paleohistology, the study of microscopic tissue structure in dinosaurs. From the 1960s forward, Armand de Ricql\u00e8s suggested that the presence of fibrolamellar bone\u2014bony tissue with an irregular, fibrous texture and filled with blood vessels\u2014was indicative of consistently fast growth and therefore endothermy. Fibrolamellar bone was common in both dinosaurs and pterosaurs, though not universally present. This has led to a significant body of work in reconstructing growth curves and modeling the evolution of growth rates across various dinosaur lineages, which has suggested overall that dinosaurs grew faster than living reptiles. Other lines of evidence suggesting endothermy include the presence of feathers and other types of body coverings in many lineages (see ); more consistent ratios of the isotope oxygen-18 in bony tissue compared to ectotherms, particularly as latitude and thus air temperature varied, which suggests stable internal temperatures (although these ratios can be altered during fossilization); and the discovery of polar dinosaurs, which lived in Australia, Antarctica, and Alaska when these places would have had cool, temperate climates.\nIn saurischian dinosaurs, higher metabolisms were supported by the evolution of the avian respiratory system, characterized by an extensive system of air sacs that extended the lungs and invaded many of the bones in the skeleton, making them hollow. Such respiratory systems, which may have appeared in the earliest saurischians, would have provided them with more oxygen compared to a mammal of similar size, while also having a larger resting tidal volume and requiring a lower breathing frequency, which would have allowed them to sustain higher activity levels. The rapid airflow would also have been an effective cooling mechanism, which in conjunction with a lower metabolic rate would have prevented large sauropods from overheating. These traits may have enabled sauropods to grow quickly to gigantic sizes. Sauropods may also have benefitted from their size\u2014their small surface area to volume ratio meant that they would have been able to thermoregulate more easily, a phenomenon termed gigantothermy.\nLike other reptiles, dinosaurs are primarily uricotelic, that is, their kidneys extract nitrogenous wastes from their bloodstream and excrete it as uric acid instead of urea or ammonia via the ureters into the intestine. This would have helped them to conserve water. In most living species, uric acid is excreted along with feces as a semisolid waste. However, at least some modern birds (such as hummingbirds) can be facultatively ammonotelic, excreting most of the nitrogenous wastes as ammonia. This material, as well as the output of the intestines, emerges from the cloaca. In addition, many species regurgitate pellets, and fossil pellets are known as early as the Jurassic from \"Anchiornis\".\nOrigin of birds.\nThe possibility that dinosaurs were the ancestors of birds was first suggested in 1868 by Thomas Henry Huxley. After the work of Gerhard Heilmann in the early 20th century, the theory of birds as dinosaur descendants was abandoned in favor of the idea of them being descendants of generalized thecodonts, with the key piece of evidence being the supposed lack of clavicles in dinosaurs. However, as later discoveries showed, clavicles (or a single fused wishbone, which derived from separate clavicles) were not actually absent; they had been found as early as 1924 in \"Oviraptor\", but misidentified as an interclavicle. In the 1970s, Ostrom revived the dinosaur\u2013bird theory, which gained momentum in the coming decades with the advent of cladistic analysis, and a great increase in the discovery of small theropods and early birds. Of particular note have been the fossils of the Yixian Formation, where a variety of theropods and early birds have been found, often with feathers of some type. Birds share over a hundred distinct anatomical features with theropod dinosaurs, which are now generally accepted to have been their closest ancient relatives. They are most closely allied with maniraptoran coelurosaurs. A minority of scientists, most notably Alan Feduccia and Larry Martin, have proposed other evolutionary paths, including revised versions of Heilmann's basal archosaur proposal, or that maniraptoran theropods are the ancestors of birds but themselves are not dinosaurs, only convergent with dinosaurs.\nFeathers.\nFeathers are one of the most recognizable characteristics of modern birds, and a trait that was also shared by several non-avian dinosaurs. Based on the current distribution of fossil evidence, it appears that feathers were an ancestral dinosaurian trait, though one that may have been selectively lost in some species. Direct fossil evidence of feathers or feather-like structures has been discovered in a diverse array of species in many non-avian dinosaur groups, both among saurischians and ornithischians. Simple, branched, feather-like structures are known from heterodontosaurids, primitive neornithischians, and theropods, and primitive ceratopsians. Evidence for true, vaned feathers similar to the flight feathers of modern birds has been found only in the theropod subgroup Maniraptora, which includes oviraptorosaurs, troodontids, dromaeosaurids, and birds. Feather-like structures known as pycnofibres have also been found in pterosaurs, suggesting the possibility that feather-like filaments may have been common in the bird lineage and evolved before the appearance of dinosaurs themselves. Research into the genetics of American alligators has also revealed that crocodylian scutes do possess feather-keratins during embryonic development, but these keratins are not expressed by the animals before hatching.\n\"Archaeopteryx\" was the first fossil found that revealed a potential connection between dinosaurs and birds. It is considered a transitional fossil, in that it displays features of both groups. Brought to light just two years after Charles Darwin's seminal \"On the Origin of Species\" (1859), its discovery spurred the nascent debate between proponents of evolutionary biology and creationism. This early bird is so dinosaur-like that, without a clear impression of feathers in the surrounding rock, at least one specimen was mistaken for the small theropod \"Compsognathus\". Since the 1990s, a number of additional feathered dinosaurs have been found, providing even stronger evidence of the close relationship between dinosaurs and modern birds. Most of these specimens were unearthed in the lagerst\u00e4tte of the Yixian Formation, Liaoning, northeastern China, which was part of an island continent during the Cretaceous. Though feathers have been found in only a few locations, it is possible that non-avian dinosaurs elsewhere in the world were also feathered. The lack of widespread fossil evidence for feathered non-avian dinosaurs may be because delicate features like skin and feathers are seldom preserved by fossilization and thus often absent from the fossil record.\nThe description of feathered dinosaurs has not been without controversy; perhaps the most vocal critics have been Alan Feduccia and Theagarten Lingham-Soliar, who have proposed that some purported feather-like fossils are the result of the decomposition of collagenous fiber that underlaid the dinosaurs' skin, and that maniraptoran dinosaurs with vaned feathers were not actually dinosaurs, but convergent with dinosaurs. However, their views have for the most part not been accepted by other researchers, to the point that the scientific nature of Feduccia's proposals has been questioned.\nSkeleton.\nBecause feathers are often associated with birds, feathered dinosaurs are often touted as the missing link between birds and dinosaurs. However, the multiple skeletal features also shared by the two groups represent another important line of evidence for paleontologists. Areas of the skeleton with important similarities include the neck, pubis, wrist (semi-lunate carpal), arm and pectoral girdle, furcula (wishbone), and breast bone. Comparison of bird and dinosaur skeletons through cladistic analysis strengthens the case for the link.\nSoft anatomy.\nLarge meat-eating dinosaurs had a complex system of air sacs similar to those found in modern birds, according to a 2005 investigation led by Patrick M. O'Connor. The lungs of theropod dinosaurs (carnivores that walked on two legs and had bird-like feet) likely pumped air into hollow sacs in their skeletons, as is the case in birds. \"What was once formally considered unique to birds was present in some form in the ancestors of birds\", O'Connor said. In 2008, scientists described \"Aerosteon riocoloradensis\", the skeleton of which supplies the strongest evidence to date of a dinosaur with a bird-like breathing system. CT scanning of \"Aerosteon\"'s fossil bones revealed evidence for the existence of air sacs within the animal's body cavity.\nBehavioral evidence.\nFossils of the troodonts \"Mei\" and \"Sinornithoides\" demonstrate that some dinosaurs slept with their heads tucked under their arms. This behavior, which may have helped to keep the head warm, is also characteristic of modern birds. Several deinonychosaur and oviraptorosaur specimens have also been found preserved on top of their nests, likely brooding in a bird-like manner. The ratio between egg volume and body mass of adults among these dinosaurs suggest that the eggs were primarily brooded by the male, and that the young were highly precocial, similar to many modern ground-dwelling birds.\nSome dinosaurs are known to have used gizzard stones like modern birds. These stones are swallowed by animals to aid digestion and break down food and hard fibers once they enter the stomach. When found in association with fossils, gizzard stones are called gastroliths.\nExtinction of major groups.\nAll non-avian dinosaurs and most lineages of birds became extinct in a mass extinction event, called the Cretaceous\u2013Paleogene (K-Pg) extinction event, at the end of the Cretaceous period. Above the Cretaceous-Paleogene boundary, which has been dated to 66.038 \u00b1 0.025 million years ago, fossils of non-avian dinosaurs disappear abruptly; the absence of dinosaur fossils was historically used to assign rocks to the ensuing Cenozoic. The nature of the event that caused this mass extinction has been extensively studied since the 1970s, leading to the development of two mechanisms that are thought to have played major roles: an extraterrestrial impact event in the Yucat\u00e1n Peninsula, along with flood basalt volcanism in India. However, the specific mechanisms of the extinction event and the extent of its effects on dinosaurs are still areas of ongoing research. Alongside dinosaurs, many other groups of animals became extinct: pterosaurs, marine reptiles such as mosasaurs and plesiosaurs, several groups of mammals, ammonites (nautilus-like mollusks), rudists (reef-building bivalves), and various groups of marine plankton. In all, approximately 47% of genera and 76% of species on Earth became extinct during the K-Pg extinction event. The relatively large size of most dinosaurs and the low diversity of small-bodied dinosaur species at the end of the Cretaceous may have contributed to their extinction; the extinction of the bird lineages that did not survive may also have been caused by a dependence on forest habitats or a lack of adaptations to eating seeds for survival.\nPre-extinction diversity.\nJust before the K-Pg extinction event, the number of non-avian dinosaur species that existed globally has been estimated at between 628 and 1078. It remains uncertain whether the diversity of dinosaurs was in gradual decline before the K-Pg extinction event, or whether dinosaurs were actually thriving prior to the extinction. Rock formations from the Maastrichtian epoch, which directly preceded the extinction, have been found to have lower diversity than the preceding Campanian epoch, which led to the prevailing view of a long-term decline in diversity. However, these comparisons did not account either for varying preservation potential between rock units or for different extents of exploration and excavation. In 1984, Dale Russell carried out an analysis to account for these biases, and found no evidence of a decline; another analysis by David Fastovsky and colleagues in 2004 even showed that dinosaur diversity continually increased until the extinction, but this analysis has been rebutted. Since then, different approaches based on statistics and mathematical models have variously supported either a sudden extinction or a gradual decline. End-Cretaceous trends in diversity may have varied between dinosaur lineages: it has been suggested that sauropods were not in decline, while ornithischians and theropods were in decline.\nImpact event.\nThe bolide impact hypothesis, first brought to wide attention in 1980 by Walter Alvarez, Luis Alvarez, and colleagues, attributes the K-Pg extinction event to a bolide (extraterrestrial projectile) impact. Alvarez and colleagues proposed that a sudden increase in iridium levels, recorded around the world in rock deposits at the Cretaceous-Paleogene boundary, was direct evidence of the impact. Shocked quartz, indicative of a strong shockwave emanating from an impact, was also found worldwide. The actual impact site remained elusive until a crater measuring wide was discovered in the Yucat\u00e1n Peninsula of southeastern Mexico, and was publicized in a 1991 paper by Alan Hildebrand and colleagues. Now, the bulk of the evidence suggests that a bolide wide impacted the Yucat\u00e1n Peninsula 66 million years ago, forming this crater and creating a \"kill mechanism\" that triggered the extinction event.\nWithin hours, the Chicxulub impact would have created immediate effects such as earthquakes, tsunamis, and a global firestorm that likely killed unsheltered animals and started wildfires. However, it would also have had longer-term consequences for the environment. Within days, sulphate aerosols released from rocks at the impact site would have contributed to acid rain and ocean acidification. Soot aerosols are thought to have spread around the world over the ensuing months and years; they would have cooled the surface of the Earth by reflecting thermal radiation, and greatly slowed photosynthesis by blocking out sunlight, thus creating an impact winter. (This role was ascribed to sulphate aerosols until experiments demonstrated otherwise.) The cessation of photosynthesis would have led to the collapse of food webs depending on leafy plants, which included all dinosaurs save for grain-eating birds.\nDeccan Traps.\nAt the time of the K-Pg extinction, the Deccan Traps flood basalts of India were actively erupting. The eruptions can be separated into three phases around the K-Pg boundary, two prior to the boundary and one after. The second phase, which occurred very close to the boundary, would have extruded 70 to 80% of the volume of these eruptions in intermittent pulses that occurred around 100,000 years apart. Greenhouse gases such as carbon dioxide and sulphur dioxide would have been released by this volcanic activity, resulting in climate change through temperature perturbations of roughly but possibly as high as . Like the Chicxulub impact, the eruptions may also have released sulphate aerosols, which would have caused acid rain and global cooling. However, due to large error margins in the dating of the eruptions, the role of the Deccan Traps in the K-Pg extinction remains unclear.\nBefore 2000, arguments that the Deccan Traps eruptions\u2014as opposed to the Chicxulub impact\u2014caused the extinction were usually linked to the view that the extinction was gradual. Prior to the discovery of the Chicxulub crater, the Deccan Traps were used to explain the global iridium layer; even after the crater's discovery, the impact was still thought to only have had a regional, not global, effect on the extinction event. In response, Luis Alvarez rejected volcanic activity as an explanation for the iridium layer and the extinction as a whole. Since then, however, most researchers have adopted a more moderate position, which identifies the Chicxulub impact as the primary progenitor of the extinction while also recognizing that the Deccan Traps may also have played a role. Walter Alvarez himself has acknowledged that the Deccan Traps and other ecological factors may have contributed to the extinctions in addition to the Chicxulub impact. Some estimates have placed the start of the second phase in the Deccan Traps eruptions within 50,000 years after the Chicxulub impact. Combined with mathematical modelling of the seismic waves that would have been generated by the impact, this has led to the suggestion that the Chicxulub impact may have triggered these eruptions by increasing the permeability of the mantle plume underlying the Deccan Traps.\nWhether the Deccan Traps were a major cause of the extinction, on par with the Chicxulub impact, remains uncertain. Proponents consider the climatic impact of the sulphur dioxide released to have been on par with the Chicxulub impact, and also note the role of flood basalt volcanism in other mass extinctions like the Permian-Triassic extinction event. They consider the Chicxulub impact to have worsened the ongoing climate change caused by the eruptions. Meanwhile, detractors point out the sudden nature of the extinction and that other pulses in Deccan Traps activity of comparable magnitude did not appear to have caused extinctions. They also contend that the causes of different mass extinctions should be assessed separately. In 2020, Alfio Chiarenza and colleagues suggested that the Deccan Traps may even have had the opposite effect: they suggested that the long-term warming caused by its carbon dioxide emissions may have dampened the impact winter from the Chicxulub impact.\nPossible Paleocene survivors.\nNon-avian dinosaur remains have occasionally been found above the K-Pg boundary. In 2000, Spencer Lucas and colleagues reported the discovery of a single hadrosaur right femur in the San Juan Basin of New Mexico, and described it as evidence of Paleocene dinosaurs. The rock unit in which the bone was discovered has been dated to the early Paleocene epoch, approximately 64.8 million years ago. If the bone was not re-deposited by weathering action, it would provide evidence that some dinosaur populations may have survived at least half a million years into the Cenozoic. Other evidence includes the presence of dinosaur remains in the Hell Creek Formation up to above the Cretaceous\u2013Paleogene boundary, representing years of elapsed time. This has been used to support the view that the K-Pg extinction was gradual. However, these supposed Paleocene dinosaurs are considered by many other researchers to be reworked, that is, washed out of their original locations and then re-buried in younger sediments. The age estimates have also been considered unreliable.\nCultural depictions.\nBy human standards, dinosaurs were creatures of fantastic appearance and often enormous size. As such, they have captured the popular imagination and become an enduring part of human culture. The entry of the word \"dinosaur\" into the common vernacular reflects the animals' cultural importance: in English, \"dinosaur\" is commonly used to describe anything that is impractically large, obsolete, or bound for extinction.\nPublic enthusiasm for dinosaurs first developed in Victorian England, where in 1854, three decades after the first scientific descriptions of dinosaur remains, a menagerie of lifelike dinosaur sculptures was unveiled in London's Crystal Palace Park. The Crystal Palace dinosaurs proved so popular that a strong market in smaller replicas soon developed. In subsequent decades, dinosaur exhibits opened at parks and museums around the world, ensuring that successive generations would be introduced to the animals in an immersive and exciting way. The enduring popularity of dinosaurs, in its turn, has resulted in significant public funding for dinosaur science, and has frequently spurred new discoveries. In the United States, for example, the competition between museums for public attention led directly to the Bone Wars of the 1880s and 1890s, during which a pair of feuding paleontologists made enormous scientific contributions.\nThe popular preoccupation with dinosaurs has ensured their appearance in literature, film, and other media. Beginning in 1852 with a passing mention in Charles Dickens \"Bleak House\", dinosaurs have been featured in large numbers of fictional works. Jules Verne's 1864 novel \"Journey to the Center of the Earth\", Sir Arthur Conan Doyle's 1912 book \"The Lost World\", the 1914 animated film Gertie the Dinosaur (featuring the first animated dinosaur), the iconic 1933 film \"King Kong\", the 1954 \"Godzilla\" and its many sequels, the best-selling 1990 novel \"Jurassic Park\" by Michael Crichton and its 1993 film adaptation are just a few notable examples of dinosaur appearances in fiction. Authors of general-interest non-fiction works about dinosaurs, including some prominent paleontologists, who have often sought to use the animals as a way to educate readers about science in general. Dinosaurs are ubiquitous in advertising; numerous companies have referenced dinosaurs in printed or televised advertisements, either in order to sell their own products or in order to characterize their rivals as slow-moving, dim-witted, or obsolete."}
{"id": "8315", "revid": "38285650", "url": "https://en.wikipedia.org/wiki?curid=8315", "title": "Diamagnetism", "text": "Diamagnetic materials are repelled by a magnetic field; an applied magnetic field creates an induced magnetic field in them in the opposite direction, causing a repulsive force. In contrast, paramagnetic and ferromagnetic materials are attracted by a magnetic field. Diamagnetism is a quantum mechanical effect that occurs in all materials; when it is the only contribution to the magnetism, the material is called diamagnetic. In paramagnetic and ferromagnetic substances, the weak diamagnetic force is overcome by the attractive force of magnetic dipoles in the material. The magnetic permeability of diamagnetic materials is less than the permeability of vacuum, \"\u03bc\"0. In most materials, diamagnetism is a weak effect which can be detected only by sensitive laboratory instruments, but a superconductor acts as a strong diamagnet because it repels a magnetic field entirely from its interior.\nDiamagnetism was first discovered when Anton Brugmans observed in 1778 that bismuth was repelled by magnetic fields. In 1845, Michael Faraday demonstrated that it was a property of matter and concluded that every material responded (in either a diamagnetic or paramagnetic way) to an applied magnetic field. On a suggestion by William Whewell, Faraday first referred to the phenomenon as \"diamagnetic\" (the prefix \"dia-\" meaning \"through\" or \"across\"), then later changed it to \"diamagnetism\".\nA simple rule of thumb is used in chemistry to determine whether a particle (atom, ion, or molecule) is paramagnetic or diamagnetic: If all electrons in the particle are paired, then the substance made of this particle is diamagnetic; If it has unpaired electrons, then the substance is paramagnetic.\nMaterials.\nDiamagnetism is a property of all materials, and always makes a weak contribution to the material's response to a magnetic field. However, other forms of magnetism (such as ferromagnetism or paramagnetism) are so much stronger that, when multiple different forms of magnetism are present in a material, the diamagnetic contribution is usually negligible. Substances where the diamagnetic behaviour is the strongest effect are termed diamagnetic materials, or diamagnets. Diamagnetic materials are those that some people generally think of as \"non-magnetic\", and include water, wood, most organic compounds such as petroleum and some plastics, and many metals including copper, particularly the heavy ones with many core electrons, such as mercury, gold and bismuth. The magnetic susceptibility values of various molecular fragments are called Pascal's constants.\nDiamagnetic materials, like water, or water-based materials, have a relative magnetic permeability that is less than or equal to 1, and therefore a magnetic susceptibility less than or equal to 0, since susceptibility is defined as . This means that diamagnetic materials are repelled by magnetic fields. However, since diamagnetism is such a weak property, its effects are not observable in everyday life. For example, the magnetic susceptibility of diamagnets such as water is . The most strongly diamagnetic material is bismuth, , although pyrolytic carbon may have a susceptibility of in one plane. Nevertheless, these values are orders of magnitude smaller than the magnetism exhibited by paramagnets and ferromagnets. Because \"\u03c7\"v is derived from the ratio of the internal magnetic field to the applied field, it is a dimensionless value.\nIn rare cases, the diamagnetic contribution can be stronger than paramagnetic contribution. This is the case for gold, which has a magnetic susceptibility less than 0 (and is thus by definition a diamagnetic material), but when measured carefully with X-ray magnetic circular dichroism, has an extremely weak paramagnetic contribution that is overcome by a stronger diamagnetic contribution.\nSuperconductors.\nSuperconductors may be considered perfect diamagnets (), because they expel all magnetic fields (except in a thin surface layer) due to the Meissner effect.\nDemonstrations.\nCurving water surfaces.\nIf a powerful magnet (such as a supermagnet) is covered with a layer of water (that is thin compared to the diameter of the magnet) then the field of the magnet significantly repels the water. This causes a slight dimple in the water's surface that may be seen by a reflection in its surface.\nLevitation.\nDiamagnets may be levitated in stable equilibrium in a magnetic field, with no power consumption. Earnshaw's theorem seems to preclude the possibility of static magnetic levitation. However, Earnshaw's theorem applies only to objects with positive susceptibilities, such as ferromagnets (which have a permanent positive moment) and paramagnets (which induce a positive moment). These are attracted to field maxima, which do not exist in free space. Diamagnets (which induce a negative moment) are attracted to field minima, and there can be a field minimum in free space.\nA thin slice of pyrolytic graphite, which is an unusually strongly diamagnetic material, can be stably floated in a magnetic field, such as that from rare earth permanent magnets. This can be done with all components at room temperature, making a visually effective and relatively convenient demonstration of diamagnetism.\nThe Radboud University Nijmegen, the Netherlands, has conducted experiments where water and other substances were successfully levitated. Most spectacularly, a live frog (see figure) was levitated.\nIn September 2009, NASA's Jet Propulsion Laboratory (JPL) in Pasadena, California announced it had successfully levitated mice using a superconducting magnet, an important step forward since mice are closer biologically to humans than frogs. JPL said it hopes to perform experiments regarding the effects of microgravity on bone and muscle mass.\nRecent experiments studying the growth of protein crystals have led to a technique using powerful magnets to allow growth in ways that counteract Earth's gravity.\nA simple homemade device for demonstration can be constructed out of bismuth plates and a few permanent magnets that levitate a permanent magnet.\nTheory.\nThe electrons in a material generally settle in orbitals, with effectively zero resistance and act like current loops. Thus it might be imagined that diamagnetism effects in general would be common, since any applied magnetic field would generate currents in these loops that would oppose the change, in a similar way to superconductors, which are essentially perfect diamagnets. However, since the electrons are rigidly held in orbitals by the charge of the protons and are further constrained by the Pauli exclusion principle, many materials exhibit diamagnetism, but typically respond very little to the applied field.\nThe Bohr\u2013Van Leeuwen theorem proves that there cannot be any diamagnetism or paramagnetism in a purely classical system. However, the classical theory of Langevin for diamagnetism gives the same prediction as the quantum theory. The classical theory is given below.\nLangevin diamagnetism.\nPaul Langevin's theory of diamagnetism (1905) applies to materials containing atoms with closed shells (see dielectrics). A field with intensity , applied to an electron with charge and mass , gives rise to Larmor precession with frequency . The number of revolutions per unit time is , so the current for an atom with electrons is (in SI units)\nThe magnetic moment of a current loop is equal to the current times the area of the loop. Suppose the field is aligned with the axis. The average loop area can be given as formula_2, where formula_3 is the mean square distance of the electrons perpendicular to the axis. The magnetic moment is therefore\nIf the distribution of charge is spherically symmetric, we can suppose that the distribution of coordinates are independent and identically distributed. Then formula_5, where formula_6 is the mean square distance of the electrons from the nucleus. Therefore, formula_7. If formula_8 is the number of atoms per unit volume, the volume diamagnetic susceptibility in SI units is\nIn atoms, Langevin susceptibility is of the same order of magnitude as Van Vleck paramagnetic susceptibility.\nIn metals.\nThe Langevin theory is not the full picture for metals because there are also non-localized electrons. The theory that describes diamagnetism in a free electron gas is called Landau diamagnetism, named after Lev Landau, and instead considers the weak counteracting field that forms when the electrons' trajectories are curved due to the Lorentz force. Landau diamagnetism, however, should be contrasted with Pauli paramagnetism, an effect associated with the polarization of delocalized electrons' spins. For the bulk case of a 3D system and low magnetic fields, the (volume) diamagnetic susceptibility can be calculated using Landau quantization, which in SI units is\nwhere formula_11 is the Fermi energy. This is equivalent to formula_12, exactly formula_13 times Pauli paramagnetic susceptibility, where formula_14 is the Bohr magneton and formula_15 is the density of states (number of states per energy per volume). This formula takes into account the spin degeneracy of the carriers (spin \u00bd electrons).\nIn doped semiconductors the ratio between Landau and Pauli susceptibilities may change due to the effective mass of the charge carriers differing from the electron mass in vacuum, increasing the diamagnetic contribution. The formula presented here only applies for the bulk; in confined systems like quantum dots, the description is altered due to quantum confinement. Additionally, for strong magnetic fields, the susceptibility of delocalized electrons oscillates as a function of the field strength, a phenomenon known as the De Haas\u2013Van Alphen effect, also first described theoretically by Landau."}
{"id": "8317", "revid": "30502683", "url": "https://en.wikipedia.org/wiki?curid=8317", "title": "Duke of Marlborough (title)", "text": "Duke of Marlborough ( ) is a title in the Peerage of England. It was created by Queen Anne in 1702 for John Churchill, 1st Earl of Marlborough (1650\u20131722), the noted military leader. In historical texts, unqualified use of the title typically refers to the 1st Duke. The name of the dukedom refers to Marlborough in Wiltshire. \nThe earldom of Marlborough was held by the family of Ley from its creation 1626 until its extinction with the death of the 4th earl in 1679. The title was recreated 10 years later for John Churchill (in 1689).\nHistory of the dukedom.\nChurchill had been made \"Lord Churchill of Eyemouth\" (1682) in the Peerage of Scotland, and \"Baron Churchill\" of Sandridge (1685) and \"Earl of Marlborough\" (1689) in the Peerage of England. Shortly after her accession to the throne in 1702, Queen Anne made Churchill the first \"Duke of Marlborough\" and granted him the subsidiary title \"Marquess of Blandford\".\nIn 1678, Churchill married Sarah Jennings (1660\u20131744), a courtier and influential favourite of the queen. They had seven children, of whom four daughters married into some of the most important families in Great Britain; one daughter and one son died in infancy. He was pre-deceased by his son, John Churchill, Marquess of Blandford, in 1703; so, to prevent the extinction of the titles, a special Act of Parliament was passed. When the 1st Duke of Marlborough died in 1722 his title as \"Lord Churchill of Eyemouth\" in the Peerage of Scotland became extinct and the Marlborough titles passed, according to the Act, to his eldest daughter Henrietta (1681\u20131733), the 2nd Duchess of Marlborough. She was married to the 2nd Earl of Godolphin and had a son who predeceased her.\nWhen Henrietta died in 1733, the Marlborough titles passed to her nephew Charles Spencer (1706\u20131758), the third son of her late sister Anne (1683\u20131716), who had married the 3rd Earl of Sunderland in 1699. After his older brother's death in 1729, Charles Spencer had already inherited the Spencer family estates and the titles of \"Earl of Sunderland\" (1643) and \"Baron Spencer\" of Wormleighton (1603), all in the Peerage of England. Upon his maternal aunt Henrietta's death in 1733, Charles Spencer succeeded to the Marlborough family estates and titles and became the 3rd Duke. When he died in 1758, his titles passed to his eldest son George (1739\u20131817), who was succeeded by his eldest son George, the 5th Duke (1766\u20131840). In 1815, Francis Spencer (the younger son of the 4th Duke) was created \"Baron Churchill\" in the Peerage of the United Kingdom. In 1902, his grandson, the 3rd Baron Churchill, was created Viscount Churchill.\nIn 1817, the 5th Duke obtained permission to assume and bear the surname of Churchill in addition to his surname of Spencer, to perpetuate the name of his illustrious great-great-grandfather. At the same time he received Royal Licence to quarter the coat of arms of Churchill with his paternal arms of Spencer. The modern Dukes thus originally bore the surname \"Spencer\": the double-barrelled surname of \"Spencer-Churchill\" as used since 1817 remains in the family, although many members have preferred to style themselves simply as \"Churchill\".\nThe 7th Duke was the paternal grandfather of the British Prime Minister Sir Winston Churchill, born at Blenheim Palace on 30 November 1874.\nThe 11th Duke, John Spencer-Churchill died in 2014, having assumed the title in 1972. The 12th and present Duke is Charles James Spencer-Churchill.\nFamily seat.\nThe family seat is Blenheim Palace in Woodstock, Oxfordshire.\nAfter his leadership in the victory against the French in the Battle of Blenheim on 13 August 1704, the 1st Duke was honoured by Queen Anne granting him the royal manor of Woodstock, and building him a house at her expense to be called Blenheim. Construction started in 1705 and the house was completed in 1722, the year of the 1st Duke's death. Blenheim Palace has since remained in the Churchill and Spencer-Churchill family.\nWith the exception of the 10th Duke and his first wife, the Dukes and Duchesses of Marlborough are buried in Blenheim Palace's chapel. Most other members of the Spencer-Churchill family are interred in St. Martin's parish churchyard at Bladon, a short distance from the palace.\nSuccession to the title.\nThe dukedom can theoretically pass through a female line. However, unlike the remainder to heirs general found in most other peerages that allow male-preference primogeniture, the grant does not allow for abeyance and follows a more restrictive Semi-Salic formula designed to keep succession wherever possible in the male line. The succession is as follows:\nSuccession to the title under the first and second contingencies have lapsed; holders of the title from the 3rd Duke trace their status from the third contingency.\nIt is now very unlikely that the dukedom will be passed to a woman or through a woman, since all the male-line descendants of the 1st Duke's second daughter Anne Spencer, Countess of Sunderland\u2014including the lines of the Viscounts Churchill and Barons Churchill of Wychwood and of the Earl Spencer and of the entire Spencer-Churchill and Spencer family\u2014would have to become extinct.\nIf that were to happen, the Churchill titles would pass to the Earl of Jersey (and merge with the earldom as long as it is extant), the heir-male of the 1st Duke's granddaughter Anne Villiers (born Egerton), Countess of Jersey, daughter of Elizabeth Egerton, Duchess of Bridgewater, the third daughter of the first Duke.\nThe next heir would be the Duke of Buccleuch, the heir-male of the 1st Duke's great-granddaughter Elizabeth Montagu, Duchess of Buccleuch, the daughter of Mary Montagu, Duchess of Montagu (1766 creation), the daughter of the 1st Duke's youngest daughter Mary, Duchess of Montagu (1705 creation).\nThe fourth surviving line is represented by the Earl of Chichester and his family, the heir-male of the 1st Duke's most senior great-great-granddaughter Mary Henrietta Osborne, Countess of Chichester, daughter of Francis Osborne, 5th Duke of Leeds, only child of Mary Godolphin, Duchess of Leeds, daughter of the 1st Duke's eldest daughter Henrietta Godolphin, 2nd Duchess of Marlborough, by her husband Francis Godolphin, 2nd Earl of Godolphin.\nOther titles of the Dukes.\nSubsidiary titles.\nThe Duke holds subsidiary titles: \"Marquess of Blandford\" (created in 1702 for John Churchill), \"Earl of Sunderland\" (created in 1643 for the Spencer family), \"Earl of Marlborough\" (created in 1689 for John Churchill), \"Baron Spencer\" of Wormleighton (created in 1603 for the Spencer family), and \"Baron Churchill\" of Sandridge (created in 1685 for John Churchill), all in the Peerage of England.\nThe title \"Marquess of Blandford\" is used as the courtesy title for the Duke's eldest son and heir. The Duke's eldest son's eldest son can use the courtesy title \"Earl of Sunderland\", and the duke's eldest son's eldest son's eldest son (not necessarily the eldest great-grandson) the title \"Lord Spencer of Wormleighton\" (not to be confused with Earl Spencer).\nThe title of \"Earl of Marlborough\", created for John Churchill in 1689, had previously been created for James Ley, in 1626, becoming extinct in 1679.\nForeign titles.\nThe 1st Duke was honoured with land and titles in the Holy Roman Empire: Emperor Leopold I created him a Prince in 1704, and in 1705, his successor Emperor Joseph I gave him the principality of Mindelheim (once the lordship of the noted soldier Georg von Frundsberg). He was obliged to surrender Mindelheim in 1714 by the Treaty of Utrecht, which returned it to Bavaria. He tried to obtain Nellenburg in Austria in exchange, which at that time was only a county ('Landgrafschaft'), but this failed, partially because Austrian law did not allow for Nellenburg to be converted into a sovereign principality. The 1st Duke's princely title of Mindelheim became extinct either on the return of the land to Bavaria or on his death, as the Empire operated Salic Law, which prevented female succession.\nCoats of arms.\nOriginal arms of the Churchill family.\nThe original arms of Sir Winston Churchill (1620\u20131688), father of the 1st Duke of Marlborough, were simple and in use by his own father in 1619. The shield was Sable a lion rampant Argent, debruised by a bendlet Gules. The addition of a canton of Saint George (see below) rendered the distinguishing mark of the bendlet unnecessary.\nThe Churchill crest is blazoned as a lion couchant guardant Argent, supporting with its dexter forepaw a banner Gules, charged with a dexter hand appaum\u00e9e of the first, staff Or.\nIn recognition of Sir Winston's services to King Charles I as Captain of the Horse, and his loyalty to King Charles II as a Member of Parliament, he was awarded an augmentation of honour to his arms around 1662. This rare mark of royal favour took the form of a canton of Saint George. At the same time, he was authorised to omit the bendlet, which had served the purpose of distinguishing this branch of the Churchill family from others which bore an undifferenced lion.\nArms of the 1st Duke of Marlborough.\nSir Winston's shield and crest were inherited by his son John Churchill, 1st Duke of Marlborough. Minor modifications reflected the bearer's social rise: the helm was now shown in profile and had a closed grille to signify the bearer's rank as a peer, and there were now supporters placed on either side of the shield. They were the mythical Griffin (part lion, part eagle) and Wyvern (a dragon without hind legs). The supporters were derived from the arms of the family of the 1st Duke's mother, Drake of Ash (Argent, a wyvern gules; these arms can be seen on the monument in Musbury Church to Sir Bernard Drake, d.1586).\nThe motto was \"Fiel pero desdichado\" (Spanish for \"Faithful but unfortunate\"). The 1st Duke was also entitled to a coronet indicating his rank.\nWhen the 1st Duke was made a Prince of the Holy Roman Empire in 1705, two unusual features were added: the Imperial Eagle and a Princely Coronet. His estates in Germany, such as Mindelheim, were represented in his arms by additional quarterings.\nArms of the Spencer-Churchill family.\nIn 1817, the 5th Duke received Royal Licence to place the quarter of Churchill ahead of his paternal arms of Spencer. The shield of the Spencer family arms is: quarterly Argent and Gules, in the second and third quarters a fret Or, over all on a bend Sable three escallops of the first. The Spencer crest is: out of a ducal coronet Or, a griffin's head between two wings expanded Argent, gorged with a collar gemel and armed Gules. Paul Courtenay observes that \"It would be normal in these circumstances for the paternal arms (Spencer) to take precedence over the maternal (Churchill), but because the Marlborough dukedom was senior to the Sunderland earldom, the procedure was reversed in this case.\"\nAlso in 1817, a further augmentation of honour was added to his armorial achievement. This incorporated the bearings from the standard of the Manor of Woodstock and was borne on an escutcheon, displayed over all in the centre chief point, as follows: Argent a cross of Saint George surmounted by an inescutcheon Azure, charged with three fleurs-de-lys Or, two over one. This inescutcheon represents the royal arms of France.\nThese quartered arms, incorporating the two augmentations of honour, have been the arms of all subsequent Dukes of Marlborough.\nMotto.\nThe motto \"Fiel pero desdichado\" is Spanish for \"Faithful though Joyless\". \"Desdichado\" means without happiness or without joy, alluding to the first Duke's father, Winston, who was a royalist and faithful supporter of the king during the English Civil War but was not compensated for his losses after the restoration. Charles II knighted Winston Churchill and other Civil War royalists but did not compensate them for their wartime losses, thereby inducing Winston to adopt the motto. It is unusual for the motto of an Englishman of the era to be in Spanish rather than Latin, and it is not known why this is the case.\nList of title holders.\nEarls of Marlborough, first creation (1626\u20131679).\nThe earldom of Marlborough was held by the family of Ley from 1626 to 1679. James Ley, the 1st Earl (c. 1550 \u2013 1629), was lord chief justice of the King\u2019s Bench in Ireland and then in England; he was an English member of parliament and was lord high treasurer from 1624 to 1628. In 1624 he was created Baron Ley and in 1626 Earl of Marlborough. The 3rd earl was his grandson James (1618\u20131665), a naval officer who was killed in action with the Dutch. James was succeeded by his uncle William, a younger son of the 1st earl, on whose death in 1679 the earldom became extinct.\nDukes of Marlborough (1702).\nThe heir apparent to the dukedom is George John Godolphin Spencer-Churchill, Marquess of Blandford (b. 1992), eldest son of the 12th Duke.\nFamily tree.\n&lt;section begin=FamilyTree /&gt;\n&lt;section end=\"FamilyTree\" /&gt;"}
{"id": "8322", "revid": "211905", "url": "https://en.wikipedia.org/wiki?curid=8322", "title": "December 17", "text": ""}
{"id": "8324", "revid": "1466867", "url": "https://en.wikipedia.org/wiki?curid=8324", "title": "Difference engine", "text": "A difference engine, a calculating machine designed in the 1820s, was first created by Charles Babbage. Difference engines are automatic mechanical calculators designed to tabulate polynomial functions. The name, the difference engine, is derived from the method of divided differences, a way to interpolate or tabulate functions by using a small set of polynomial co-efficients. Some of the most common mathematical functions used in engineering, science and navigation, were, and still are able to be computed with the use of the difference engine's capability of computing logarithmic and trigonometric functions, which can be approximated by polynomials, so a difference engine can compute many useful tables of numbers.\nHistory.\nThe notion of a mechanical calculator for mathematical functions can be traced back to the Antikythera mechanism of the 2nd century BC, while early modern examples are attributed to Pascal and Leibniz in the 17th century. \nIn 1784 J. H. M\u00fcller, an engineer in the Hessian army, devised and built an adding machine and described the basic principles of a difference machine in a book published in 1786 (the first written reference to a difference machine is dated to 1784), but he was unable to obtain funding to progress with the idea.\nCharles Babbage's difference engines.\nCharles Babbage began to construct a small difference engine in c. 1819 and had completed it by 1822 (Difference Engine 0). He announced his invention on 14 June 1822, in a paper to the Royal Astronomical Society, entitled \"Note on the application of machinery to the computation of astronomical and mathematical tables\". This machine used the decimal number system and was powered by cranking a handle. The British government was interested, since producing tables was time-consuming and expensive and they hoped the difference engine would make the task more economical.\nIn 1823, the British government gave Babbage \u00a31700 to start work on the project. Although Babbage's design was feasible, the metalworking techniques of the era could not economically make parts in the precision and quantity required. Thus the implementation proved to be much more expensive and doubtful of success than the government's initial estimate. In 1832, Babbage and Joseph Clement produced a small working model (one-seventh of the calculating section of Difference Engine No. 1, which was intended to operate on 20-digit numbers and sixth-order differences) which operated on 6-digit numbers and second-order differences. Lady Byron described seeing the working prototype in 1833: \"We both went to see the thinking machine (or so it seems) last Monday. It raised several Nos. to the 2nd and 3rd powers, and extracted the root of a Quadratic equation.\" Work on the larger engine was suspended in 1833.\nBy the time the government abandoned the project in 1842, Babbage had received and spent over \u00a317,000 on development, which still fell short of achieving a working engine. The government valued only the machine's output (economically produced tables), not the development (at unknown and unpredictable cost to complete) of the machine itself. Babbage did not, or was unwilling to, recognize that predicament. Meanwhile, Babbage's attention had moved on to developing an analytical engine, further undermining the government's confidence in the eventual success of the difference engine. By improving the concept as an analytical engine, Babbage had made the difference engine concept obsolete, and the project to implement it an utter failure in the view of the government.\nThe incomplete Difference Engine No. 1 was put on display to the public at the 1862 International Exhibition in South Kensington, London.\nBabbage went on to design his much more general analytical engine, but later produced an improved \"Difference Engine No. 2\" design (31-digit numbers and seventh-order differences), between 1846 and 1849. Babbage was able to take advantage of ideas developed for the analytical engine to make the new difference engine calculate more quickly while using fewer parts.\nScheutzian calculation engine.\nInspired by Babbage's difference engine in 1834, Per Georg Scheutz built several experimental models. In 1837 his son Edward proposed to construct a working model in metal, and in 1840 finished the calculating part, capable of calculating series with 5-digit numbers and first-order differences, which was later extended to third-order (1842). In 1843, after adding the printing part, the model was completed.\nIn 1851, funded by the government, construction of the larger and improved (15-digit numbers and fourth-order differences) machine began, and finished in 1853. The machine was demonstrated at the World's Fair in Paris, 1855 and then sold in 1856 to the Dudley Observatory in Albany, New York. Delivered in 1857, it was the first printing calculator sold. In 1857 the British government ordered the next Scheutz's difference machine, which was built in 1859. It had the same basic construction as the previous one, weighing about .\nOthers.\nMartin Wiberg improved Scheutz's construction (c. 1859, his machine has the same capacity as Scheutz's - 15-digit and fourth-order) but used his device only for producing and publishing printed tables (interest tables in 1860, and logarithmic tables in 1875).\nAlfred Deacon of London in c. 1862 produced a small difference engine (20-digit numbers and third-order differences).\nAmerican George B. Grant started working on his calculating machine in 1869, unaware of the works of Babbage and Scheutz (Schentz). One year later (1870) he learned about difference engines and proceed to design one himself, describing his construction in 1871. In 1874 the Boston Thursday Club raised a subscription for the construction of a large-scale model, which was built in 1876. It could be expanded to enhance precision and weighed about .\nChristel Hamann built one machine (16-digit numbers and second-order differences) in 1909 for the \"Tables of Bauschinger and Peters\" (\"Logarithmic-Trigonometrical Tables with eight decimal places\"), which was first published in Leipzig in 1910. It weighed about .\nBurroughs Corporation in about 1912 built a machine for the Nautical Almanac Office which was used as a difference engine of second-order. It was later replaced in 1929 by a Burroughs Class 11 (13-digit numbers and second-order differences, or 11-digit numbers and [at least up to] fifth-order differences).\nAlexander John Thompson about 1927 built \"integrating and differencing machine\" (13-digit numbers and fifth-order differences) for his table of logarithms \"Logarithmetica britannica\". This machine was composed of four modified Triumphator calculators.\nLeslie Comrie in 1928 described how to use the Brunsviga-Dupla calculating machine as a difference engine of second-order (15-digit numbers). He also noted in 1931 that National Accounting Machine Class 3000 could be used as a difference engine of sixth-order.\nConstruction of two working No. 2 difference engines.\nDuring the 1980s, Allan G. Bromley, an associate professor at the University of Sydney, Australia, studied Babbage's original drawings for the Difference and Analytical Engines at the Science Museum library in London. This work led the Science Museum to construct a working calculating section of difference engine No. 2 from 1985 to 1991, under Doron Swade, the then Curator of Computing. This was to celebrate the 200th anniversary of Babbage's birth in 1991. In 2002, the printer which Babbage originally designed for the difference engine was also completed. The conversion of the original design drawings into drawings suitable for engineering manufacturers' use revealed some minor errors in Babbage's design (possibly introduced as a protection in case the plans were stolen), which had to be corrected. Once completed, both the engine and its printer worked flawlessly, and still do. The difference engine and printer were constructed to tolerances achievable with 19th-century technology, resolving a long-standing debate as to whether Babbage's design would have worked. (One of the reasons formerly advanced for the non-completion of Babbage's engines had been that engineering methods were insufficiently developed in the late Georgian era.)\nThe printer's primary purpose is to produce stereotype plates for use in printing presses, which it does by pressing type into soft plaster to create a flong. Babbage intended that the Engine's results be conveyed directly to mass printing, having recognized that many errors in previous tables were not the result of human calculating mistakes but from error in the manual typesetting process. The printer's paper output is mainly a means of checking the engine's performance.\nIn addition to funding the construction of the output mechanism for the Science Museum's difference engine, Nathan Myhrvold commissioned the construction of a second complete Difference Engine No. 2, which was on exhibit at the Computer History Museum in Mountain View, California from 10 May 2008 until 31 January 2016.\nIt has since been transferred to Intellectual Ventures in Seattle where it is on display just outside the main lobby.\nOperation.\nThe difference engine consists of a number of columns, numbered from 1 to N. The machine is able to store one decimal number in each column. The machine can only add the value of a column \"n\"\u00a0+\u00a01 to column \"n\" to produce the new value of \"n\". Column \"N\" can only store a constant, column 1 displays (and possibly prints) the value of the calculation on the current iteration.\nThe engine is programmed by setting initial values to the columns. Column 1 is set to the value of the polynomial at the start of computation. Column 2 is set to a value derived from the first and higher derivatives of the polynomial at the same value of X. Each of the columns from 3 to \"N\" is set to a value derived from the formula_1 first and higher derivatives of the polynomial.\nTiming.\nIn the Babbage design, one iteration (i.e., one full set of addition and carry operations) happens for each rotation of the main shaft. Odd and even columns alternately perform an addition in one cycle. The sequence of operations for column formula_2 is thus:\nSteps 1,2,3,4 occur for every odd column, while steps 3,4,1,2 occur for every even column.\nWhile Babbage's original design placed the crank directly on the main shaft, it was later realized that the force required to crank the machine would have been too great for a human to handle comfortably. Therefore, the two models that were built incorporate a 4:1 reduction gear at the crank, and four revolutions of the crank are required to perform one full cycle.\nSteps.\nEach iteration creates a new result, and is accomplished in four steps corresponding to four complete turns of the handle shown at the far right in the picture below. The four steps are:\nSubtraction.\nThe engine represents negative numbers as ten's complements. Subtraction amounts to addition of a negative number. This works in the same manner that modern computers perform subtraction, known as two's complement.\nMethod of differences.\nThe principle of a difference engine is Newton's method of divided differences. If the initial value of a polynomial (and of its finite differences) is calculated by some means for some value of X, the difference engine can calculate any number of nearby values, using the method generally known as the method of finite differences. For example, consider the quadratic polynomial\nwith the goal of tabulating the values \"p\"(0), \"p\"(1), \"p\"(2), \"p\"(3), \"p\"(4), and so forth. The table below is constructed as follows: the second column contains the values of the polynomial, the third column contains the differences of the two left neighbors in the second column, and the fourth column contains the differences of the two neighbors in the third column:\nThe numbers in the third values-column are constant. In fact, by starting with any polynomial of degree \"n\", the column number \"n\"\u00a0+\u00a01 will always be constant. This is the crucial fact behind the success of the method.\nThis table was built from left to right, but it is possible to continue building it from right to left down a diagonal in order to compute more values. To calculate \"p\"(4) use the values from the lowest diagonal. Start with the fourth column constant value of 4 and copy it down the column. Then continue the third column by adding 4 to 11 to get 15. Next continue the second column by taking its previous value, 22 and adding the 15 from the third column. Thus \"p\"(5) is 22\u00a0+\u00a015\u00a0=\u00a037. In order to compute \"p\"(6), we iterate the same algorithm on the \"p\"(5) values: take 4 from the fourth column, add that to the third column's value 15 to get 19, then add that to the second column's value 37 to get 56, which is \"p\"(6). This process may be continued ad infinitum. The values of the polynomial are produced without ever having to multiply. A difference engine only needs to be able to add. From one loop to the next, it needs to store 2 numbers\u2014in this example (the last elements in the first and second columns). To tabulate polynomials of degree \"n\", one needs sufficient storage to hold \"n\" numbers.\nBabbage's difference engine No. 2, finally built in 1991, can hold 8 numbers of 31 decimal digits each and can thus tabulate 7th degree polynomials to that precision. The best machines from Scheutz could store 4 numbers with 15 digits each.\nInitial values.\nThe initial values of columns can be calculated by first manually calculating N consecutive values of the function and by backtracking, i.e. calculating the required differences.\nCol formula_6 gets the value of the function at the start of computation formula_7. Col formula_8 is the difference between formula_9 and formula_7...\nIf the function to be calculated is a polynomial function, expressed as\nthe initial values can be calculated directly from the constant coefficients \"a\"0, \"a\"1,\"a\"2, ..., \"an\" without calculating any data points. The initial values are thus:\nUse of derivatives.\nMany commonly used functions are analytic functions, which can be expressed as power series, for example as a Taylor series. The initial values can be calculated to any degree of accuracy; if done correctly the engine will give exact results for first N steps. After that, the engine will only give an approximation of the function.\nThe Taylor series expresses the function as a sum obtained from its derivatives at one point. For many functions the higher derivatives are trivial to obtain; for instance, the sine function at 0 has values of 0 or formula_19 for all derivatives. Setting 0 as the start of computation we get the simplified Maclaurin series\nThe same method of calculating the initial values from the coefficients can be used as for polynomial functions. The polynomial constant coefficients will now have the value\nCurve fitting.\nThe problem with the methods described above is that errors will accumulate and the series will tend to diverge from the true function. A solution which guarantees a constant maximum error is to use curve fitting. A minimum of \"N\" values are calculated evenly spaced along the range of the desired calculations. Using a curve fitting technique like Gaussian reduction an \"N\"\u22121th degree polynomial interpolation of the function is found. With the optimized polynomial, the initial values can be calculated as above.\nIn popular culture.\nWilliam Gibson and Bruce Sterling's \"The Difference Engine\" is an alternative history novel that looks at how society would have progressed had the difference engine and his Analytical Engine worked as Babbage envisioned.\nThe story takes place in Victorian England in which technological advancement is on the rise because of the success of Babbage's analytical machine. The convention of steampunk in which Victorian fashion is combined with the technological elements of the Industrial Revolution is seen throughout the story since its technology is so advanced in the era."}
{"id": "8326", "revid": "40961761", "url": "https://en.wikipedia.org/wiki?curid=8326", "title": "Draupnir", "text": "In Norse mythology, Draupnir (Old Norse \"the dripper\") is a gold ring possessed by the god Odin with the ability to multiply itself: Every ninth night, eight new rings 'drip' from Draupnir, each one of the same size and weight as the original.\nDraupnir was forged by the dwarven brothers Brokkr and Eitri (or Sindri). Brokkr and Eitri made this ring as one of a set of three gifts which included Mj\u00f6llnir and Gullinbursti. They made these gifts in accordance with a bet Loki made saying that Brokkr and Eitri could not make better gifts than the three made by the Sons of Ivaldi. In the end, Mj\u00f6llnir, Thor's hammer, won the contest for Brokkr and Eitri. Loki used a loophole to get out of the wager for his head (the wager was for Loki's head only, but he argued that, to remove his head, they would have to injure his neck, which was not in the bargain) and Brokkr punished him by sealing his lips shut with wire.\nThe ring was placed by Odin on the funeral pyre of his son Baldr:\nOdin laid upon the pyre the gold ring called Draupnir; this quality attended it: that every ninth night there fell from it eight gold rings of equal weight. (from the \"Gylfaginning\").\nThe ring was subsequently retrieved by Herm\u00f3\u00f0r. It was offered as a gift by Freyr's servant Sk\u00edrnir in the wooing of Ger\u00f0r, which is described in the poem \"Sk\u00edrnism\u00e1l\".\nIn popular culture.\nDraupnir is represented as a card in the Yu-Gi-Oh Trading Card Game. It has an effect that mimics the multiplication ability of the mythological version. If it is destroyed by another card's effect, you can add another \"Nordic Relic\" card to your hand. \nDraupnir also has a representation in the set Kaldheim, which is based on Nordic mythology. The card Replicating Ring adds a night counter to itself each turn, and once eight counters are put on it, it makes eight Replicated Rings.\n\"DRAUPNIR\" was revealed as the key to a website that Neal Caffrey and Mozzie used to view their stolen Nazi U-boat treasure in \"Taking Account\", the seventh episode of the third season of \"White Collar\".\nIt also appeared in episode 11 of \"\" as a tool to seal Loki's spirit.\nThe Draupnir is never called by name but is simply known as Odin's ring in the first three books of the Witches of East End novels. This ring allows the wearer to teleport to any place of the nine worlds, and a copy of equal power was once owned by Loki before it was destroyed by Freya."}
{"id": "8327", "revid": "7724", "url": "https://en.wikipedia.org/wiki?curid=8327", "title": "Dromi", "text": ""}
{"id": "8328", "revid": "1009749685", "url": "https://en.wikipedia.org/wiki?curid=8328", "title": "Divergence", "text": "In vector calculus, divergence is a vector operator that operates on a vector field, producing a scalar field giving the quantity of the vector field's source at each point. More technically, the divergence represents the volume density of the outward flux of a vector field from an infinitesimal volume around a given point.\nAs an example, consider air as it is heated or cooled. The velocity of the air at each point defines a vector field. While air is heated in a region, it expands in all directions, and thus the velocity field points outward from that region. The divergence of the velocity field in that region would thus have a positive value. While the air is cooled and thus contracting, the divergence of the velocity has a negative value.\nPhysical interpretation of divergence.\nIn physical terms, the divergence of a vector field is the extent to which the vector field flux behaves like a source at a given point. It is a local measure of its \"outgoingness\" \u2013 the extent to which there are more of the field vectors exiting an infinitesimal region of space than entering it. A point at which the flux is outgoing has positive divergence, and is often called a \"source\" of the field. A point at which the flux is directed inward has negative divergence, and is often called a \"sink\" of the field. The greater the flux of field through a small surface enclosing a given point, the greater the value of divergence at that point. A point at which there is zero flux through an enclosing surface has zero divergence. \nThe divergence of a vector field is often illustrated using the example of the velocity field of a fluid, a liquid or gas. A moving gas has a velocity, a speed and direction, at each point which can be represented by a vector, so the velocity of the gas forms a vector field. If a gas is heated, it will expand. This will cause a net motion of gas particles outward in all directions. Any closed surface in the gas will enclose gas which is expanding, so there will be an outward flux of gas through the surface. So the velocity field will have positive divergence everywhere. Similarly, if the gas is cooled, it will contract. There will be more room for gas particles in any volume, so the external pressure of the fluid will cause a net flow of gas volume inward through any closed surface. Therefore the velocity field has negative divergence everywhere. In contrast to an unheated gas with a constant density, the gas may be moving, but the volume rate of gas flowing into any closed surface must equal the volume rate flowing out, so the \"net\" flux of fluid through any closed surface is zero. Thus the gas velocity has zero divergence everywhere. A field which has zero divergence everywhere is called solenoidal. \nIf the fluid is heated only at one point or small region, or a small tube is introduced which supplies a source of additional fluid at one point, the fluid there will expand, pushing fluid particles around it outward in all directions. This will cause an outward velocity field throughout the fluid, centered on the heated point. Any closed surface enclosing the heated point will have a flux of fluid particles passing out of it, so there is positive divergence at that point. However any closed surface \"not\" enclosing the point will have a constant density of fluid inside, so just as many fluid particles are entering as leaving the volume, thus the net flux out of the volume is zero. Therefore the divergence at any other point is zero.\nDefinition.\nThe divergence of a vector field at a point is defined as the limit of the ratio of the surface integral of out of the surface of a closed volume enclosing to the volume of , as shrinks to zero\nwhere is the volume of , is the boundary of , and formula_1 is the outward unit normal to that surface. It can be shown that the above limit always converges to the same value for any sequence of volumes that contain and approach zero volume. The result, , is a scalar function of . \nSince this definition is coordinate-free, it shows that the divergence is the same in any coordinate system. However it is not often used practically to calculate divergence; when the vector field is given in a coordinate system the coordinate definitions below are much simpler to use.\nA vector field with zero divergence everywhere is called \"solenoidal\" \u2013 in which case any closed surface has no net flux across it.\nDefinition in coordinates.\nCartesian coordinates.\nIn three-dimensional Cartesian coordinates, the divergence of a continuously differentiable vector field formula_2 is defined as the scalar-valued function:\nAlthough expressed in terms of coordinates, the result is invariant under rotations, as the physical interpretation suggests. This is because the trace of the Jacobian matrix of an -dimensional vector field in -dimensional space is invariant under any invertible linear transformation.\nThe common notation for the divergence is a convenient mnemonic, where the dot denotes an operation reminiscent of the dot product: take the components of the operator (see del), apply them to the corresponding components of , and sum the results. Because applying an operator is different from multiplying the components, this is considered an abuse of notation.\nCylindrical coordinates.\nFor a vector expressed in local unit cylindrical coordinates as\nwhere is the unit vector in direction , the divergence is\nThe use of local coordinates is vital for the validity of the expression. If we consider the position vector and the functions , , and , which assign the corresponding global cylindrical coordinate to a vector, in general formula_6, formula_7, and formula_8. In particular, if we consider the identity function , we find that:\nSpherical coordinates.\nIn spherical coordinates, with the angle with the axis and the rotation around the axis, and again written in local unit coordinates, the divergence is\nTensor field.\nLet be continuously differentiable second-order tensor field defined as follows:\nthe divergence in cartesian coordinate system is a first-order tensor field and can be defined in two ways:\nand\nWe have\nIf tensor is symmetric then formula_15. Because of this, often in the literature the two definitions (and symbols and formula_16) are used interchangeably (especially in mechanics equations where tensor symmetry is assumed).\nExpressions of formula_17 in cylindrical and spherical coordinates are given in the article del in cylindrical and spherical coordinates.\nGeneral coordinates.\nUsing Einstein notation we can consider the divergence in general coordinates, which we write as , where is the number of dimensions of the domain. Here, the upper index refers to the number of the coordinate or component, so refers to the second component, and not the quantity squared. The index variable is used to refer to an arbitrary component, such as . The divergence can then be written via the Voss-Weyl formula, as:\nwhere formula_19 is the local coefficient of the volume element and are the components of with respect to the local unnormalized covariant basis (sometimes written as . The Einstein notation implies summation over , since it appears as both an upper and lower index.\nThe volume coefficient is a function of position which depends on the coordinate system. In Cartesian, cylindrical and spherical coordinates, using the same conventions as before, we have , and , respectively. The volume can also be expressed as formula_20, where is the metric tensor. The determinant appears because it provides the appropriate invariant definition of the volume, given a set of vectors. Since the determinant is a scalar quantity which doesn't depend on the indices, these can be suppressed, writing formula_20. The absolute value is taken in order to handle the general case where the determinant might be negative, such as in pseudo-Riemannian spaces. The reason for the square-root is a bit subtle: it effectively avoids double-counting as one goes from curved to Cartesian coordinates, and back. The volume (the determinant) can also be understood as the Jacobian of the transformation from Cartesian to curvilinear coordinates, which for gives \nSome conventions expect all local basis elements to be normalized to unit length, as was done in the previous sections. If we write formula_22 for the normalized basis, and formula_23 for the components of with respect to it, we have that \nusing one of the properties of the metric tensor. By dotting both sides of the last equality with the contravariant element formula_25, we can conclude that formula_26. After substituting, the formula becomes:\nSee \"\" for further discussion.\nProperties.\nThe following properties can all be derived from the ordinary differentiation rules of calculus. Most importantly, the divergence is a linear operator, i.e.,\nfor all vector fields and and all real numbers and .\nThere is a product rule of the following type: if is a scalar-valued function and is a vector field, then\nor in more suggestive notation\nAnother product rule for the cross product of two vector fields and in three dimensions involves the curl and reads as follows:\nor\nThe Laplacian of a scalar field is the divergence of the field's gradient:\nThe divergence of the curl of any vector field (in three dimensions) is equal to zero: \nIf a vector field with zero divergence is defined on a ball in , then there exists some vector field on the ball with . For regions in more topologically complicated than this, the latter statement might be false (see Poincar\u00e9 lemma). The degree of \"failure\" of the truth of the statement, measured by the homology of the chain complex\nserves as a nice quantification of the complicatedness of the underlying region . These are the beginnings and main motivations of de Rham cohomology.\nDecomposition theorem.\nIt can be shown that any stationary flux that is twice continuously differentiable in and vanishes sufficiently fast for can be decomposed uniquely into an \"irrotational part\" and a \"source-free part\" . Moreover, these parts are explicitly determined by the respective \"source densities\" (see above) and \"circulation densities\" (see the article Curl):\nFor the irrotational part one has\nwith\nThe source-free part, , can be similarly written: one only has to replace the \"scalar potential\" by a \"vector potential\" and the terms by , and the source density \nby the circulation density .\nThis \"decomposition theorem\" is a by-product of the stationary case of electrodynamics. It is a special case of the more general Helmholtz decomposition, which works in dimensions greater than three as well.\nIn arbitrary dimensions.\nThe divergence of a vector field can be defined in any number of dimensions. If \nin a Euclidean coordinate system with coordinates , define\nIn the case of one dimension, reduces to a regular function, and the divergence reduces to the derivative.\nFor any , the divergence is a linear operator, and it satisfies the \"product rule\"\nfor any scalar-valued function .\nRelation to the exterior derivative.\nOne can express the divergence as a particular case of the exterior derivative, which takes a 2-form to a 3-form in . Define the current two-form as\nIt measures the amount of \"stuff\" flowing through a surface per unit time in a \"stuff fluid\" of density moving with local velocity . Its exterior derivative is then given by\nwhere formula_43 is the wedge product. \nThus, the divergence of the vector field can be expressed as:\nHere the superscript is one of the two musical isomorphisms, and is the Hodge star operator. When the divergence is written in this way, the operator formula_45 is referred to as the codifferential. Working with the current two-form and the exterior derivative is usually easier than working with the vector field and divergence, because unlike the divergence, the exterior derivative commutes with a change of (curvilinear) coordinate system.\nIn curvilinear coordinates.\nThe appropriate expression is more complicated in curvilinear coordinates. The divergence of a vector field extends naturally to any differentiable manifold of dimension that has a volume form (or density) , e.g. a Riemannian or Lorentzian manifold. Generalising the construction of a two-form for a vector field on , on such a manifold a vector field defines an -form obtained by contracting with . The divergence is then the function defined by\nThe divergence can be defined in terms of the Lie derivative as\nThis means that the divergence measures the rate of expansion of a unit of volume (a volume element)) as it flows with the vector field.\nOn a pseudo-Riemannian manifold, the divergence with respect to the volume can be expressed in terms of the Levi-Civita connection :\nwhere the second expression is the contraction of the vector field valued 1-form with itself and the last expression is the traditional coordinate expression from Ricci calculus.\nAn equivalent expression without using a connection is\nwhere is the metric and formula_50 denotes the partial derivative with respect to coordinate . The square-root of the (absolute value of the determinant of the) metric appears because the divergence must be written with the correct conception of the volume. In curvilinear coordinates, the basis vectors are no longer orthonormal; the determinant encodes the correct idea of volume in this case. It appears twice, here, once, so that the formula_51 can be transformed into \"flat space\" (where coordinates are actually orthonormal), and once again so that formula_50 is also transformed into \"flat space\", so that finally, the \"ordinary\" divergence can be written with the \"ordinary\" concept of volume in flat space (\"i.e.\" unit volume, \"i.e.\" one, \"i.e.\" not written down). The square-root appears in the denominator, because the derivative transforms in the opposite way (contravariantly) to the vector (which is covariant). This idea of getting to a \"flat coordinate system\" where local computations can be done in a conventional way is called a vielbein. A different way to see this is to note that the divergence is the codifferential in disguise. That is, the divergence corresponds to the expression formula_53 with formula_54 the differential and formula_55 the Hodge star. The Hodge star, by its construction, causes the volume form to appear in all of the right places.\nThe divergence of tensors.\nDivergence can also be generalised to tensors. In Einstein notation, the divergence of a contravariant vector is given by\nwhere denotes the covariant derivative. In this general setting, the correct formulation of the divergence is to recognize that it is a codifferential; the appropriate properties follow from there.\nEquivalently, some authors define the divergence of a mixed tensor by using the musical isomorphism : if is a -tensor ( for the contravariant vector and for the covariant one), then we define the \"divergence of \" to be the -tensor\nthat is, we take the trace over the \"first two\" covariant indices of the covariant derivative.\nThe formula_58 symbol refers to the musical isomorphism."}
{"id": "8331", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=8331", "title": "Drug Mix", "text": ""}
{"id": "8332", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=8332", "title": "Induhvidual", "text": ""}
{"id": "8334", "revid": "211905", "url": "https://en.wikipedia.org/wiki?curid=8334", "title": "December 18", "text": ""}
{"id": "8336", "revid": "31339567", "url": "https://en.wikipedia.org/wiki?curid=8336", "title": "Decision problem", "text": "In computability theory and computational complexity theory, a decision problem is a problem that can be posed as a yes-no question of the input values. An example of a decision problem is deciding whether a given natural number is prime. Another is the problem \"given two numbers \"x\" and \"y\", does \"x\" evenly divide \"y\"?\". The answer is either 'yes' or 'no' depending upon the values of \"x\" and \"y\". A method for solving a decision problem, given in the form of an algorithm, is called a decision procedure for that problem. A decision procedure for the decision problem \"given two numbers \"x\" and \"y\", does \"x\" evenly divide \"y\"?\" would give the steps for determining whether \"x\" evenly divides \"y\". One such algorithm is long division. If the remainder is zero the answer is 'yes', otherwise it is 'no'. A decision problem which can be solved by an algorithm is called \"decidable\".\nDecision problems typically appear in mathematical questions of decidability, that is, the question of the existence of an effective method to determine the existence of some object or its membership in a set; some of the most important problems in mathematics are undecidable.\nThe field of computational complexity categorizes \"decidable\" decision problems by how difficult they are to solve. \"Difficult\", in this sense, is described in terms of the computational resources needed by the most efficient algorithm for a certain problem. The field of recursion theory, meanwhile, categorizes \"undecidable\" decision problems by Turing degree, which is a measure of the noncomputability inherent in any solution.\nDefinition.\nA \"decision problem\" is a yes-or-no question on an infinite set of inputs. It is traditional to define the decision problem as the set of possible inputs together with the set of inputs for which the answer is \"yes\".\nThese inputs can be natural numbers, but can also be values of some other kind, like binary strings or strings over some other alphabet. The subset of strings for which the problem returns \"yes\" is a formal language, and often decision problems are defined as formal languages.\nUsing an encoding such as G\u00f6del numberings, any string can be encoded as a natural number, via which a decision problem can be defined as a subset of the natural numbers.\nExamples.\nA classic example of a decidable decision problem is the set of prime numbers. It is possible to effectively decide whether a given natural number is prime by testing every possible nontrivial factor. Although much more efficient methods of primality testing are known, the existence of any effective method is enough to establish decidability.\nDecidability.\nA decision problem \"A\" is \"decidable\" or \"effectively solvable\" if \"A\" is a recursive set. A problem is \"partially decidable\", \"semidecidable\", \"solvable\", or \"provable\" if \"A\" is a recursively enumerable set. Problems that are not decidable are \"undecidable\". For those it is not possible to create an algorithm, efficient or otherwise, that solves them.\nThe halting problem is an important undecidable decision problem; for more examples, see list of undecidable problems.\nComplete problems.\nDecision problems can be ordered according to many-one reducibility and related to feasible reductions such as polynomial-time reductions. A decision problem \"P\" is said to be \"complete\" for a set of decision problems \"S\" if \"P\" is a member of \"S\" and every problem in \"S\" can be reduced to \"P\". Complete decision problems are used in computational complexity theory to characterize complexity classes of decision problems. For example, the Boolean satisfiability problem is complete for the class NP of decision problems under polynomial-time reducibility.\nFunction problems.\nDecision problems are closely related to function problems, which can have answers that are more complex than a simple 'yes' or 'no'. A corresponding function problem is \"given two numbers \"x\" and \"y\", what is \"x\" divided by \"y\"?\".\nA function problem consists of a partial function \"f\"; the informal \"problem\" is to compute the values of \"f\" on the inputs for which it is defined.\nEvery function problem can be turned into a decision problem; the decision problem is just the graph of the associated function. (The graph of a function \"f\" is the set of pairs (\"x\",\"y\") such that \"f\"(\"x\") = \"y\".) If this decision problem were effectively solvable then the function problem would be as well. This reduction does not respect computational complexity, however. For example, it is possible for the graph of a function to be decidable in polynomial time (in which case running time is computed as a function of the pair (\"x\",\"y\")) when the function is not computable in polynomial time (in which case running time is computed as a function of \"x\" alone). The function \"f\"(\"x\") = 2\"x\" has this property.\nEvery decision problem can be converted into the function problem of computing the characteristic function of the set associated to the decision problem. If this function is computable then the associated decision problem is decidable. However, this reduction is more liberal than the standard reduction used in computational complexity (sometimes called polynomial-time many-one reduction); for example, the complexity of the characteristic functions of an NP-complete problem and its co-NP-complete complement is exactly the same even though the underlying decision problems may not be considered equivalent in some typical models of computation.\nOptimization problems.\nUnlike decision problems, for which there is only one correct answer for each input, optimization problems are concerned with finding the \"best\" answer to a particular input. Optimization problems arise naturally in many applications, such as the traveling salesman problem and many questions in linear programming.\nThere are standard techniques for transforming function and optimization problems into decision problems. For example, in the traveling salesman problem, the optimization problem is to produce a tour with minimal weight. The associated decision problem is: for each \"N\", to decide whether the graph has any tour with weight less than \"N\". By repeatedly answering the decision problem, it is possible to find the minimal weight of a tour.\nBecause the theory of decision problems is very well developed, research in complexity theory has typically focused on decision problems. Optimization problems themselves are still of interest in computability theory, as well as in fields such as operations research."}
{"id": "8339", "revid": "140154", "url": "https://en.wikipedia.org/wiki?curid=8339", "title": "Domain Name System", "text": "The Domain Name System (DNS) is a hierarchical and decentralized naming system for computers, services, or other resources connected to the Internet or a private network. It associates various information with domain names assigned to each of the participating entities. Most prominently, it translates more readily memorized domain names to the numerical IP addresses needed for locating and identifying computer services and devices with the underlying network protocols. By providing a worldwide, distributed directory service, the Domain Name System has been an essential component of the functionality of the Internet since 1985.\nThe Domain Name System delegates the responsibility of assigning domain names and mapping those names to Internet resources by designating authoritative name servers for each domain. Network administrators may delegate authority over sub-domains of their allocated name space to other name servers. This mechanism provides distributed and fault-tolerant service and was designed to avoid a single large central database.\nThe Domain Name System also specifies the technical functionality of the database service that is at its core. It defines the DNS protocol, a detailed specification of the data structures and data communication exchanges used in the DNS, as part of the Internet Protocol Suite.\nThe Internet maintains two principal namespaces, the domain name hierarchy and the Internet Protocol (IP) address spaces. The Domain Name System maintains the domain name hierarchy and provides translation services between it and the address spaces. Internet name servers and a communication protocol implement the Domain Name System. A DNS name server is a server that stores the DNS records for a domain; a DNS name server responds with answers to queries against its database.\nThe most common types of records stored in the DNS database are for Start of Authority (SOA), IP addresses (A and AAAA), SMTP mail exchangers (MX), name servers (NS), pointers for reverse DNS lookups (PTR), and domain name aliases (CNAME). Although not intended to be a general purpose database, DNS has been expanded over time to store records for other types of data for either automatic lookups, such as DNSSEC records, or for human queries such as \"responsible person\" (RP) records. As a general purpose database, the DNS has also been used in combating unsolicited email (spam) by storing a real-time blackhole list (RBL). The DNS database is traditionally stored in a structured text file, the zone file, but other database systems are common.\nFunction.\nAn often-used analogy to explain the Domain Name System is that it serves as the phone book for the Internet by translating human-friendly computer hostnames into IP addresses. For example, the domain name www.example.com translates to the addresses (IPv4) and (IPv6). The DNS can be quickly and transparently updated, allowing a service's location on the network to change without affecting the end users, who continue to use the same hostname. Users take advantage of this when they use meaningful Uniform Resource Locators (URLs) and e-mail addresses without having to know how the computer actually locates the services.\nAn important and ubiquitous function of the DNS is its central role in distributed Internet services such as cloud services and content delivery networks. When a user accesses a distributed Internet service using a URL, the domain name of the URL is translated to the IP address of a server that is proximal to the user. The key functionality of the DNS exploited here is that different users can \"simultaneously\" receive different translations for the \"same\" domain name, a key point of divergence from a traditional phone-book view of the DNS. This process of using the DNS to assign proximal servers to users is key to providing faster and more reliable responses on the Internet and is widely used by most major Internet services.\nThe DNS reflects the structure of administrative responsibility in the Internet. Each subdomain is a zone of administrative autonomy delegated to a manager. For zones operated by a registry, administrative information is often complemented by the registry's RDAP and WHOIS services. That data can be used to gain insight on, and track responsibility for, a given host on the Internet.\nHistory.\nUsing a simpler, more memorable name in place of a host's numerical address dates back to the ARPANET era. The Stanford Research Institute (now SRI International) maintained a text file named HOSTS.TXT that mapped host names to the numerical addresses of computers on the ARPANET. Elizabeth Feinler developed and maintained the first ARPANET directory. Maintenance of numerical addresses, called the Assigned Numbers List, was handled by Jon Postel at the University of Southern California's Information Sciences Institute (ISI), whose team worked closely with SRI.\nAddresses were assigned manually. Computers, including their hostnames and addresses, were added to the primary file by contacting the SRI's Network Information Center (NIC), directed by Elizabeth Feinler, by telephone during business hours. Later, Feinler set up a WHOIS directory on a server in the NIC for retrieval of information about resources, contacts, and entities. She and her team developed the concept of domains. Feinler suggested that domains should be based on the location of the physical address of the computer. Computers at educational institutions would have the domain \"edu\", for example. She and her team managed the Host Naming Registry from 1972 to 1989.\nBy the early 1980s, maintaining a single, centralized host table had become slow and unwieldy and the emerging network required an automated naming system to address technical and personnel issues. Postel directed the task of forging a compromise between five competing proposals of solutions to Paul Mockapetris. Mockapetris instead created the Domain Name System in 1983.\nThe Internet Engineering Task Force published the original specifications in RFC 882 and RFC 883 in November 1983.\nIn 1984, four UC Berkeley students, Douglas Terry, Mark Painter, David Riggle, and Songnian Zhou, wrote the first Unix name server implementation for the Berkeley Internet Name Domain, commonly referred to as BIND. In 1985, Kevin Dunlap of DEC substantially revised the DNS implementation. Mike Karels, Phil Almquist, and Paul Vixie have maintained BIND since then. In the early 1990s, BIND was ported to the Windows NT platform.\nIn November 1987, RFC 1034 and RFC 1035 superseded the 1983 DNS specifications. Several additional Request for Comments have proposed extensions to the core DNS protocols.\nStructure.\nDomain name space.\nThe domain name space consists of a tree data structure. Each node or leaf in the tree has a \"label\" and zero or more \"resource records\" (RR), which hold information associated with the domain name. The domain name itself consists of the label, concatenated with the name of its parent node on the right, separated by a dot.\nThe tree sub-divides into \"zones\" beginning at the root zone. A DNS zone may consist of only one domain, or may consist of many domains and sub-domains, depending on the administrative choices of the zone manager. DNS can also be partitioned according to \"class\" where the separate classes can be thought of as an array of parallel namespace trees.\nAdministrative responsibility for any zone may be divided by creating additional zones. Authority over the new zone is said to be \"delegated\" to a designated name server. The parent zone ceases to be authoritative for the new zone.\nDomain name syntax, internationalization.\nThe definitive descriptions of the rules for forming domain names appear in RFC 1035, RFC 1123, RFC 2181, and RFC 5892. A domain name consists of one or more parts, technically called \"labels\", that are conventionally concatenated, and delimited by dots, such as example.com.\nThe right-most label conveys the top-level domain; for example, the domain name www.example.com belongs to the top-level domain \"com\".\nThe hierarchy of domains descends from right to left; each label to the left specifies a subdivision, or subdomain of the domain to the right. For example, the label \"example\" specifies a subdomain of the \"com\" domain, and \"www\" is a subdomain of example.com. This tree of subdivisions may have up to 127 levels.\nA label may contain zero to 63 characters. The null label, of length zero, is reserved for the root zone. The full domain name may not exceed the length of 253 characters in its textual representation. In the internal binary representation of the DNS the maximum length requires 255 octets of storage, as it also stores the length of the name.\nAlthough no technical limitation exists to use any character in domain name labels which are representable by an octet, hostnames use a preferred format and character set. The characters allowed in labels are a subset of the ASCII character set, consisting of characters \"a\" through \"z\", \"A\" through \"Z\", digits \"0\" through \"9\", and hyphen. This rule is known as the \"LDH rule\" (letters, digits, hyphen). Domain names are interpreted in case-independent manner. Labels may not start or end with a hyphen. An additional rule requires that top-level domain names should not be all-numeric.\nThe limited set of ASCII characters permitted in the DNS prevented the representation of names and words of many languages in their native alphabets or scripts. To make this possible, ICANN approved the Internationalizing Domain Names in Applications (IDNA) system, by which user applications, such as web browsers, map Unicode strings into the valid DNS character set using Punycode. In 2009 ICANN approved the installation of internationalized domain name country code top-level domains (\"ccTLD\"s). In addition, many registries of the existing top-level domain names (\"TLD\"s) have adopted the IDNA system, guided by RFC 5890, RFC 5891, RFC 5892, RFC 5893.\nName servers.\nThe Domain Name System is maintained by a distributed database system, which uses the client\u2013server model. The nodes of this database are the name servers. Each domain has at least one authoritative DNS server that publishes information about that domain and the name servers of any domains subordinate to it. The top of the hierarchy is served by the root name servers, the servers to query when looking up (\"resolving\") a TLD.\nAuthoritative name server.\nAn \"authoritative\" name server is a name server that only gives answers to DNS queries from data that has been configured by an original source, for example, the domain administrator or by dynamic DNS methods, in contrast to answers obtained via a query to another name server that only maintains a cache of data.\nAn authoritative name server can either be a \"primary\" server or a \"secondary\" server. Historically the terms \"master/slave\" and \"primary/secondary\" were sometimes used interchangeably but the current practice is to use the latter form. A primary server is a server that stores the original copies of all zone records. A secondary server uses a special automatic updating mechanism in the DNS protocol in communication with its primary to maintain an identical copy of the primary records.\nEvery DNS zone must be assigned a set of authoritative name servers. This set of servers is stored in the parent domain zone with name server (NS) records.\nAn authoritative server indicates its status of supplying definitive answers, deemed \"authoritative\", by setting a protocol flag, called the \"Authoritative Answer\" (\"AA\") bit in its responses. This flag is usually reproduced prominently in the output of DNS administration query tools, such as dig, to indicate \"that the responding name server is an authority for the domain name in question.\"\nOperation.\nAddress resolution mechanism.\nDomain name resolvers determine the domain name servers responsible for the domain name in question by a sequence of queries starting with the right-most (top-level) domain label.\nFor proper operation of its domain name resolver, a network host is configured with an initial cache (\"hints\") of the known addresses of the root name servers. The hints are updated periodically by an administrator by retrieving a dataset from a reliable source.\nAssuming the resolver has no cached records to accelerate the process, the resolution process starts with a query to one of the root servers. In typical operation, the root servers do not answer directly, but respond with a referral to more authoritative servers, e.g., a query for \"www.wikipedia.org\" is referred to the \"org\" servers. The resolver now queries the servers referred to, and iteratively repeats this process until it receives an authoritative answer. The diagram illustrates this process for the host that is named by the fully qualified domain name \"www.wikipedia.org\".\nThis mechanism would place a large traffic burden on the root servers, if every resolution on the Internet required starting at the root. In practice caching is used in DNS servers to off-load the root servers, and as a result, root name servers actually are involved in only a relatively small fraction of all requests.\nRecursive and caching name server.\nIn theory, authoritative name servers are sufficient for the operation of the Internet. However, with only authoritative name servers operating, every DNS query must start with recursive queries at the root zone of the Domain Name System and each user system would have to implement resolver software capable of recursive operation.\nTo improve efficiency, reduce DNS traffic across the Internet, and increase performance in end-user applications, the Domain Name System supports DNS cache servers which store DNS query results for a period of time determined in the configuration (\"time-to-live\") of the domain name record in question.\nTypically, such caching DNS servers also implement the recursive algorithm necessary to resolve a given name starting with the DNS root through to the authoritative name servers of the queried domain. With this function implemented in the name server, user applications gain efficiency in design and operation.\nThe combination of DNS caching and recursive functions in a name server is not mandatory; the functions can be implemented independently in servers for special purposes.\nInternet service providers typically provide recursive and caching name servers for their customers. In addition, many home networking routers implement DNS caches and recursors to improve efficiency in the local network.\nDNS resolvers.\nThe client side of the DNS is called a DNS resolver. A resolver is responsible for initiating and sequencing the queries that ultimately lead to a full resolution (translation) of the resource sought, e.g., translation of a domain name into an IP address. DNS resolvers are classified by a variety of query methods, such as \"recursive\", \"non-recursive\", and \"iterative\". A resolution process may use a combination of these methods.\nIn a \"non-recursive query\", a DNS resolver queries a DNS server that provides a record either for which the server is authoritative, or it provides a partial result without querying other servers. In case of a caching DNS resolver, the non-recursive query of its local DNS cache delivers a result and reduces the load on upstream DNS servers by caching DNS resource records for a period of time after an initial response from upstream DNS servers.\nIn a \"recursive query\", a DNS resolver queries a single DNS server, which may in turn query other DNS servers on behalf of the requester. For example, a simple stub resolver running on a home router typically makes a recursive query to the DNS server run by the user's ISP. A recursive query is one for which the DNS server answers the query completely by querying other name servers as needed. In typical operation, a client issues a recursive query to a caching recursive DNS server, which subsequently issues non-recursive queries to determine the answer and send a single answer back to the client. The resolver, or another DNS server acting recursively on behalf of the resolver, negotiates use of recursive service using bits in the query headers. DNS servers are not required to support recursive queries.\nThe \"iterative query\" procedure is a process in which a DNS resolver queries a chain of one or more DNS servers. Each server refers the client to the next server in the chain, until the current server can fully resolve the request. For example, a possible resolution of www.example.com would query a global root server, then a \"com\" server, and finally an \"example.com\" server.\nCircular dependencies and glue records.\nName servers in delegations are identified by name, rather than by IP address. This means that a resolving name server must issue another DNS request to find out the IP address of the server to which it has been referred. If the name given in the delegation is a subdomain of the domain for which the delegation is being provided, there is a circular dependency.\nIn this case, the name server providing the delegation must also provide one or more IP addresses for the authoritative name server mentioned in the delegation. This information is called \"glue\". The delegating name server provides this glue in the form of records in the \"additional section\" of the DNS response, and provides the delegation in the \"authority section\" of the response. A glue record is a combination of the name server and IP address.\nFor example, if the authoritative name server for example.org is ns1.example.org, a computer trying to resolve www.example.org first resolves ns1.example.org. As ns1 is contained in example.org, this requires resolving example.org first, which presents a circular dependency. To break the dependency, the name server for the top level domain org includes glue along with the delegation for example.org. The glue records are address records that provide IP addresses for ns1.example.org. The resolver uses one or more of these IP addresses to query one of the domain's authoritative servers, which allows it to complete the DNS query.\nRecord caching.\nA standard practice in implementing name resolution in applications is to reduce the load on the Domain Name System servers by caching results locally, or in intermediate resolver hosts. Results obtained from a DNS request are always associated with the time to live (TTL), an expiration time after which the results must be discarded or refreshed. The TTL is set by the administrator of the authoritative DNS server. The period of validity may vary from a few seconds to days or even weeks.\nAs a result of this distributed caching architecture, changes to DNS records do not propagate throughout the network immediately, but require all caches to expire and to be refreshed after the TTL. RFC 1912 conveys basic rules for determining appropriate TTL values.\nSome resolvers may override TTL values, as the protocol supports caching for up to sixty-eight years or no caching at all. Negative caching, i.e. the caching of the fact of non-existence of a record, is determined by name servers authoritative for a zone which must include the Start of Authority (SOA) record when reporting no data of the requested type exists. The value of the \"minimum\" field of the SOA record and the TTL of the SOA itself is used to establish the TTL for the negative answer.\nReverse lookup.\nA reverse DNS lookup is a query of the DNS for domain names when the IP address is known. Multiple domain names may be associated with an IP address. The DNS stores IP addresses in the form of domain names as specially formatted names in pointer (PTR) records within the infrastructure top-level domain arpa. For IPv4, the domain is in-addr.arpa. For IPv6, the reverse lookup domain is ip6.arpa. The IP address is represented as a name in reverse-ordered octet representation for IPv4, and reverse-ordered nibble representation for IPv6.\nWhen performing a reverse lookup, the DNS client converts the address into these formats before querying the name for a PTR record following the delegation chain as for any DNS query. For example, assuming the IPv4 address 208.80.152.2 is assigned to Wikimedia, it is represented as a DNS name in reverse order: 2.152.80.208.in-addr.arpa. When the DNS resolver gets a pointer (PTR) request, it begins by querying the root servers, which point to the servers of American Registry for Internet Numbers (ARIN) for the 208.in-addr.arpa zone. ARIN's servers delegate 152.80.208.in-addr.arpa to Wikimedia to which the resolver sends another query for 2.152.80.208.in-addr.arpa, which results in an authoritative response.\nClient lookup.\nUsers generally do not communicate directly with a DNS resolver. Instead DNS resolution takes place transparently in applications such as web browsers, e-mail clients, and other Internet applications. When an application makes a request that requires a domain name lookup, such programs send a resolution request to the DNS resolver in the local operating system, which in turn handles the communications required.\nThe DNS resolver will almost invariably have a cache (see above) containing recent lookups. If the cache can provide the answer to the request, the resolver will return the value in the cache to the program that made the request. If the cache does not contain the answer, the resolver will send the request to one or more designated DNS servers. In the case of most home users, the Internet service provider to which the machine connects will usually supply this DNS server: such a user will either have configured that server's address manually or allowed DHCP to set it; however, where systems administrators have configured systems to use their own DNS servers, their DNS resolvers point to separately maintained name servers of the organization. In any event, the name server thus queried will follow the process outlined above, until it either successfully finds a result or does not. It then returns its results to the DNS resolver; assuming it has found a result, the resolver duly caches that result for future use, and hands the result back to the software which initiated the request.\nBroken resolvers.\nSome large ISPs have configured their DNS servers to violate rules, such as by disobeying TTLs, or by indicating that a domain name does not exist just because one of its name servers does not respond.\nSome applications such as web browsers maintain an internal DNS cache to avoid repeated lookups via the network. This practice can add extra difficulty when debugging DNS issues as it obscures the history of such data. These caches typically use very short caching times on the order of one minute.\nInternet Explorer represents a notable exception: versions up to IE 3.x cache DNS records for 24 hours by default. Internet Explorer 4.x and later versions (up to IE 8) decrease the default timeout value to half an hour, which may be changed by modifying the default configuration.\nWhen Google Chrome detects issues with the DNS server it displays a specific error message.\nOther applications.\nThe Domain Name System includes several other functions and features.\nHostnames and IP addresses are not required to match in a one-to-one relationship. Multiple hostnames may correspond to a single IP address, which is useful in virtual hosting, in which many web sites are served from a single host. Alternatively, a single hostname may resolve to many IP addresses to facilitate fault tolerance and load distribution to multiple server instances across an enterprise or the global Internet.\nDNS serves other purposes in addition to translating names to IP addresses. For instance, mail transfer agents use DNS to find the best mail server to deliver e-mail: An MX record provides a mapping between a domain and a mail exchanger; this can provide an additional layer of fault tolerance and load distribution.\nThe DNS is used for efficient storage and distribution of IP addresses of blacklisted email hosts. A common method is to place the IP address of the subject host into the sub-domain of a higher level domain name, and to resolve that name to a record that indicates a positive or a negative indication.\nFor example:\nE-mail servers can query blacklist.example to find out if a specific host connecting to them is in the blacklist. Many of such blacklists, either subscription-based or free of cost, are available for use by email administrators and anti-spam software.\nTo provide resilience in the event of computer or network failure, multiple DNS servers are usually provided for coverage of each domain. At the top level of global DNS, thirteen groups of root name servers exist, with additional \"copies\" of them distributed worldwide via anycast addressing.\nDynamic DNS (DDNS) updates a DNS server with a client IP address on-the-fly, for example, when moving between ISPs or mobile hot spots, or when the IP address changes administratively.\nDNS message format.\nThe DNS protocol uses two types of DNS messages, queries and replies; both have the same format. Each message consists of a header and four sections: question, answer, authority, and an additional space. A header field (\"flags\") controls the content of these four sections.\nThe header section consists of the following fields: \"Identification\", \"Flags\", \"Number of questions\", \"Number of answers\", \"Number of authority resource records\" (RRs), and \"Number of additional RRs\". Each field is 16 bits long, and appears in the order given. The identification field is used to match responses with queries. The flag field consists of sub-fields as follows:\nAfter the flag, the header ends with four 16-bit integers which contain the number of records in each of the sections that follow, in the same order.\nQuestion section.\nThe question section has a simpler format than the resource record format used in the other sections. Each question record (there is usually just one in the section) contains the following fields:\nThe domain name is broken into discrete labels which are concatenated; each label is prefixed by the length of that label.\nDNS protocol transport.\nDNS primarily uses the User Datagram Protocol (UDP) on port number 53 to serve requests. DNS queries consist of a single UDP request from the client followed by a single UDP reply from the server. When the length of the answer exceeds 512 bytes and both client and server support Extension Mechanisms for DNS (EDNS), larger UDP packets are used. Otherwise, the query is sent again using the Transmission Control Protocol (TCP). TCP is also used for tasks such as zone transfers. Some resolver implementations use TCP for all queries.\nResource records.\nThe Domain Name System specifies a database of information elements for network resources. The types of information elements are categorized and organized with a list of DNS record types, the resource records (RRs). Each record has a type (name and number), an expiration time (time to live), a class, and type-specific data. Resource records of the same type are described as a \"resource record set\" (RRset), having no special ordering. DNS resolvers return the entire set upon query, but servers may implement round-robin ordering to achieve load balancing. In contrast, the Domain Name System Security Extensions (DNSSEC) work on the complete set of resource record in canonical order.\nWhen sent over an Internet Protocol network, all records use the common format specified in RFC 1035:\n\"NAME\" is the fully qualified domain name of the node in the tree . On the wire, the name may be shortened using label compression where ends of domain names mentioned earlier in the packet can be substituted for the end of the current domain name.\n\"TYPE\" is the record type. It indicates the format of the data and it gives a hint of its intended use. For example, the \"A\" record is used to translate from a domain name to an IPv4 address, the \"NS\" record lists which name servers can answer lookups on a DNS zone, and the \"MX\" record specifies the mail server used to handle mail for a domain specified in an e-mail address.\n\"RDATA\" is data of type-specific relevance, such as the IP address for address records, or the priority and hostname for MX records. Well known record types may use label compression in the RDATA field, but \"unknown\" record types must not (RFC 3597).\nThe \"CLASS\" of a record is set to IN (for \"Internet\") for common DNS records involving Internet hostnames, servers, or IP addresses. In addition, the classes Chaos (CH) and Hesiod (HS) exist. Each class is an independent name space with potentially different delegations of DNS zones.\nIn addition to resource records defined in a zone file, the domain name system also defines several request types that are used only in communication with other DNS nodes (\"on the wire\"), such as when performing zone transfers (AXFR/IXFR) or for EDNS (OPT).\nWildcard DNS records.\nThe domain name system supports wildcard DNS records which specify names that start with the \"asterisk label\", '*', e.g., *.example. DNS records belonging to wildcard domain names specify rules for generating resource records within a single DNS zone by substituting whole labels with matching components of the query name, including any specified descendants. For example, in the following configuration, the DNS zone \"x.example\" specifies that all subdomains, including subdomains of subdomains, of \"x.example\" use the mail exchanger (MX) \"a.x.example\". The A record for \"a.x.example\" is needed to specify the mail exchanger IP address. As this has the result of excluding this domain name and its subdomains from the wildcard matches, an additional MX record for the subdomain \"a.x.example\", as well as a wildcarded MX record for all of its subdomains, must also be defined in the DNS zone.\nThe role of wildcard records was refined in RFC 4592, because the original definition in RFC 1034 was incomplete and resulted in misinterpretations by implementers.\nProtocol extensions.\nThe original DNS protocol had limited provisions for extension with new features. In 1999, Paul Vixie published in RFC 2671 (superseded by RFC 6891) an extension mechanism, called Extension Mechanisms for DNS (EDNS) that introduced optional protocol elements without increasing overhead when not in use. This was accomplished through the OPT pseudo-resource record that only exists in wire transmissions of the protocol, but not in any zone files. Initial extensions were also suggested (EDNS0), such as increasing the DNS message size in UDP datagrams.\nDynamic zone updates.\nDynamic DNS updates use the UPDATE DNS opcode to add or remove resource records dynamically from a zone database maintained on an authoritative DNS server. The feature is described in RFC 2136. This facility is useful to register network clients into the DNS when they boot or become otherwise available on the network. As a booting client may be assigned a different IP address each time from a DHCP server, it is not possible to provide static DNS assignments for such clients.\nSecurity issues.\nOriginally, security concerns were not major design considerations for DNS software or any software for deployment on the early Internet, as the network was not open for participation by the general public. However, the expansion of the Internet into the commercial sector in the 1990s changed the requirements for security measures to protect data integrity and user authentication.\nSeveral vulnerability issues were discovered and exploited by malicious users. One such issue is DNS cache poisoning, in which data is distributed to caching resolvers under the pretense of being an authoritative origin server, thereby polluting the data store with potentially false information and long expiration times (time-to-live). Subsequently, legitimate application requests may be redirected to network hosts operated with malicious intent.\nDNS responses traditionally do not have a cryptographic signature, leading to many attack possibilities; the Domain Name System Security Extensions (DNSSEC) modify DNS to add support for cryptographically signed responses. DNSCurve has been proposed as an alternative to DNSSEC. Other extensions, such as TSIG, add support for cryptographic authentication between trusted peers and are commonly used to authorize zone transfer or dynamic update operations.\nSome domain names may be used to achieve spoofing effects. For example, and paypa1.com are different names, yet users may be unable to distinguish them in a graphical user interface depending on the user's chosen typeface. In many fonts the letter \"l\" and the numeral \"1\" look very similar or even identical. This problem is acute in systems that support internationalized domain names, as many character codes in ISO 10646 may appear identical on typical computer screens. This vulnerability is occasionally exploited in phishing.\nTechniques such as forward-confirmed reverse DNS can also be used to help validate DNS results.\nDNS can also \"leak\" from otherwise secure or private connections, if attention is not paid to their configuration, and at times DNS has been used to bypass firewalls by malicious persons, and exfiltrate data, since it is often seen as innocuous.\nPrivacy and tracking issues.\nOriginally designed as a public, hierarchical, distributed and heavily cached database, DNS protocol has no confidentiality controls. User queries and nameserver responses are being sent unencrypted which enables network packet sniffing, DNS hijacking, DNS cache poisoning and man-in-the-middle attacks. This deficiency is commonly used by cybercriminals and network operators for marketing purposes, user authentication on captive portals and censorship.\nUser privacy is further exposed by proposals for increasing the level of client IP information in DNS queries (RFC 7871) for the benefit of Content Delivery Networks.\nThe main approaches that are in use to counter privacy issues with DNS:\nSolutions preventing DNS inspection by local network operator are criticized for thwarting corporate network security policies and Internet censorship. They are also criticized from privacy point of view, as giving away the DNS resolution to the hands of a small number of companies known for monetizing user traffic and for centralizing DNS name resolution, which is generally perceived as harmful for the Internet.\nDomain name registration.\nThe right to use a domain name is delegated by domain name registrars which are accredited by the Internet Corporation for Assigned Names and Numbers (ICANN) or other organizations such as OpenNIC, that are charged with overseeing the name and number systems of the Internet. In addition to ICANN, each top-level domain (TLD) is maintained and serviced technically by an administrative organization, operating a registry. A \"registry\" is responsible for operating the database of names within its authoritative zone, although the term is most often used for TLDs. A \"registrant\" is a person or organization who asked for domain registration. The registry receives registration information from each domain name \"registrar\", which is authorized (accredited) to assign names in the corresponding zone and publishes the information using the WHOIS protocol. As of 2015, usage of RDAP is being considered.\nICANN publishes the complete list of TLDs, TLD registries, and domain name registrars. Registrant information associated with domain names is maintained in an online database accessible with the WHOIS service. For most of the more than 290 country code top-level domains (ccTLDs), the domain registries maintain the WHOIS (Registrant, name servers, expiration dates, etc.) information. For instance, DENIC, Germany NIC, holds the DE domain data. From about 2001, most Generic top-level domain (gTLD) registries have adopted this so-called \"thick\" registry approach, i.e. keeping the WHOIS data in central registries instead of registrar databases.\nFor top-level domains on COM and NET, a \"thin\" registry model is used. The domain registry (e.g., GoDaddy, BigRock and PDR, VeriSign, etc., etc.) holds basic WHOIS data (i.e., registrar and name servers, etc.). Organizations, or registrants using ORG on the other hand, are on the Public Interest Registry exclusively.\nSome domain name registries, often called \"network information centers\" (NIC), also function as registrars to end-users, in addition to providing access to the WHOIS datasets. The top-level domain registries, such as for the domains COM, NET, and ORG use a registry-registrar model consisting of many domain name registrars. In this method of management, the registry only manages the domain name database and the relationship with the registrars. The \"registrants\" (users of a domain name) are customers of the registrar, in some cases through additional subcontracting of resellers.\nRFC documents.\nStandards.\nThe Domain Name System is defined by Request for Comments (RFC) documents published by the Internet Engineering Task Force (Internet standards). The following is a list of RFCs that define the DNS protocol.\nInformational RFCs.\nThese RFCs are advisory in nature, but may provide useful information despite defining neither a standard or BCP. (RFC 1796)\nUnknown.\nThese RFCs have an official status of Unknown, but due to their age are not clearly labeled as such."}
{"id": "8340", "revid": "1755206", "url": "https://en.wikipedia.org/wiki?curid=8340", "title": "David Letterman", "text": "David Michael Letterman (born April 12, 1947) is an American television host, comedian, writer, and producer. He hosted late night television talk shows for 33 years, beginning with the February 1, 1982, debut of \"Late Night with David Letterman\" on NBC, and ending with the May 20, 2015, broadcast of \"Late Show with David Letterman\" on CBS. In total, Letterman hosted 6,080 episodes of \"Late Night\" and \"Late Show\", surpassing his friend and mentor Johnny Carson as the longest-serving late night talk show host in American television history. In 1996, Letterman was ranked 45th on \"TV Guide\"s 50 Greatest TV Stars of All Time. In 2002, \"The Late Show with David Letterman\" was ranked seventh on TV Guide's 50 Greatest TV Shows of All Time.\nHe is also a television and film producer. His company, Worldwide Pants, produced his shows as well as \"The Late Late Show\" and several prime-time comedies, the most successful of which was \"Everybody Loves Raymond\", now in syndication.\nSeveral late-night hosts have cited Letterman's influence, including Conan O'Brien (his successor on \"Late Night\"), Stephen Colbert (his successor on \"The Late Show\"), Jimmy Fallon, Jimmy Kimmel, John Oliver, and Seth Meyers.\nLetterman currently hosts the Netflix series \"My Next Guest Needs No Introduction with David Letterman\".\nEarly life and career.\nLetterman was born in Indianapolis, Indiana in 1947, and has two sisters, one older and one younger. His father, Harry Joseph Letterman (April 15, 1915 \u2013 February 13, 1973), was a florist. His mother, Dorothy Marie Letterman Mengering (n\u00e9e Hofert; July 18, 1921 \u2013 April 11, 2017), a church secretary for the Second Presbyterian Church of Indianapolis, was an occasional figure on Letterman's show, usually at holidays and birthdays.\nLetterman grew up on the north side of Indianapolis, in the Broad Ripple area, about 12 miles from the Indianapolis Motor Speedway. He enjoyed collecting model cars, including racers. In 2000, he told an interviewer for \"Esquire\" that, while growing up, he admired his father's ability to tell jokes and be the life of the party. Harry Joseph Letterman survived a heart attack at the age of 36, when David was a young boy. The fear of losing his father was constantly with Letterman as he grew up. The elder Letterman died of a second heart attack in 1973, at the age of 57.\nLetterman attended his hometown's Broad Ripple High School and worked as a stock boy at the local Atlas Supermarket. According to the \"Ball State Daily News\", he originally wanted to attend Indiana University, but his grades were not good enough, so he instead attended Ball State University, in Muncie, Indiana. He is a member of the Sigma Chi fraternity, and graduated in 1969 from what was then the Department of Radio and Television. A self-described average student, Letterman later endowed a scholarship for what he called \"C students\" at Ball State. Though he registered for the draft and passed his physical after graduating from college, he was not drafted for service in Vietnam because he received a draft lottery number of 346 (out of 366).\nLetterman began his broadcasting career as an announcer and newscaster at the college's student-run radio station\u2014WBST\u2014a 10-watt campus station that is now part of Indiana Public Radio. He was fired for treating classical music with irreverence. He then became involved with the founding of another campus station\u2014WAGO-AM 570 (now WWHI, 91.3).\nHe credits Paul Dixon, host of the \"Paul Dixon Show\", a Cincinnati-based talk show also shown in Indianapolis while he was growing up, for inspiring his choice of career:\nI was just out of college [in 1969], and I really didn't know what I wanted to do. And then all of a sudden I saw him doing it [on TV]. And I thought: That's really what I want to do!\nWeatherman.\nSoon after graduating from Ball State in 1969, Letterman began his career as a radio talk show host on WNTS (AM) and on Indianapolis television station WLWI (which changed its call sign to WTHR in 1976) as an anchor and weatherman. He received some attention for his unpredictable on-air behavior, which included congratulating a tropical storm for being upgraded to a hurricane and predicting hailstones \"the size of canned hams.\" He also occasionally reported the weather and the day's very high and low temps for fictitious cities (\"Eight inches of snow in Bingree and surrounding areas\"), on another occasion saying that the state border between Indiana and Ohio had been erased when a satellite map accidentally omitted it, attributing it to dirty political dealings. (\"The higher-ups have removed the border between Indiana and Ohio, making it one giant state. Personally, I'm against it. I don't know what to do about it.\") He also starred in a local kiddie show, made wisecracks as host of a late-night TV show called \"Freeze-Dried Movies\" (he once acted out a scene from \"Godzilla\" using plastic dinosaurs), and hosted a talk show that aired early on Saturday mornings called \"Clover Power\", in which he interviewed 4-H members about their projects.\nIn 1971, Letterman appeared as a pit road reporter for ABC Sports' tape-delayed coverage of the Indianapolis 500, which was his first nationally telecast appearance (WLWI was the local ABC affiliate at the time). He was initially introduced as Chris Economaki, but this was corrected at the end of the interview (Jim McKay announced his name as Dave Letterman). Letterman interviewed Mario Andretti, who had just crashed out of the race.\nMove to Los Angeles.\nIn 1975, encouraged by his then-wife Michelle and several of his Sigma Chi fraternity brothers, Letterman moved to Los Angeles, California, with hope of becoming a comedy writer. He and Michelle packed their belongings in his pickup truck and headed west. As of 2012, he still owned the truck. In Los Angeles, he began performing comedy at The Comedy Store. Jimmie Walker saw him on stage; with an endorsement from George Miller, Letterman joined a group of comedians whom Walker hired to write jokes for his stand-up act, a group that at various times also included Jay Leno, Paul Mooney, Robert Schimmel, Richard Jeni, Louie Anderson, Elayne Boosler, Byron Allen, Jack Handey, and Steve Oedekerk.\nBy the summer of 1977, Letterman was a writer and regular on the six-week summer series \"The Starland Vocal Band Show\", broadcast on CBS. He hosted a 1977 pilot for a game show called \"The Riddlers\" (which was never picked up), and co-starred in the Barry Levinson-produced comedy special \"Peeping Times\", which aired in January 1978. Later that year, Letterman was a cast member on Mary Tyler Moore's variety show, \"Mary\". He made a guest appearance on \"Mork &amp; Mindy\" (as a parody of EST leader Werner Erhard) and appearances on game shows such as \"The $20,000 Pyramid\", \"The Gong Show\", \"Hollywood Squares\", \"Password Plus\", and \"Liar's Club\", as well as the Canadian cooking show \"Celebrity Cooks\" (November 1977), talk shows such as \"90 Minutes Live\" (February 24 and April 14, 1978), and \"The Mike Douglas Show\" (April 3, 1979 and February 7, 1980). He was also screen tested for the lead role in the 1980 film \"Airplane!\", a role that eventually went to Robert Hays.\nLetterman's brand of dry, sarcastic humor caught the attention of scouts for \"The Tonight Show Starring Johnny Carson\", and he was soon a regular guest on the show. He became a favorite of Carson and was a regular guest host for the show beginning in 1978. Letterman credits Carson as the person who influenced his career the most.\nNBC.\nMorning show.\nOn June 23, 1980, Letterman was given his own morning comedy show on NBC, \"The David Letterman Show\". It was originally 90 minutes long, but was shortened to 60 minutes in August 1980. The show was a critical success, winning two Emmy Awards, but a ratings disappointment and was canceled, the last show airing October 24, 1980.\n\"Late Night with David Letterman\".\nNBC kept Letterman on its payroll to try him in a different time slot. \"Late Night with David Letterman\" debuted February 1, 1982; the first guest was Bill Murray. Murray went on to become one of Letterman's most recurrent guests, guesting on his later CBS show's celebration of his 30th anniversary in late-night television, which aired January 31, 2012, and on the final CBS show, which aired May 20, 2015. The show ran Monday through Thursday nights at 12:30\u00a0a.m. Eastern Time, immediately following \"The Tonight Show Starring Johnny Carson\" (a Friday night broadcast was added in June 1987). It was seen as edgy and unpredictable, and soon developed a cult following (particularly among college students). Letterman's reputation as an acerbic interviewer was borne out in verbal sparring matches with Cher (who even called him an \"asshole\" on the show), Shirley MacLaine, Charles Grodin, and Madonna. The show also featured comedy segments and running characters, in a style heavily influenced by the 1950s and 1960s programs of Steve Allen.\nThe show often featured quirky, genre-mocking regular features, including \"Stupid Pet Tricks\" (which had its origins on Letterman's morning show), Stupid Human Tricks, dropping various objects off the roof of a five-story building, demonstrations of unorthodox clothing (such as suits made of Alka-Seltzer, Velcro and suet), a recurring Top 10 list, the Monkey-Cam (and the Audience Cam), a facetious letter-answering segment, several \"Film[s] by My Dog Bob\" in which a camera was mounted on Letterman's own dog (often with comic results) and Small Town News, all of which moved with Letterman to CBS.\nOther episodes included Letterman using a bullhorn to interrupt a live interview on \"The Today Show\", announcing that he was the NBC News president and that he was not wearing any pants; walking across the hall to Studio 6B, at the time the news studio for WNBC-TV, and interrupting Al Roker's weather segments during \"Live at Five\"; and staging \"elevator races\", complete with commentary by NBC Sports' Bob Costas. In one appearance, in 1982, Andy Kaufman (who was wearing a neck brace) appeared with professional wrestler Jerry Lawler, who slapped and knocked the comedian to the ground (Lawler and Kaufman's friend Bob Zmuda later revealed that the incident was staged).\nCBS.\n\"Late Show with David Letterman\".\nIn 1992, Johnny Carson retired and many fans believed that Letterman would become host of \"The Tonight Show\". When NBC instead gave the job to Jay Leno, Letterman departed NBC to host his own late-night show on CBS, opposite \"The Tonight Show\" at 11:30\u00a0p.m., called the \"Late Show with David Letterman\". The new show debuted on August 30, 1993, and was taped at the historic Ed Sullivan Theater, where Ed Sullivan broadcast his eponymous variety series from 1948 to 1971. For Letterman's arrival, CBS spent \u00a0million in renovations. CBS also signed Letterman to a lucrative three-year, \u00a0million/year contract, doubling his \"Late Night\" salary. \nBut while the expectation was that Letterman would retain his unique style and sense of humor with the move, \"Late Show\" was not an exact replica of his old NBC program. The monologue was lengthened. Paul Shaffer and the World's Most Dangerous Band followed Letterman to CBS, but they added a brass section and were rebranded the CBS Orchestra (Shaffer's request); a small band had been mandated by Carson while Letterman occupied the 12:30 slot. Additionally, because of intellectual property disagreements, Letterman was unable to import many of his \"Late Night\" segments verbatim, but he sidestepped this problem by simply renaming them (the \"Top Ten List\" became the \"Late Show Top Ten\", \"Viewer Mail\" became the \"CBS Mailbag\", etc.). \"Time\" magazine wrote, \"Letterman's innovation ... gained power from its rigorous formalism\"; as his biographer Jason Zinoman puts it, he was \"a fascinatingly disgruntled eccentric trapped inside a more traditional talk show.\"\nPopularity.\nThe main competitor of the \"Late Show\" was NBC's \"The Tonight Show\", which was hosted by Jay Leno for 22 years, but from June 1, 2009, to January 22, 2010, by Conan O'Brien. In 1993 and 1994, the \"Late Show\" consistently gained higher ratings than \"The Tonight Show\". But in 1995, ratings dipped and Leno's show consistently beat Letterman's in the ratings from the time that Hugh Grant came on Leno's show after Grant's arrest for soliciting a prostitute.\nLeno typically attracted about five\u00a0million nightly viewers between 1999 and 2009. The \"Late Show\" lost nearly half its audience during its competition with Leno, attracting 7.1\u00a0million viewers nightly in its 1993\u201394 season and about 3.8\u00a0million per night as of Leno's departure in 2009. In the final months of his first stint as host of \"The Tonight Show\", Leno beat Letterman in the ratings by a 1.3\u00a0million viewer margin (5.2\u00a0million to 3.9\u00a0million), and \"Nightline\" and the \"Late Show\" were virtually tied. Once O'Brien took over \"Tonight\", Letterman closed the gap in the ratings. O'Brien initially drove the median age of \"Tonight Show\" viewers from 55 to 45, with most older viewers opting to watch the \"Late Show\" instead. Following Leno's return to \"The Tonight Show\", Leno regained his lead.\nLetterman's shows have garnered both critical and industry praise, receiving 67 Emmy Award nominations, winning 12 times in his first 20 years in late night television. From 1993 to 2009, Letterman ranked higher than Leno in the annual Harris Poll of \"Nation's Favorite TV Personality\" 12 times. For example, in 2003 and 2004 Letterman ranked second in that poll, behind only Oprah Winfrey, a year that Leno was ranked fifth. Leno was higher than Letterman on that poll three times during the same period, in 1998, 2007, and 2008.\nHosting the Academy Awards.\nOn March 27, 1995, Letterman hosted the 67th Academy Awards ceremony. Critics blasted him for what they deemed a poor hosting of the Oscars, noting that his irreverent style undermined the traditional importance and glamor of the event. In a joke about their unusual names (inspired by a celebrated comic essay in \"The New Yorker\", \"Yma Dream\" by Thomas Meehan), he started off by introducing Uma Thurman to Oprah Winfrey, and then both of them to Keanu Reeves: \"Oprah...Uma. Uma...Oprah,\" \"Have you kids met Keanu?\" This and many of his other jokes fell flat. Although Letterman attracted the highest ratings to the annual telecast since 1983, many felt that the bad publicity he generated caused a decline in the \"Late Show\"'s ratings.\nLetterman recycled the apparent debacle into a long-running gag. On his first show after the Oscars, he joked, \"Looking back, I had no idea that thing was being televised.\" He lampooned his stint two years later, during Billy Crystal's opening Oscar skit, which also parodied the plane-crashing scenes from that year's chief nominated film, \"The English Patient\".\nFor years afterward, Letterman recounted his hosting the Oscars, although the Academy of Motion Picture Arts and Sciences continued to hold Letterman in high regard and invited him to host the Oscars again. On September 7, 2010, he made an appearance on the premiere of the 14th season of \"The View\", and confirmed that he had been considered for hosting again.\nHeart surgery hiatus.\nOn January 14, 2000, a routine check-up revealed that an artery in Letterman's heart was severely obstructed. He was rushed to emergency surgery for a quintuple bypass at New York Presbyterian Hospital. During the initial weeks of his recovery, reruns of the \"Late Show\" were shown and introduced by friends of Letterman including Norm Macdonald, Drew Barrymore, Ray Romano, Robin Williams, Bonnie Hunt, Megan Mullally, Bill Murray, Regis Philbin, Charles Grodin, Nathan Lane, Julia Roberts, Bruce Willis, Jerry Seinfeld, Martin Short, Steven Seagal, Hillary Clinton, Danny DeVito, Steve Martin, and Sarah Jessica Parker.\nSubsequently, while still recovering from surgery, Letterman revived the late-night talk show tradition of \"guest hosts\" that had virtually disappeared on network television during the 1990s, allowing Bill Cosby, Kathie Lee Gifford, Dana Carvey, Janeane Garofalo, and others to host new episodes of the \"Late Show\". Upon his return to the show on February 21, 2000, Letterman brought all but one of the doctors and nurses on stage who had participated in his surgery and recovery (with extra teasing of a nurse who had given him bed baths\u2014\"This woman has seen me naked!\"), including Dr. O. Wayne Isom and physician Louis Aronne, who frequently appeared on the show. In a show of emotion, Letterman was nearly in tears as he thanked the health care team with the words \"These are the people who saved my life!\" The episode earned an Emmy nomination.\nFor a number of episodes, Letterman continued to crack jokes about his bypass, including saying, \"Bypass surgery: it's when doctors surgically create new blood flow to your heart. A bypass is what happened to me when I didn't get \"The Tonight Show!\" It's a whole different thing.\" In a later running gag he lobbied Indiana to rename the freeway circling Indianapolis (I-465) \"The David Letterman Bypass\". He also featured a montage of faux news coverage of his bypass surgery, which included a clip of Letterman's heart for sale on the Home Shopping Network. Letterman became friends with his doctors and nurses. In 2008, a \"Rolling Stone\" interview stated he hosted a doctor and nurse who'd helped perform the emergency quintuple-bypass heart surgery that saved his life in 2000. 'These are people who were complete strangers when they opened my chest,' he says. 'And now, eight years later, they're among my best friends.' Additionally, Letterman invited the band Foo Fighters to play \"Everlong\", introducing them as \"my favorite band, playing my favorite song.\" During Letterman's last show, on which Foo Fighters appeared, Letterman said that Foo Fighters had been in the middle of a South American tour which they canceled to come play on his comeback episode.\nLetterman again handed over the reins of the show to several guest hosts (including Bill Cosby, Brad Garrett, Whoopi Goldberg, Elvis Costello, John McEnroe, Vince Vaughn, Will Ferrell, Bonnie Hunt, Luke Wilson, and bandleader Paul Shaffer) in February 2003, when he was diagnosed with a severe case of shingles. Later that year, Letterman made regular use of guest hosts\u2014including Tom Arnold and Kelsey Grammer\u2014for new shows broadcast on Fridays. In March 2007, Adam Sandler, who had been scheduled to be the lead guest, served as a guest host while Letterman was ill with a stomach virus.\nRe-signing with CBS.\nIn March 2002, as Letterman's contract with CBS neared expiration, ABC offered him the time slot for long-running news program \"Nightline\" with Ted Koppel. Letterman was interested, as he believed he could never match Leno's ratings at CBS due to Letterman's complaint of weaker lead-ins from the network's late local news programs, but was reluctant to replace Koppel. He addressed his decision to re-sign on the air, stating that he was content at CBS and that he had great respect for Koppel.\nOn December 4, 2006, CBS revealed that Letterman signed a new contract to host \"Late Show with David Letterman\" through the fall of 2010. \"I'm thrilled to be continuing on at CBS,\" said Letterman. \"At my age you really don't want to have to learn a new commute.\" Letterman further joked about the subject by pulling up his right pants leg, revealing a tattoo, presumably temporary, of the ABC logo.\n\"Thirteen years ago, David Letterman put CBS late night on the map and in the process became one of the defining icons of our network,\" said Leslie Moonves, president and CEO of CBS Corporation. \"His presence on our air is an ongoing source of pride, and the creativity and imagination that the \"Late Show\" puts forth every night is an ongoing display of the highest quality entertainment. We are truly honored that one of the most revered and talented entertainers of our time will continue to call CBS 'home.'\"\nAccording to a 2007 article in \"Forbes\" magazine, Letterman earned \u00a0million a year. A 2009 article in \"The New York Times\", however, said his salary was estimated at \u00a0million per year. In June 2009, Letterman's Worldwide Pants and CBS reached an agreement to continue the \"Late Show\" until at least August 2012. The previous contract had been set to expire in 2010, and the two-year extension was shorter than the typical three-year contract period negotiated in the past. Worldwide Pants agreed to lower its fee for the show, though it had remained a \"solid moneymaker for CBS\" under the previous contract.\nOn the February 3, 2011, edition of the \"Late Show\", during an interview with Howard Stern, Letterman said he would continue to do his talk show for \"maybe two years, I think.\" In April 2012, CBS announced it had extended its contract with Letterman through 2014. His contract was subsequently extended to 2015.\nRetirement from \"Late Show\".\nDuring the taping of his show on April 3, 2014, Letterman announced that he had informed CBS president Leslie Moonves that he would retire from hosting \"Late Show\" by May 20, 2015. Later in his retirement Letterman occasionally stated, in jest, that he was fired. It was announced soon after that comedian and political satirist Stephen Colbert would succeed Letterman. Letterman's last episode aired on May 20, 2015, and opened with a presidential sendoff featuring four of the five living American presidents, George H. W. Bush, Bill Clinton, George W. Bush, and Barack Obama, each mimicking the late president Gerald Ford's statement \"Our long national nightmare is over.\" It also featured cameos from \"The Simpsons\" and \"Wheel of Fortune\" (the latter with a puzzle saying \"Good riddance to David Letterman\"), a Top Ten List of \"things I wish I could have said to David Letterman\" performed by regular guests including Alec Baldwin, Barbara Walters, Steve Martin, Jerry Seinfeld, Jim Carrey, Chris Rock, Julia Louis-Dreyfus, Peyton Manning, Tina Fey, and Bill Murray, and closed with a montage of scenes from both his CBS and NBC series set to a live performance of \"Everlong\" by Foo Fighters.\nThe final episode of \"Late Show with David Letterman\" was watched by 13.76\u00a0million viewers in the United States with an audience share of 9.3/24, earning the show its highest ratings since following the 1994 Winter Olympics on February 25, 1994, and the show's highest demo numbers (4.1 in adults 25\u201354 and 3.1 in adults 18\u201349) since Oprah Winfrey's first \"Late Show\" appearance following the ending of her feud with Letterman on December 1, 2005. Bill Murray, who had been his first guest on \"Late Night\", was his final guest on \"Late Show\". In a rarity for a late-night show, it was also the highest-rated program on network television that night, beating out all prime-time shows. In total, Letterman hosted 6,080 episodes of \"Late Night\" and \"Late Show\", surpassing friend and mentor Johnny Carson as the longest-serving late-night talk show host in American television history.\nPost-\"Late Show\".\nIn the months following the end of \"Late Show\", Letterman was seen occasionally at sports events such as the Indianapolis 500, during which he submitted to an interview with a local publication. He made a surprise appearance on stage in San Antonio, Texas, when he was invited up for an extended segment during Steve Martin and Martin Short's \"A Very Stupid Conversation\" show, saying \"I retired, and...I have no regrets,\" Letterman told the crowd after walking on stage. \"I was happy. I'll make actual friends. I was complacent. I was satisfied. I was content, and then a couple of days ago Donald Trump said he was running for president. I have made the biggest mistake of my life, ladies and gentlemen\" and then delivering a Top Ten List roasting Trump's presidential campaign followed by an on-stage conversation with Martin and Short. Cell phone recordings of the appearance were posted on YouTube by audience members and were widely reported in the media.\nIn 2016, Letterman joined the climate change documentary show \"Years of Living Dangerously\" as one of the show's celebrity correspondents. In season two's premiere episode, Letterman traveled to India to investigate the country's efforts to expand its inadequate energy grid, power its booming economy, and bring electricity to 300 million citizens for the first time. He also interviewed Indian Prime Minister Narendra Modi, and traveled to rural villages where power is a scarce luxury and explored the United States' role in India's energy future.\nOn April 7, 2017, Letterman gave the induction speech for the band Pearl Jam into the Rock &amp; Roll Hall Of Fame at a ceremony held at the Barclays Center in Brooklyn, New York City. Also in 2017, Letterman and Alec Baldwin co-hosted \"The Essentials\" on Turner Classic Movies. Letterman and Baldwin introduced seven films for the series.\nNetflix.\nIn 2018, Letterman began hosting a six-episode monthly series of hour-long programs on Netflix consisting of long-form interviews and field segments. The show, \"My Next Guest Needs No Introduction with David Letterman\", premiered January 12, 2018, with Barack Obama as its first guest. The second season premiered on May 31, 2019. Season 3 premiered on October 21, 2020, and includes Kim Kardashian West, Robert Downey Jr., Dave Chappelle and Lizzo as guests.\nNotable exchanges and incidents.\nNBC and Johnny Carson.\nIn spite of Johnny Carson's clear intention to pass his title to Letterman, NBC selected Jay Leno to host \"The Tonight Show\" after Carson's departure. Letterman maintained a close relationship with Carson through his break with NBC. Three years after he left for CBS, HBO produced a made-for-television movie called \"The Late Shift\", based on a book by \"The New York Times\" reporter Bill Carter, chronicling the battle between Letterman and Leno for the coveted \"Tonight Show\" hosting spot.\nCarson later made a few cameo appearances as a guest on Letterman's show. Carson's final television appearance came May 13, 1994, on a \"Late Show\" episode taped in Los Angeles, when he made a surprise appearance during a Top 10 list segment. In early 2005, it was revealed that Carson occasionally sent jokes to Letterman, who used them in his monologue; according to CBS senior vice president Peter Lassally (a onetime producer for both men), Carson got \"a big kick out of it.\" Letterman would do a characteristic Johnny Carson golf swing after delivering one of Carson's jokes. In a tribute to Carson, all the opening monologue jokes during the first show after Carson's death were by Carson.\nLassally also claimed that Carson had always believed Letterman, not Leno, to be his \"rightful successor\". During the early years of the \"Late Show\"s run, Letterman occasionally used some of Carson's trademark bits, including \"Carnac the Magnificent\" (with Paul Shaffer as Carnac), \"Stump the Band\", and the \"Week in Review\".\nOprah Winfrey.\nOprah Winfrey appeared on Letterman's show when he was hosting NBC's \"Late Night\" on May 2, 1989. Following that appearance, the two had a sixteen-year feud that arose, as Winfrey explained to Letterman after it had been resolved, as a result of the acerbic tone of their 1989 interview, of which she said that it \"felt so uncomfortable to me that I didn't want to have that experience again\". The feud apparently ended on December 2, 2005 when Winfrey appeared on CBS's \"Late Show with David Letterman\" in an event Letterman jokingly referred to as \"the Super Bowl of Love\".\nWinfrey and Letterman also appeared together in a \"Late Show\" promo aired during CBS's coverage of Super Bowl XLI in February 2007, with the two sitting next to each other on a couch watching the game. Since the game was played between the Indianapolis Colts and Chicago Bears, the Indianapolis-born Letterman wore a Peyton Manning jersey, while Winfrey, whose show was taped in Chicago, wore a Brian Urlacher jersey. On September 10, 2007, Letterman made his first appearance on \"The Oprah Winfrey Show\" at Madison Square Garden in New York City.\nThree years later, during CBS's coverage of Super Bowl XLIV between the Colts and the New Orleans Saints, the two appeared again in a \"Late Show\" promo, this time with Winfrey sitting on a couch between Letterman and Leno. Letterman wore the retired 70 jersey of Art Donovan, a member of the Colts' Hall of Fame and a regular Letterman guest. The appearance was Letterman's idea: Leno flew to New York City on an NBC corporate jet, sneaking into the Ed Sullivan Theater during the \"Late Show\"s February 4 taping wearing a disguise and meeting Winfrey and Letterman at a living room set created in the theater's balcony, where they taped their promo.\nWinfrey interviewed Letterman in January 2013 on \"Oprah's Next Chapter\". They discussed their feud and Winfrey revealed that she had had a \"terrible experience\" while appearing on Letterman's show years earlier. Letterman could not recall the incident but apologized.\n2007\u20132008 writers' strike.\n\"Late Show\" went off air for eight weeks in 2007 during November and December because of the Writers Guild of America strike. Letterman's production company, Worldwide Pants, was the first company to make an individual agreement with the WGA, allowing his show to come back on the air on January 2, 2008. In his first episode back, he surprised the audience with a newly grown beard, which signified solidarity with the strike. His beard was shaved off during the show on January 7, 2008.\nPalin joke.\nOn June 8 and 9, 2009, Letterman told two sexually themed jokes about a daughter (never named) of Sarah Palin on his TV show. Palin was in New York City at the time with her then 14-year-old daughter, Willow, and some contemporaries thought the jokes were aimed at Willow, which caused some controversy.\nIn a statement posted on the Internet, Palin said, \"I doubt [Letterman would] ever dare make such comments about anyone else's daughter\" and that \"laughter incited by sexually perverted comments made by a 62-year-old male celebrity aimed at a 14-year-old girl is disgusting.\" On his show of June 10, Letterman responded to the controversy, saying the jokes were meant to be about Palin's 18-year-old daughter, Bristol, whose pregnancy as an unmarried teenager had caused some controversy during the United States presidential election of 2008. \"These are not jokes made about [Palin's] 14-year-old daughter ... I would never, never make jokes about raping or having sex of any description with a 14-year-old girl.\"\nHis remarks did not put an end to public criticism, however. The National Organization for Women (NOW) released a statement supporting Palin, noting that Letterman had made \"[only] something of an apology.\" When the controversy failed to subside, Letterman addressed the issue again on his show of June 15, faulting himself for the error and apologizing \"especially to the two daughters involved, Bristol and Willow, and also to the governor and her family and everybody else who was outraged by the joke.\"\nAl-Qaeda death threat.\nOn August 17, 2011, it was reported that an Islamist militant had posted a death threat against Letterman on a website frequented by Al-Qaeda supporters, calling on American Muslims to kill Letterman for making a joke about the death of Ilyas Kashmiri, an Al-Qaeda leader who was killed in a June 2011 drone strike in Pakistan. In his show on August 22, Letterman joked about the threat, saying \"State Department authorities are looking into this. They're not taking this lightly. They're looking into it. They're questioning, they're interrogating, there's an electronic trail\u2014but everybody knows it's Leno.\"\nAppearances in other media.\nLetterman appeared in the pilot episode of the short-lived 1986 series \"Coach Toast\", and appears with a bag over his head as a guest on Bonnie Hunt's 1990s sitcom, \"The Building\". He appeared in \"The Simpsons\" as himself in a couch gag when the Simpsons find themselves (and the couch) in \"Late Night with David Letterman\". He had a cameo in the feature film \"Cabin Boy\", with Chris Elliott, who worked as a writer on Letterman's show. In this and other appearances, Letterman is listed in the credits as \"Earl Hofert\", the name of Letterman's maternal grandfather. He also appeared as himself in the Howard Stern biographical film \"Private Parts\" as well as the 1999 Andy Kaufman biopic \"Man on the Moon\", in a few episodes of Garry Shandling's 1990s TV series \"The Larry Sanders Show\", and in \"The Abstinence\", a 1996 episode of the sitcom \"Seinfeld\".\nLetterman provided vocals for the Warren Zevon song \"Hit Somebody\" from \"My Ride's Here\", and provided the voice for Butt-head's father in the 1996 animated film \"Beavis and Butt-Head Do America\", again credited as Earl Hofert.\nLetterman was the focus of \"The Avengers on \"Late Night with David Letterman\"\", issue 239 (January 1984) of the Marvel comic book series \"The Avengers\", in which the title characters (specifically Hawkeye, Wonder Man, Black Widow, Beast, and Black Panther) are guests on \"Late Night\". A parody of Letterman named David Endochrine is gassed to death along with his bandleader, Paul, and their audience in Frank Miller's \"The Dark Knight Returns\". In \"\", Letterman was parodied as \"David Litterbin\". Letterman appears in issues #13\u201314 and #18 of \"American Splendor\", the autobiographical comic book by Harvey Pekar. Those issues show Pekar's accounts of appearances on \"Late Night\".\nIn 2010, a documentary directed by Joke Fincioen and Biagio Messina, \"Dying to do Letterman\", was released, featuring Steve Mazan, a stand-up comic, who has cancer and wants to appear on the Letterman show. The film won best documentary and jury awards at the Cinequest Film Festival. Mazan published a book of the same name (full title \"Dying to Do Letterman: Turning Someday into Today\") about his own saga.\nLetterman appeared as a guest on CNN's \"Piers Morgan Tonight\" on May 29, 2012, when he was interviewed by Regis Philbin, the guest host and Letterman's long-time friend. Philbin again interviewed Letterman (and Shaffer) while guest-hosting CBS's \"The Late Late Show\" (between the tenures of Craig Ferguson and James Corden) on January 27, 2015. In June 2013, Letterman appeared in the second episode of season two of \"Comedians in Cars Getting Coffee\". On November 5, 2013, he and Bruce McCall published a fiction satire book, \"This Land Was Made for You and Me (But Mostly Me)\".\nBusiness ventures.\nLetterman started his production company, Worldwide Pants Incorporated, which produced his show and several others, in 1991. The company also produces feature films and documentaries and founded its own record label, Clear Entertainment. Worldwide Pants received significant attention in December 2007, after it was announced the company had independently negotiated its own contract with the Writers Guild of America, East, thus allowing Letterman, Craig Ferguson, and their writers to return to work, while the union continued its strike against production companies, networks, and studios with whom it had not yet reached agreements.\nLetterman, Bobby Rahal, and Mike Lanigan are co-owners of Rahal Letterman Lanigan Racing, an auto racing team competing in the WeatherTech SportsCar Championship and NTT IndyCar series. The team has twice won the Indianapolis 500: in 2004 with driver Buddy Rice, and in 2020 with Takuma Sato.\nThe Letterman Foundation for Courtesy and Grooming is a private foundation through which Letterman has donated millions of dollars to charities and other non-profit organizations in Indiana and Montana, celebrity-affiliated organizations such as Paul Newman's Hole in the Wall Gang Camp, Ball State University, the American Cancer Society, the Salvation Army, and \"M\u00e9decins Sans Fronti\u00e8res\".\nInfluences.\nLetterman's biggest influence and his mentor was Johnny Carson. Other comedians that influenced Letterman were Paul Dixon, Steve Allen, Jonathan Winters, Garry Moore, Jack Paar, Don Rickles, and David Brenner. Although Ernie Kovacs has also been mentioned as an influence, Letterman has denied this.\nComedians influenced by Letterman include Conan O'Brien, Jon Stewart, Stephen Colbert, Ray Romano, Jimmy Kimmel, Jay Leno, Arsenio Hall, Larry Wilmore, Seth Meyers, Norm Macdonald, Jimmy Fallon, John Oliver, and James Corden.\nPersonal life.\nOn July 2, 1968, Letterman married his college sweetheart, Michelle Cook, in Muncie, Indiana; their marriage ended in divorce by October 1977. He also had a long-term cohabiting relationship with the former head writer and producer on \"Late Night\", Merrill Markoe, from 1978 to 1988. Markoe was the mind behind several \"Late Night\" staples, such as \"Stupid Pet/Human Tricks\". \"Time\" magazine stated that theirs was the defining relationship of Letterman's career, with Markoe also acting as his writing partner. She \"put the surrealism in Letterman's comedy.\"\nLetterman and Regina Lasko started dating in February 1986, while he was still living with Markoe. Lasko gave birth to a son in 2003. In 2005, police discovered a plot to kidnap his son and demand a ransom of US$5\u00a0million. Kelly Frank, a house painter who had worked for Letterman, was charged in the conspiracy.\nLetterman and Lasko wed on March 19, 2009, in a quiet courthouse civil ceremony in Choteau, Montana, where he had purchased a ranch in 1999. Letterman announced the marriage during the taping of his show of March 23, shortly after congratulating Bruce Willis for his marriage the week before. Letterman told the audience he nearly missed the ceremony because his truck became stuck in mud two miles from their house. The family resides in North Salem, New York, on a estate.\nLetterman suffers from tinnitus, a symptom of hearing loss. On the \"Late Show\" in 1996, Letterman talked about his experience with tinnitus during an interview with William Shatner, who himself has severe tinnitus caused by an on-set explosion. Letterman has said that initially he was unable to pinpoint the noise inside his head, and that he hears a constant ringing in his ears 24\u00a0hours a day.\nLetterman no longer drinks alcohol. On more than one occasion, he said that he had once been a \"horrible alcoholic\" and had begun drinking around the age of 13 and continued until 1981 when he was 34. He has said that in 1981, \"I was drunk 80% of the time\u00a0... I loved it. I was one of those guys, I looked around, and everyone else had stopped drinking and I couldn't understand why.\" When he is shown drinking what appears to be alcohol on \"Late Night\" or the \"Late Show\", it is actually replaced with apple juice by the crew.\nIn 2015, Letterman said of his anxiety: \"For years and years and years\u201430, 40\u00a0years\u2014I was anxious and hypochondriacal and an alcoholic, and many, many other things that made me different from other people.\" He became calmer through a combination of transcendental meditation and low doses of medication. Letterman is a Presbyterian, a religious tradition he was originally brought up in by his mother, though he once said he was motivated by \"Lutheran, Midwestern guilt\".\nInterests.\nLetterman is a car enthusiast and owns an extensive collection. In 2012, it was reported that the collection consisted of ten Ferraris, eight Porsches, four Austin-Healeys, two Honda motorcycles, a Chevy pickup, and one car each from automakers Mercedes-Benz, Jaguar, MG, Volvo, and Pontiac.\nIn his 2013 appearance on \"Comedians in Cars Getting Coffee\", part of Jerry Seinfeld's conversation with Letterman was filmed in Letterman's 1995 Volvo 960 station wagon, which is powered by a 380-horsepower racing engine. Paul Newman had the car built for Letterman.\nLetterman shares a close relationship with the rock and roll band Foo Fighters since their appearance on his first show upon his return from heart surgery. The band appeared many times on the \"Late Show\", including a week-long stint in October 2014. While introducing the band's performance of \"Miracle\" on the show of October 17, 2014, Letterman told the story of how a souvenir video of himself and his four-year-old son learning to ski used the song as background music, unbeknownst to Letterman until he saw it. He stated: \"This is the second song of theirs that will always have great, great meaning for me for the rest of my life\". This was the first time the band had heard this story. Worldwide Pants co-produced Dave Grohl's \"\" TV series. \"Letterman was the first person to get behind this project,\" Grohl said.\nStalkers.\nBeginning in May 1988, Letterman was stalked by Margaret Mary Ray, a woman suffering from schizophrenia. She stole his Porsche, camped out on his tennis court, and repeatedly broke into his house. Her exploits drew national attention, with Letterman occasionally joking about her on his show, although he never referred to her by name. After she killed herself at age 46 in October 1998, Letterman told \"The New York Times\" that he had great compassion for her. A spokesperson for Letterman said: \"This is a sad ending to a confused life.\"\nIn 2005 another person was able to obtain a restraining order from a New Mexico judge, prohibiting Letterman from contacting her. She claimed he had sent her coded messages via his television program, causing her bankruptcy and emotional distress. Law professor Eugene Volokh called the case \"patently frivolous\".\nAffairs and blackmail.\nOn October 1, 2009, Letterman announced on his show that he had been the victim of a blackmail attempt by a person threatening to reveal his sexual relationships with several of his female employees\u2014a fact Letterman immediately thereafter confirmed. He said that someone had left a package in his car with material he said he would write into a screenplay and a book if Letterman did not pay him US$2\u00a0million. Letterman said that he contacted the Manhattan District Attorney's office and partook in a sting operation that involved the handover of a fake check to his extortionist.\nSubsequently, Joe Halderman, a producer of the CBS news magazine television series \"48 Hours\", was arrested around noon (EST) on October 1, 2009 after trying to deposit the check. He was indicted by a Manhattan grand jury following testimony from Letterman and pleaded not guilty to a charge of attempted grand larceny on October 2, 2009. Halderman pleaded guilty in March 2010 and was sentenced to six months in prison, followed by probation and community service.\nA central figure in the case and one of the women with whom Letterman had had a sexual relationship was his long-time personal assistant Stephanie Birkitt, who often appeared with him on his show. She had also worked for \"48 Hours\". Until a month before the revelations, she had shared a residence with Halderman, who allegedly had copied her personal diary and used it, along with private emails, in the blackmail package.\nIn the days following the initial announcement of the affairs and the arrest, several prominent women, including Kathie Lee Gifford, co-host of NBC's \"Today Show\", and NBC news anchor Ann Curry, questioned whether Letterman's affairs with subordinates created an unfair working environment. A spokesman for Worldwide Pants said that the company's sexual harassment policy did not prohibit sexual relationships between managers and employees. According to business news reporter Eve Tahmincioglu, \"CBS suppliers are supposed to follow the company's business conduct policies\" and the CBS 2008 Business Conduct Statement states that \"If a consenting romantic or sexual relationship between a supervisor and a direct or indirect subordinate should develop, CBS requires the supervisor to disclose this information to his or her Company's Human Resources Department\".\nOn October 3, 2009, a former CBS employee, Holly Hester, announced that she and Letterman had engaged in a year-long secret affair in the early 1990s while she was his intern and a student at New York University. On October 5, 2009, Letterman devoted a segment of his show to a public apology to his wife and staff. Three days later, Worldwide Pants announced that Birkitt had been placed on a \"paid leave of absence\" from the \"Late Show\". On October 15, CBS News announced that the company's chief investigative correspondent, Armen Keteyian, had been assigned to conduct an \"in-depth investigation\" into Letterman.\nAwards and honors.\nDavid Letterman Communication and Media Building.\nOn September 7, 2007, Letterman visited his \"alma mater\", Ball State University in Muncie, Indiana, for the dedication of a communications facility named in his honor for his dedication to the university. The \u00a0million, David Letterman Communication and Media Building opened for the 2007 fall semester. Thousands of Ball State students, faculty, and local residents welcomed Letterman back to Indiana. Letterman's emotional speech touched on his struggles as a college student and his late father, and also included the \"top ten good things about having your name on a building\", finishing with \"if reasonable people can put my name on a \u00a0million building, anything is possible.\" Over many years Letterman \"has provided substantial assistance to [Ball State's] Department of Telecommunications, including an annual scholarship that bears his name.\"\nAt the same time, Letterman received a Sagamore of the Wabash award given by Indiana Governor Mitch Daniels, which recognizes distinguished service to the state of Indiana.\nAwards and nominations.\nIn his capacities as either a performer, producer, or as part of a writing team, Letterman is among the most nominated people in the history of the Emmy Awards with 52 nominations, winning two Daytime Emmys and ten Primetime Emmys since 1981. He won four American Comedy Awards and in 2011 became the first recipient of the Johnny Carson Award for Comedic Excellence at The Comedy Awards.\nLetterman was a recipient of the 2012 Kennedy Center Honors, where he was called \"one of the most influential personalities in the history of television, entertaining an entire generation of late-night viewers with his unconventional wit and charm.\" On May 16, 2017, Letterman was named the next recipient of the Mark Twain Prize for American Humor, the award granted annually by the John F. Kennedy Center for the Performing Arts. He received the prize in a ceremony on October 22, 2017."}
{"id": "8341", "revid": "39720202", "url": "https://en.wikipedia.org/wiki?curid=8341", "title": "Delroy Lindo", "text": "Delroy George Lindo (born 18 November 1952) is a British-American actor of film, stage, and television. He is the recipient of such accolades as a NAACP Image Award, a Satellite Award, and nominations for a Drama Desk Award, a Helen Hayes Award, a Tony Award, two Critics' Choice Television Awards, and three Screen Actors Guild Awards.\nLindo has played prominent roles in four Spike Lee films: West Indian Archie in \"Malcolm X\" (1992), Woody Carmichael in \"Crooklyn\" (1994), Rodney Little in \"Clockers\" (1995), and Paul in \"Da 5 Bloods\" (2020), the latter of which he received universal acclaim for his performance as a Vietnam War veteran, winning the New York Film Critics Circle Award for Best Actor and the National Society of Film Critics Award for Best Actor. Lindo also played Bo Catlett in \"Get Shorty\" (1995), Arthur Rose in \"The Cider House Rules\" (1999), and Detective Castlebeck in \"Gone in 60 Seconds\" (2000). Lindo starred as Alderman Ronin Gibbons in the TV series \"The Chicago Code\" (2011), as Winter on the series \"Believe\" (2014), and currently stars as Adrian Boseman in \"The Good Fight\" (2017\u2013present).\nEarly life.\nDelroy Lindo was born in 1952 in Lewisham, south east London, the son of Jamaican parents who had immigrated in the United Kingdom. Lindo grew up in nearby Eltham, and became interested in acting as a child when he appeared in a nativity play at school. Lindo's mother emigrated to the UK in 1951 from Jamaica to work as a nurse and his father worked in various jobs. As a teenager, he and his mother moved to Toronto, Ontario, Canada. When he was sixteen, they moved to San Francisco. At the age of 24, Lindo started acting studies at the American Conservatory Theater, graduating in 1979.\nCareer.\nLindo's film debut came in 1976 with the Canadian John Candy comedy \"Find the Lady\", followed by two other roles in films, including an Army Sergeant in \"More American Graffiti\" (1979).\nHe stopped his film career for 10 years to concentrate on theatre acting. In 1982 he debuted on Broadway in \"\"Master Harold\"...and the Boys,\" directed by the play's South African author Athol Fugard. By 1988 Lindo had earned a Tony nomination for his portrayal of Herald Loomis in August Wilson's \"Joe Turner's Come and Gone\".\nLindo returned to film in the 1990s, acting alongside Rutger Hauer and Joan Chen in the science fiction film \"Salute of the Jugger\" (1990), which has become a cult classic. Although he had turned down Spike Lee for a role in \"Do the Right Thing\", Lee cast him as Woody Carmichael in the drama \"Crooklyn\" (1994), which brought him notice. Together with his other roles with Lee - as the West Indian Archie, a psychotic gangster, in \"Malcolm X\", and a starring role as a neighbourhood drug dealer in \"Clockers\" - he became established in his film career.\nOther films in which he has starring roles are Barry Sonnenfeld's \"Get Shorty\" (1995), Ron Howard's \"Ransom\" (1996) and \"Soul of the Game\" (1996), as the baseball player Satchel Paige.\nIn 1998 Lindo co-starred as African-American explorer Matthew Henson, in the TV film \"Glory &amp; Honor\", directed by Kevin Hooks. It portrayed his nearly 20-year partnership with Commander Robert Peary in Arctic exploration and their effort to find the Geographic North Pole in 1909. He received a Satellite Award for best actor. Lindo has continued to work in television and in 2006 was seen on the short-lived NBC drama \"Kidnapped\".\nLindo had a small role in the 1995 film \"Congo,\" playing the corrupt Captain Wanta. Lindo was not credited for the role. Lindo played an angel in the comedy film \"A Life Less Ordinary\" (1997).\nHe guest-starred on \"The Simpsons\" in the episode \"Brawl in the Family\", playing a character named Gabriel.\nIn the British film, \"Wondrous Oblivion\" (2003), directed by Paul Morrison, he starred as Dennis Samuels, the father of a Jamaican immigrant family in London in the 1950s; he coaches his children and the son of a neighbour Jewish family in cricket, earning their admiration in a time of strained social relations. Lindo said he made the film in honour of his parents, who had similarly moved to London in those years.\nIn 2007, Lindo began an association with Berkeley Repertory Theatre in Berkeley, California, when he directed Tanya Barfield's play \"The Blue Door\". In the autumn of 2008, Lindo revisited August Wilson's play, \"Joe Turner's Come and Gone\", directing a production at the Berkeley Rep. In 2010, he played the role of elderly seer Bynum in David Lan's production of \"Joe Turner\" at the Young Vic Theatre in London.\nIn 2015, Lindo was expected to play Marcus Garvey in a biopic of the black nationalist historical figure that had been in pre-production for several years.\nIn 2020, Lindo starred in \"Da 5 Bloods\", marking yet another collaboration with Spike Lee.\nLindo has an Honorary Doctorate in Arts and Humanities from Virginia Union University and in 2014, earned an M.F.A. from New York University\u2019s Gallatin School."}
{"id": "8343", "revid": "36439062", "url": "https://en.wikipedia.org/wiki?curid=8343", "title": "David Janssen", "text": "David Janssen (born David Harold Meyer) (March 27, 1931 - February 13, 1980) was an American film and television actor who is best known for his starring role as Richard Kimble in the television series \"The Fugitive\" (1963\u20131967). Janssen also had the title roles in three other series: \"Richard Diamond, Private Detective\"; \"Harry O\"; and \"O'Hara, U.S. Treasury\".\nIn 1996 \"TV Guide\" ranked him number 36 on its \"50 Greatest TV Stars of All Time\" list.\nAccording to friend and \"Fugitive\" co-star Barry Morse, \"David Janssen was well known as one of the hardest working actors in the USA\", regularly working 12-14 hours a day, and he kept working until his early death in 1980 at the age of 48.\nEarly life.\nDavid Janssen was born on March 27, 1931 in Naponee, a village in Franklin County in southern Nebraska, to Harold Edward Meyer, a banker (May 12, 1906\u00a0\u2013 November 4, 1990) and Berniece Graf (May 11, 1910\u00a0\u2013 November 26, 1995). Following his parents' divorce in 1935, his mother moved with five-year-old David to Los Angeles, California, and later married Eugene Janssen (February 18, 1918\u00a0\u2013 March 30, 1996) in 1940 in Los Angeles. Young David used his stepfather's name after he entered show business as a child.\nHe attended Fairfax High School in Los Angeles, where he excelled on the basketball court, setting a school scoring record that lasted over 20 years. His first film part was at the age of thirteen, and by the age of twenty-five he had appeared in twenty films and served two years as an enlisted man in the United States Army. During his Army days, Janssen became friends with fellow enlistees Martin Milner and Clint Eastwood while posted at Fort Ord, California.\nActing career.\nJanssen appeared in many television series before he landed programs of his own. In 1956, he and Peter Breck appeared in John Bromfield's syndicated series \"Sheriff of Cochise\" in the episode \"The Turkey Farmers\". Later, he guest-starred on NBC's medical drama \"The Eleventh Hour\" in the role of Hal Kincaid in the 1962 episode \"Make Me a Place\", with series co-stars Wendell Corey and Jack Ging. He joined friend Martin Milner in a 1962 episode of \"Route 66\" as the character Kamo in the episode \"One Tiger to a Hill.\"\nJanssen starred in four television series of his own:\nAt the time, the final episode of \"The Fugitive\" held the record for the greatest number of American homes with television sets to watch a series finale, at 72 percent in August 1967. \nHis films include \"To Hell and Back\", the biography of Audie Murphy, who was the most decorated American soldier of World War II; John Wayne's Vietnam war film \"The Green Berets\"; opposite Gregory Peck in the space story \"Marooned\", in which Janssen played an astronaut sent to rescue three stranded men in space, and \"The Shoes of the Fisherman\", as a television journalist in Rome reporting on the election of a new Pope (Anthony Quinn). He also played pilot Harry Walker in the 1973 action movie \"Birds of Prey\".\nHe starred as a Los Angeles police detective trying to clear himself in the killing of an apparently innocent doctor in the 1967 film \"Warning Shot\". The film was shot during a break in the spring and summer of 1966 between the third and fourth seasons of \"The Fugitive.\"\nJanssen played an alcoholic in the 1977 TV movie \"A Sensitive, Passionate Man\", which co-starred Angie Dickinson, and an engineer who devises an unbeatable system for blackjack in the 1978 made-for-TV movie \"Nowhere to Run\", co-starring Stefanie Powers and Linda Evans. Janssen's impressively husky voice was used to good effect as the narrator for the TV mini-series \"Centennial\" (1978\u201379); he also appeared in the final episode. He starred in the made-for-TV mini series \"S.O.S. Titanic\" as John Jacob Astor, playing opposite Beverly Ross as his wife, Madeleine, in 1979.\nThough Janssen's scenes were cut from the final release, he also appeared as a journalist in the film \"Inchon\", which he accepted to work with Laurence Olivier who played General Douglas MacArthur. At the time of his death, Janssen had just begun filming a television movie playing the part of Father Damien, the priest who dedicated himself to the leper colony on the island of Molokai, Hawaii. The part was eventually reassigned to actor Ken Howard of the CBS series \"The White Shadow\".\nIn 1996 \"TV Guide\" ranked \"The Fugitive\" number 36 on its '50 Greatest Shows of All Time' list.\nPersonal life.\nJanssen was married twice. His first marriage was to model and interior decorator Ellie Graham, whom he married in Las Vegas on August 25, 1958. They divorced in 1968. In 1975, he married actress and model Dani Crayne Greco. They remained married until Janssen's death.\nDeath.\nDavid Janssen died of a sudden heart attack in the early morning of February 13, 1980, at his home in Malibu, California at the age of 48. At the time of his death, Janssen was filming the television movie \"Father Damien\". Janssen was buried at the Hillside Memorial Park Cemetery in Culver City, California. A non-denominational funeral was held at the Jewish chapel of the cemetery on February 17. Suzanne Pleshette delivered the eulogy at the request of Janssen's widow. Milton Berle, Johnny Carson, Tommy Gallagher, Richard Harris, Stan Herman, Rod Stewart and Gregory Peck were among Janssen's pallbearers. Honorary pallbearers included Jack Lemmon, George Peppard, James Stewart and Danny Thomas.\nFor his contribution to the television industry, David Janssen has a star on the Hollywood Walk of Fame located on the 7700 block of Hollywood Boulevard."}
{"id": "8344", "revid": "1009657123", "url": "https://en.wikipedia.org/wiki?curid=8344", "title": "Docetism", "text": "In the history of Christianity, docetism (from the \"doke\u0129n\" \"to seem\", \"d\u00f3k\u0113sis\" \"apparition, phantom\") is the heterodox doctrine that the phenomenon of Jesus, his historical and bodily existence, and above all the human form of Jesus, was mere semblance without any true reality. Broadly it is taken as the belief that Jesus only seemed to be human, and that his human form was an illusion.\nThe word \"Dok\u0113ta\u00ed\" (\"Illusionists\") referring to early groups who denied Jesus's humanity, first occurred in a letter by Bishop Serapion of Antioch (197\u2013203), who discovered the doctrine in the Gospel of Peter, during a pastoral visit to a Christian community using it in Rhosus, and later condemned it as a forgery. It appears to have arisen over theological contentions concerning the meaning, figurative or literal, of a sentence from the Gospel of John: \"the Word was made Flesh\".\nDocetism was unequivocally rejected at the First Council of Nicaea in 325 and is regarded as heretical by the Catholic Church, Eastern Orthodox Church, Coptic Orthodox Church of Alexandria, Orthodox Tewahedo, and many Protestant denominations that accept and hold to the statements of these early church councils, such as Reformed Baptists, Reformed Christians, all Trinitarian Christians.\nDefinitions.\nDocetism is broadly defined as any teaching that claims that Jesus' body was either absent or illusory. The term 'docetic' is rather nebulous. Two varieties were widely known. In one version, as in Marcionism, Christ was so divine that he could not have been human, since God lacked a material body, which therefore could not physically suffer. Jesus only \"appeared\" to be a flesh-and-blood man; his body was a phantasm. Other groups who were accused of docetism held that Jesus was a man in the flesh, but Christ was a separate entity who entered Jesus' body in the form of a dove at his baptism, empowered him to perform miracles, and abandoned him upon his death on the cross.\nChristology and theological implications.\nDocetism's origin within Christianity is obscure. Ernst K\u00e4semann controversially defined the Christology of St John\u2019s Gospel as \"na\u00efve docetism\" in 1968. The ensuing debate reached an impasse as awareness grew that the very term \"docetism\", like \"gnosticism\", was difficult to define within the religio-historical framework of the debate. It has occasionally been argued that its origins were in heterodox Judaism or Oriental and Grecian philosophies. The alleged connection with Jewish Christianity would have reflected Jewish Christian concerns with the inviolability of (Jewish) monotheism. Docetic opinions seem to have circulated from very early times, 1 John 4:2 appearing explicitly to reject them. Some 1stcentury Christian groups developed docetic interpretations partly as a way to make Christian teachings more acceptable to pagan ways of thinking about divinity.\nIn his critique of the theology of Clement of Alexandria, Photius in his Myriobiblon held that Clement's views reflected a quasi-docetic view of the nature of Christ, writing that \"[Clement] hallucinates that the Word was not incarnate but \"only seems to be\".\" (\u1f40\u03bd\u03b5\u03b9\u03c1\u03bf\u03c0\u03bf\u03bb\u03b5\u1fd6 \u03ba\u03b1\u1f76 \u03bc\u1f74 \u03c3\u03b1\u03c1\u03ba\u03c9\u03b8\u1fc6\u03bd\u03b1\u03b9 \u03c4\u1f78\u03bd \u03bb\u03cc\u03b3\u03bf\u03bd \u1f00\u03bb\u03bb\u1f70 \"\u03b4\u03cc\u03be\u03b1\u03b9\".) In Clement's time, some disputes contended over whether Christ assumed the \"psychic\" flesh of mankind as heirs to Adam, or the \"spiritual\" flesh of the resurrection. Docetism largely died out during the first millennium AD.\nThe opponents against whom Ignatius of Antioch inveighs are often taken to be Monophysite docetists. In his letter to the Smyrnaeans, 7:1, written around 110AD, he writes:\nWhile these characteristics fit a Monophysite framework, a slight majority of scholars consider that Ignatius was waging a polemic on two distinct fronts, one Jewish, the other docetic; a minority holds that he was concerned with a group that commingled Judaism and docetism. Others, however, doubt that there was actual docetism threatening the churches, arguing that he was merely criticizing Christians who lived Jewishly or that his critical remarks were directed at an Ebionite or Cerinthian possessionist Christology, according to which Christ was a heavenly spirit that temporarily possessed Jesus.\nIslam and docetism.\nSome commentators have attempted to make a connection between Islam and docetism using the following Quranic verse:\nSome scholars accept that Islam was influenced by Manichaeism (Docetism) in this view. However the general consensus is that Manichaeism was not prevalent in Mecca in the 6th and 7th centuries, when Islam developed.\nDocetism and Christ myth theory.\nSince Arthur Drews published his \"The Christ Myth\" (\"Die Christusmythe\") in 1909, occasional connections have been drawn between docetist theories and the modern idea that Christ was a myth. Shailer Mathews called Drews' theory a \"modern docetism\". Frederick Cornwallis Conybeare thought any connection to be based on a misunderstanding of docetism. The idea recurred in classicist Michael Grant's 1977 review of the evidence for Jesus, who compared modern scepticism about a historical Jesus to the ancient docetic idea that Jesus only \"seemed\" to come into the world \"in the flesh\". Modern theories did away with \"seeming\"."}
{"id": "8347", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=8347", "title": "Greek drachma", "text": "The drachma ( , ; pl. \"drachmae\" or \"drachmas\") was the currency used in Greece during several periods in its history:\nIt was also a small unit of weight.\nAncient drachma.\nThe name \"drachma\" is derived from the verb (, \"(I) grasp\"). It is believed that the same word with the meaning of \"handful\" or \"handle\" is found in Linear B tablets of the Mycenean Pylos. Initially a drachma was a fistful (a \"grasp\") of six \"obolo\u00ed\" or \"obelo\u00ed\" (metal sticks, literally \"spits\") used as a form of currency as early as 1100\u00a0BC and being a form of \"bullion\": bronze, copper, or iron ingots denominated by weight. A hoard of over 150 rod-shaped obeloi was uncovered at Heraion of Argos in Peloponnese. Six of them are displayed at the Numismatic Museum of Athens.\nIt was the standard unit of silver coinage at most ancient Greek mints, and the name \"obol\" was used to describe a coin that was one-sixth of a drachma. The notion that \"drachma\" derived from the word for fistful was recorded by Herakleides of Pontos (387\u2013312\u00a0BC) who was informed by the priests of Heraion that Pheidon, king of Argos, dedicated rod-shaped obeloi to Heraion. Similar information about Pheidon's obeloi was also recorded at the Parian Chronicle.\nAncient Greek coins normally had distinctive names in daily use. The Athenian tetradrachm was called owl, the Aeginetic stater was called chelone, the Corinthian stater was called \"hippos\" (horse) and so on. Each city would mint its own and have them stamped with recognizable symbols of the city, known as badge in numismatics, along with suitable inscriptions, and they would often be referred to either by the name of the city or of the image depicted. The exact exchange value of each was determined by the quantity and quality of the metal, which reflected on the reputation of each mint.\nAmong the Greek cities that used the drachma were: Abdera, Abydos, Alexandria, Aetna, Antioch, Athens, Chios, Cyzicus, Corinth, Ephesus, Eretria, Gela, Catana, Kos, Maronia, Naxos, Pella, Pergamum, Rhegion, Salamis, Smyrni, Sparta, Syracuse, Tarsus, Thasos, Tenedos, Troy and more.\nThe 5th century BC Athenian \"tetradrachm\" (\"four drachmae\") coin was perhaps the most widely used coin in the Greek world prior to the time of Alexander the Great (along with the Corinthian stater). It featured the helmeted profile bust of Athena on the obverse (front) and an owl on the reverse (back). In daily use they were called \"glaukes\" (owls), hence the proverb , 'an owl to Athens', referring to something that was in plentiful supply, like 'coals to Newcastle'. The reverse is featured on the national side of the modern Greek 1 euro coin.\nDrachmae were minted on different weight standards at different Greek mints. The standard that came to be most commonly used was the Athenian or Attic one, which weighed a little over 4.3\u00a0grams.\nAfter Alexander the Great's conquests, the name \"drachma\" was used in many of the Hellenistic kingdoms in the Middle East, including the Ptolemaic kingdom in Alexandria and the Parthian Empire based in what is modern-day Iran. The Arabic unit of currency known as \"dirham\" (), known from pre-Islamic times and afterwards, inherited its name from the drachma or didrachm (, 2 drachmae); the dirham is still the name of the official currencies of Morocco and the United Arab Emirates. The Armenian dram () also derives its name from the drachma.\nValue.\nIt is difficult to estimate comparative exchange rates with modern currency because the range of products produced by economies of centuries gone by were different from today, which makes purchasing power parity (PPP) calculations very difficult; however, some historians and economists have estimated that in the 5th century BC a drachma had a rough value of 25 U.S. dollars (in the year 1990 \u2013 equivalent to 46.50 USD in 2015), whereas classical historians regularly say that in the heyday of ancient Greece (the fifth and fourth centuries) the daily wage for a skilled worker or a hoplite was one drachma, and for a heliast (juror) half a drachma since 425\u00a0BC.\nModern commentators derived from Xenophon that half a drachma per day (360 days per year) would provide \"a comfortable subsistence\" for \"the poor citizens\" (for the head of a household in 355\u00a0BC). Earlier in 422\u00a0BC, we also see in Aristophanes (\"Wasps\", line 300\u2013302) that the daily half-drachma of a juror is just enough for the daily subsistence of a family of three.\nA modern person might think of one drachma as the rough equivalent of a skilled worker's daily pay in the place where they live, which could be as low as US$1, or as high as $100, depending on the country.\nFractions and multiples of the drachma were minted by many states, most notably in Ptolemaic Egypt, which minted large coins in gold, silver and bronze.\nNotable Ptolemaic coins included the gold \"pentadrachm\" and \"octadrachm\", and silver \"tetradrachm\", \"decadrachm\" and \"pentakaidecadrachm\". This was especially noteworthy as it would not be until the introduction of the Guldengroschen in 1486 that coins of substantial size (particularly in silver) would be minted in significant quantities.\nFor the Roman successors of the drachma, see Roman provincial coins.\nDenominations of Ancient Greek drachma.\nThe weight of the silver drachma was approximately 4.3 grams or 0.15 ounces, although weights varied significantly from one city-state to another. It was divided into six obols of 0.72 grams, which were subdivided into four tetartemoria of 0.18 grams, one of the smallest coins ever struck, approximately 5\u20137\u00a0mm in diameter.\nHistoric currency divisions.\nMinae and talents were never actually minted: they represented weight measures used for commodities (e.g. grain) as well as metals like silver or gold. The New Testament mentions both didrachma and, by implication, tetradrachma in context of the Temple tax. Luke's Gospel includes a parable told by Jesus of a woman with 10 drachmae, who lost one and searched her home until she found it.\nModern drachma.\nFirst modern drachma.\nThe drachma was reintroduced in May 1832, shortly before the establishment of the modern state of Greece (with the exception of the subdivision Taurus). It replaced the \"phoenix\" at par. The drachma was subdivided into 100 lepta.\nCoins.\nThe first coinage consisted of copper denominations of 1, 2, 5 and 10 lepta, silver denominations of , , 1 and 5 drachmae and a gold coin of 20 drachmae. The drachma coin weighed 4.5\u00a0g and contained 90% silver, with the 20-drachma coin containing 5.8\u00a0g of gold.\nIn 1868, Greece joined the Latin Monetary Union and the drachma became equal in weight and value to the French franc. The new coinage issued consisted of copper coins of 1, 2, 5 and 10 lepta, with the 5- and 10-lepta coins bearing the names \"obolos\" () and \"diobolon\" (), respectively; silver coins of 20 and 50 lepta, 1, 2 and 5 drachmae and gold coins of 5, 10 and 20 drachmae. (Very small numbers of 50- and 100-drachma coins in gold were also issued.)\nIn 1894, cupro-nickel 5-, 10- and 20-lepta coins were introduced. No 1-lepton or 2-lepta coin had been issued since the late 1870s. Silver coins of 1 and 2 drachmae were last issued in 1911, and no coins were issued between 1912 and 1922, during which time the Latin Monetary Union collapsed due to World War I.\nBetween 1926 and 1930, a new coinage was introduced for the new Hellenic Republic, consisting of cupro-nickel coins in denominations of 20 lepta, 50 lepta, 1 drachma, and 2 drachmae; nickel coins of 5 drachmae; and silver coins of 10 and 20 drachmae. These were the last coins issued for the first modern drachma, and none were issued for the second.\nNotes.\nNotes were issued by the National Bank of Greece from 1841 until 1928. The Bank of Greece issued notes from 1928 until 2001, when Greece joined the Euro. Early denominations ranged from 10 to 500 drachmae. Smaller denominations (1, 2, 3 and 5 drachmae) were issued from 1885, with the first 5-drachma notes being made by cutting 10-drachma notes in half.\nWhen Greece finally achieved its independence from the Ottoman Empire in 1828, the phoenix was introduced as the monetary unit; its use was short-lived, however, and in 1832 the phoenix was replaced by the drachma, adorned with the image of King Otto of Greece, who reigned as modern Greece's first king from 1832 to 1862. The drachma was divided into 100 lepta. In 2002 the drachma ceased to be legal tender after the euro, the monetary unit of the European Union, became Greece's sole currency.\nFrom 1917 to 1920, the Greek government took control of issuing small change notes under Law 991/1917. During that time, the government issued denominations of 10 &amp; 50 lepta, and 1, 2 &amp; 5 drachmae. The National Bank of Greece introduced 1000-drachma notes in 1901, and the Bank of Greece introduced 5,000-drachma notes in 1928. The economic depression of the 1920s affected many nations around the globe, including Greece. In 1922, the Greek government issued a forced loan in order to finance their growing budget deficit. On April 1, 1922, the government decreed that half of all bank notes had to be surrendered and exchanged for 6.5% bonds. The notes were then cut in half, with the portion bearing the Greek crown standing in for the bonds while the other half was exchanged for a new issue of central bank notes at half the original value. The Greek government again issued notes between 1940 and 1944, in denominations ranging from 50 lepta to 20 drachmae.\nDuring the German\u2013Italian occupation of Greece from 1941 to 1944, catastrophic hyperinflation and Nazi looting of the Greek treasury caused much higher denominations to be issued, culminating in 100,000,000,000-drachma notes in 1944. The Italian occupation authorities in the Ionian Islands printed their own currency (Ionian drachma).\nSecond modern drachma.\nOn 11 November 1944, following the liberation of Greece from Nazi Germany, old drachma were exchanged for new ones at the rate of 50,000,000,000 to 1. Only paper money was issued for the second drachma. The government issued notes of 1, 5, 10 and 20 drachma, with the Bank of Greece issuing 50-, 100-, 500-, 1000-, 5000-, and 10,000-drachma notes. This drachma also suffered from high inflation. The government later issued 100-, 500-, and 1000-drachma notes, and the Bank of Greece issued 20,000-and 50,000-drachma notes.\nThird modern drachma.\nOn 9 April 1953, in an effort to halt inflation, Greece joined the Bretton Woods system. On 1 May 1954, the drachma was revalued at a rate of 1000 to 1, and small change notes were abolished for the last time. The third drachma assumed a fixed exchange rate of 30 drachmae per dollar until 20 October 1973: over the next 25 years, the official exchange rate gradually declined, reaching 400 drachmae per dollar. On 1 January 2002, the Greek drachma was officially replaced as the circulating currency by the euro, and it has not been legal tender since 1 March 2002.\nThird modern drachma coins.\nThe first issue of coins minted in 1954 consisted of holed aluminium 5-, 10- and 20-lepton pieces, with 50-lepton, 1-, 2-, 5- and 10-drachma pieces in cupro-nickel. A silver 20-drachma piece was issued in 1960, replacing the 20-drachma banknote, and also minted only in collector sets in 1965. Coins in denominations from 50 lepta to 20 drachmae carried a portrait of King Paul (1947\u20131964). New coins were introduced in 1966, ranging from 50 lepta to 10 drachmae, depicting King Constantine II (1964\u20131974). A silver 30 drachma coin for the centennial of Greece's royal dynasty was minted in 1963. The following year a non-circulating coin of this value was produced to commemorate the royal wedding. The reverse of all coins was altered in 1971 to reflect the military junta which was in power from 1967 to 1974. This design included a soldier standing in front of the flames of the rising phoenix.\nA 20-drachmae coin in cupro-nickel with an image of Europa on the obverse was issued in 1973. In the late 1973, several new coin types were introduced: unholed aluminium (10 and 20 lepta), nickel-brass (50 lepta, 1 drachma, and 2 drachmae) and cupro-nickel (5, 10, and 20 drachmae). These provisional coins carried the design of the phoenix rising from the flame on the obverse, and used the country's new designation as the \"Hellenic Republic\", replacing the coins also issued in 1973 as the Kingdom of Greece with King Constantine II's portrait. A new series of all 8 denominations was introduced in 1976 carrying images of early national heroes on the smaller values.\nCupro-nickel 50-drachmae coins were introduced in 1980. In 1986, aluminium-bronze 50-drachma coins were introduced, followed by copper 1- and 2-drachma pieces in 1988 and aluminium-bronze coins of 20 and 100 drachmae in 1990. In 2000, a set of 6 themed 500-drachma coins were issued to commemorate the 2004 Athens Olympic Games.\nCoins in circulation at the time of the adoption of the euro were\nBanknotes.\nThe first issues of banknotes were in denominations of 10, 20 and 50 drachmae, soon followed by 100, 500 and 1000 drachmae by 1956. 5000-drachma notes were introduced in 1984, followed by 10,000-drachma notes in 1995 and 200-drachma notes in 1997.\nBanknotes in circulation at the time of the adoption of the euro were\nEncoding.\nIn Unicode, the currency symbol is . There is a special Attic numeral, , for the value of one drachma but it fails to render in most browsers.\nRestoration.\nThe Drachmi Greek Democratic Movement Five Stars which was founded in 2013, aims to restore the Drachma, as Greece's currency.\nExternal links.\n "}
{"id": "8349", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=8349", "title": "Denarius", "text": "The denarius (, d\u0113n\u0101ri\u012b ) was the standard Roman silver coin from its introduction in the Second Punic War to the reign of Gordian III (AD 238\u2013244), when it was gradually replaced by the Antoninianus. It continued to be minted in very small quantities, likely for ceremonial purposes, until and through the tetrarchy (293\u2013313).\nThe word \"d\u0113n\u0101rius\" is derived from the Latin \"d\u0113n\u012b\" \"containing ten\", as its value was originally of 10 ass\u0113s. The word for \"money\" descends from it in Italian (\"denaro\"), Slovene (\"denar\"), Portuguese (\"dinheiro\"), and Spanish (\"dinero\"). Its name also survives in the dinar currency.\nIts symbol is represented in Unicode as \ud800\udd96 (U+10196), however it can also be represented as X\u0336 (capital letter X with combining long stroke overlay).\nHistory.\nA predecessor of the \"denarius\" was first struck in 269 or 268 BC, five years before the First Punic War, with an average weight of 6.81\u00a0grams, or of a Roman pound. Contact with the Greeks had prompted a need for silver coinage in addition to the bronze currency that the Romans were using at that time. This predecessor of the \"denarius\" was a Greek-styled silver coin of \"didrachm\" weight, which was struck in Neapolis and other Greek cities in southern Italy. These coins were inscribed with a legend that indicated that they were struck for Rome, but in style they closely resembled their Greek counterparts. They were rarely seen at Rome, to judge from finds and hoards, and were probably used either to buy supplies or pay soldiers.\nThe first distinctively Roman silver coin appeared around 226 BC. Classical historians have sometimes called these coins \"heavy denarii\", but they are classified by modern numismatists as \"quadrigati\", a term which survives in one or two ancient texts and is derived from the quadriga, or four-horse chariot, on the reverse. This, with a two-horse chariot or \"biga\" which was used as a reverse type for some early denarii, was the prototype for the most common designs used on Roman silver coins for a number of years.\nRome overhauled its coinage shortly before 211 BC, and introduced the denarius alongside a short-lived denomination called the victoriatus. The denarius contained an average 4.5\u00a0grams, or of a Roman pound, of silver, and was at first tariffed at ten asses, hence its name, which means 'tenner'. It formed the backbone of Roman currency throughout the Roman republic and the early empire.\nThe denarius began to undergo slow debasement toward the end of the republican period. Under the rule of Augustus (27 BC to AD 14) its weight fell to 3.9\u00a0grams (a theoretical weight of of a Roman pound). It remained at nearly this weight until the time of Nero (AD 37\u201368), when it was reduced to of a pound, or 3.4\u00a0grams. Debasement of the coin's silver content continued after Nero. Later Roman emperors also reduced its weight to 3\u00a0grams around the late 3rd century.\nThe value at its introduction was 10 asses, giving the denarius its name, which translates as \"containing ten\". In about 141 BC, it was re-tariffed at 16 asses, to reflect the decrease in weight of the as. The denarius continued to be the main coin of the Roman Empire until it was replaced by the so-called antoninianus in the early 3rd century AD. The coin was last issued, in bronze, under Aurelian between AD 270 and 275, and in the first years of the reign of Diocletian. ('Denarius', in \"A Dictionary of Ancient Roman Coins\", by John R. Melville-Jones (1990)).\nValue, Comparisons and silver content.\n1 gold aureus = 2 gold quinarii = 25 silver denarii = 50 silver quinarii = 100 bronze sestertii = 200 bronze dupondii = 400 copper asses = 800 copper semisses = 1,600 copper quadrantes\nIt is difficult to give even rough comparative values for money from before the 20th century, as the range of products and services available for purchase was so different. During the republic (509 BC\u201327 BC), a legionnaire earned 112.5 denarii per year (0.3 denarii per day) Under Julius Caesar, this was doubled to 225 denarii/yr, with soldiers having to pay for their own food and arms, while in the reign of Augustus a Centurion received at least 3,750 denarii per year, and for the highest rank, 15,000 denarii..\nBy the late Roman Republic and early Roman Empire (), a common soldier or unskilled laborer would be paid 1 denarius/day (with no tax deductions), around 300% inflation compared to the early period. Using the cost of bread as a baseline, this pay equates to around US$20 in 2013 terms. Expressed in terms of the price of silver, and assuming 0.999 purity, a troy ounce denarius had a precious metal value of around US$2.60 in 2021.\nAt the height of the Roman Empire a sextarius (546ml or about 2 1/4 cups) of ordinary wine cost roughly one Dupondius (\u215b of a Denarius), after Diocletian's Edict on Maximum Prices were issued in 301 AD, the same item cost 8 debased common denarii \u2013 6,400% inflation.\nSilver content plummeted across the lifespan of the denarius. Under the Roman Empire (after Nero) the denarius contained approximately 50 grains, 3.24 grams, or (0.105ozt) troy ounce. The fineness of the silver content varied with political and economic circumstances. From a purity of greater than 90% silver in the 1st century AD, the denarius fell to under 60% purity by AD 200, and plummeted to 5% purity by AD 300. By the reign of Gallienus, the \"antoninianus\" was a copper coin with a thin silver wash.\nInfluence.\nIn the final years of the 1st century BC Tincomarus, a local ruler in southern Britain, started issuing coins that appear to have been made from melted down \"denarii\". The coins of Eppillus, issued around Calleva Atrebatum around the same time, appear to have derived design elements from various \"denarii\" such as those of Augustus and M. Volteius.\nEven after the \"denarius\" was no longer regularly issued, it continued to be used as a unit of account, and the name was applied to later Roman coins in a way that is not understood. The Arabs who conquered large parts of the land that once belonged to the Eastern Roman Empire issued their own gold dinar. The lasting legacy of the \"denarius\" can be seen in the use of \"d\" as the abbreviation for the British penny until 1971. It also survived in France as the name of a coin, the denier. The denarius also survives in the common Arabic name for a currency unit, the \"dinar\" used from pre-Islamic times, and still used in several modern Arab nations. The major currency unit in former Principality of Serbia, Kingdom of Serbia and former Yugoslavia was \"dinar\", and it is still used in present-day Serbia. The Macedonian currency \"denar\" is also derived from the Roman denarius. The Italian word \"denaro\", the Spanish word \"dinero\", the Portuguese word \"dinheiro\", and the Slovene word \"\", all meaning money, are also derived from Latin \"denarius\".\nUse in the Bible.\nIn the New Testament, the gospels refer to the denarius as a day's wage for a common laborer (Matthew 20:2, John 12:5). In the Book of Revelation, during the Third Seal: Black Horse, a choinix (\"quart\") of wheat and three quarts of barley were each valued at one denarius. Bible scholar Robert H. Mounce says the price of the wheat and barley as described in the vision appears to be ten to twelve times their normal cost in ancient times. Revelation thus describes a condition where basic goods are sold at greatly inflated prices. Thus, the black horse rider depicts times of deep scarcity or famine, but not of starvation. Apparently, a choinix of wheat was the daily ration of one adult. Thus, in the conditions pictured by Revelation 6, the normal income for a working-class family would buy enough food for only one person. The less costly barley would feed three people for one day's wages.\nThe denarius is also mentioned in the Parable of the Good Samaritan (Luke 10:25\u201337). The Render unto Caesar passage in Matthew 22:15\u201322 and Mark 12:13\u201317 uses the word (\u03b4\u03b7\u03bd\u03ac\u03c1\u03b9\u03bf\u03bd) to describe the coin held up by Jesus, translated in the King James Bible as \"tribute penny\". It is commonly thought to be a denarius with the head of Tiberius."}
{"id": "8350", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=8350", "title": "Della Rovere", "text": "The Della Rovere family (; literally \"of the oak tree\") was a noble family of Italy. It had humble origins in Savona, in Liguria, and acquired power and influence through nepotism and ambitious marriages arranged by two Della Rovere popes: Francesco Della Rovere, who ruled as Sixtus IV from 1471 to 1484) and his nephew Giuliano, who became Julius II in 1503. Sixtus IV built the Sistine Chapel, which is named for him. The Basilica of San Pietro in Vincoli in Rome is the family church of the Della Rovere. Members of the family were influential in the Church of Rome, and as dukes of Urbino; that title was extinguished with the death of Francesco Maria II in 1631, and the family died out with the death of his granddaughter Vittoria, Grand Duchess of Tuscany.\nHistory.\nFrancesco Della Rovere was born into a poor family in Liguria in north-west Italy in 1414, the son of Leonardo della Rovere of Savona. He was elected pope in 1471. As Sixtus IV he was both wealthy and powerful, and at once set about giving power and wealth to his nephews of the Della Rovere and Riario families. Within months of his election, he had made Giuliano della Rovere (the future pope Julius II) and Pietro Riario both cardinals and bishops; four other nephews were also made cardinals. He made Giovanni Della Rovere, who was not a priest, prefect of Rome, and arranged for him to marry into the da Montefeltro family, dukes of Urbino. Sixtus claimed descent from a noble Della Rovere family, the counts of Vinovo in Piemonte, and adopted their coat-of-arms.\nGuidobaldo da Montefeltro adopted Francesco Maria I della Rovere, his sister's child and nephew of Pope Julius II. Guidobaldo I, who was heirless, called Francesco Maria at his court, and named him as heir of the Duchy of Urbino in 1504, this through the intercession of Julius II. In 1508, Francesco Maria inherited the duchy thereby starting the line of Rovere Dukes of Urbino. That dynasty ended in 1626 when Pope Urban VIII incorporated Urbino into the papal dominions. As compensation to the last sovereign duke, the title only could be continued by Francesco Maria II, and after his death by his heir, Federico Ubaldo.\nVittoria, last descendant of the della Rovere family (she was the only child of Federico Ubaldo), married Ferdinando II de' Medici, Grand Duke of Tuscany. They had two children: Cosimo III, Tuscany's longest reigning monarch, and Francesco Maria de' Medici, a prince of the Church.\nOther people with the same surname.\nAmong the many people who did not belong to this family, but bore the same name, are:\nand various artists, including:"}
{"id": "8351", "revid": "383280", "url": "https://en.wikipedia.org/wiki?curid=8351", "title": "David Mamet", "text": "David Alan Mamet (; born November 30, 1947) is an American playwright, film director, screenwriter and author. He won a Pulitzer Prize and received Tony nominations for his plays \"Glengarry Glen Ross\" (1984) and \"Speed-the-Plow\" (1988). He first gained critical acclaim for a trio of off-Broadway 1970s plays: \"The Duck Variations,\" \"Sexual Perversity in Chicago,\" and \"American Buffalo.\" His plays \"Race\" and \"The Penitent\", respectively, opened on Broadway in 2009 and previewed off-Broadway in 2017.\nFeature films that Mamet both wrote and directed include \"House of Games\" (1987), \"Homicide\" (1991), \"The Spanish Prisoner\" (1997) and his biggest commercial success \"Heist\" (2001). His screenwriting credits include \"The Postman Always Rings Twice\" (1981), \"The Verdict\" (1982), \"The Untouchables\" (1987), \"Hoffa\" (1992), \"Wag the Dog\" (1997), and \"Hannibal\" (2001). Mamet himself wrote the screenplay for the 1992 adaptation of \"Glengarry Glen Ross\", and wrote and directed the 1994 adaptation of his play \"Oleanna\" (1992). He was the executive producer and frequent writer for the TV show \"The Unit\" (2006\u20132009).\nMamet's books include: \"On Directing Film\" (1991), a commentary and dialogue about film-making; \"The Old Religion\" (1997), a novel about the lynching of Leo Frank; \"Five Cities of Refuge: Weekly Reflections on Genesis, Exodus, Leviticus, Numbers and Deuteronomy\" (2004), a Torah commentary with Rabbi Lawrence Kushner; \"The Wicked Son\" (2006), a study of Jewish self-hatred and antisemitism; \"Bambi vs. Godzilla\", a commentary on the movie business; \"The Secret Knowledge: On the Dismantling of American Culture\" (2011), a commentary on cultural and political issues; and \"Three War Stories\" (2013), a trio of novellas about the physical and psychological effects of war.\nEarly life.\nMamet was born in 1947 in Chicago to Lenore June (n\u00e9e Silver), a teacher, and Bernard Morris Mamet, a labor attorney. His family was Jewish. His paternal grandparents were Polish Jews. One of Mamet's earliest jobs was as a busboy at Chicago's London House and The Second City. He also worked as an actor, editor for \"Oui\" magazine and as a cab-driver. He was educated at the progressive Francis W. Parker School and at Goddard College in Plainfield, Vermont. At the Chicago Public Library Foundation 20th anniversary fundraiser in 2006, though, Mamet announced \"My alma mater is the Chicago Public Library. I got what little educational foundation I got in the third-floor reading room, under the tutelage of a Coca-Cola sign\".\nAfter a move to Chicago's North Side, Mamet encountered theater director Robert Sickinger, and began to work occasionally at Sickinger's Hull House Theatre. This represented the beginning of Mamet's lifelong involvement with the theater.\nCareer.\nTheater.\nMamet is a founding member of the Atlantic Theater Company; he first gained acclaim for a trio of off-Broadway plays in 1976, \"The Duck Variations,\" \"Sexual Perversity in Chicago,\" and \"American Buffalo.\" He was awarded the Pulitzer Prize in 1984 for \"Glengarry Glen Ross,\" which received its first Broadway revival in the summer of 2005. His play \"Race\", which opened on Broadway on December 6, 2009 and featured James Spader, David Alan Grier, Kerry Washington, and Richard Thomas in the cast, received mixed reviews. His play \"The Anarchist\", starring Patti LuPone and Debra Winger, in her Broadway debut, opened on Broadway on November 13, 2012 in previews and was scheduled to close on December 16, 2012. His 2017 play \"The Penitent\" previewed off-Broadway on February 8, 2017.\nIn 2002, Mamet was inducted into the American Theater Hall of Fame. Mamet later received the PEN/Laura Pels Theater Award for Grand Master of American Theater in 2010.\nIn 2017, Mamet released an online class for writers entitled \"David Mamet teaches dramatic writing\".\nIn 2019 Mamet returned to the London West End with a new play \"Bitter Wheat\", at the Garrick Theatre, starring John Malkovich.\nFilm.\nMamet's first film work was as a screenwriter, later directing his own scripts.\nMamet's first produced screenplay was the 1981 production of \"The Postman Always Rings Twice\", based on James M. Cain's novel. He received an Academy Award nomination one year later for \"The Verdict\", written in the late 1970s. He also wrote the screenplays for \"The Untouchables\" (1987), \"Hoffa\" (1992), \"The Edge\" (1997), \"Wag the Dog\" (1997), \"Ronin\" (1998), and \"Hannibal\" (2001). He received a second Academy Award nomination for \"Wag the Dog\".\nIn 1987, Mamet made his film directing debut with his screenplay \"House of Games\", which won Best Film and Best Screenplay awards at the 1987 Venice Film Festival and the Film of the Year in 1989 from the London Film Critics' Circle Awards. The film starred his then-wife, Lindsay Crouse, and many longtime stage associates and friends, including fellow Goddard College graduates. Mamet was quoted as saying, \"It was my first film as a director and I needed support, so I stacked the deck.\" After \"House of Games\", Mamet later wrote and directed two more films focusing on the world of con artists, \"The Spanish Prisoner\" (1997) and \"Heist\" (2001). Among those films, \"Heist\" enjoyed the biggest commercial success.\nOther films that Mamet both wrote and directed include: \"Things Change\" (1988), \"Homicide\" (1991) (nominated for the Palme d'Or at 1991 Cannes Film Festival and won a \"Screenwriter of the Year\" award for Mamet from the London Film Critics' Circle Awards), \"Oleanna\" (1994), \"The Winslow Boy\" (1999), \"State and Main\" (2000), \"Spartan\" (2004), \"Redbelt\" (2008), and the 2013 bio-pic TV movie \"Phil Spector\".\nA feature-length film, a thriller titled \"Blackbird\", was intended for release in 2015, but is still in development.\nWhen Mamet adapted his play for the 1992 film \"Glengarry Glen Ross\", he wrote an additional part (including the monologue \"Coffee's for closers\") for Alec Baldwin.\nMamet continues to work with an informal repertory company for his films, including Crouse, William H. Macy, Joe Mantegna, and Rebecca Pidgeon, as well as the aforementioned school friends.\nDavid did a rewrite of the script for \"Ronin\" under the pseudonym \"Richard Weisz\" and turned in an early version of a script for \"Malcolm X\" which was rejected by director Spike Lee. In 2000, Mamet directed a film version of \"Catastrophe,\" a one-act play by Samuel Beckett featuring Harold Pinter and John Gielgud (in his final screen performance). In 2008, he directed and wrote the mixed martial arts movie \"Redbelt,\" about a martial arts instructor tricked into fighting in a professional bout.\nIn \"On Directing Film\", Mamet asserts that directors should focus on getting the point of a scene across, rather than simply following a protagonist, or adding visually beautiful or intriguing shots. Films should create order from disorder in search of the objective.\nBooks.\nIn 1986 Mamet published \u201cWriting in Restaurants\u201d a collection of essays. \nIn 1990 Mamet published \"The Hero Pony\", a 55-page collection of poetry. He has also published a series of short plays, monologues and four novels, \"The Village\" (1994), \"The Old Religion\" (1997), \"Wilson: A Consideration of the Sources\" (2000), and \"Chicago\" (2018). He has written several non-fiction texts, and children's stories, including \"True and False: Heresy and Common Sense for the Actor\"(1997). In 2004 he published a lauded version of the classical Faust story, \"Faustus\", however, when the play was staged in San Francisco during the spring of 2004, it was not well received by critics. On May 1, 2010, Mamet released a graphic novel \"The Trials of Roderick Spode (The Human Ant)\".\nOn June 2, 2011, \"The Secret Knowledge: On the Dismantling of American Culture\", Mamet's book detailing his conversion from modern liberalism to \"a reformed liberal\" was released.\nMamet published \"Three War Stories\", a collection of novellas, on November 11, 2013. In an interview with Newsmax TV, Mamet said he wanted to write about war, despite never having served. Moreover, the book allowed Mamet to free characters that had occupied his mind for years. On the subject of characters as a reason for writing, Mamet told the host, \"You want to get these guys out of your head. You just want them to stop talking to you.\"\nOn December 3, 2019, Mamet is set to publish a novel, \"The Diary of a Porn Star by Priscilla Wriston-Ranger: As Told to David Mamet With an Afterword by Mr. Mamet.\"\nTelevision and radio.\nMamet wrote one episode of \"Hill Street Blues\", \"A Wasted Weekend\", that aired in 1987. His then-wife, Lindsay Crouse, appeared in numerous episodes (including that one) as Officer McBride. Mamet is also the creator, producer and frequent writer of the television series \"The Unit\", where he wrote a well-circulated memo to the writing staff. He directed a third-season episode of \"The Shield\" with Shawn Ryan. In 2007, Mamet directed two television commercials for Ford Motor Company. The two 30-second ads featured the Ford Edge and were filmed in Mamet's signature style of fast-paced dialogue and clear, simple imagery. Mamet's sister, Lynn, is a producer and writer for television shows, such as \"The Unit\" and \"Law &amp; Order\".\nMamet has contributed several dramas to BBC Radio through Jarvis &amp; Ayres Productions, including an adaptation of \"Glengarry Glen Ross\" for BBC Radio 3 and new dramas for BBC Radio 4. The comedy \"Keep Your Pantheon (or On the Whole I'd Rather Be in Mesopotamia)\" was aired in 2007. \"The Christopher Boy's Communion\" was another Jarvis &amp; Ayres production, first broadcast on BBC Radio 4 on March 8, 2021.\nOther media and political views.\nSince May 2005 he has been a contributing blogger at \"The Huffington Post\", drawing satirical cartoons with themes including political strife in Israel. In a 2008 essay at \"The Village Voice\" titled \"Why I Am No Longer a 'Brain-Dead Liberal'\" he revealed that he had gradually rejected so-called political correctness and progressivism and embraced conservatism. Mamet has spoken in interviews of changes in his views, highlighting his agreement with free market theorists such as Friedrich Hayek the historian Paul Johnson, and economist Thomas Sowell, whom Mamet called \"one of our greatest minds\".\nDuring promotion of a book, Mamet said British people had \"a taint of anti-semitism,\" claiming they \"want to give [Israel] away to some people whose claim is rather dubious.\" In the same interview, Mamet went on to say that \"there are famous dramatists and novelists [in the UK] whose works are full of anti-Semitic filth.\" He refused to give examples because of British libel laws (the interview was conducted in New York City for the \"Financial Times\"). He is known for his pro-Israel positions; in his book \"The Secret Knowledge\" he claimed that \"Israelis would like to live in peace within their borders; the Arabs would like to kill them all.\"\nMamet wrote an article for the November 2012 issue of \"The Jewish Journal of Greater Los Angeles\" imploring fellow Jewish Americans to vote for Republican nominee Mitt Romney.\nIn an essay for \"Newsweek\", published on January 29, 2013, Mamet argued against gun control laws: \"It was intended to guard us against this inevitable decay of government that the Constitution was written. Its purpose was and is not to enthrone a Government superior to an imperfect and confused electorate, but to protect us from such a government.\"\nMamet has described the NFL anthem protests as \"absolutely fucking despicable\". In a 2020 interview, he described Donald Trump as a \"great president\" and supported his re-election.\nMamet is a contributing editor to Flying magazine.\nCritical reception to Mamet.\n\"Mamet speak\".\nMamet's style of writing dialogue, marked by a cynical, street-smart edge, precisely crafted for effect, is so distinctive that it has come to be called \"Mamet speak.\" Mamet himself has criticized his (and other writers') tendency to write \"pretty\" at the expense of sound, logical plots. When asked how he developed his style for writing dialogue, Mamet said, \"In my family, in the days prior to television, we liked to while away the evenings by making ourselves miserable, based solely on our ability to speak the language viciously. That's probably where my ability was honed.\"\nOne instance of Mamet's dialogue style can be found in \"Glengarry Glen Ross\", in which two down-on-their-luck real estate salesmen are considering stealing from their employer's office. George Aaronow and Dave Moss equivocate on the meaning of \"talk\" and \"speak\", turning language and meaning to deceptive purposes:\nMamet dedicated \"Glengarry Glen Ross\" to Harold Pinter, who was instrumental in its being first staged at the Royal National Theatre, (London) in 1983, and whom Mamet has acknowledged as an influence on its success, and on his other work.\nMamet and gender issues.\nMamet's plays have frequently sparked debate and controversy. Following a 1992 staging of \"Oleanna\", a play in which a college student falsely accuses her professor of trying to rape her, a critic reported that the play divided the audience by gender and recounted that \"couples emerged screaming at each other\".\nIn his 2014 book \"David Mamet and Male Friendship\", Arthur Holmberg examined Mamet's portrayal of male friendships, especially focusing on the contradictions and ambiguities of male bonding as dramatized in Mamet's plays and films.\nPersonal life.\nMamet and actress Lindsay Crouse married in 1977 and divorced in 1990. The couple have two children, Willa and Zosia. Willa was a professional photographer and is now a singer/songwriter; Zosia is an actress. Mamet has been married to actress and singer-songwriter Rebecca Pidgeon since 1991. They live together in Santa Monica, California. They have two children, Clara and Noah.\nMamet is a Reform Jew and strongly pro-Israel.\nArchive.\nThe papers of David Mamet were sold to the Harry Ransom Center at the University of Texas at Austin in 2007 and first opened for research in 2009. The growing collection consists mainly of manuscripts and related production materials for most of his plays, films, and other writings, but also includes his personal journals from 1966 to 2005. In 2015, the Ransom Center secured a second major addition to Mamet's papers, including more recent works. Additional materials relating to Mamet and his career can be found in the Ransom Center's collections of Robert De Niro, Mel Gussow, Tom Stoppard, Sam Shepard, Paul Schrader, Don DeLillo, and John Russell Brown.\nWorks.\nMamet is credited as writer of these works except where noted. Credits in addition to writer also noted."}
{"id": "8352", "revid": "14967932", "url": "https://en.wikipedia.org/wiki?curid=8352", "title": "December 6", "text": ""}
{"id": "8353", "revid": "211905", "url": "https://en.wikipedia.org/wiki?curid=8353", "title": "December 5", "text": ""}
{"id": "8354", "revid": "211905", "url": "https://en.wikipedia.org/wiki?curid=8354", "title": "December 4", "text": ""}
{"id": "8355", "revid": "211905", "url": "https://en.wikipedia.org/wiki?curid=8355", "title": "December 3", "text": ""}
{"id": "8356", "revid": "26636090", "url": "https://en.wikipedia.org/wiki?curid=8356", "title": "December 2", "text": ""}
{"id": "8357", "revid": "35766075", "url": "https://en.wikipedia.org/wiki?curid=8357", "title": "December 1", "text": ""}
{"id": "8359", "revid": "9856656", "url": "https://en.wikipedia.org/wiki?curid=8359", "title": "December 24", "text": ""}
{"id": "8360", "revid": "211905", "url": "https://en.wikipedia.org/wiki?curid=8360", "title": "December 26", "text": ""}
{"id": "8361", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=8361", "title": "Definable real number", "text": "Informally, a definable real number is a real number that can be uniquely specified by its description. The description may be expressed as a construction or as a formula of a formal language. For example, the positive square root of 2, formula_1, can be defined as the unique positive solution to the equation formula_2, and it can be constructed with a compass and straightedge.\nDifferent choices of a formal language or its interpretation can give rise to different notions of definability. Specific varieties of definable numbers include the constructible numbers of geometry, the algebraic numbers, and the computable numbers. Because formal languages can have only countably many formulas, every notion of definable numbers has at most countably many definable real numbers. However, by Cantor's diagonal argument, there are uncountably many real numbers, so almost every real number is undefinable.\nConstructible numbers.\nOne way of specifying a real number uses geometric techniques. A real number \"r\" is a constructible number if there is a method to construct a line segment of length \"r\" using a compass and straightedge, beginning with a fixed line segment of length 1.\nEach positive integer, and each positive rational number, is constructible. The positive square root of 2 is constructible. However, the cube root of 2 is not constructible; this is related to the impossibility of doubling the cube.\nReal algebraic numbers.\nA real number \"r\" is called a real algebraic number if there is a polynomial \"p\"(\"x\"), with only integer coefficients, so that \"r\" is a root of \"p\", that is, \"p\"(\"r\")=0. \nEach real algebraic number can be defined individually using the order relation on the reals. For example, if a polynomial \"q\"(\"x\") has 5 roots, the third one can be defined as the unique \"r\" such that \"q\"(\"r\") = 0 and such that there are two distinct numbers less than \"r\" for which \"q\" is zero.\nAll rational numbers are algebraic, and all constructible numbers are algebraic. There are numbers such as the cube root of 2 which are algebraic but not constructible.\nThe real algebraic numbers form a subfield of the real numbers. This means that 0 and 1 are algebraic numbers and, moreover, if \"a\" and \"b\" are algebraic numbers, then so are \"a\"+\"b\", \"a\"\u2212\"b\", \"ab\" and, if \"b\" is nonzero, \"a\"/\"b\".\nThe real algebraic numbers also have the property, which goes beyond being a subfield of the reals, that for each positive integer \"n\" and each real algebraic number \"a\", all of the \"n\"th roots of \"a\" that are real numbers are also algebraic.\nThere are only countably many algebraic numbers, but there are uncountably many real numbers, so in the sense of cardinality most real numbers are not algebraic. This nonconstructive proof that not all real numbers are algebraic was first published by\nGeorg Cantor in his 1874 paper \"On a Property of the Collection of All Real Algebraic Numbers\".\nNon-algebraic numbers are called transcendental numbers. Specific examples of transcendental numbers include \u03c0 and Euler's number \"e\".\nComputable real numbers.\nA real number is a computable number if there is an algorithm that, given a natural number \"n\", produces a decimal expansion for the number accurate to \"n\" decimal places. This notion was introduced by Alan Turing in 1936.\nThe computable numbers include the algebraic numbers along with many transcendental numbers including \u03c0 and\u00a0\"e\". Like the algebraic numbers, the computable numbers also form a subfield of the real numbers, and the positive computable numbers are closed under taking \"n\"th roots for each positive\u00a0\"n\".\nNot all real numbers are computable. The entire set of computable numbers is countable, so most reals are not computable. Specific examples of noncomputable real numbers include the limits of Specker sequences, and algorithmically random real numbers such as Chaitin's \u03a9 numbers.\nDefinability in arithmetic.\nAnother notion of definability comes from the formal theories of arithmetic, such as Peano arithmetic. The language of arithmetic has symbols for 0, 1, the successor operation, addition, and multiplication, intended to be interpreted in the usual way over the natural numbers. Because no variables of this language range over the real numbers, a different sort of definability is needed to refer to real numbers. A real number \"a\" is \"definable in the language of arithmetic\" (or \"arithmetical\") if its Dedekind cut can be defined as a predicate in that language; that is, if there is a first-order formula \"\u03c6\" in the language of arithmetic, with three free variables, such that\nDefinability in models of ZFC.\nA real number \"a\" is first-order definable in the language of set theory, without parameters, if there is a formula \"\u03c6\" in the language of set theory, with one free variable, such that \"a\" is the unique real number such that \"\u03c6\"(\"a\") holds (see ). This notion cannot be expressed as a formula in the language of set theory.\nAll analytical numbers, and in particular all computable numbers, are definable in the language of set theory. Thus the real numbers definable in the language of set theory include all familiar real numbers such as 0, 1, \u03c0, \"e\", et cetera, along with all algebraic numbers. Assuming that they form a set in the model, the real numbers definable in the language of set theory over a particular model of ZFC form a field. \nEach set model \"M\" of ZFC set theory that contains uncountably many real numbers must contain real numbers that are not definable within \"M\" (without parameters). This follows from the fact that there are only countably many formulas, and so only countably many elements of \"M\" can be definable over \"M\". Thus, if \"M\" has uncountably many real numbers, we can prove from \"outside\" \"M\" that not every real number of \"M\" is definable over \"M\". \nThis argument becomes more problematic if it is applied to class models of ZFC, such as the von Neumann universe . The argument that applies to set models cannot be directly generalized to class models in ZFC because the property \"the real number \"x\" is definable over the class model \"N\"\" cannot be expressed as a formula of ZFC. Similarly, the question whether the von Neumann universe contains real numbers that it cannot define cannot be expressed as a sentence in the language of ZFC. Moreover, there are countable models of ZFC in which all real numbers, all sets of real numbers, functions on the reals, etc. are definable ."}
{"id": "8362", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=8362", "title": "Diego de Almagro", "text": "Diego de Almagro (; \u2013 July 8, 1538), also known as El Adelantado and El Viejo, was a Spanish conquistador known for his exploits in western South America. He participated with Francisco Pizarro in the Spanish conquest of Peru. While subduing the Inca Empire he laid the foundation for Quito and Trujillo as Spanish cities in present-day Ecuador and Peru respectively. From Peru Almagro led the first Spanish military expedition to central Chile. Back in Peru, a longstanding conflict with Pizarro over the control of the former Inca capital of Cuzco erupted into a civil war between the two bands of conquistadores. In the battle of Las Salinas in 1538 Almagro was defeated by the Pizarro brothers and months later he was executed.\nEarly years.\nThe origins of Diego de Almagro were humble. He was born in 1475 in the village of Almagro, in Ciudad Real, where he was given the name of the village for his surname as he was the illegitimate son of Juan de Montenegro and Elvira Guti\u00e9rrez. In order to preserve the honor of his mother, her relatives took the infant Diego and took him to the nearby town of Bola\u00f1os de Calatrava, where he was raised by Sancha L\u00f3pez del Peral, later moving to Aldea del Rey.\nAt the age of four he returned to Almagro, and was placed under the tutelage of an uncle named Hern\u00e1n Guti\u00e9rrez. At age fifteen he ran away from home because of his uncle's harshness. He went to the home of his mother, who was now living with her new husband, to tell her what had happened and that he was going to travel the world, and asked for some bread. His mother, anguished, gave him a piece of bread and some coins and said: \"Take, son, and do not give me more trouble, and go, and God help you in your adventure.\"\nHe went to Seville and after probably stealing to survive, Almagro became a \"criado\" or servant of Don Luis Gonzalez de Polanco, one of the four \"Alcaldes de la Casa y Corte de Su Majestad\" and later a Counselor of the Catholic Monarchs. While living in Seville, Almagro stabbed another servant in an argument, inflicting serious enough injuries that he was to be tried in court.\nDon Luis, using his influence, prevailed upon Don Pedro Arias D\u00e1vila to allow Almagro to embark in one of the ships going to the New World from the port of Sanlucar de Barrameda. The Casa de Contratacion (royal agency for the Spanish Empire required that the men who crossed the Atlantic provide their own weapons, clothes, and farming tools, which Don Polanco provided to his servant.\nArrival in America.\nDiego de Almagro, now in his late thirties, arrived in the New World on June 30, 1514, with the expedition that Ferdinand II of Aragon had sent under the leadership of D\u00e1vila. The expedition arrived at the city of Santa Mar\u00eda la Antigua del Dari\u00e9n, Panama, where many other future conquistadors were already assembled, among them Francisco Pizarro.\nThere are not many details of Almagro's activities during this period, but it is known that he accompanied various sailors who departed from Darien between 1514 and 1515. He eventually returned and settled in Darien, where he was granted an encomienda, building a house and making a living from agriculture.\nAlmagro undertook his first independent conquest on November 1515, commanding 260 men as he founded Villa del Acla, named after the Indian place. Due to illness he had to hand over command to Gaspar de Espinosa.\nEspinosa decided to undertake a new expedition, which departed in December 1515 with 200 men, including Almagro and Francisco Pizarro, who for the first time was designated as a captain. During this expedition, which lasted 14 months, Almagro, Pizarro and Hernando de Luque became close friends.\nAlso during this time Almagro established a friendship with Vasco N\u00fa\u00f1ez de Balboa, who was in charge of Acla. Almagro wanted to have a ship built with the remaining materials of the Espinosa expedition, to be finished on the coast of the \"Great South Sea\", as the Pacific Ocean was first called by the Spanish. Current historians do not believe that Almagro was expected to participate in Balboa's expedition and probably returned to Darien.\nAlmagro took part in the various expeditions that took place in the Gulf of Panama, including those of Espinosa, which were supported by Balboa's ships. Almagro was recorded as a witness on the lists of natives whom Espinosa ordered to be carried. He remained as an early settler in the newly founded city of Panama, staying there for four years, managing his properties and those of Pizarro. He took Ana Mart\u00ednez, an indigenous woman, as a common-law wife. In this period, his first son, \"El Mozo\", was born to them.\nConquest of Peru.\nBy 1524 an association of conquest regarding South America was formalized among Almagro, Pizarro and Luque. By the beginning of August 1524, they had received the requisite permission to discover and conquer lands further south. De Almagro would remain in Panama to recruit men and gather supplies for the expeditions led by Pizarro.\nAfter several expeditions to South America, Pizarro secured his stay in Peru with the \"Capitulation\" on 6 July 1529. During Pizarro's continued exploration of Incan territory, he and his men succeeded in defeating the Inca army under Emperor Atahualpa during the Battle of Cajamarca in 1532. De Almagro joined Pizarro soon afterward, bringing more men and arms.\nAfter Peru fell to the Spanish, both Pizarro and De Almagro initially worked together in the founding of new cities to consolidate their dominions. As such, Pizarro dispatched De Almagro to pursue Quizquiz, fleeing to the Inca Empire's northern city of Quito. Their fellow conquistador Sebasti\u00e1n de Belalc\u00e1zar, who had gone forth without Pizarro's approval, had already reached Quito and witnessed the destruction of the city by Inca general Rumi\u00f1awi. The Inca warrior had ordered the city to be burned and its gold to be buried at an undisclosed location where the Spanish could never find it. The arrival of Pedro de Alvarado from Guatemala, in search of Inca gold further complicated the situation for Almagro and Belalc\u00e1zar. Alvarado's presence, however, did not last long as he left South America in exchange for monetary compensation from Pizarro.\nIn an attempt to claim Quito ahead of Belalc\u00e1zar, in August 1534 De Almagro founded a city on the shores of Laguna de Colta (Colta Lake) in the foothills of Chimborazo, some south of present-day Quito, and named it \"Santiago de Quito.\" Four months later would come the foundation of the Peruvian city of Trujillo, which Almagro named as \"Villa Trujillo de Nueva Castilla\" (the Village of Trujillo in New Castille) in honor of Francisco Pizarro's birthplace, Trujillo in Extremadura, Spain. These events were the height of the Pizarro-Almagro friendship, which historians describe as one of the last events in which their friendship soon faded and entered a period of turmoil for the control of the Incan capital of Cuzco.\nConflict with Pizarro.\nAfter splitting the treasure of Inca emperor Atahualpa, both Pizarro and Almagro left towards Cuzco and took the city in 1533. However, De Almagro's friendship with Pizarro showed signs of deterioration in 1526 when Pizarro, in the name of the rest of the conquistadors, called forth the \"Capitulacion de Toledo\" law in which King Charles I of Spain had laid out his authorization for the conquest of Peru and the awards every conquistador would receive from it. Long before, however, each conquistador had promised to equally split the benefits. Pizarro managed to have a larger stake and awards for himself. Despite this, De Almagro still obtained an important fortune for his services, and the King awarded him in November 1532 the noble title of \"Don\" and he was assigned a personal coat of arms.\nAlthough by this time Diego de Almagro had already acquired sufficient wealth in the conquest of Peru and was living a luxurious life in Cuzco, the prospect of conquering the lands further south was very attractive to him. Given that the dispute with Pizarro over Cuzco had kept intensifying, Almagro spent a great deal of time and money equipping a company of 500 men for a new exploration south of Peru.\nBy 1534 the Spanish crown had determined to split the region in two parallel lines, forming the governorship of \"Nueva Castilla\" (from the 1\u00b0 to the 14\u00b0 latitude, close to Pisco), and that of \"Nueva Toledo\" (from the 14\u00b0 to the 25\u00b0 latitude, in Taltal, Chile), assigning the first to Francisco Pizarro and the second to Diego de Almagro. The crown had previously assigned Almagro the governorship of Cuzco, and as such De Almagro was heading there when Charles V divided the territory between Nueva Castilla and Nuevo Toledo. This might have been the reason why Almagro did not immediately confront Pizarro for Cuzco, and promptly decided to embark on his new quest for the discovery of the riches of Chile.\nDiscovery of Chile.\nThe preparations.\nCharles V had given Diego a grant extending two hundred leagues south of Francisco Pizarro's. Francisco and Diego concluded a new contract on 12 June 1535, in which they agreed to share future discoveries equally. Diego raised an expedition for Chile, expecting it \"would lead to even greater riches than they had found in Peru.\" Almagro prepared the way by sending ahead three of his Spanish soldiers, the religious chief of the Inca empire, Willaq Umu, and Paullo Topa, brother of Manco Inca Yupanqui. De Almagro sent Juan de Saavedra forward with one hundred and fifty men, and soon followed them with additional forces. Saavedra established on January 23, 1535 the first Spanish settlement in Bolivia near the Inca regional capital of Paria.\nFollowing the Inca Trail and crossing the Andes.\nAlmagro left Cuzco on July 3, 1535 with his supporters and stopped at Moina until the 20th of that month. Meanwhile, Francisco Pizarro's brother, Juan Pizarro, had arrested Inca Manco Inca Yupanqui, further complicating De Almagro's plans as it heavily increased the dissatisfaction of the Indians submitted to Spanish rule. Not having formally been appointed governor of any territories in the Capitulation of Toledo in 1528, however, forcing him to declare himself \"adelantado\" (governor) of Nueva Toledo, or southern Peru and present-day Chile. Some sources suggest Almagro received such a requirement in 1534 by the Spanish king and was officially declared governor of New Toledo.\nOnce he left Moina, De Almagro followed the Inca trail followed by 750 Spaniards deciding to join him in quest for the gold lost in the ransom of Atahualpa, which had mainly benefited the Pizarro brothers and their supporters. After crossing the Bolivian mountain range and traveling past Lake Titicaca, Almagro arrived on the shores of the Desaguadero River and finally set up camp in Tupiza. From there, the expedition stopped at Chicoana and then turned to the southeast to cross the Andes mountains.\nThe expedition turned out to be a difficult and exhausting endeavor. The hardest phase was the crossing of the Andean cordilleras: the cold, hunger and tiredness meant the death of various Spanish and natives, but mainly slaves who were not accustomed to such rigorous climate.\nUpon this point, De Almagro determined everything was a failure. He ordered a small group under Rodrigo Orgonez on a reconnaissance of the country to the south.\nBy luck, these men found the Valley of Copiap\u00f3, where Gonzalo Calvo Barrientos, a Spanish soldier whom Pizarro had expelled from Peru for stealing objects the Inca had offered for his ransom, had already established a friendship with the local natives. There, in the valley of the river Copiap\u00f3, Almagro took official possession of Chile and claimed it in the name of King Charles V.\nDismayed in Chile.\nDe Almagro promptly initiated the exploration of the new territory, starting up the valley the Aconcagua River, where he was well received by the natives. However, the intrigues of his interpreter, Felipillo, who had previously helped Pizarro in dealing with \"Atahualpa\", almost thwarted De Almagro's efforts. Felipillo had secretly urged the local natives to attack the Spanish, but they desisted, not understanding the dangers that they posed. De Almagro directed G\u00f3mez de Alvarado along with 100 horsemen and 100 foot to continue the exploration, which ended in the confluence of the \u00d1uble and Itata rivers. The Battle of Reinohuel\u00e9n between the Spanish and Mapuche indigenous peoples forced the explorers to return to the north.\nDe Almagro's own reconnaissance of the land and the bad news of G\u00f3mez de Alvarado's encounter with the fierce Mapuche, along with the bitter cold winter that settled ferociously upon them, only served to confirm that everything had failed. He never found gold or the cities which Incan scouts had told him lay ahead, only communities of the indigenous population who lived from subsistence agriculture. Local tribes put up fierce resistance to the Spanish forces. The exploration of the territories of Nueva Toledo, which lasted 2 years, was marked by a complete failure for De Almagro. Despite this, at first he thought staying and founding a city would serve well for his honor. The initial optimism that led Almagro to bring his son he had with the indigenous Panamanian Ana Mart\u00ednez to Chile had faded.\nSome historians have suggested that, but for the urging of his senior explorers, De Almagro would probably have stayed permanently in Chile. He was urged to return to Peru and this time take definitive possession of Cuzco, so as to consolidate an inheritance for his son. Dismayed with his experience in the south, Almagro made plans of return to Peru. He never officially founded a city in the territory of what is now Chile.\nThe withdrawal of the Spanish from valleys of Chile was violent: Almagro authorized his soldiers to ransack the natives' properties, leaving their soil desolate. In addition, the Spanish soldiers took natives captive to serve as slaves. The locals were captured, tied together, and forced to carry the heavy loads belonging to the conquistadors.\nReturn to Peru.\nAfter the exhausting crossing of the Atacama Desert, mainly due to the harsh weather conditions, Almagro finally reached Cuzco, Peru, in 1537. According to some authors, it was during this time that the Spanish term \"roto\" (torn), used by Peruvians to refer to Chileans, was first coined. De Almagro's disappointed troops returned to Cuzco with their \"torn clothes\" due to the extensive and laborious passage on foot by the Atacama Desert.\nAfter his return, De Almagro was surprised to learn of the Inca Manco's rebellion. Diego de Almagro sent an embassy to the Inca, but they mistrusted all of the Spaniards by this time. Hernando Pizarro's men formed an uneasy truce with De Almagro's men, surveying to determine the boundaries of their leaders' royal grants. They needed to determine in which portion the city of Cuzco was located. However, De Almagro's troops quickly took the city and imprisoned the Pizarro brothers, Hernando and Gonzalo, on the night of 8 April 1537.\nAfter occupying Cuzco, De Almagro confronted an army sent by Francisco Pizarro to liberate his brothers. Alonso de Alvarado commanded it and was defeated during the Battle of Abancay on July 12, 1537. He and some of his men were imprisoned. Later, Gonzalo Pizarro and De Alvarado escaped prison. Subsequent negotiations between Francisco Pizarro and De Almagro concluded with the liberation of Hernando, the third Pizarro brother, in return for conceding control and administration of Cuzco to De Almagro. Pizarro never intended to give up the city permanently, but was buying time to organize an army strong enough to defeat Almagro's troops. \nDuring this time De Almagro fell ill, and Pizarro and his brothers grabbed the opportunity to defeat him and his followers. The Almagristas were defeated at Las Salinas in April 1538, with Org\u00f3\u00f1ez being killed on the field of battle. De Almagro fled to Cuzco, still in the hands of his loyal supporters, but found only temporary refuge; the forces of the Pizarro brothers entered the city without resistance. Once captured, Almagro was humiliated by Hernando Pizarro and his requests to appeal to the King were ignored.\nWhen Diego de Almagro begged for his life, Hernando responded:\n\"-he was surprised to see Almagro demean himself in a manner so unbecoming a brave cavalier, that his fate was no worse than had befallen many a soldier before him; and that, since God had given him the grace to be a Christian, he should employ his remaining moments in making up his account with Heaven!\"\nAlmagro was condemned to death and executed by \"garrote\" in his dungeon, and then decapitated, on July 8, 1538. His corpse was taken to the public Plaza Mayor of Cuzco, where a herald proclaimed his crimes. Hern\u00e1n Ponce de Le\u00f3n took his body and buried him in the church of Our Lady of Mercy in Cuzco.\nEl Mozo.\nDiego de Almagro II (1520\u20131542), known as \"El Mozo\" (The Lad), son of Diego de Almagro I, whose mother was an Indian girl of Panama, became the foil of the conspirators who had put Pizarro to the sword. Pizarro was murdered on June 26, 1541; the conspirators promptly proclaimed the lad De Almagro Governor of Peru. From various causes, all of the conspirators either died or were killed except for one, who was executed after the lad Almagro gave an order. The lad De Almagro fought the desperate battle of Chupas on September 16, 1542, escaped to Cuzco, but was arrested, immediately condemned to death, and executed in the great square of the city."}
{"id": "8363", "revid": "13825260", "url": "https://en.wikipedia.org/wiki?curid=8363", "title": "Divinity", "text": "Divinity or the divine are things that are either related to, devoted to, or proceeding from a deity. What is or is not divine may be loosely defined, as it is used by different belief systems.\nThe root of the word \"divine\" is literally \"godly\" (from the Latin \"deus\", cf. \"Dyaus\", closely related to Greek \"zeus\", \"div\" in Persian and \"deva\" in Sanskrit, but the use varies significantly depending on which deity is being discussed.\nFor specific related academic terms, see Divinity (academic discipline), or Divine (Anglican).\nUsages.\nDivinity as a quality has two distinct usages:\nOverlap occurs between these usages because deities or godly entities are often identical with or identified by the powers and forces that are credited to them\u00a0\u2014 in many cases a deity is merely a power or force personified\u00a0\u2014 and these powers and forces may then be extended or granted to mortal individuals. For instance, Jehovah is closely associated with storms and thunder throughout much of the Old Testament. He is said to speak in thunder, and thunder is seen as a token of his anger. This power was then extended to prophets like Moses and Samuel, who caused thunderous storms to rain down on their enemies (see and 1 Samuel 12:18). Divinity always carries connotations of goodness, beauty, beneficence, justice, and other positive, pro-social attributes. In monotheistic faiths there is an equivalent cohort of malefic supernatural beings and powers, such as demons, devils, afreet, etc., which are not conventionally referred to as divine; \"demonic\" is often used instead. Pantheistic and polytheistic faiths make no such distinction; gods and other beings of transcendent power often have complex, ignoble, or even irrational motivations for their acts. Note that while the terms \"demon\" and \"demonic\" are used in monotheistic faiths as antonyms to \"divine\", they are in fact derived from the Greek word \"daim\u00f3n\" (\u03b4\u03b1\u03af\u03bc\u03c9\u03bd), which itself translates as \"divinity\".\nThere are three distinct usages of \"divinity\" and \"divine\" in religious discourse:\nEntity.\nIn monotheistic faiths, the word \"divinity\" is often used to refer to the singular God central to that faith. Often the word takes the definite article and is capitalized\u00a0\u2014 \"the Divinity\"\u00a0\u2014 as though it were a proper name or definitive honorific. \n\"Divine\"\u00a0\u2014 capitalized\u00a0\u2014 may be used as an adjective to refer to the manifestations of such a Divinity or its powers: e.g. \"basking in the Divine presence...\"\nThe terms \"divinity\" and \"divine\"\u00a0\u2014 uncapitalized, and lacking the definite article\u00a0\u2014 are sometimes used as to denote 'god(s) or certain other beings and entities which fall short of absolute Godhood but lie outside the human realm. These include (by no means an exhaustive list):\nDivine force or power.\nAs previously noted, divinities are closely related to the transcendent force(s) or power(s) credited to them, so much so that in some cases the powers or forces may themselves be invoked independently. This leads to the second usage of the word \"divine\" (and a less common usage of \"divinity\"): to refer to the operation of transcendent power in the world.\nIn its most direct form, the operation of transcendent power implies some form of divine intervention. For pan- and polytheistic faiths this usually implies the direct action of one god or another on the course of human events. In Greek legend, for instance, it was Poseidon (god of the sea) who raised the storms that blew Odysseus's craft off course on his return journey, and Japanese tradition holds that a god-sent wind saved them from Mongol invasion. Prayers or propitiations are often offered to specific gods of pantheisms to garner favorable interventions in particular enterprises: e.g. safe journeys, success in war, or a season of bountiful crops. Many faiths around the world\u00a0\u2014 from Japanese Shinto and Chinese traditional religion, to certain African practices and the faiths derived from those in the Caribbean, to Native American beliefs\u00a0\u2014 hold that ancestral or household deities offer daily protection and blessings. In monotheistic religions, divine intervention may take very direct forms: miracles, visions, or intercessions by blessed figures.\nTranscendent force or power may also operate through more subtle and indirect paths. Monotheistic faiths generally support some version of divine providence, which acknowledges that the divinity of the faith has a profound but unknowable plan always unfolding in the world. Unforeseeable, overwhelming, or seemingly unjust events are often thrown on 'the will of the Divine', in deferences like the Muslim \"inshallah\" ('as God wills it') and Christian 'God works in mysterious ways'. Often such faiths hold out the possibility of divine retribution as well, where the divinity will unexpectedly bring evil-doers to justice through the conventional workings of the world; from the subtle redressing of minor personal wrongs, to such large-scale havoc as the destruction of Sodom and Gomorrah or the biblical Great Flood. Other faiths are even more subtle: the doctrine of \"karma\" shared by Buddhism and Hinduism is a divine law similar to divine retribution but without the connotation of punishment: our acts, good or bad, intentional or unintentional, reflect back on us as part of the natural working of the universe. Philosophical Taoism also proposes a transcendent operant principle\u00a0\u2014 transliterated in English as \"tao\" or \"dao\", meaning 'the way'\u00a0\u2014 which is neither an entity or a being per se, but reflects the natural ongoing process of the world. Modern western mysticism and new age philosophy often use the term 'the Divine' as a noun in this latter sense: a non-specific principle or being that gives rise to the world, and acts as the source or wellspring of life. In these latter cases the faiths do not promote deference, as happens in monotheisms; rather each suggests a path of action that will bring the practitioner into conformance with the divine law: \"ahimsa\"\u00a0\u2014 'no harm'\u00a0\u2014 for Buddhist and Hindu faiths; \"de\" or \"te\"\u00a0\u2014 'virtuous action'\u00a0\u2014 in Taoism; and any of numerous practices of peace and love in new age thinking.\nMortals.\nIn the third usage, extensions of divinity and divine power are credited to living, mortal individuals. Political leaders are known to have claimed actual divinity in certain early societies\u00a0\u2014 the ancient Egyptian Pharaohs being the premier case\u00a0\u2014 taking a role as objects of worship and being credited with superhuman status and powers. More commonly, and more pertinent to recent history, leaders merely claim some form of divine mandate, suggesting that their rule is in accordance with the will of God. The doctrine of the divine right of kings was introduced as late as the 17th century, proposing that kings rule by divine decree; Japanese Emperors ruled by divine mandate until the inception of the Japanese constitution after World War II.\nLess politically, most faiths have any number of people that are believed to have been touched by divine forces: saints, prophets, heroes, oracles, martyrs, and enlightened beings, among others. Saint Francis of Assisi, in Catholicism, is said to have received instruction directly from God and it is believed that he grants plenary indulgence to all who confess their sins and visit his chapel on the appropriate day. In Greek mythology, Achilles' mother bathed him in the river Styx to give him immortality, and Hercules\u00a0\u2014 as the son of Zeus\u00a0\u2014 inherited near-godly powers. In religious Taoism, Lao Tsu is venerated as a saint with his own powers. Various individuals in the Buddhist faith, beginning with Siddhartha, are considered to be enlightened, and in religious forms of Buddhism they are credited with divine powers. Christ in the Bible is said to be God's Son and is said to have performed divine miracles.\nIn general, mortals with divine qualities are carefully distinguished from the deity or deities in their religion's main pantheon. Even the Christian faith, which generally holds Christ to be identical to God, distinguishes between God the Father and Christ the begotten Son. There are, however, certain esoteric and mystical schools of thought, present in many faiths\u00a0\u2014 Sufis in Islam, Gnostics in Christianity, Advaitan Hindus, Zen Buddhists, as well as several non-specific perspectives developed in new age philosophy\u00a0\u2014 which hold that all humans are in essence divine, or unified with the Divine in a non-trivial way. Such divinity, in these faiths, would express itself naturally if it were not obscured by the social and physical worlds we live in; it needs to be brought to the fore through appropriate spiritual practices.\nChristianity.\nIn traditional Christian theology, divinity is the state or quality of being divine, and can denote Godly nature or character. In Hebrew, the terms would usually be \"el\", \"elohim\", and in Greek usually \"theos\", or \"theias\". The divinity in the Bible is considered the Godhead itself, or God in general. Or it may have reference to a deity. Even angels in the Psalms are considered divine or \"elohim\", as spirit beings, in God's form.\nIn the New Testament the Greek word \u03b8\u03b5\u1fd6\u03bf\u03bd (\"theion\") in the Douay Version, is translated as \"divinity\". Examples are below:\nThe word translated as either \"deity\", \"Godhead\", or \"divinity\" in the Greek New Testament is also the Greek word \u03b8\u03b5\u03cc\u03c4\u03b7\u03c4\u03bf\u03c2 (\"theot\u0113tos\"), and the one verse that contains it is this:\nColossians 2:9\nThe word \"divine\" in the New Testament is the Greek word \u03b8\u03b5\u03af\u03b1\u03c2 (\"theias\"), and is the adjective form of \"divinity\". Biblical examples from the King James Bible are below:\nLatter-day Saints.\nThe most prominent conception of divine entities in The Church of Jesus Christ of Latter-day Saints (LDS Church) is the Godhead, a divine council of three distinct beings: Elohim (the Father), Jehovah (the Son, or Jesus), and the Holy Spirit. Joseph Smith described a nontrinitarian Godhead, with God the Father and Jesus Christ each having individual physical bodies, and the Holy Spirit as a distinct personage with a spirit body. Smith also introduced the existence of a Heavenly Mother in the King Follett Discourse, but very little is acknowledged or known beyond her existence.\nMormons hold a belief in the divine potential of humanity; Smith taught a form of divinization where mortal men and women can become like god through salvation and exaltation. Lorenzo Snow succinctly summarized this using a couplet, which is often repeated within the LDS Church: \"As man now is, God once was: As God now is, man may be.\"\nEpicureanism.\nEpicurean philosophy admits the existence of gods, but since it does not accept the supernatural and teaches that all things are material, posits a theology where the Epicurean gods are physical beings whose bodies are made of atoms and who live in the region between the words (intermundia). Needless to say, these gods do not need our worship, are not creators or maintainers of the cosmos, nor do they answer prayers. Therefore, Epicurean theology belongs properly in the realm of speculation about super-evolved, intelligent extraterrestrial life.\nHowever, Epicurus of Samos (the founder of the School) recognized the utility of religiosity and its central, unifying symbols. He was adamant in his requirement that his disciples be pious, and established two taboos concerning their conception of the gods: they had to believe that their gods were immortal (that is, indestructible and fully self-sufficient) and blessed (happy, or blissful). Outside of that, Epicureans are free to speculate concerning the nature of the highest life-forms in the cosmos."}
{"id": "8364", "revid": "4928500", "url": "https://en.wikipedia.org/wiki?curid=8364", "title": "Doug Engelbart", "text": ""}
{"id": "8365", "revid": "113850", "url": "https://en.wikipedia.org/wiki?curid=8365", "title": "Dynamical systems and chaos theory", "text": ""}
{"id": "8367", "revid": "405256", "url": "https://en.wikipedia.org/wiki?curid=8367", "title": "Depth of field", "text": "For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image. The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques/equipment.\nFactors affecting depth of field.\nFor cameras that can only focus on one object distance at a time, depth of field is the distance between the nearest and the farthest objects that are in acceptably sharp focus. \"Acceptably sharp focus\" is defined using a property called the \"circle of confusion\".\nThe depth of field can be determined by focal length, distance to subject, the acceptable circle of confusion size, and aperture. The approximate depth of field can be given by:\nfor a given circle of confusion (c), focal length (f), f-number (N), and distance to subject (u).\nAs distance or the size of the acceptable circle of confusion increases, the depth of field increases; however, increasing the size of the aperture or increasing the focal length reduces the depth of field. Depth of Field changes linearly with F-number and circle of confusion, but changes in proportional to the square of the focal length and the distance to the subject. As a result, photos taken at extremely close range have a proportionally much smaller depth of field.\nSensor size affects DOF in counterintuitive ways. Because the circle of confusion is directly tied to the sensor size, decreasing the size of the sensor while holding focal length and aperture constant will \"decrease\" the depth of field (by the crop factor). The resulting image however will have a different field of view. If the focal length is altered to maintain the field of view, the change in focal length will counter the decrease of DOF from the smaller sensor and \"increase\" the depth of field (also by the crop factor).\nEffect of lens aperture.\nFor a given subject framing and camera position, the DOF is controlled by the lens aperture diameter, which is usually specified as the f-number (the ratio of lens focal length to aperture diameter). Reducing the aperture diameter (increasing the f-number) increases the DOF because only the light travelling at shallower angles passes through the aperture. Because the angles are shallow, the light rays are within the acceptable circle of confusion for a greater distance.\nMotion pictures make only limited use of this control; to produce a consistent image quality from shot to shot, cinematographers usually choose a single aperture setting for interiors and another for exteriors, and adjust exposure through the use of camera filters or light levels. Aperture settings are adjusted more frequently in still photography, where variations in depth of field are used to produce a variety of special effects.\nEffect of circle of confusion.\nPrecise focus is only possible at an exact distance from the lens; at that distance, a point object will produce a point image. Otherwise, a point object will produce a blur spot shaped like the aperture, typically and approximately a circle. When this circular spot is sufficiently small, it is visually indistinguishable from a point, and appears to be in focus. The diameter of the largest circle that is indistinguishable from a point is known as the acceptable circle of confusion, or informally, simply as the circle of confusion. Points that produce a blur spot smaller than this acceptable circle of confusion are considered acceptably sharp.\nThe acceptable circle of confusion depends on how the final image will be used. It is generally accepted to be 0.25\u00a0mm for an image viewed from 25\u00a0cm away.\nFor 35\u00a0mm motion pictures, the image area on the film is roughly 22\u00a0mm by 16\u00a0mm. The limit of tolerable error was traditionally set at 0.05\u00a0mm (0.002\u00a0in) diameter, while for 16\u00a0mm\u00a0film, where the size is about half as large, the tolerance is stricter, 0.025\u00a0mm (0.001\u00a0in). More modern practice for 35\u00a0mm productions set the circle of confusion limit at 0.025\u00a0mm (0.001\u00a0in).\nCamera movements.\nThe term \"camera movements\" refers to swivel (swing and tilt, in modern terminology) and shift adjustments of the lens holder and the film holder. These features have been in use since the 1800s and are still in use today on view cameras, technical cameras, cameras with tilt/shift or perspective control lenses, etc. Swiveling the lens or sensor causes the plane of focus (POF) to swivel, and also causes the field of acceptable focus to swivel with the POF; and depending on the DOF criteria, to also change the shape of the field of acceptable focus. While calculations for DOF of cameras with swivel set to zero have been discussed, formulated, and documented since before the 1940s, documenting calculations for cameras with non-zero swivel seem to have begun in 1990.\nMore so than in the case of the zero swivel camera, there are various methods to form criteria and set up calculations for DOF when swivel is non-zero. There is a gradual reduction of clarity in objects as they move away from the POF, and at some virtual flat or curved surface the reduced clarity becomes unacceptable. Some photographers do calculations or use tables, some use markings on their equipment, some judge by previewing the image.\nWhen the POF is rotated, the near and far limits of DOF may be thought of as wedge-shaped, with the apex of the wedge nearest the camera; or they may be thought of as parallel to the POF.\nObject-field calculation methods.\nTraditional depth-of-field formulas can be hard to use in practice. As an alternative, the same effective calculation can be done without regard to the focal length and f-number. Moritz von Rohr and later Merklinger observe that the effective absolute aperture diameter can be used for similar formula in certain circumstances.\nMoreover, traditional depth-of-field formulas assume equal acceptable circles of confusion for near and far objects. Merklinger suggested that distant objects often need to be much sharper to be clearly recognizable, whereas closer objects, being larger on the film, do not need to be so sharp. The loss of detail in distant objects may be particularly noticeable with extreme enlargements. Achieving this additional sharpness in distant objects usually requires focusing beyond the hyperfocal distance, sometimes almost at infinity. For example, if photographing a cityscape with a traffic bollard in the foreground, this approach, termed the \"object field method\" by Merklinger, would recommend focusing very close to infinity, and stopping down to make the bollard sharp enough. With this approach, foreground objects cannot always be made perfectly sharp, but the loss of sharpness in near objects may be acceptable if recognizability of distant objects is paramount.\nOther authors such as Ansel Adams have taken the opposite position, maintaining that slight unsharpness in foreground objects is usually more disturbing than slight unsharpness in distant parts of a scene.\nOvercoming DOF limitations.\nSome methods and equipment allow altering the apparent DOF, and some even allow the DOF to be determined after the image is made. For example, Focus stacking combines multiple images focused on different planes, resulting in an image with a greater (or less, if so desired) apparent depth of field than any of the individual source images. Similarly, in order to reconstruct the 3-dimensional shape of an object, a depth map can be generated from multiple photographs with different depths of field. Xiong and Shafer concluded, in part, \"...the improvements on precisions of focus ranging and defocus ranging can lead to efficient shape recovery methods.\"\nAnother approach is focus sweep. The focal plane is swept across the entire relevant range during a single exposure. This creates a blurred image, but with a convolution kernel that is nearly independent of object depth, so that the blur is almost entirely removed after computational deconvolution. This has the added benefit of dramatically reducing motion blur.\nOther technologies use a combination of lens design and post-processing: Wavefront coding is a method by which controlled aberrations are added to the optical system so that the focus and depth of field can be improved later in the process.\nThe lens design can be changed even more: in colour apodization the lens is modified such that each colour channel has a different lens aperture. For example, the red channel may be \"f\"/2.4, green may be \"f\"/2.4, whilst the blue channel may be \"f\"/5.6. Therefore, the blue channel will have a greater depth of field than the other colours. The image processing identifies blurred regions in the red and green channels and in these regions copies the sharper edge data from the blue channel. The result is an image that combines the best features from the different \"f\"-numbers.\nAt the extreme, a plenoptic camera captures 4D light field information about a scene, so the focus and depth of field can be altered after the photo is taken.\nDiffraction and DOF.\nDiffraction causes images to lose sharpness at high F-numbers, and hence limits the potential depth of field. In general photography this is rarely an issue; because large f-numbers typically require long exposure times, motion blur may cause greater loss of sharpness than the loss from diffraction. However, diffraction is a greater issue in close-up photography, and the tradeoff between DOF and overall sharpness can become quite noticeable as photographers are trying to maximise depth of field with very small apertures.\nHansma and Peterson have discussed determining the combined effects of defocus and diffraction using a root-square combination of the individual blur spots. Hansma's approach determines the f-number that will give the maximum possible sharpness; Peterson's approach determines the minimum f-number that will give the desired sharpness in the final image, and yields a maximum depth of field for which the desired sharpness can be achieved. In combination, the two methods can be regarded as giving a maximum and minimum f-number for a given situation, with the photographer free to choose any value within the range, as conditions (e.g., potential motion blur) permit. Gibson gives a similar discussion, additionally considering blurring effects of camera lens aberrations, enlarging lens diffraction and aberrations, the negative emulsion, and the printing paper. Couzin gave a formula essentially the same as Hansma's for optimal \"f\"-number, but did not discuss its derivation.\nHopkins, Stokseth, and Williams and Becklund have discussed the combined effects using the modulation transfer function.\nDOF scales.\nMany lenses include scales that indicate the DOF for a given focus distance and f-number; the 35\u00a0mm lens in the image is typical. That lens includes distance scales in feet and meters; when a marked distance is set opposite the large white index mark, the focus is set to that distance. The DOF scale below the distance scales includes markings on either side of the index that correspond to f-numbers. When the lens is set to a given f-number, the DOF extends between the distances that align with the f-number markings.\nPhotographers can use the lens scales to work backwards from the desired depth of field to find the necessary focus distance and aperture. For the 35\u00a0mm lens shown, if it were desired for the DOF to extend from 1\u00a0m to 2\u00a0m, focus would be set so that index mark was centered between the marks for those distances, and the aperture would be set to f/11.\nOn a view camera, the focus and f-number can be obtained by measuring the depth of field and performing simple calculations. Some view cameras include DOF calculators that indicate focus and f-number without the need for any calculations by the photographer.\nNear:far distribution.\nThe DOF beyond the subject is always greater than the DOF in front of the subject. When the subject is at the hyperfocal distance or beyond, the far DOF is infinite, so the ratio is 1:\u221e; as the subject distance decreases, near:far DOF ratio increases, approaching unity at high magnification. For large apertures at typical portrait distances, the ratio is still close to 1:1.\nDOF formulae.\nThis section covers some additional formula for evaluating depth of field; however they are all subject to significant simplifying assumptions: for example, they assume the paraxial approximation of Gaussian optics. They are suitable for practical photography, lens designers would use significantly more complex ones.\nFocus and f-number from DOF limits.\nFor given near and far DOF limits formula_2 and formula_3, the required f-number is smallest when focus is set to\nthe harmonic mean of the near and far distances. In practice, this is equivalent to the arithmetic mean for shallow depths of field. Sometimes, view camera users refer to the difference formula_5 as the \"focus spread\".\nForeground and background blur.\nIf a subject is at distance formula_6 and the foreground or background is at distance formula_7, let the distance between the subject and the foreground or background be indicated by\nThe blur disk diameter formula_9 of a detail at distance formula_10 from the subject can be expressed as a function of the subject magnification formula_11, focal length formula_12, f-number formula_13, or alternatively the aperture formula_14, according to\nThe minus sign applies to a foreground object, and the plus sign applies to a background object.\nThe blur increases with the distance from the subject; when formula_9 is less than the circle of confusion, the detail is within the depth of field."}
{"id": "8368", "revid": "12797494", "url": "https://en.wikipedia.org/wiki?curid=8368", "title": "Dumnonii", "text": "The Dumnonii or Dumnones were a British tribe who inhabited Dumnonia, the area now known as Devon and Cornwall (and some areas of present-day Dorset and Somerset) in the further parts of the South West peninsula of Britain, from at least the Iron Age up to the early Saxon period. They were bordered to the east by the Durotriges tribe.\nEtymology.\nWilliam Camden, in his 1607 edition of \"Britannia\", describes Cornwall and Devon as being two parts of the same 'country' which:\nCamden had learnt some Welsh during the course of his studies and it would appear that he is the origin of the interpretation of Dumnonii as \"deep valley dwellers\" from his understanding of the Welsh of his time. John Rhys later theorized that the tribal name was derived from the name of a goddess, \"Domnu\", probably meaning \"the goddess of the deep\". The proto-Celtic root *dubno- or *dumno- meaning \"the deep\" or \"the earth\" (or alternatively meaning \"dark\" or \"gloomy\") appears in personal names such as Dumnorix and Dubnovellaunus. Another group with a similar name but with no known links were the Fir Domnann of Connacht.\nThe Roman name of the town of Exeter, \"Isca Dumnoniorum\" (\"Isca of the Dumnonii\"), contains the root \"*iska-\" \"water\" for \"Water of the Dumnonii\". The Latin name suggests that the city was already an \"oppidum\", or walled town, on the banks on the River Exe before the foundation of the Roman city, in about AD 50. The Dumnonii gave their name to the English county of Devon, and their name is represented in Britain's two extant Brythonic languages as \"Dewnans\" in Cornish and \"Dyfnaint\" in Welsh. Am\u00e9d\u00e9e Thierry (\"Histoire des Gaulois\", 1828), one of the inventors of the \"historic race\" of Gauls, could confidently equate them with the Cornish (\"les Cornouailles\").\nVictorian historians often referred to the tribe as the Damnonii, which is also the name of another people from lowland Scotland, although there are no known links between the two populations.\nLanguage.\nThe people of Dumnonia spoke a Southwestern Brythonic dialect similar to the forerunner of more recent Cornish and Breton. Irish immigrants, the D\u00e9isi, are evidenced by the Ogham-inscribed stones they have left behind, confirmed and supplemented by toponymical studies. The stones are sometimes inscribed in Latin, sometimes in both scripts. Tristram Risdon suggested the continuance of a Brythonic dialect in the South Hams, Devon, as late as the 14th century, in addition to its use in Cornwall.\nTerritory.\nPtolemy's 2nd century \"Geography\" places the Dumnonii to the west of the Durotriges. The name \"purocoronavium\" that appears in the Ravenna Cosmography implies the existence of a sub-tribe called the Cornavii or Cornovii, perhaps the ancestors of the Cornish people.\nGaius Iulius Solinus, probably in the 3rd century, remarks: \"This turbid strait also divides the island Silura from the shore which is held by the Dumnonii, a British tribe. The men of this island even now preserve an old custom: they do not use coins. They give and accept, obtaining the necessities of life by exchange rather than by money. They reverence gods, and the men and women equally declare knowledge of the future.\"\nIn the sub-Roman period a Brythonic kingdom called Dumnonia emerged, covering the entire peninsula, although it is believed by some to have effectively been a collection of sub-kingdoms.\nA kingdom of Domnon\u00e9e (and of Cornouaille alongside) was established in the province of Armorica directly across the English Channel, and has apparent links with the British population, suggesting an ancient connection of peoples along the western Atlantic seaboard.\nSettlements.\nIsca Dumnoniorum.\nThe Latin name for Exeter is Isca Dumnoniorum (\"Water of the Dumnonii\"). This oppidum (a Latin term meaning an important town) on the banks of I River Exe certainly existed prior to the foundation of the Roman city in about AD 50. \"Isca\" is derived from the Brythonic word for flowing water, which was given to the River Exe. This is reflected in the Welsh name for Exeter: \"Caerwysg\" meaning \"fortified settlement on the river Uisc\".\nIsca Dumnoniorum originated with a settlement that developed around the Roman fortress of the Legio II Augusta and is one of the four \"poleis\" (cities) attributed to the tribe by Ptolemy. It is also listed in two routes of the late 2nd century Antonine Itinerary.\nA legionary bath-house was built inside the fortress sometime between 55 and 60 and underwent renovation shortly afterwards (c. 60-65) but by c. 68 (perhaps even 66) the legion had transferred to a newer fortress at Gloucester. This saw the dismantling of the Isca fortress, and the site was then abandoned. Around AD 75, work on the \"civitas forum\" and \"basilica\" had commenced on the site of the former \"principia\" and by the late 2nd century the \"civitas\" walls had been completed. They were 3 metres thick and 6 metres high and enclosed exactly the same area as the earlier fortress. However, by the late 4th century the \"civitas\" was in decline.\nOther settlements.\nAs well as Isca Dumnoniorum, Ptolemy's 2nd century \"Geography\" names three other towns:\nThe Ravenna Cosmography includes the last two names (in slightly different forms, as \"Tamaris\" and \"Uxelis\"), and adds several more names which may be settlements in the territory. These include:\nOther Romano-British sites in Dumnonia include:\nNew settlements continued to be built throughout the Roman period, including sites at Chysauster and Trevelgue Head. The style is native in form with no Romanised features. Near Padstow, a site of some importance that was inhabited from the late Bronze/early Iron Age to the mid 6th century now lies buried under the sands on the opposite side of the Camel estuary near St. Enodoc's Church, and may have been a western coastal equivalent of a Saxon Shore Fort. Byzantine and African pottery has been discovered at the site. At Magor Farm in Illogan, near Camborne, an archaeological site has been identified as being a villa.\nArchaeology.\nThe Dumnonii are thought to have occupied relatively isolated territory in Cornwall, Devon, Somerset and possibly part of Dorset. Their cultural connections, as expressed in their ceramics, were with the peninsula of Armorica across the Channel, rather than with the southeast of Britain. They do not seem to have been politically centralised: coins are relatively rare, none of them locally minted, and the structure, distribution and construction of Bronze Age and Iron Age hill forts, \"rounds\" and defensible farmsteads in the south west point to a number of smaller tribal groups living alongside each other.\nDumnonia is noteworthy for its many settlements that have survived from the Romano-British period, but also for its lack of a villa system. Local archaeology has revealed instead the isolated enclosed farmsteads known locally as \"rounds\". These seem to have survived the Roman abandonment of Britain, but were subsequently replaced, in the 6th and 7th centuries, by the unenclosed farms taking the Brythonic toponymic \"tre-\".\nAs in most other Brythonic areas, Iron Age hill forts, such as Hembury Castle, were refortified for the use of chieftains or kings. Other high-status settlements such as Tintagel seem to have been reconstructed during this period. Post-Roman imported pottery has been excavated from many sites across the region, and the apparent surge in late 5th century Mediterranean and/or Byzantine imports is yet to be explained satisfactorily.\nIndustries.\nApart from fishing and agriculture, the main economic resource of the Dumnonii was tin mining. The area of Dumnonia had been mined since ancient times, and the tin was exported from the ancient trading port of Ictis (St Michael's Mount). Tin extraction (mainly by streaming) had existed here from the early Bronze Age around the 22nd century BC. West Cornwall, around Mount's Bay, was traditionally thought to have been visited by metal traders from the eastern Mediterranean\nDuring the first millennium BC trade became more organised, first with the Phoenicians, who settled Gades (Cadiz) around 1100 BC, and later with the Greeks, who had settled Massilia (Marseilles) and Narbo (Narbonne) around 600 BC. Smelted Cornish tin was collected at Ictis whence it was conveyed across the Bay of Biscay to the mouth of the Loire and then to Gades via the Loire and Rhone valleys. It went then through the Mediterranean Sea in ships to Gades.\nDuring the period c. 500-450 BC, the tin deposits seem to have become more important, and fortified settlements appear such as at Chun Castle and Kenidjack Castle, to protect both the tin smelters and mines.\nThe earliest account of Cornish tin mining was written by Pytheas of Massilia late in the 4th century BC after his circumnavigation of the British Isles. Underground mining was described in this account, although it cannot be determined when it had started. Pytheas's account was noted later by other writers including Pliny the Elder and Diodorus Siculus.\nIt is likely that tin trade with the Mediterranean was later on under the control of the Veneti. Britain was one of the places proposed for the \"Cassiterides\", that is Tin Islands. Tin working continued throughout Roman occupation although it appears that output declined because of new supplies brought in from the deposits discovered in Iberia (Spain and Portugal). However, when these supplies diminished, production in Dumnonia increased and appears to have reached a peak during the 3rd century AD.\nSub-Roman and post-Roman Dumnonia.\nThe Sub-Roman or Post-Roman history of Dumnonia comes from a variety of sources and is considered exceedingly difficult to interpret given that historical fact, legend and confused pseudo-history are compounded by a variety of sources in Middle Welsh and Latin. The main sources available for discussion of this period include Gildas's \"De Excidio Britanniae\" and Nennius's \"Historia Brittonum\", the \"Annales Cambriae\", \"Anglo-Saxon Chronicle\", William of Malmesbury's \"Gesta Regum Anglorum\" and \"De Antiquitate Glastoniensis Ecclesiae\", along with texts from the \"Black Book of Carmarthen\" and the \"Red Book of Hergest\", and Bede's \"Historia ecclesiastica gentis Anglorum\" as well as \"The Descent of the Men of the North\" (\"Bonedd Gw\u0177r y Gogledd\", in Peniarth MS 45 and elsewhere) and the \"Book of Baglan\"."}
{"id": "8371", "revid": "35126782", "url": "https://en.wikipedia.org/wiki?curid=8371", "title": "Declaration of Independence", "text": ""}
{"id": "8372", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=8372", "title": "Declaration of independence", "text": "A declaration of independence or declaration of statehood is an assertion by a defined territory that it is independent and constitutes a state. Such places are usually declared from part or all of the of another state or failed state, or are breakaway territories from within the larger state. In 2010, the UN's International Court of Justice ruled in an advisory opinion in Kosovo that \"International law contains no prohibition on declarations of independence\", though the state from which the territory wishes to secede may regard the declaration as rebellion, which may lead to a war of independence or a constitutional settlement to resolve the crisis."}
{"id": "8373", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=8373", "title": "Drag racing", "text": "Drag racing is a type of motor racing in which automobiles or motorcycles (usually specially prepared for the purpose) compete, usually two at a time, to be first to cross a set finish line. The race follows a short, straight course from a standing start over a measured distance, most commonly , with a shorter () distance becoming increasingly popular, as it has become the standard for Top Fuel dragsters and funny cars, where some major bracket races and other sanctioning bodies have adopted it as the standard. The is also popular in some circles. Electronic timing and speed sensing systems have been used to record race results since the 1960s.\nThe history of automobiles and motorcycles being used for drag racing is nearly as long as the history of motorized vehicles themselves, and has taken the form of both illegal street racing, and as an organize regulated motorsport.\nBasics of drag racing.\nStarting.\nPush starts to get engines running were necessary until the National Hot Rod Association (NHRA) mandated self-starters in 1976. After burnouts, cars would be pushed back by crews; this persisted until NHRA required reversing systems in 1980. Don Garlits was the first to do burnouts across the starting line, which is now standard practice. Each driver then backs up to and stages at the starting line.\nPrerace preparations.\nBefore each race (commonly known as a pass), each driver is allowed to perform a burnout, which heats the driving tires and lays rubber down at the beginning of the track, improving traction. The cars run through a \"water box\" (formerly a \"bleach box\", before bleach was replaced by flammable traction compound, which produced spectacular, and dangerous, flame burnouts; the hazard led NHRA to mandate use of water in the 1970s).\nModern races are started electronically by a system known as a \"Christmas tree\", which consists of a column of lights for each driver/lane, and two light beam sensors per lane on the track at the starting line. Current NHRA trees, for example, feature one blue light (split into halves), then three amber, one green, and one red. When the first light beam is broken by a vehicle's front tire(s), the vehicle is \"pre-staged\" (approximately from the starting line), and the pre-stage indicator on the tree is lit. When the second light beam is broken, the vehicle is \"staged\", and the stage indicator on the tree is lit. Vehicles may then leave the pre-stage beam, but must remain in the stage beam until the race starts.\nStaging.\nOnce one competitor is staged, their opponent has a set amount of time to stage or they will be instantly disqualified, indicated by a red light on the tree. Otherwise, once both drivers are staged, the system chooses a short delay at random (to prevent a driver being able to anticipate the start), then starts the race. The light sequence at this point varies slightly. For example, in NHRA Professional classes, three amber lights on the tree flash simultaneously, followed 0.4 seconds later by a green light (this is also known as a \"pro tree\"). In NHRA Sportsman classes, the amber lights illuminate in sequence from top to bottom, 0.5 seconds apart, followed 0.5 seconds later by the green light (this is also known as a \"sportsman tree\" or \"full tree\"). If a vehicle leaves the starting line before the green light illuminates, the red light for that lane illuminates instead, and the driver is disqualified (also known as \"red lighting\"). In a handicap start, the green light automatically lights up for the first driver, and the red light is only lit in the proper lane after both cars have launched if one driver leaves early, or if both drivers left early, the driver whose reaction time is worse (if one lane has a -.015 and the other lane has a -.022, the lane of the driver who committed a 0.022 is given the red light after both cars have left), as a red light infraction is only assessed to the driver with the worse infraction, if both drivers leave early. Even if both drivers leave early, the green light is automatically lit for the driver that left last, and they still may win the pass (as in the 2014 NHRA Auto Club Pro Stock final, Erica Enders-Stevens and Jason Line both committed red light infractions; only Line was assessed with a red light, as he was -.011 versus Enders-Stevens' -.002).\nMeasurements.\nSeveral measurements are taken for each race: reaction time, elapsed time, and speed. Reaction time is the period from the green light illuminating to the vehicle leaving the staging beams or breaking the guard beam. Elapsed time is the period from the vehicle leaving the starting line to crossing the finish line. Speed is measured through a speed trap covering the final to the finish line, indicating average speed of the vehicle in that distance.\nExcept where a breakout rule is in place, the winner is the first vehicle to cross the finish line, and therefore the driver with the lowest combined reaction time and elapsed time. Because these times are measured separately, a driver with a slower elapsed time can actually win if that driver's advantage in reaction time exceeds the elapsed time difference. In heads-up racing, this is known as a \"holeshot win\". In categories where a breakout rule is in effect (for example, NHRA Junior Dragster, Super Comp, Super Gas, Super Stock, and Stock classes, as well as some dial-in classes), if a competitor is faster than his or her predetermined time (a \"breakout\"), that competitor loses. If both competitors are faster than their predetermined times, the competitor who breaks out by less time wins. Regardless, a red light foul is worse than a breakout, except in Junior Dragster where exceeding the absolute limit is a cause for disqualification.\nBracket system.\nMost race events use a traditional bracket system, where the losing car and driver are eliminated from the event while the winner advances to the next round, until a champion is crowned. Events can range from 16 to over 100 car brackets. Drivers are typically seeded by elapsed times in qualifying. In bracket racing without a breakout (such as NHRA Competition Eliminator), pairings are based on times compared to their index (faster than index for class is better). In bracket racing with a breakout (Stock, Super Stock, but also the NHRA's Super classes), the closest to the index is favourable.\nA popular alternative to the standard eliminations format is the Chicago Style format (also called the Three Round format in Australia), named for the US 30 Dragstrip in suburban Gary, Indiana where a midweek meet featured this format. All entered cars participate in one qualifying round, and then are paired for the elimination round. The two fastest times among winners from this round participate in the championship round. Depending on the organisation, the next two fastest times may play for third, then fifth, and so forth, in consolation rounds. Currently, an IHRA 400 Thunder championship race in Australia uses the format.\nDistances.\nThe standard distance of a drag race is 1,320 feet, 402 m, or 1/4 mile( +- 0,2% FIA &amp; NHRA rules). However, due to safety concerns, certain sanctioning bodies (notably the NHRA for its Top Fuel and Funny Car classes) have shortened races to 1,000 feet. Some drag strips are even shorter and run 660 feet, 201 m, or 1/8 mile. The 1,000 foot distance is now also popular with bracket racing, especially in meets where there are 1/8 mile cars and 1/4 mile cars racing together, and is used by the revived American Drag Racing League for its primary classes (not Jr Dragster). Some organisations that deal with Pro Modified and \"Mountain Motor\" Pro Stock cars (Professional Drag Racers Association) use the 1/8 mile distance, even if the tracks are 1/4 mile tracks.\nRacing organizations.\nNorth America.\nThe National Hot Rod Association (NHRA) oversees the majority of drag racing events in North America. The next largest organization is the International Hot Rod Association (IHRA). Nearly all drag strips are associated with one sanctioning body or the other.\nBesides NHRA and IHRA, there are niche organizations for muscle cars and nostalgia vehicles. The Nostalgia Drag Racing League (NDRL) based in Brownsburg, IN, runs a series of 1/4 mile (402m) drag races in the Midwest for 1979 and older nostalgic appearing cars, with four classes of competition running in an index system. Pro 7.0 and Pro 7.50 run heads up 200 mile per hour (320 kilometre per hour) passes, while Pro Comp and Pro Gas run 8.0 to 10.0 indices. NDRL competition vehicles typically include Front Engine Dragsters, Altereds, Funny Cars, early Pro Stock clones, Super Stocks and Gassers.\nThe National Electric Drag Racing Association (NEDRA) races electric vehicles against high performance gasoline-powered vehicles such as Dodge Vipers or classic muscle cars in 1/4 and 1/8\u00a0mile (402m &amp; 201m) races. The current electric drag racing record is 6.940 seconds at 201.37\u00a0mph (324.0736 km/h) for a quarter mile (402m). Another niche organization is the VWDRC which run a VW-only championship with vehicles running under 7 seconds.\nPrior to the founding of the NHRA and IHRA, smaller organizations sanctioned drag racing in the early years, which included the competing AHRA in the United States from 1955 to 2005.\nAustralia.\nThe first Australian Nationals event was run in 1965 at Riverside raceway, near Melbourne. The Australian National Drag Racing Association (ANDRA) was established in 1973, and today they claim they are the \"best in the world outside the United States\". ANDRA sanctions races throughout Australia and throughout the year at all levels, from Junior Dragster to Top Fuel.\nThe ANDRA Drag Racing Series is for professional drivers and riders and includes Top Fuel, Top Alcohol, Top Doorslammer (similar to the USA Pro Modified class), Pro Stock (using 400 cubic inch engines (6.5 litres)), Top Bike and Pro Stock Motorcycle.\nThe Summit Sportsman Series is for ANDRA sportsman drivers and riders and includes Competition, Super Stock, Super Compact, Competition Bike, Supercharged Outlaws, Top Sportsman, Modified, Super Sedan, Modified Bike, Super Street and Junior Dragster.\nIn 2015, after a dispute with ANDRA, Sydney Dragway, Willowbank Raceway and the Perth Motorplex invited the International Hot Rod Association (IHRA) to sanction events at their tracks. Since then the Perth Motorplex has reverted to an ANDRA sanction and Springmount Raceway has embraced the IHRA umbrella. The 400 Thunder Series now attracts professional racers to its races at Sydney Dragway and Willowbank Raceway and is the premiere series in Australia.\nCommunications provider OVO Mobile provides a live stream of all 400 Thunder Australian Professional Drag Racing Series events to fans globally. The 400 Thunder Series is aired on SBS Speedweek.\nEurope.\nDrag racing was imported to Europe by American NATO troops during the Cold War. Races were held in West Germany beginning in the 1960s at the airbases at Ramstein and Sembach and in the UK at various airstrips and racing circuits before the opening of Europe's first permanent drag strip at Santa Pod Raceway in 1966.\nThe FIA organises a Europe-wide four wheeled championship for the Top Fuel, Top Methanol Dragster, Top Methanol Funny Car, Pro Modified and Pro Stock classes. FIM Europe organises a similar championship for bike classes. In addition, championships are run for sportsman classes in many countries throughout Europe by the various national motorsport governing bodies.\nNew Zealand.\nDrag racing in New Zealand started in the 1960s. The New Zealand Hot Rod Association (NZHRA) sanctioned what is believed to have been the first drag meeting at an open cut coal mine at Kopuku, south of Auckland, sometime in 1966. In 1973, the first and only purpose built drag strip opened in Meremere by the Pukekohe Hot Rod Club. In April 1993 the governance of drag racing was separated from the NZHRA and the New Zealand Drag Racing Association (NZDRA) was formed. In 2014, New Zealand's second purpose built drag strip \u2013 Masterton Motorplex \u2013 opened.\nThe first New Zealand Drag Racing Nationals was held in the 1966/67 season at Kopuku, near Auckland.\nThere are now two governing bodies operating drag racing in New Zealand with the Florida-based International Hot Rod Association sanctioning both of New Zealands major tracks at Ruapuna (Pegasus Bay Drag Racing Association) in the South Island and Meremere Dragway Inc in the North Island which is now become the best drag strip in NZ. However, the official ASN of the sport, per FIA regulations, is the New Zealand Drag Racing Association.\nSouth America.\nMany countries in South America race 200 meters, unlike in the United States and Australia, where 400 meters or 1/4 mile is typical.\nOrganized drag racing in Colombia is the responsibility of Club G3, a private organization. The events take place at Aut\u00f3dromo de Tocancip\u00e1.\nCaribbean.\nCura\u00e7ao\nOn the island of Cura\u00e7ao, organization of drag racing events is handled by the Cura\u00e7ao Autosport Foundation (FAC)\nAll racing events, including street legal competitions, happen at the Cura\u00e7ao International Raceway.\nAruba.\nOn the island of Aruba, all racing events, including street legal competitions, happen at Palomarga International Raceway.\nBarbados\nOn the island of Barbados, organization of drag racing events is done by the Barbados Association of Dragsters and Drifters. Currently the drag racing is done at Bushy Park racing circuit over 1/8 mile, while \"acceleration tests\" of 1/4 mile are done at the Paragon military base.\nSaint Lucia\nOn the Island of Saint Lucia, organization of drag racing events is done by no-one. All local groups are tie ups. Currently races are held at the US Old military base also known as the \"Ca Ca Beff\", \"The Base\" near the Hewanorra International Airport in Vieux Fort.\nDominican Republic\nOn Santo Domingo, organization of drag racing events is done by Autodromo Sunix and they happen at the Autodromo Sunix, close to the Airport SDQ.\nSouth Asia.\nOrganized drag racing is rapidly growing in India. The country's first drag race meet was organized by \"Autocar India\" in Mumbai in 2002. Since then there have been many drag racing events in India. The most popular event is Elite Octanes' Valley Run which is held at Ambey Valley air strip in Loanavla every year. \nThe biggest drag series event was organized by India Speed Week with three different locations around India. After the series two riders were chosen to represent the country 2017 initiative to bring 11 times world drag racing champion Rickey Gadson to India. The initiative was executed during the Valley Run 2017 event, which gave the participants a platform to perform at the highest level globally. Rickey Gadson, as an extension of the initiative invited two of the top performing drag racers to visit USA to train and get an opportunity to represent India at the World Finals of drag racing held on 16-18 November 2018 in Valdosta GA, USA. As a result the two riders performed in their maiden event outside India. Also during the event, Amit Sharma, the fastest drag racer in Indian drag racing history, produced a time slip of 8.87 sec's \u2013 the fastest ever by any Indian.\nDrag racing is also gaining popularity in Pakistan, with private organizations sponsoring such events. The Bahria Town housing project recently organized a drag racing event in Rawalpindi with the help of some of the country's best drivers.\nSri Lanka has seen an immense growth in drag racing due to legal meets held by the Ceylon Motor Sports Club, an FIA sanctioned body. In recent years, exotic cars and Japanese power houses have been taking part in these popular events.\nSouth Africa.\nDrag racing is an established sport in South Africa, with a number of strips around the country including Tarlton International Raceway and ODI Raceway. Drag racing is controlled by Motorsport South Africa and all drivers are required to hold a valid Motorsport South Africa license. Drivers can compete in a number of categories including Top Eliminator, Senior Eliminator, Super Competition Eliminator, Competition Eliminator, Pro Street Bikes, Superbike Eliminator, Supersport Shootout (motorcycle), Street Modified, and Factory Stock.\nRussian Federation.\nDrag racing in Russia started in 2004 in Moscow when the Russian Automotive Federation (RAF) sanctioned it as an official motorsport. Drag Racing became popular in Russia after \"The Fast and the Furious\" film in 2001, but competitions were illegal before 2004. The most outstanding drag racing event of the early years was \"DRAG BITVA\" (Drag Battle) which took place in Krasnoyarsk, Siberia from 2005 to 2008. Krasnoyarsk is located in the middle of Russia, so it was the best place to bring all the fastest cars from all over the country. Due to the financial situation \"DRAG BITVA\" was canceled in 2009 and never came back. It was difficult times for drag racing in Russia from 2009 to 2014, but it was supported by enthusiasts in every region. There were a lot of competitions but it wasn't as big as \"DRAG BITVA\". In 2014 Dragtimes company in partnership with SMP Racing became the Russian Drag Racing Championship (SMP RDRC) promoters, since then Drag Racing in Russia became more professional. From the very beginning to 2014 only streetcars were allowed to compete in Russia. Now it's also allowed to run promods and dragsters in SMP RDRC. Thanks to the efforts of SMP RDRC promoters in 2019 the first professional dragstrip in Russia \"RDRC Racepark\" was built. It's located near Moscow in 40 kilometers of downtown at the former airfield Bykovo. It gave many opportunities to test the cars and make new records. Before the track was built, competitions took place on straight parts of circuits, so it wasn't allowed to prepare the whole 1/4 mile, only 1/8 and the tracks were available for drag racers except racing weekends of local or national events. From the very beginning one of the main ideas of the promoters was to increase the quality and reach of live broadcasts, so SMP RDRC became the first racing series with its video production and remains so to this day.\nRussian Championship has four classes:\nRegional Series also have four classes divided by ET:\nThe national record belongs to 4-time national champion Dmitry Samorukov: 6.325 seconds at . It was set in a special record run in 2016 on Dodge Viper Doorslammer in Grozny, Chechen Republic at \"Fort Grozny\" racetrack.\nDmitry Samorukov was the first Russian participant of the FIA European Championship on a newly built Chevrolet Camaro in the most competitive Promod class in 2019. After six stages of the competition, he took 10th of 38 places overall.\nRussian driver Dmitry Kapustin on Nissan Skyline GT-R R32 is holding the European record of AWD streetcars: 7.182 seconds at . The record was set in a qualifying run in Grozny, Chechen Republic at \"Fort Grozny\" racetrack in 2018.\n1/2 mile races are also popular in Russia. \"Unlim 500+\" is the main 1/2 mile race in Russia. It's a supercar and sportscar festival where only 500+ hp cars are allowed (e. g. Nissan GT-R, McLaren 720S, Lamborghini Aventador, Porsche 911, Ferrari 488, etc.). The national record on 1/2 mile distance also belongs to Dmitry Samorukov on Nissan GT-R R 35: 13.305 seconds at . The record was set on a test and tune day at the \"RDRC Racepark\" track in 2020.\nClasses.\nThere are hundreds of classes in drag racing, each with different requirements and restrictions on things such as weight, engine size, body style, modifications, and many others. NHRA and IHRA share some of these classes, but many are solely used by one sanctioning body or the other. The NHRA boasts over 200 classes, while the IHRA has fewer. Some IHRA classes have multiple sub-classes in them to differentiate by engine components and other features. There is even a class for aspiring youngsters, Junior Dragster, which typically uses an eighth-mile track, also favored by VW racers.\nIn 1997, the FIA (cars) and UEM (bikes) began sanctioning drag racing in Europe with a fully established European Drag Racing Championship, in cooperation (and rules compliance) with NHRA. The major European drag strips include Santa Pod Raceway in Podington, England; Alastaro Circuit, Finland; Mantorp Park, Sweden; Gardermoen Raceway, Norway and the Hockenheimring in Germany.\nThere is a somewhat arbitrary definition of what constitutes a \"professional\" class. The NHRA includes 5 pro classes; Top Fuel, Funny Car, Pro Stock, Pro Modified and Pro Stock Motorcycle. The FIA features a different set of 5 pro classes; Top Fuel, Top Methanol Dragster, Top Methanol Funny Car, Pro Modified and Pro Stock. Other sanctioning bodies have similarly different definitions. A partial list of classes includes:\n \nA complete listing of all classes can be found on the respective NHRA and IHRA official websites.\nThe UEM also has a different structure of professional categories with Top Fuel Bike, Super Twin Top Fuel Bike, and Pro Stock Bike contested, leaving the entire European series with a total of 8 professional categories.\nTo allow different cars to compete against each other, some competitions are raced on a handicap basis, with faster cars delayed on the starting line enough to theoretically even things up with the slower car. This may be based on rule differences between the cars in stock, super stock, and modified classes, or on a competitor's chosen \"dial-in\" in bracket racing.\nFor a list of drag racing world records in each class, see Dragstrip#Quarter mile times.\nDial-in.\nA 'dial-in' is a time the driver estimates it will take his or her car to cross the finish line, and is generally displayed on one or more windows so the starter can adjust the starting lights on the tree accordingly. The slower car will then get a head start equal to the difference in the two dial-ins, so if both cars perform perfectly, they would cross the finish line dead even. If either car goes faster than its dial-in (called breaking out), it is disqualified regardless of who has the lower elapsed time; if both cars break out, the one who breaks out by the smallest amount wins. However, if a driver had jump-started (red light) or crossed a boundary line, both violations override any break out (except in some classes with an absolute break out rule such as Junior classes).\nThe effect of the bracket racing rules is to place a premium on consistency of performance of the driver and car rather than on raw speed, in that victory goes to the driver able to precisely predict elapsed time, whether it is fast or slow. This in turn makes victory much less dependent on budget, and more dependent on skill, making it popular with casual weekend racers.\nHistory.\nThe National Hot Rod Association (NHRA) was founded in 1951, to take illegal racing off the street.\nThe organization banned the use of nitromethane in 1957, calling it unsafe, in part through the efforts of C. J. Hart; the ban would be lifted in 1963."}
{"id": "8375", "revid": "1011223704", "url": "https://en.wikipedia.org/wiki?curid=8375", "title": "Draugr", "text": "The draugr or draug (, plural ; modern , and Danish, Swedish, and ) is an undead creature from the Scandinavian saga literature and folktale.\nCommentators extend the term \"draugr\" to the undead in medieval literature, even if it is never explicitly referred to as that in the text, and designated them rather as a (\"barrow-dweller\") or an , literally \"again-walker\" (). \nOverview.\nDraugar live in their graves or royal palaces, often guarding treasure buried with them in their burial mound. They are revenants, or animated corpses with a corporeal body, rather than ghosts which possess intangible spiritual bodies.\nTerminology.\nOld Norse \"\" is defined as \"a ghost, spirit, esp. the dead inhabitant of a cairn\". Often the \"draugr\" is regarded not so much as a ghost but a revenant, i.e., the reanimated of the deceased inside the burial mound (as in the example of K\u00e1rr inn gamli in \"Grettis saga\").\nThe \"draugr\" was referred to as \"as barrow-wight\" in the 1869 translation of \"Grettis saga\", long before J. R. R. Tolkien's employed this term in his novels,\n though \"barrow-wight\" is actually a rendering of (literally the \u2018howe-dweller\u2019), otherwise translated as \"barrow-dweller\".\nCognates and etymology.\nIn Swedish, \"draug\" is a modern loanword from West Norse, as the native Swedish form \"dr\u00f6g\" has acquired the meaning of \"a pale, ineffectual, and slow-minded person that drags himself along\". \nThe word is hypothetically traced to Proto-Indo European stem \"*\" \"phantom\", from \"*\" \"deceive\" (see also Avestan \"druj\").\nBroadened usage.\nUnlike K\u00e1rr inn gamli (Kar the Old) in \"Grettis saga\", who is specifically called a \"draugr\", Gl\u00e1mr the ghost in the same saga is never explicitly called a \"draugr\" in the text, though called a \"troll\" in it. Yet Gl\u00e1mr is still routinely referred to as a \"draugr\".\nBeings not specifically called , but actually only referred to as (\u2018revenants\u2019, pl. of ) and (\u2018haunting\u2019) in these medieval sagas are still commonly discussed as a in various scholarly works, or the \"draugar\" and the haugb\u00faar are lumped into one.\nA further caveat is that the application of the term \"draugr\" may not necessarily follow what the term might have meant in the strict sense during medieval times, but rather follow a modern definition or notion of \"draugr\", specifically such ghostly beings (by whatever names they are called) that occur in Icelandic folktales categorized as \"Draugas\u00f6gur\" in J\u00f3n \u00c1rnason's collection, based on the classification groundwork laid by Konrad Maurer.\nOverall classification.\nThe draugr is a \"corporeal ghost\" with a physical tangible body and not an \"imago\", and in tales it is often delivered a \"second death\" by destruction of the enlivened corpse.\nThe draugr has also been conceived of as a type of \"vampire\" by folktale anthologist Andrew Lang in the late 1897, with the idea further pursued by more modern commentators. The focus here is not on blood-sucking, which is not attested for the \"draugr\", but rather, contagiousness or transmittable nature of vampirism, that is to say, how a vampire begets another by turning his or her attack victim into one of his own kind. Sometimes the chain of contagion becomes an outbreak, e.g., the case of \u00de\u00f3r\u00f3lfr b\u00e6gif\u00f3tr (Thorolf Lame-foot or Twist-Foot), and even called an \"epidemic\" regarding \u00de\u00f3rgunna (Thorgunna).\nA more speculative case of vampirism is that of Gl\u00e1mr, who was asked to tend sheep for a haunted farmstead and was subsequently found dead with his neck and every bone in his body broken. It has been surmised by commentators that Gl\u00e1mr by \"contamination\" was turned into an undead (\"draugr\") by whatever being was haunting the farm.\nPhysical traits.\nDraugar usually possessed superhuman strength, and was \"generally hideous to look at\", bearing a necrotic black color, and was associated with a \"reek of decay\" or more precisely inhabited haunts that often issued foul stench. \nThe draugar were said to be either \"hel-bl\u00e1r\" (\"death-blue\") or \"n\u00e1r-f\u00f6lr\" (\"corpse-pale\"), to state it in shorthand. Gl\u00e1mr when found dead was described as \"\"bl\u00e1r sem Hel en digr sem naut\" (black as hell and bloated to the size of a bull)\". \u00de\u00f3r\u00f3lfr Lame-foot, when lying dormant, looked \"uncorrupted\" and also \"was black as death [i.e., bruised black and blue] and swollen to the size of an ox\". The close similarity of these descriptions have been noted. \"Laxd\u00e6la saga\" describes how bones were dug up belonging to a dead sorceress who had appeared in dreams, and they were \"blue and evil looking\".\n\u00der\u00e1inn (Thrain) the berserker of Valland turned \"turned himself into a troll\" in \"Hr\u00f3mundar saga Gripssonar\" was a fiend (\"d\u00f3lgr\") which was \"black and huge.. roaring loudly and blowing fire\", and moreover, possessed long scratching claws, and the claws stuck in the neck, prompting the hero Hr\u00f3mundr to refer to the \"dragur\" as a sort of cat ().\n The long claw is a common trait of another revenant, \u00c1svi\u00f0r (Aswitus) who came to life in the night and attacked his foster-brother \u00c1smundr (Asmundus) with the claws, scratching the face and tearing an ear.\nThere mound where K\u00e1rr the Old was entombed reeked horribly. In \"Har\u00f0ar saga\" H\u00f6r\u00f0r Gr\u00edmkelsson\u2019s two underlings die even before entering S\u00f3ti the Viking's mound, due to the \"gust and stink ()\" wafting out of it.\nMagical abilities.\nDraugar are noted for having numerous magical abilities (referred to as \"trollskap\") resembling those of living witches and wizards, such as shape-shifting, controlling the weather, and seeing into the future.\nShape-shifting.\nThe undead V\u00edga-Hrappr Sumarli\u00f0ason (Killer-Hrapp) of \"Laxdaela saga\", unlike the typical guardian of a treasure hoard, does not stay put in his burial place but roams around his farmstead of Hrappsta\u00f0ir, menacing the living. V\u00edga-Hrappr's ghost, it has been suggested, was capable of transforming into the seal with human-like eyes which appeared before \u00deorsteinn svarti/surt (Thorsteinn the Black) sailing by ship, and was responsible for the sinking of the ship to prevent the family from reaching Hrappsta\u00f0ir. The ability to shape-shift has been ascribed to Icelandic ghosts generally, particularly into the shape of a seal.\nA draugr in Icelandic folktales collected in the modern age can also change into a great flayed bull, a grey horse with a broken back but no ears or tail, and a cat that would sit upon a sleeper's chest and grow steadily heavier until victim suffocated.\nOther magical abilities.\nDraugar have the ability to enter into the dreams of the living, and they will frequently leave a gift behind so that \"the living person may be assured of the tangible nature of the visit\". Draugar also have the ability to curse a victim, as shown in the Grettis saga, where Grettir is cursed to be unable to become any stronger. Draugar also brought disease to a village and could create temporary darkness in daylight hours. They preferred to be active during the night, although it did not appear to be vulnerable to sunlight like some other revenants. Draugr can also kill people with bad luck.\nA draugr's presence might be shown by a great light that glowed from the mound like foxfire. This fire would form a barrier between the land of the living and the land of the dead. \nThe undead V\u00edga-Hrappr exhibited the ability to sink into the ground to escape from \u00d3l\u00e1fr H\u01ebskuldsson the Peacock.\nSome draugar are immune to weapons, and only a hero has the strength and courage needed to stand up to so formidable an opponent. In legends, the hero would often have to wrestle the draugr back to his grave, thereby defeating him, since weapons would do no good. A good example of this is found in \"Hr\u00f3mundar saga Gripssonar\". Iron could injure a draugr, as is the case with many supernatural creatures, although it would not be sufficient to stop it. Sometimes the hero is required to dispose of the body in unconventional ways. The preferred method is to cut off the draugr's head, burn the body, and dump the ashes in the sea\u2014the emphasis being on making absolutely sure that the draugr was dead and gone.\nBehaviour and character.\nAny mean, nasty, or greedy person can become a draugr. As \u00c1rmann Jakobsson notes, \"most medieval Icelandic ghosts are evil or marginal people. If not dissatisfied or evil, they are unpopular\".\nGreed.\nThe draugr's motivation was primarily jealousy and greed. Greed causes it to viciously attack any would-be grave robbers, but the draugr also expresses an innate jealousy of the living stemming from a longing for the things of life which it once had. They also exhibit an immense and nearly insatiable appetite, as shown in the encounter of Aran and Asmund, sword brothers who made an oath that, if one should die, the other would sit vigil with him for three days inside the burial mound. When Aran died, Asmund brought his own possessions into the barrow\u2014banners, armor, hawk, hound, and horse\u2014then set himself to wait the three days:\nBloodthirst.\nThe draugr's victims were not limited to trespassers in its home. The roaming undead devastated livestock by running the animals to death either by riding them or pursuing them in some hideous, half-flayed form. Shepherds' duties kept them outdoors at night, and they were particular targets for the hunger and hatred of the undead:\nAnimals feeding near the grave of a draugr might be driven mad by the creature's influence. They may also die from being driven mad. Thorolf, for example, caused birds to drop dead when they flew over his bowl barrow.\nSitting posture and evil eye.\nThe main indication that a deceased person will become a draugr is that the corpse is not in a horizontal position but is found standing upright (V\u00edga-Hrappr), or in a sitting position (\u00de\u00f3r\u00f3lfr), indicating that the dead might return. \u00c1rmann Jakobsson suggests further that breaking the draugr's posture is a necessary or helpful step in destroying the \"draugr\", but this is fraught with the risk of being inflicted with the evil eye, whether this is explictly told in the case of Grettir who receives the curse from Gl\u00e1mr, or only implied in the case of \u00de\u00f3r\u00f3lfr, whose son warns the others to beware while they unbend \u00de\u00f3r\u00f3lfr's seated posture. \nAnnihilating.\nThe revenant \"draugr\" needing to be decapitated in order to incapacitate them from further hauntings is a common theme in the family sagas.\nMeans of prevention.\nTraditionally, a pair of open iron scissors was placed on the chest of the recently deceased, and straws or twigs might be hidden among their clothes. The big toes were tied together or needles were driven through the soles of the feet in order to keep the dead from being able to walk. Tradition also held that the coffin should be lifted and lowered in three different directions as it was carried from the house to confuse a possible draugr's sense of direction.\nThe most effective means of preventing the return of the dead was believed to be a corpse door, a special door through which the corpse was carried feet-first with people surrounding it so that the corpse couldn't see where it was going. The door was then bricked up to prevent a return. It is speculated that this belief began in Denmark and spread throughout the Norse culture, founded on the idea that the dead could only leave through the way they entered.\nIn \"Eyrbyggja saga\", draugar are driven off by holding a \"door-doom\". One by one, they are summoned to the door-doom and given judgment and forced out of the home by this legal method. The home was then purified with holy water to ensure that they never came back.\nSimilar beings.\nA variation of the draugr is the \"haugbui\" (from Old Norse \"haugr\"' \"howe, barrow, tumulus\") which was a mound-dweller, the dead body living on within its tomb. The notable difference between the two was that the haugbui is unable to leave its grave site and only attacks those who trespass upon their territory.\nThe haugbui was rarely found far from its burial place and is a type of undead commonly found in Norse sagas. The creature is said to either swim alongside boats or sail around them in a partially submerged vessel, always on their own. In some accounts, witnesses portray them as shapeshifters who take on the appearance of seaweed or moss-covered stones on the shoreline.\nFolklore.\nIcelandic Sagas.\nOne of the best-known draugar is Gl\u00e1mr, who is defeated by the hero in \"Grettis saga\". After Gl\u00e1mr dies on Christmas Eve, \"people became aware that Gl\u00e1mr was not resting in peace. He wrought such havoc that some people fainted at the sight of him, while others went out of their minds\". After a battle, Grettir eventually gets Gl\u00e1mr on his back. Just before Grettir kills him, Gl\u00e1mr curses Grettir because \"Gl\u00e1mr was endowed with more evil force than most other ghosts\", and thus he was able to speak and leave Grettir with his curse after his death.\nA somewhat ambivalent, alternative view of the draugr is presented by the example of Gunnar H\u00e1mundarson in \"Nj\u00e1ls saga\": \"It seemed as though the howe was agape, and that Gunnar had turned within the howe to look upwards at the moon. They thought that they saw four lights within the howe, but not a shadow to be seen. Then they saw that Gunnar was merry, with a joyful face.\"\nIn the \"Eyrbyggja saga\", a shepherd is assaulted by a blue-black draugr. The shepherd's neck is broken during the ensuing scuffle. The shepherd rises the next night as a draugr.\nRecent.\nIn more recent Scandinavian folklore, the draug (the modern spelling used in Denmark, Norway, and Sweden) is often identified with the spirits of mariners drowned at sea. The creature is said to possess a distinctly human form, with the exception that its head is composed entirely of seaweed. In other tellings, the draug is described as being a headless fisherman, dressed in oilskin and sailing in half a boat (the Norwegian municipality of B\u00f8, Nordland has the half-boat in its coat-of-arms). This trait is common in the northernmost part of Norway, where life and culture was based on fishing more than anywhere else. The reason for this may be that the fishermen often drowned in great numbers, and the stories of restless dead coming in from sea were more common in the north than any other region of the country.\nA recorded legend from Tr\u00f8ndelag tells how a cadaver lying on a beach became the object of a quarrel between the two types of draug (headless and seaweed-headed). A similar source even tells of a third type, the \"gleip\", known to hitch themselves to sailors walking ashore and make them slip on the wet rocks.\nBut, though the draug usually presages death, there is an amusing account in Northern Norway of a northerner who managed to outwit him:\nUse in popular culture.\nThe modern and popular connection between the draug and the sea can be traced back to authors like Jonas Lie and Regine Nordmann, whose works include several books of fairy tales, as well as the drawings of Theodor Kittelsen, who spent some years living in Svolv\u00e6r. Up north, the tradition of sea-draugs is especially vivid.\nArne Garborg describes land-draugs coming fresh from the graveyards, and the term \"draug\" is even used of vampires. The notion of draugs who live in the mountains is present in the poetic works of Henrik Ibsen (\"Peer Gynt\"), and Aasmund Olavsson Vinje. The Nynorsk translation of \"The Lord of the Rings\" used the term for both Nazg\u00fbl and the dead men of Dunharrow. Tolkien's Barrow-Wights bear obvious similarity to, and were inspired by the haugbui. In the video game \"\", draugr are the undead skeletal remains of fallen warriors that inhabit the ancient burial sites of a Nordic-inspired race of man. Draugr are a common enemy, the first encountered by the player, in the 2018 video game \"God of War\", with a variety of different powers and abilities. Draugr appear as an enemies in the 2021 Early Acess game \"Valheim\", where they take the more recent, seaweed version of the Draug.\nThe exoplanet PSR B1257+12 A has been named \"Draugr\"."}
{"id": "8376", "revid": "40858793", "url": "https://en.wikipedia.org/wiki?curid=8376", "title": "Day", "text": "A day is approximately the period during which the Earth completes one rotation around its axis, which takes around 24 hours. A solar day is the length of time which elapses between the Sun reaching its highest point in the sky two consecutive times. Days on other planets are defined similarly and vary in length due to differing rotation periods, that of Mars being slightly longer and sometimes called a sol. \nThe unit of measurement \"day\" (symbol d) is defined as 86,400 SI seconds. \nThe second is designated the SI base unit of time. Previously, it was defined in terms of the orbital motion of the Earth in the year 1900, but since 1967 the second and so the day are defined by atomic electron transition. \nA civil day is usually 24 hours, plus or minus a possible leap second in Coordinated Universal Time (UTC), and occasionally plus or minus an hour in those locations that change from or to daylight saving time.\nDay can be defined as each of the twenty-four-hour periods, reckoned from one midnight to the next, into which a week, month, or year is divided, and corresponding to a rotation of the earth on its axis. However, its use depends on its context; for example, when people say 'day and night', 'day' will have a different meaning: the interval of light between two successive nights, the time between sunrise and sunset; the time of light between one night and the next. For clarity when meaning 'day' in that sense, the word \"daytime\" may be used instead, though context and phrasing often makes the meaning clear. The word \"day\" may also refer to a day of the week or to a calendar date, as in answer to the question, \"On which day?\" The life patterns (circadian rhythms) of humans and many other species are related to Earth's solar day and the day-night cycle.\nIntroduction.\nApparent and mean solar day.\nSeveral definitions of this universal human concept are used according to context, need and convenience. Besides the day of 24 hours (86,400 seconds), the word \"day\" is used for several different spans of time based on the rotation of the Earth around its axis. An important one is the solar day, defined as the time it takes for the Sun to return to its culmination point (its highest point in the sky). Because celestial orbits are not perfectly circular, and thus objects travel at different speeds at various positions in their orbit, a solar day is not the same length of time throughout the orbital year. Because the Earth moves along an eccentric orbit around the Sun while the Earth spins on an inclined axis, this period can be up to 7.9 seconds more than (or less than) 24 hours. In recent decades, the average length of a solar day on Earth has been about 86,400.002 seconds\n(24.000 000 6 hours) and there are currently about 365.242199 solar days in one mean tropical year.\nAncient custom has a new day start at either the rising or setting of the Sun on the local horizon (Italian reckoning, for example, being 24 hours from sunset, oldstyle). The exact moment of, and the interval between, two sunrises or sunsets depends on the geographical position (longitude as well as latitude), and the time of year (as indicated by ancient hemispherical sundials).\nA more constant day can be defined by the Sun passing through the local meridian, which happens at local noon (upper culmination) or midnight (lower culmination). The exact moment is dependent on the geographical longitude, and to a lesser extent on the time of the year. The length of such a day is nearly constant (24 hours \u00b1 30 seconds). This is the time as indicated by modern sundials.\nA further improvement defines a fictitious mean Sun that moves with constant speed along the celestial equator; the speed is the same as the average speed of the real Sun, but this removes the variation over a year as the Earth moves along its orbit around the Sun (due to both its velocity and its axial tilt).\nStellar day.\nA \"day\", understood as the span of time it takes for the Earth to make one entire rotation with respect to the celestial background or a distant star (assumed to be fixed), is called a \"stellar day\". This period of rotation is about 4 minutes less than 24 hours (23 hours 56 minutes and 4.09 seconds) and there are about 366.2422 stellar days in one mean tropical year (one stellar day more than the number of solar days). Other planets and moons have stellar and solar days of different lengths from Earth's.\nBesides a stellar day on Earth, there are related such days for bodies in the Solar System other than the Earth.\nDaytime.\nA day, in the sense of daytime that is distinguished from night time, is commonly defined as the period during which sunlight directly reaches the ground, assuming that there are no local obstacles. The length of daytime averages slightly more than half of the 24-hour day. Two effects make daytime on average longer than nights. The Sun is not a point, but has an apparent size of about 32 minutes of arc. Additionally, the atmosphere refracts sunlight in such a way that some of it reaches the ground even when the Sun is below the horizon by about 34 minutes of arc. So the first light reaches the ground when the centre of the Sun is still below the horizon by about 50 minutes of arc. Thus, daytime is on average around 7 minutes longer than 12 hours.\nEtymology.\nThe term comes from the Old English \"d\u00e6g\", with its cognates such as \"dagur\" in Icelandic, \"Tag\" in German, and \"dag\" in Norwegian, Danish, Swedish and Dutch. All of them from the Indo-European root dyau which explains the similarity with Latin dies though the word is known to come from the Germanic branch. , \"day\" is the 205th most common word in US English, and the 210th most common in UK English.\nInternational System of Units (SI).\nA day, symbol d, defined as 86,400 seconds, is not an SI unit, but is accepted for use with SI. The second is the base unit of time in SI units.\nIn 1967\u201368, during the 13th CGPM (Resolution 1), the International Bureau of Weights and Measures (BIPM) redefined a second as ... the duration of 9 192 631 770 periods of the radiation corresponding to the transition between two hyperfine levels of the ground state of the caesium 133 atom.\nThis makes the SI-based day last exactly 794,243,384,928,000 of those periods.\nThere are 365.25 days in a Julian year.\nLeap seconds.\nMainly due to tidal effects, the Earth's rotational period is not constant, resulting in minor variations for both solar days and stellar \"days\". The Earth's day has increased in length over time due to tides raised by the Moon which slow Earth's rotation. Because of the way the second is defined, the mean length of a day is now about 86,400.002 seconds, and is increasing by about 1.7 milliseconds per century (an average over the last 2,700 years). The length of a day circa 620 million years ago has been estimated from rhythmites (alternating layers in sandstone) as having been about 21.9 hours.\nIn order to keep the civil day aligned with the apparent movement of the Sun, a day according to Coordinated Universal Time (UTC) can include a negative or positive leap second. Therefore, although typically 86,400 SI seconds in duration, a civil day can be either 86,401 or 86,399 SI seconds long on such a day.\nLeap seconds are announced in advance by the International Earth Rotation and Reference Systems Service (IERS), which measures the Earth's rotation and determines whether a leap second is necessary.\nCivil day.\nFor civil purposes, a common clock time is typically defined for an entire region based on the local mean solar time at a central meridian. Such \"time zones\" began to be adopted about the middle of the 19th century when railroads with regularly occurring schedules came into use, with most major countries having adopted them by 1929. As of 2015, throughout the world, 40 such zones are now in use: the central zone, from which all others are defined as offsets, is known as , which uses Coordinated Universal Time (UTC).\nThe most common convention starts the civil day at midnight: this is near the time of the lower culmination of the Sun on the central meridian of the time zone. Such a day may be referred to as a calendar day.\nA day is commonly divided into 24 hours of 60 minutes, with each minute composed of 60 seconds.\nDecimal and metric time.\nIn the 19th century, an idea circulated to make a decimal fraction ( or ) of an astronomical day the base unit of time. This was an afterglow of the short-lived movement toward a decimalisation of timekeeping and the calendar, which had been given up already due to its difficulty in transitioning from traditional, more familiar units. The most successful alternative is the \"centiday\", equal to 14.4 minutes (864 seconds), being not only a shorter multiple of an hour (0.24 vs 2.4) but also closer to the SI multiple \"kilosecond\" (1,000 seconds) and equal to the traditional Chinese unit, \"k\u00e8\".\nColloquial.\nThe word refers to various similarly defined ideas, such as:\nBoundaries.\nFor most diurnal animals, the day naturally begins at dawn and ends at sunset. Humans, with their cultural norms and scientific knowledge, have employed several different conceptions of the day's boundaries. In the Hebrew Bible, Genesis 1:5 defines a day in terms of \"evening\" and \"morning\" before recounting the creation of a sun to illuminate it: \"And God called the light Day, and the darkness he called Night. And the evening and the morning were the first day.\" Common convention among the ancient Romans, ancient Chinese and in modern times is for the civil day to begin at midnight, i.e. 00:00, and to last a full 24 hours until 24:00 (i.e. 00:00 of the next day).\nIn ancient Egypt the day was reckoned from sunrise to sunrise. The Jewish day begins at either sunset or nightfall (when three second-magnitude stars appear).\nMedieval Europe also followed this tradition, known as Florentine reckoning: in this system, a reference like \"two hours into the day\" meant \"two hours after sunset\" and thus times during the evening need to be shifted back one calendar day in modern reckoning. Days such as Christmas Eve, Halloween, and the Eve of Saint Agnes are remnants of the older pattern when holidays began during the prior evening. Prior to 1926, Turkey had two time systems: Turkish (counting the hours from sunset) and French (counting the hours from midnight).\nValidity of tickets, passes, etc., for a day or a number of days may end at midnight, or closing time, whichever occurs earlier. However, if a service (e.g., public transport) operates from for example, 06:00 to 01:00 the next day (which may be noted as 25:00), the last hour may well count as being part of the previous day. For services depending on the day (\"closed on Sundays\", \"does not run on Fridays\", and so on) there is a risk of ambiguity. For example, a day ticket on the Nederlandse Spoorwegen (Dutch Railways) is valid for 28 hours, from 00:00 to 28:00 (that is, 4:00 the next day); the validity of a pass on Transport for London (TfL) services runs until the end of the \"transport day\"\u00a0\u2013 that is to say, until 4:30 am on the day after the \"expires\" date stamped on the pass.\nMidnight sun.\nIn places which experience the midnight sun (polar day), daytime may extend beyond one 24-hour period and could even extend to months."}
{"id": "8377", "revid": "7226930", "url": "https://en.wikipedia.org/wiki?curid=8377", "title": "Database", "text": "A database is an organized collection of data, generally stored and accessed electronically from a computer system. Where databases are more complex they are often developed using formal design and modeling techniques.\nThe database management system (DBMS) is the software that interacts with end users, applications, and the database itself to capture and analyze the data. The DBMS software additionally encompasses the core facilities provided to administer the database. The sum total of the database, the DBMS and the associated applications can be referred to as a \"database system\". Often the term \"database\" is also used to loosely refer to any of the DBMS, the database system or an application associated with the database.\nComputer scientists may classify database-management systems according to the database models that they support. Relational databases became dominant in the 1980s. These model data as rows and columns in a series of tables, and the vast majority use SQL for writing and querying data. In the 2000s, non-relational databases became popular, referred to as NoSQL because they use different query languages.\nTerminology and overview.\nFormally, a \"database\" refers to a set of related data and the way it is organized. Access to this data is usually provided by a \"database management system\" (DBMS) consisting of an integrated set of computer software that allows users to interact with one or more databases and provides access to all of the data contained in the database (although restrictions may exist that limit access to particular data). The DBMS provides various functions that allow entry, storage and retrieval of large quantities of information and provides ways to manage how that information is organized.\nBecause of the close relationship between them, the term \"database\" is often used casually to refer to both a database and the DBMS used to manipulate it.\nOutside the world of professional information technology, the term \"database\" is often used to refer to any collection of related data (such as a spreadsheet or a card index) as size and usage requirements typically necessitate use of a database management system.\nExisting DBMSs provide various functions that allow management of a database and its data which can be classified into four main functional groups:\nBoth a database and its DBMS conform to the principles of a particular database model. \"Database system\" refers collectively to the database model, database management system, and database.\nPhysically, database servers are dedicated computers that hold the actual databases and run only the DBMS and related software. Database servers are usually multiprocessor computers, with generous memory and RAID disk arrays used for stable storage. Hardware database accelerators, connected to one or more servers via a high-speed channel, are also used in large volume transaction processing environments. DBMSs are found at the heart of most database applications. DBMSs may be built around a custom multitasking kernel with built-in networking support, but modern DBMSs typically rely on a standard operating system to provide these functions.\nSince DBMSs comprise a significant market, computer and storage vendors often take into account DBMS requirements in their own development plans.\nDatabases and DBMSs can be categorized according to the database model(s) that they support (such as relational or XML), the type(s) of computer they run on (from a server cluster to a mobile phone), the query language(s) used to access the database (such as SQL or XQuery), and their internal engineering, which affects performance, scalability, resilience, and security.\nHistory.\nThe sizes, capabilities, and performance of databases and their respective DBMSs have grown in orders of magnitude. These performance increases were enabled by the technology progress in the areas of processors, computer memory, computer storage, and computer networks. The concept of a database was made possible by the emergence of direct access storage media such as magnetic disks, which became widely available in the mid 1960s; earlier systems relied on sequential storage of data on magnetic tape. The subsequent development of database technology can be divided into three eras based on data model or structure: navigational, SQL/relational, and post-relational.\nThe two main early navigational data models were the hierarchical model and the CODASYL model (network model). These were characterized by the use of pointers (often physical disk addresses) to follow relationships from one record to another.\nThe relational model, first proposed in 1970 by Edgar F. Codd, departed from this tradition by insisting that applications should search for data by content, rather than by following links. The relational model employs sets of ledger-style tables, each used for a different type of entity. Only in the mid-1980s did computing hardware become powerful enough to allow the wide deployment of relational systems (DBMSs plus applications). By the early 1990s, however, relational systems dominated in all large-scale data processing applications, and they remain dominant: IBM DB2, Oracle, MySQL, and Microsoft SQL Server are the most searched DBMS. The dominant database language, standardised SQL for the relational model, has influenced database languages for other data models.\nObject databases were developed in the 1980s to overcome the inconvenience of object-relational impedance mismatch, which led to the coining of the term \"post-relational\" and also the development of hybrid object-relational databases.\nThe next generation of post-relational databases in the late 2000s became known as NoSQL databases, introducing fast key-value stores and document-oriented databases. A competing \"next generation\" known as NewSQL databases attempted new implementations that retained the relational/SQL model while aiming to match the high performance of NoSQL compared to commercially available relational DBMSs.\n1960s, navigational DBMS.\nThe introduction of the term \"database\" coincided with the availability of direct-access storage (disks and drums) from the mid-1960s onwards. The term represented a contrast with the tape-based systems of the past, allowing shared interactive use rather than daily batch processing. The Oxford English Dictionary cites a 1962 report by the System Development Corporation of California as the first to use the term \"data-base\" in a specific technical sense.\nAs computers grew in speed and capability, a number of general-purpose database systems emerged; by the mid-1960s a number of such systems had come into commercial use. Interest in a standard began to grow, and Charles Bachman, author of one such product, the Integrated Data Store (IDS), founded the Database Task Group within CODASYL, the group responsible for the creation and standardization of COBOL. In 1971, the Database Task Group delivered their standard, which generally became known as the \"CODASYL approach\", and soon a number of commercial products based on this approach entered the market.\nThe CODASYL approach offered applications the ability to navigate around a linked data set which was formed into a large network. Applications could find records by one of three methods:\nLater systems added B-trees to provide alternate access paths. Many CODASYL databases also added a declarative query language for end users (as distinct from the navigational API). However CODASYL databases were complex and required significant training and effort to produce useful applications.\nIBM also had their own DBMS in 1966, known as Information Management System (IMS). IMS was a development of software written for the Apollo program on the System/360. IMS was generally similar in concept to CODASYL, but used a strict hierarchy for its model of data navigation instead of CODASYL's network model. Both concepts later became known as navigational databases due to the way data was accessed: the term was popularized by Bachman's 1973 Turing Award presentation \"The Programmer as Navigator\". IMS is classified by IBM as a hierarchical database. IDMS and Cincom Systems' TOTAL database are classified as network databases. IMS remains in use .\n1970s, relational DBMS.\nEdgar F. Codd worked at IBM in San Jose, California, in one of their offshoot offices that was primarily involved in the development of hard disk systems. He was unhappy with the navigational model of the CODASYL approach, notably the lack of a \"search\" facility. In 1970, he wrote a number of papers that outlined a new approach to database construction that eventually culminated in the groundbreaking \"A Relational Model of Data for Large Shared Data Banks\".\nIn this paper, he described a new system for storing and working with large databases. Instead of records being stored in some sort of linked list of free-form records as in CODASYL, Codd's idea was to organise the data as a number of \"tables\", each table being used for a different type of entity. Each table would contain a fixed number of columns containing the attributes of the entity. One or more columns of each table were designated as a primary key by which the rows of the table could be uniquely identified; cross-references between tables always used these primary keys, rather than disk addresses, and queries would join tables based on these key relationships, using a set of operations based on the mathematical system of relational calculus (from which the model takes its name). Splitting the data into a set of normalized tables (or \"relations\") aimed to ensure that each \"fact\" was only stored once, thus simplifying update operations. Virtual tables called \"views\" could present the data in different ways for different users, but views could not be directly updated.\nCodd used mathematical terms to define the model: relations, tuples, and domains rather than tables, rows, and columns. The terminology that is now familiar came from early implementations. Codd would later criticize the tendency for practical implementations to depart from the mathematical foundations on which the model was based.\n \nThe use of primary keys (user-oriented identifiers) to represent cross-table relationships, rather than disk addresses, had two primary motivations. From an engineering perspective, it enabled tables to be relocated and resized without expensive database reorganization. But Codd was more interested in the difference in semantics: the use of explicit identifiers made it easier to define update operations with clean mathematical definitions, and it also enabled query operations to be defined in terms of the established discipline of first-order predicate calculus; because these operations have clean mathematical properties, it becomes possible to rewrite queries in provably correct ways, which is the basis of query optimization. There is no loss of expressiveness compared with the hierarchic or network models, though the connections between tables are no longer so explicit.\nIn the hierarchic and network models, records were allowed to have a complex internal structure. For example, the salary history of an employee might be represented as a \"repeating group\" within the employee record. In the relational model, the process of normalization led to such internal structures being replaced by data held in multiple tables, connected only by logical keys.\nFor instance, a common use of a database system is to track information about users, their name, login information, various addresses and phone numbers. In the navigational approach, all of this data would be placed in a single variable-length record. In the relational approach, the data would be \"normalized\" into a user table, an address table and a phone number table (for instance). Records would be created in these optional tables only if the address or phone numbers were actually provided.\nAs well as identifying rows/records using logical identifiers rather than disk addresses, Codd changed the way in which applications assembled data from multiple records. Rather than requiring applications to gather data one record at a time by navigating the links, they would use a declarative query language that expressed what data was required, rather than the access path by which it should be found. Finding an efficient access path to the data became the responsibility of the database management system, rather than the application programmer. This process, called query optimization, depended on the fact that queries were expressed in terms of mathematical logic.\nCodd's paper was picked up by two people at Berkeley, Eugene Wong and Michael Stonebraker. They started a project known as INGRES using funding that had already been allocated for a geographical database project and student programmers to produce code. Beginning in 1973, INGRES delivered its first test products which were generally ready for widespread use in 1979. INGRES was similar to System R in a number of ways, including the use of a \"language\" for data access, known as QUEL. Over time, INGRES moved to the emerging SQL standard.\nIBM itself did one test implementation of the relational model, PRTV, and a production one, Business System 12, both now discontinued. Honeywell wrote MRDS for Multics, and now there are two new implementations: Alphora Dataphor and Rel. Most other DBMS implementations usually called \"relational\" are actually SQL DBMSs.\nIn 1970, the University of Michigan began development of the MICRO Information Management System based on D.L. Childs' Set-Theoretic Data model. MICRO was used to manage very large data sets by the US Department of Labor, the U.S. Environmental Protection Agency, and researchers from the University of Alberta, the University of Michigan, and Wayne State University. It ran on IBM mainframe computers using the Michigan Terminal System. The system remained in production until 1998.\nIntegrated approach.\nIn the 1970s and 1980s, attempts were made to build database systems with integrated hardware and software. The underlying philosophy was that such integration would provide higher performance at a lower cost. Examples were IBM System/38, the early offering of Teradata, and the Britton Lee, Inc. database machine.\nAnother approach to hardware support for database management was ICL's CAFS accelerator, a hardware disk controller with programmable search capabilities. In the long term, these efforts were generally unsuccessful because specialized database machines could not keep pace with the rapid development and progress of general-purpose computers. Thus most database systems nowadays are software systems running on general-purpose hardware, using general-purpose computer data storage. However, this idea is still pursued for certain applications by some companies like Netezza and Oracle (Exadata).\nLate 1970s, SQL DBMS.\nIBM started working on a prototype system loosely based on Codd's concepts as \"System R\" in the early 1970s. The first version was ready in 1974/5, and work then started on multi-table systems in which the data could be split so that all of the data for a record (some of which is optional) did not have to be stored in a single large \"chunk\". Subsequent multi-user versions were tested by customers in 1978 and 1979, by which time a standardized query language \u2013 SQL \u2013 had been added. Codd's ideas were establishing themselves as both workable and superior to CODASYL, pushing IBM to develop a true production version of System R, known as \"SQL/DS\", and, later, \"Database 2\" (DB2).\nLarry Ellison's Oracle Database (or more simply, Oracle) started from a different chain, based on IBM's papers on System R. Though Oracle V1 implementations were completed in 1978, it wasn't until Oracle Version 2 when Ellison beat IBM to market in 1979.\nStonebraker went on to apply the lessons from INGRES to develop a new database, Postgres, which is now known as PostgreSQL. PostgreSQL is often used for global mission-critical applications (the .org and .info domain name registries use it as their primary data store, as do many large companies and financial institutions).\nIn Sweden, Codd's paper was also read and Mimer SQL was developed from the mid-1970s at Uppsala University. In 1984, this project was consolidated into an independent enterprise.\nAnother data model, the entity\u2013relationship model, emerged in 1976 and gained popularity for database design as it emphasized a more familiar description than the earlier relational model. Later on, entity\u2013relationship constructs were retrofitted as a data modeling construct for the relational model, and the difference between the two have become irrelevant.\n1980s, on the desktop.\nThe 1980s ushered in the age of desktop computing. The new computers empowered their users with spreadsheets like Lotus 1-2-3 and database software like dBASE. The dBASE product was lightweight and easy for any computer user to understand out of the box. C. Wayne Ratliff, the creator of dBASE, stated: \"dBASE was different from programs like BASIC, C, FORTRAN, and COBOL in that a lot of the dirty work had already been done. The data manipulation is done by dBASE instead of by the user, so the user can concentrate on what he is doing, rather than having to mess with the dirty details of opening, reading, and closing files, and managing space allocation.\" dBASE was one of the top selling software titles in the 1980s and early 1990s.\n1990s, object-oriented.\nThe 1990s, along with a rise in object-oriented programming, saw a growth in how data in various databases were handled. Programmers and designers began to treat the data in their databases as objects. That is to say that if a person's data were in a database, that person's attributes, such as their address, phone number, and age, were now considered to belong to that person instead of being extraneous data. This allows for relations between data to be relations to objects and their attributes and not to individual fields. The term \"object-relational impedance mismatch\" described the inconvenience of translating between programmed objects and database tables. Object databases and object-relational databases attempt to solve this problem by providing an object-oriented language (sometimes as extensions to SQL) that programmers can use as alternative to purely relational SQL. On the programming side, libraries known as object-relational mappings (ORMs) attempt to solve the same problem.\n2000s, NoSQL and NewSQL.\nXML databases are a type of structured document-oriented database that allows querying based on XML document attributes. XML databases are mostly used in applications where the data is conveniently viewed as a collection of documents, with a structure that can vary from the very flexible to the highly rigid: examples include scientific articles, patents, tax filings, and personnel records.\nNoSQL databases are often very fast, do not require fixed table schemas, avoid join operations by storing denormalized data, and are designed to scale horizontally.\nIn recent years, there has been a strong demand for massively distributed databases with high partition tolerance, but according to the CAP theorem it is impossible for a distributed system to simultaneously provide consistency, availability, and partition tolerance guarantees. A distributed system can satisfy any two of these guarantees at the same time, but not all three. For that reason, many NoSQL databases are using what is called eventual consistency to provide both availability and partition tolerance guarantees with a reduced level of data consistency.\nNewSQL is a class of modern relational databases that aims to provide the same scalable performance of NoSQL systems for online transaction processing (read-write) workloads while still using SQL and maintaining the ACID guarantees of a traditional database system.\nUse cases.\nDatabases are used to support internal operations of organizations and to underpin online interactions with customers and suppliers (see Enterprise software).\nDatabases are used to hold administrative information and more specialized data, such as engineering data or economic models. Examples include computerized library systems, flight reservation systems, computerized parts inventory systems, and many content management systems that store websites as collections of webpages in a database.\nClassification.\nOne way to classify databases involves the type of their contents, for example: bibliographic, document-text, statistical, or multimedia objects. Another way is by their application area, for example: accounting, music compositions, movies, banking, manufacturing, or insurance. A third way is by some technical aspect, such as the database structure or interface type. This section lists a few of the adjectives used to characterize different kinds of databases.\nDatabase interaction.\nDatabase management system.\nConnolly and Begg define database management system (DBMS) as a \"software system that enables users to define, create, maintain and control access to the database\". Examples of DBMS's include MySQL, PostgreSQL, MSSQL, Oracle Database, and Microsoft Access.\nThe DBMS acronym is sometimes extended to indicate the underlying database model, with RDBMS for the relational, OODBMS for the object (oriented) and ORDBMS for the object-relational model. Other extensions can indicate some other characteristic, such as DDBMS for a distributed database management systems.\nThe functionality provided by a DBMS can vary enormously. The core functionality is the storage, retrieval and update of data. Codd proposed the following functions and services a fully-fledged general purpose DBMS should provide:\nIt is also generally to be expected the DBMS will provide a set of utilities for such purposes as may be necessary to administer the database effectively, including import, export, monitoring, defragmentation and analysis utilities. The core part of the DBMS interacting between the database and the application interface sometimes referred to as the database engine.\nOften DBMSs will have configuration parameters that can be statically and dynamically tuned, for example the maximum amount of main memory on a server the database can use. The trend is to minimise the amount of manual configuration, and for cases such as embedded databases the need to target zero-administration is paramount.\nThe large major enterprise DBMSs have tended to increase in size and functionality and can have involved thousands of human years of development effort through their lifetime.\nEarly multi-user DBMS typically only allowed for the application to reside on the same computer with access via terminals or terminal emulation software. The client\u2013server architecture was a development where the application resided on a client desktop and the database on a server allowing the processing to be distributed. This evolved into a multitier architecture incorporating application servers and web servers with the end user interface via a web browser with the database only directly connected to the adjacent tier.\nA general-purpose DBMS will provide public application programming interfaces (API) and optionally a processor for database languages such as SQL to allow applications to be written to interact with the database. A special purpose DBMS may use a private API and be specifically customised and linked to a single application. For example, an email system performing many of the functions of a general-purpose DBMS such as message insertion, message deletion, attachment handling, blocklist lookup, associating messages an email address and so forth however these functions are limited to what is required to handle email.\nApplication.\nExternal interaction with the database will be via an application program that interfaces with the DBMS. This can range from a database tool that allows users to execute SQL queries textually or graphically, to a web site that happens to use a database to store and search information.\nApplication program interface.\nA programmer will code interactions to the database (sometimes referred to as a datasource) via an application program interface (API) or via a database language. The particular API or language chosen will need to be supported by DBMS, possible indirectly via a pre-processor or a bridging API. Some API's aim to be database independent, ODBC being a commonly known example. Other common API's include JDBC and ADO.NET.\nDatabase languages.\nDatabase languages are special-purpose languages, which allow one or more of the following tasks, sometimes distinguished as sublanguages:\nDatabase languages are specific to a particular data model. Notable examples include:\nA database language may also incorporate features like:\nStorage.\nDatabase storage is the container of the physical materialization of a database. It comprises the \"internal\" (physical) \"level\" in the database architecture. It also contains all the information needed (e.g., metadata, \"data about the data\", and internal data structures) to reconstruct the \"conceptual level\" and \"external level\" from the internal level when needed. Putting data into permanent storage is generally the responsibility of the database engine a.k.a. \"storage engine\". Though typically accessed by a DBMS through the underlying operating system (and often using the operating systems' file systems as intermediates for storage layout), storage properties and configuration setting are extremely important for the efficient operation of the DBMS, and thus are closely maintained by database administrators. A DBMS, while in operation, always has its database residing in several types of storage (e.g., memory and external storage). The database data and the additional needed information, possibly in very large amounts, are coded into bits. Data typically reside in the storage in structures that look completely different from the way the data look in the conceptual and external levels, but in ways that attempt to optimize (the best possible) these levels' reconstruction when needed by users and programs, as well as for computing additional types of needed information from the data (e.g., when querying the database).\nSome DBMSs support specifying which character encoding was used to store data, so multiple encodings can be used in the same database.\nVarious low-level database storage structures are used by the storage engine to serialize the data model so it can be written to the medium of choice. Techniques such as indexing may be used to improve performance. Conventional storage is row-oriented, but there are also column-oriented and correlation databases.\nMaterialized views.\nOften storage redundancy is employed to increase performance. A common example is storing \"materialized views\", which consist of frequently needed \"external views\" or query results. Storing such views saves the expensive computing of them each time they are needed. The downsides of materialized views are the overhead incurred when updating them to keep them synchronized with their original updated database data, and the cost of storage redundancy.\nReplication.\nOccasionally a database employs storage redundancy by database objects replication (with one or more copies) to increase data availability (both to improve performance of simultaneous multiple end-user accesses to a same database object, and to provide resiliency in a case of partial failure of a distributed database). Updates of a replicated object need to be synchronized across the object copies. In many cases, the entire database is replicated.\nSecurity.\nDatabase security deals with all various aspects of protecting the database content, its owners, and its users. It ranges from protection from intentional unauthorized database uses to unintentional database accesses by unauthorized entities (e.g., a person or a computer program).\nDatabase access control deals with controlling who (a person or a certain computer program) is allowed to access what information in the database. The information may comprise specific database objects (e.g., record types, specific records, data structures), certain computations over certain objects (e.g., query types, or specific queries), or using specific access paths to the former (e.g., using specific indexes or other data structures to access information). Database access controls are set by special authorized (by the database owner) personnel that uses dedicated protected security DBMS interfaces.\nThis may be managed directly on an individual basis, or by the assignment of individuals and privileges to groups, or (in the most elaborate models) through the assignment of individuals and groups to roles which are then granted entitlements. Data security prevents unauthorized users from viewing or updating the database. Using passwords, users are allowed access to the entire database or subsets of it called \"subschemas\". For example, an employee database can contain all the data about an individual employee, but one group of users may be authorized to view only payroll data, while others are allowed access to only work history and medical data. If the DBMS provides a way to interactively enter and update the database, as well as interrogate it, this capability allows for managing personal databases.\nData security in general deals with protecting specific chunks of data, both physically (i.e., from corruption, or destruction, or removal; e.g., see physical security), or the interpretation of them, or parts of them to meaningful information (e.g., by looking at the strings of bits that they comprise, concluding specific valid credit-card numbers; e.g., see data encryption).\nChange and access logging records who accessed which attributes, what was changed, and when it was changed. Logging services allow for a forensic database audit later by keeping a record of access occurrences and changes. Sometimes application-level code is used to record changes rather than leaving this to the database. Monitoring can be set up to attempt to detect security breaches.\nTransactions and concurrency.\nDatabase transactions can be used to introduce some level of fault tolerance and data integrity after recovery from a crash. A database transaction is a unit of work, typically encapsulating a number of operations over a database (e.g., reading a database object, writing, acquiring lock, etc.), an abstraction supported in database and also other systems. Each transaction has well defined boundaries in terms of which program/code executions are included in that transaction (determined by the transaction's programmer via special transaction commands).\nThe acronym ACID describes some ideal properties of a database transaction: atomicity, consistency, isolation, and durability.\nMigration.\nA database built with one DBMS is not portable to another DBMS (i.e., the other DBMS cannot run it). However, in some situations, it is desirable to migrate a database from one DBMS to another. The reasons are primarily economical (different DBMSs may have different total costs of ownership or TCOs), functional, and operational (different DBMSs may have different capabilities). The migration involves the database's transformation from one DBMS type to another. The transformation should maintain (if possible) the database related application (i.e., all related application programs) intact. Thus, the database's conceptual and external architectural levels should be maintained in the transformation. It may be desired that also some aspects of the architecture internal level are maintained. A complex or large database migration may be a complicated and costly (one-time) project by itself, which should be factored into the decision to migrate. This in spite of the fact that tools may exist to help migration between specific DBMSs. Typically, a DBMS vendor provides tools to help importing databases from other popular DBMSs.\nBuilding, maintaining, and tuning.\nAfter designing a database for an application, the next stage is building the database. Typically, an appropriate general-purpose DBMS can be selected to be used for this purpose. A DBMS provides the needed user interfaces to be used by database administrators to define the needed application's data structures within the DBMS's respective data model. Other user interfaces are used to select needed DBMS parameters (like security related, storage allocation parameters, etc.).\nWhen the database is ready (all its data structures and other needed components are defined), it is typically populated with initial application's data (database initialization, which is typically a distinct project; in many cases using specialized DBMS interfaces that support bulk insertion) before making it operational. In some cases, the database becomes operational while empty of application data, and data are accumulated during its operation.\nAfter the database is created, initialised and populated it needs to be maintained. Various database parameters may need changing and the database may need to be tuned (tuning) for better performance; application's data structures may be changed or added, new related application programs may be written to add to the application's functionality, etc.\nBackup and restore.\nSometimes it is desired to bring a database back to a previous state (for many reasons, e.g., cases when the database is found corrupted due to a software error, or if it has been updated with erroneous data). To achieve this, a backup operation is done occasionally or continuously, where each desired database state (i.e., the values of its data and their embedding in database's data structures) is kept within dedicated backup files (many techniques exist to do this effectively). When it is decided by a database administrator to bring the database back to this state (e.g., by specifying this state by a desired point in time when the database was in this state), these files are used to restore that state.\nStatic analysis.\nStatic analysis techniques for software verification can be applied also in the scenario of query languages. In particular, the *Abstract interpretation framework has been extended to the field of query languages for relational databases as a way to support sound approximation techniques. The semantics of query languages can be tuned according to suitable abstractions of the concrete domain of data. The abstraction of relational database system has many interesting applications, in particular, for security purposes, such as fine grained access control, watermarking, etc.\nMiscellaneous features.\nOther DBMS features might include:\nIncreasingly, there are calls for a single system that incorporates all of these core functionalities into the same build, test, and deployment framework for database management and source control. Borrowing from other developments in the software industry, some market such offerings as \"DevOps for database\".\nDesign and modeling.\nThe first task of a database designer is to produce a conceptual data model that reflects the structure of the information to be held in the database. A common approach to this is to develop an entity-relationship model, often with the aid of drawing tools. Another popular approach is the Unified Modeling Language. A successful data model will accurately reflect the possible state of the external world being modeled: for example, if people can have more than one phone number, it will allow this information to be captured. Designing a good conceptual data model requires a good understanding of the application domain; it typically involves asking deep questions about the things of interest to an organization, like \"can a customer also be a supplier?\", or \"if a product is sold with two different forms of packaging, are those the same product or different products?\", or \"if a plane flies from New York to Dubai via Frankfurt, is that one flight or two (or maybe even three)?\". The answers to these questions establish definitions of the terminology used for entities (customers, products, flights, flight segments) and their relationships and attributes.\nProducing the conceptual data model sometimes involves input from business processes, or the analysis of workflow in the organization. This can help to establish what information is needed in the database, and what can be left out. For example, it can help when deciding whether the database needs to hold historic data as well as current data.\nHaving produced a conceptual data model that users are happy with, the next stage is to translate this into a schema that implements the relevant data structures within the database. This process is often called logical database design, and the output is a logical data model expressed in the form of a schema. Whereas the conceptual data model is (in theory at least) independent of the choice of database technology, the logical data model will be expressed in terms of a particular database model supported by the chosen DBMS. (The terms \"data model\" and \"database model\" are often used interchangeably, but in this article we use \"data model\" for the design of a specific database, and \"database model\" for the modeling notation used to express that design).\nThe most popular database model for general-purpose databases is the relational model, or more precisely, the relational model as represented by the SQL language. The process of creating a logical database design using this model uses a methodical approach known as normalization. The goal of normalization is to ensure that each elementary \"fact\" is only recorded in one place, so that insertions, updates, and deletions automatically maintain consistency.\nThe final stage of database design is to make the decisions that affect performance, scalability, recovery, security, and the like, which depend on the particular DBMS. This is often called \"physical database design\", and the output is the physical data model. A key goal during this stage is data independence, meaning that the decisions made for performance optimization purposes should be invisible to end-users and applications. There are two types of data independence: Physical data independence and logical data independence. Physical design is driven mainly by performance requirements, and requires a good knowledge of the expected workload and access patterns, and a deep understanding of the features offered by the chosen DBMS.\nAnother aspect of physical database design is security. It involves both defining access control to database objects as well as defining security levels and methods for the data itself.\nModels.\nA database model is a type of data model that determines the logical structure of a database and fundamentally determines in which manner data can be stored, organized, and manipulated. The most popular example of a database model is the relational model (or the SQL approximation of relational), which uses a table-based format.\nCommon logical data models for databases include:\nAn object-relational database combines the two related structures.\nPhysical data models include:\nOther models include:\nSpecialized models are optimized for particular types of data:\nExternal, conceptual, and internal views.\nA database management system provides three views of the database data:\nWhile there is typically only one conceptual (or logical) and physical (or internal) view of the data, there can be any number of different external views. This allows users to see database information in a more business-related way rather than from a technical, processing viewpoint. For example, a financial department of a company needs the payment details of all employees as part of the company's expenses, but does not need details about employees that are the interest of the human resources department. Thus different departments need different \"views\" of the company's database.\nThe three-level database architecture relates to the concept of \"data independence\" which was one of the major initial driving forces of the relational model. The idea is that changes made at a certain level do not affect the view at a higher level. For example, changes in the internal level do not affect application programs written using conceptual level interfaces, which reduces the impact of making physical changes to improve performance.\nThe conceptual view provides a level of indirection between internal and external. On one hand it provides a common view of the database, independent of different external view structures, and on the other hand it abstracts away details of how the data are stored or managed (internal level). In principle every level, and even every external view, can be presented by a different data model. In practice usually a given DBMS uses the same data model for both the external and the conceptual levels (e.g., relational model). The internal level, which is hidden inside the DBMS and depends on its implementation, requires a different level of detail and uses its own types of data structure types.\nSeparating the \"external\", \"conceptual\" and \"internal\" levels was a major feature of the relational database model implementations that dominate 21st century databases.\nResearch.\nDatabase technology has been an active research topic since the 1960s, both in academia and in the research and development groups of companies (for example IBM Research). Research activity includes theory and development of prototypes. Notable research topics have included models, the atomic transaction concept, and related concurrency control techniques, query languages and query optimization methods, RAID, and more.\nThe database research area has several dedicated academic journals (for example, \"ACM Transactions on Database Systems\"-TODS, \"Data and Knowledge Engineering\"-DKE) and annual conferences (e.g., ACM SIGMOD, ACM PODS, VLDB, IEEE ICDE)."}
{"id": "8378", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=8378", "title": "Dipole", "text": "In electromagnetism, there are two kinds of dipoles:\nDipoles, whether electric or magnetic, can be characterized by their dipole moment, a vector quantity. For the simple electric dipole, the electric dipole moment points from the negative charge towards the positive charge, and has a magnitude equal to the strength of each charge times the separation between the charges. (To be precise: for the definition of the dipole moment, one should always consider the \"dipole limit\", where, for example, the distance of the generating charges should \"converge\" to 0 while simultaneously, the charge strength should \"diverge\" to infinity in such a way that the product remains a positive constant.)\nFor the magnetic (dipole) current loop, the magnetic dipole moment points through the loop (according to the right hand grip rule), with a magnitude equal to the current in the loop times the area of the loop.\nSimilar to magnetic current loops, the electron particle and some other fundamental particles have magnetic dipole moments, as an electron generates a magnetic field identical to that generated by a very small current loop. However, an electron's magnetic dipole moment is not due to a current loop, but to an intrinsic property of the electron. The electron may also have an \"electric\" dipole moment though such has yet to be observed (see electron electric dipole moment).\nA permanent magnet, such as a bar magnet, owes its magnetism to the intrinsic magnetic dipole moment of the electron. The two ends of a bar magnet are referred to as poles\u2014not to be confused with monopoles, see Classification below)\u2014and may be labeled \"north\" and \"south\". In terms of the Earth's magnetic field, they are respectively \"north-seeking\" and \"south-seeking\" poles: if the magnet were freely suspended in the Earth's magnetic field, the north-seeking pole would point towards the north and the south-seeking pole would point towards the south. The dipole moment of the bar magnet points from its magnetic south to its magnetic north pole. In a magnetic compass, the north pole of a bar magnet points north. However, that means that Earth's geomagnetic north pole is the \"south\" pole (south-seeking pole) of its dipole moment and vice versa.\nThe only known mechanisms for the creation of magnetic dipoles are by current loops or quantum-mechanical spin since the existence of magnetic monopoles has never been experimentally demonstrated.\nThe term comes from the Greek (\"dis\"), \"twice\" and (\"polos\"), \"axis\".\nClassification.\nA \"physical dipole\" consists of two equal and opposite point charges: in the literal sense, two poles. Its field at large distances (i.e., distances large in comparison to the separation of the poles) depends almost entirely on the dipole moment as defined above. A \"point (electric) dipole\" is the limit obtained by letting the separation tend to 0 while keeping the dipole moment fixed. The field of a point dipole has a particularly simple form, and the order-1 term in the multipole expansion is precisely the point dipole field.\nAlthough there are no known magnetic monopoles in nature, there are magnetic dipoles in the form of the quantum-mechanical spin associated with particles such as electrons (although the accurate description of such effects falls outside of classical electromagnetism). A theoretical magnetic \"point dipole\" has a magnetic field of exactly the same form as the electric field of an electric point dipole. A very small current-carrying loop is approximately a magnetic point dipole; the magnetic dipole moment of such a loop is the product of the current flowing in the loop and the (vector) area of the loop.\nAny configuration of charges or currents has a 'dipole moment', which describes the dipole whose field is the best approximation, at large distances, to that of the given configuration. This is simply one term in the multipole expansion when the total charge (\"monopole moment\") is 0\u2014as it \"always\" is for the magnetic case, since there are no magnetic monopoles. The dipole term is the dominant one at large distances: Its field falls off in proportion to , as compared to for the next (quadrupole) term and higher powers of for higher terms, or for the monopole term.\nMolecular dipoles.\nMany molecules have such dipole moments due to non-uniform distributions of positive and negative charges on the various atoms. Such is the case with polar compounds like hydrogen fluoride (HF), where electron density is shared unequally between atoms. Therefore, a molecule's dipole is an electric dipole with an inherent electric field that should not be confused with a magnetic dipole which generates a magnetic field.\nThe physical chemist Peter J. W. Debye was the first scientist to study molecular dipoles extensively, and, as a consequence, dipole moments are measured in units named \"debye\" in his honor.\nFor molecules there are three types of dipoles:\nMore generally, an induced dipole of \"any\" polarizable charge distribution \"\u03c1\" (remember that a molecule has a charge distribution) is caused by an electric field external to \"\u03c1\". This field may, for instance, originate from an ion or polar molecule in the vicinity of \"\u03c1\" or may be macroscopic (e.g., a molecule between the plates of a charged capacitor). The size of the induced dipole moment is equal to the product of the strength of the external field and the dipole polarizability of \"\u03c1\".\nDipole moment values can be obtained from measurement of the dielectric constant. Some typical gas phase values in debye units are:\nPotassium bromide (KBr) has one of the highest dipole moments because it is an ionic compound that exists as a molecule in the gas phase.\nThe overall dipole moment of a molecule may be approximated as a vector sum of bond dipole moments. As a vector sum it depends on the relative orientation of the bonds, so that from the dipole moment information can be deduced about the molecular geometry.\nFor example, the zero dipole of CO2 implies that the two C=O bond dipole moments cancel so that the molecule must be linear. For H2O the O\u2212H bond moments do not cancel because the molecule is bent. For ozone (O3) which is also a bent molecule, the bond dipole moments are not zero even though the O\u2212O bonds are between similar atoms. This agrees with the Lewis structures for the resonance forms of ozone which show a positive charge on the central oxygen atom. \nAn example in organic chemistry of the role of geometry in determining dipole moment is the \"cis\" and \"trans\" isomers of 1,2-dichloroethene. In the \"cis\" isomer the two polar C\u2212Cl bonds are on the same side of the C=C double bond and the molecular dipole moment is 1.90\u00a0D. In the \"trans\" isomer, the dipole moment is zero because the two C\u2212Cl bonds are on opposite sides of the C=C and cancel (and the two bond moments for the much less polar C\u2212H bonds also cancel).\nAnother example of the role of molecular geometry is boron trifluoride, which has three polar bonds with a difference in electronegativity greater than the traditionally cited threshold of 1.7 for ionic bonding. However, due to the equilateral triangular distribution of the fluoride ions about the boron cation center, the molecule as a whole does not exhibit any identifiable pole: one cannot construct a plane that divides the molecule into a net negative part and a net positive part.\nQuantum mechanical dipole operator.\nConsider a collection of \"N\" particles with charges \"qi\" and position vectors r\"i\". For instance, this collection may be a molecule consisting of electrons, all with charge \u2212\"e\", and nuclei with charge \"eZi\", where \"Zi\" is the atomic number of the \"i\"\u2009th nucleus.\nThe dipole observable (physical quantity) has the quantum mechanical dipole operator:\nNotice that this definition is valid only for neutral atoms or molecules, i.e. total charge equal to zero. In the ionized case, we have\nwhere formula_3 is the center of mass of the molecule/group of particles.\nAtomic dipoles.\nA non-degenerate (\"S\"-state) atom can have only a zero permanent dipole. This fact follows quantum mechanically from the inversion symmetry of atoms. All 3 components of the dipole operator are antisymmetric under inversion with respect to the nucleus,\nwhere formula_5 is the dipole operator and formula_6 is the inversion operator.\nThe permanent dipole moment of an atom in a non-degenerate state (see degenerate energy level) is given as the expectation (average) value of the dipole operator,\nwhere formula_8 is an \"S\"-state, non-degenerate, wavefunction, which is symmetric or antisymmetric under inversion: formula_9. Since the product of the wavefunction (in the ket) and its complex conjugate (in the bra) is always symmetric under inversion and its inverse,\nit follows that the expectation value changes sign under inversion. We used here the fact that formula_11, being a symmetry operator, is unitary: formula_12 and by definition the Hermitian adjoint formula_13 may be moved from bra to ket and then becomes formula_14. Since the only quantity that is equal to minus itself is the zero, the expectation value vanishes,\nIn the case of open-shell atoms with degenerate energy levels, one could define a dipole moment by the aid of the first-order Stark effect. This gives a non-vanishing dipole (by definition proportional to a non-vanishing first-order Stark shift) only if some of the wavefunctions belonging to the degenerate energies have opposite parity; i.e., have different behavior under inversion. This is a rare occurrence, but happens for the excited H-atom, where 2s and 2p states are \"accidentally\" degenerate (see article Laplace\u2013Runge\u2013Lenz vector for the origin of this degeneracy) and have opposite parity (2s is even and 2p is odd).\nField of a static magnetic dipole.\nMagnitude.\nThe far-field strength, \"B\", of a dipole magnetic field is given by\nwhere\nConversion to cylindrical coordinates is achieved using and\nwhere \"\u03c1\" is the perpendicular distance from the \"z\"-axis. Then,\nVector form.\nThe field itself is a vector quantity:\nwhere\nThis is \"exactly\" the field of a point dipole, \"exactly\" the dipole term in the multipole expansion of an arbitrary field, and \"approximately\" the field of any dipole-like configuration at large distances.\nMagnetic vector potential.\nThe vector potential A of a magnetic dipole is\nwith the same definitions as above.\nField from an electric dipole.\nThe electrostatic potential at position r due to an electric dipole at the origin is given by:\nwhere p is the (vector) dipole moment, and \"\u0454\"0 is the permittivity of free space.\nThis term appears as the second term in the multipole expansion of an arbitrary electrostatic potential \u03a6(r). If the source of \u03a6(r) is a dipole, as it is assumed here, this term is the only non-vanishing term in the multipole expansion of \u03a6(r). The electric field from a dipole can be found from the gradient of this potential:\nThis is formally identical to the expression for the magnetic field of a point magnetic dipole with only a few names changed. In a real dipole, however, where the charges are physically separate, the \"internal\" field lines are different, since the magnetic field lines are continuous, while those of the electric field diverge or converge from the point charges. For further discussions about the internal field of dipoles, see or Magnetic moment#Internal magnetic field of a dipole. \nTorque on a dipole.\nSince the direction of an electric field is defined as the direction of the force on a positive charge, electric field lines point away from a positive charge and toward a negative charge.\nWhen placed in a homogeneous electric or magnetic field, equal but opposite forces arise on each side of the dipole creating a torque }:\nfor an electric dipole moment p (in coulomb-meters), or\nfor a magnetic dipole moment m (in ampere-square meters).\nThe resulting torque will tend to align the dipole with the applied field, which in the case of an electric dipole, yields a potential energy of\nThe energy of a magnetic dipole is similarly\nDipole radiation.\nIn addition to dipoles in electrostatics, it is also common to consider an electric or magnetic dipole that is oscillating in time. It is an extension, or a more physical next-step, to spherical wave radiation.\nIn particular, consider a harmonically oscillating electric dipole, with angular frequency \"\u03c9\" and a dipole moment \"p\"0 along the \u1e91 direction of the form\nIn vacuum, the exact field produced by this oscillating dipole can be derived using the retarded potential formulation as:\nFor \u00a0\u226b\u00a01, the far-field takes the simpler form of a radiating \"spherical\" wave, but with angular dependence embedded in the cross-product:\nThe time-averaged Poynting vector\nis not distributed isotropically, but concentrated around the directions lying perpendicular to the dipole moment, as a result of the non-spherical electric and magnetic waves. In fact, the spherical harmonic function (sin \"\u03b8\") responsible for such toroidal angular distribution is precisely the \"l\"\u00a0=\u00a01 \"p\" wave.\nThe total time-average power radiated by the field can then be derived from the Poynting vector as\nNotice that the dependence of the power on the fourth power of the frequency of the radiation is in accordance with the Rayleigh scattering, and the underlying effects why the sky consists of mainly blue colour.\nA circular polarized dipole is described as a superposition of two linear dipoles."}
{"id": "8379", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=8379", "title": "Dipole-dipole bond", "text": ""}
{"id": "8380", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=8380", "title": "Dipole\u2013dipole attraction", "text": ""}
{"id": "8382", "revid": "83784", "url": "https://en.wikipedia.org/wiki?curid=8382", "title": "Delocalised", "text": ""}
{"id": "8385", "revid": "2970138", "url": "https://en.wikipedia.org/wiki?curid=8385", "title": "Dry beer", "text": ""}
{"id": "8386", "revid": "31330659", "url": "https://en.wikipedia.org/wiki?curid=8386", "title": "Dynamics", "text": "Dynamics (from Greek \u03b4\u03c5\u03bd\u03b1\u03bc\u03b9\u03ba\u03cc\u03c2 \"dynamikos\" \"powerful\", from \u03b4\u03cd\u03bd\u03b1\u03bc\u03b9\u03c2 \"dynamis\" \"power\") or dynamic may refer to:"}
{"id": "8387", "revid": "1002619401", "url": "https://en.wikipedia.org/wiki?curid=8387", "title": "Draught beer", "text": "Draught beer, also spelt draft, is beer served from a cask or keg rather than from a bottle or can. Draught beer served from a pressurised keg is also known as \nName.\nUntil Joseph Bramah patented the beer engine in 1785, beer was served directly from the barrel and carried to the customer. The Old English \"\" (\"carry; pull\") developed into a series of related words including \"drag\", \"draw\", and \"draught\". By the time Bramah's beer pumps became popular, the use of the term \"draught\" to refer to the acts of serving or drinking beer was well established and transferred easily to beer served via the hand pumps. In time, the word came to be restricted to only such beer. The usual spelling is now \"draught\" in the United Kingdom, Ireland, Australia, and New Zealand and more commonly \"draft\" in North America, although it can be spelt either way. Regardless of spelling, the word is pronounced or depending on the region the speaker is from.\nCanned draught is beer served from a pressurised container featuring a widget. Smooth flow (also known as cream flow, nitrokeg, or smooth) is the name brewers give to draught beers pressurised with a partial nitrogen gas blend.\nHistory.\nIn 1691, an article in the \"London Gazette\" mentioned John Lofting, who held a patent for a fire engine: \"The said patentee has also projected a very useful engine for starting of beer, and other liquors which will draw from 20 to 30 barrels an hour, which are completely fixed with brass joints and screws at reasonable rates\".\nIn the early 20th century, draught beer started to be served from pressurised containers. Artificial carbonation was introduced in the United Kingdom in 1936, with Watney\u2019s experimental pasteurised beer Red Barrel. Though this method of serving beer did not take hold in the UK until the late 1950s, it did become the favored method in the rest of Europe, where it is known by such terms as \"en pression\". The carbonation method of serving beer subsequently spread to the rest of the world; by the early 1970s the term \"draught beer\" almost exclusively referred to beer served under pressure as opposed to the traditional cask or barrel beer.\nIn Britain, the Campaign for Real Ale (CAMRA) was founded in 1971 to protect traditional\u2014unpressurised\u2014beer and brewing methods. The group devised the term \"real ale\" to differentiate between beer served from the cask and beer served under pressure. The term \"real ale\" has since been expanded to include bottle-conditioned beer.\nKeg beer.\nKeg beer is often filtered and/or pasteurised, both of which are processes that render the yeast inactive.\nIn brewing parlance, a keg is different from a cask. A cask has a tap hole near the edge of the top, and a spile hole on the side used for conditioning the unfiltered and unpasteurised beer. A keg has a single opening in the centre of the top to which a flow pipe is attached. Kegs are artificially pressurised after fermentation with carbon dioxide or a mixture of carbon dioxide and nitrogen gas or especially in Czech Republic solely compressed air.\n\"Keg\" has become a term of contempt used by some, particularly in the UK, since the 1960s when pasteurised draught beers started replacing traditional cask beers.\nKeg beer was replacing traditional cask ale in all parts of the UK, primarily because it requires less care to handle. Since 1971, CAMRA has conducted a consumer campaign on behalf of those who prefer traditional cask beer. CAMRA has lobbied the British Parliament to ensure support for cask ale and microbreweries have sprung up to serve those consumers who prefer traditional cask beer.\nPressurised CO2 in the keg's headspace maintains carbonation in the beer. The CO2 pressure varies depending on the amount of CO2 already in the beer and the keg storage temperature. Occasionally the CO2 gas is blended with nitrogen gas. CO2 / nitrogen blends are used to allow a higher operating pressure in complex dispensing systems.\nNitrogen is used under high pressure when dispensing dry stouts (such as Guinness) and other creamy beers because it displaces CO2 to (artificially) form a rich tight head and a less carbonated taste. This makes the beer feel smooth on the palate and gives a foamy appearance. Premixed bottled gas for creamy beers is usually 75% nitrogen and 25% CO2. This premixed gas which only works well with creamy beers is often referred to as Guinness Gas, Beer Gas, or Aligal (an Air Liquide brand name). Using \"Beer Gas\" with other beer styles can cause the last 5% to 10% of the beer in each keg to taste very flat and lifeless. In the UK, the term \"keg beer\" would imply the beer is pasteurised, in contrast to unpasteurised cask ale. Some of the newer microbreweries may offer a nitro keg stout which is filtered but not pasteurized.\nStorage and serving temperature.\nCask beer should be stored and served at a cellar temperature of . Once a cask is opened, it should be consumed within three days. Keg beer is given additional cooling just prior to being served either by flash coolers or a remote cooler in the cellar. This chills the beer to temperatures between .\nCanned and bottled \"draught\".\nThe words \"draft\" and \"draught\" have been used as marketing terms to describe canned or bottled beers, implying that they taste and appear like beers from a cask or keg. Commercial brewers use this as a marketing tool although it is incorrect to call any beer not drawn from a cask or keg \"draught\". Two examples are Miller Genuine Draft, a pale lager which is produced using a cold filtering system, and Guinness stout in patented \"Draught-flow\" cans and bottles. Guinness is an example of beers that use a nitrogen widget to create a smooth beer with a dense head. Guinness has recently replaced the widget system from their bottled \"draught\" beer with a coating of cellulose fibres on the inside of the bottle. Statements indicate a new development in bottling technology that enables the mixture of nitrogen and carbon dioxide to be present in the beer without using a widget, making it according to Guinness \"more drinkable\" from the bottle.\nIn some countries, such as Japan, the term \"draft\" applied to canned or bottled beer indicates that the beer is not pasteurized (though it may be filtered), giving it a fresher taste but shorter shelf-life than conventional packaged beers."}
{"id": "8388", "revid": "1921264", "url": "https://en.wikipedia.org/wiki?curid=8388", "title": "Director", "text": "Director may refer to:"}
{"id": "8389", "revid": "878749", "url": "https://en.wikipedia.org/wiki?curid=8389", "title": "Major depressive disorder", "text": "Major depressive disorder (MDD), also known simply as depression, is a mental disorder characterized by at least two weeks of pervasive low mood. Low self-esteem, loss of interest in normally enjoyable activities, low energy, and pain without a clear cause are common symptoms. Those affected may also occasionally have delusions or hallucinations. Some people have periods of depression separated by years, while others nearly always have symptoms present. Major depression is more severe and lasts longer than sadness, which is a normal part of life.\nThe diagnosis of major depressive disorder is based on the person's reported experiences and a mental status examination. There is no laboratory test for the disorder, but testing may be done to rule out physical conditions that can cause similar symptoms. Those with major depressive disorder are typically treated with counseling and antidepressant medication. Medication appears to be effective, but the effect may only be significant in the most severely depressed. Types of counseling used include cognitive behavioral therapy (CBT) and interpersonal therapy, and electroconvulsive therapy (ECT) may be considered if other measures are not effective. Hospitalization may be necessary in cases with a risk of harm to self and may occasionally occur against a person's wishes.\nThe most common time of onset is in a person's 20s and 30s, with females affected about twice as often as males. Major depressive disorder affected approximately 163\u00a0million people (2% of the world's population) in 2017. The percentage of people who are affected at one point in their life varies from 7% in Japan to 21% in France. Lifetime rates are higher in the developed world (15%) compared to the developing world (11%). The disorder causes the second-most years lived with disability, after lower back pain.\nThe term \"major depressive disorder\" was introduced by a group of US clinicians in the mid-1970s. The cause of major depressive disorder is believed to be a combination of genetic, environmental, and psychological factors, with about 40% of the risk related to genetics. Risk factors include a family history of the condition, major life changes, certain medications, chronic health problems, and substance abuse. It can negatively affect a person's personal life, work life, or education as well as sleeping, eating habits, and general health. Those currently or previously affected with the disorder may be stigmatized.\nSymptoms and signs.\nMajor depression significantly affects a person's family and personal relationships, work or school life, sleeping and eating habits, and general health. Its impact on functioning and well-being has been compared to that of other chronic medical conditions, such as diabetes.\nA person having a major depressive episode usually exhibits a low mood, which pervades all aspects of life, and an inability to experience pleasure in previously enjoyable activities. Depressed people may be preoccupied with\u2014or ruminate over\u2014thoughts and feelings of worthlessness, inappropriate guilt or regret, helplessness or hopelessness. In severe cases, depressed people may have symptoms of psychosis. These symptoms include delusions or, less commonly, hallucinations, usually unpleasant. Other symptoms of depression include poor concentration and memory, especially in those with melancholic or psychotic features, withdrawal from social situations and activities, reduced sex drive, irritability, and thoughts of death or suicide. Insomnia is common among the depressed. In the typical pattern, a person wakes very early and cannot get back to sleep. Hypersomnia, or oversleeping, can also happen. Some antidepressants may also cause insomnia due to their stimulating effect.\nA depressed person may report multiple physical symptoms such as fatigue, headaches, or digestive problems; physical complaints are the most common presenting problem in developing countries, according to the World Health Organization's criteria for depression. Appetite often decreases, with resulting weight loss, although increased appetite and weight gain occasionally occur. Family and friends may notice that the person's behavior is either agitated or lethargic. Older depressed people may have cognitive symptoms of recent onset, such as forgetfulness, and a more noticeable slowing of movements.\nDepressed children may often display an irritable mood rather than a depressed one, and show varying symptoms depending on age and situation. Most lose interest in school and show a decline in academic performance. They may be described as clingy, demanding, dependent, or insecure. Diagnosis may be delayed or missed when symptoms are interpreted as \"normal moodiness.\"\nAssociated conditions.\nMajor depression frequently co-occurs with other psychiatric problems. The 1990\u201392 \"National Comorbidity Survey\" (US) reports that half of those with major depression also have lifetime anxiety and its associated disorders such as generalized anxiety disorder. Anxiety symptoms can have a major impact on the course of a depressive illness, with delayed recovery, increased risk of relapse, greater disability and increased suicide attempts. There are increased rates of alcohol and drug abuse and particularly dependence, and around a third of individuals diagnosed with ADHD develop comorbid depression. Post-traumatic stress disorder and depression often co-occur. Depression may also coexist with attention deficit hyperactivity disorder (ADHD), complicating the diagnosis and treatment of both. Depression is also frequently comorbid with alcohol abuse and personality disorders. Depression can also be exacerbated during particular months (usually winter) for those with seasonal affective disorder. While overuse of digital media has been associated with depressive symptoms, digital media may also be utilised in some situations to improve mood.\nDepression and pain often co-occur. One or more pain symptoms are present in 65% of depressed patients, and anywhere from 5 to 85% of patients with pain will be suffering from depression, depending on the setting; there is a lower prevalence in general practice, and higher in specialty clinics. The diagnosis of depression is often delayed or missed, and the outcome can worsen if the depression is noticed but completely misunderstood.\nDepression is also associated with a 1.5- to 2-fold increased risk of cardiovascular disease, independent of other known risk factors, and is itself linked directly or indirectly to risk factors such as smoking and obesity. People with major depression are less likely to follow medical recommendations for treating and preventing cardiovascular disorders, which further increases their risk of medical complications. In addition, cardiologists may not recognize underlying depression that complicates a cardiovascular problem under their care.\nDepression often coexists with physical disorders common among the elderly, such as stroke, other cardiovascular diseases, Parkinson's disease, and chronic obstructive pulmonary disease.\nCause.\nThe biopsychosocial model proposes that biological, psychological, and social factors all play a role in causing depression. The diathesis\u2013stress model specifies that depression results when a preexisting vulnerability, or diathesis, is activated by stressful life events. The preexisting vulnerability can be either genetic, implying an interaction between nature and nurture, or schematic, resulting from views of the world learned in childhood.\nChildhood abuse, either physical, sexual or psychological, are all risk factors for depression, among other psychiatric issues that co-occur such as anxiety and drug abuse. Childhood trauma also correlates with severity of depression, lack of response to treatment and length of illness. However, some are more susceptible to developing mental illness such as depression after trauma, and various genes have been suggested to control susceptibility.\nGenetics.\nFamily and twin studies find that nearly 40% of individual differences in risk for major depressive disorder can be explained by genetic factors. Like most psychiatric disorders, major depressive disorder is likely to be influenced by many individual genetic changes. In 2018, a genome-wide association study discovered 44 variants in the genome linked to risk for major depression. This was followed by a 2019 study that found 102 variants in the genome linked to depression.\nThe 5-HTTLPR, or serotonin transporter promoter gene's short allele has been associated with increased risk of depression. However, since the 1990s, results have been inconsistent, with three recent reviews finding an effect and two finding none. Other genes that have been linked to a gene-environment interaction include CRHR1, FKBP5 and BDNF, the first two of which are related to the stress reaction of the HPA axis, and the latter of which is involved in neurogenesis. There is no conclusive effects of candidate gene on depression, either alone or in combination with life stress. Research focusing on specific candidate genes has been criticized for its tendency to generate false positive findings. There are also other efforts to examine interactions between life stress and polygenic risk for depression.\nOther health problems.\nDepression may also come secondary to a chronic or terminal medical condition, such as HIV/AIDS or asthma, and may be labeled \"secondary depression.\" It is unknown whether the underlying diseases induce depression through effect on quality of life, of through shared etiologies (such as degeneration of the basal ganglia in Parkinson's disease or immune dysregulation in asthma). Depression may also be iatrogenic (the result of healthcare), such as drug-induced depression. Therapies associated with depression include interferons, beta-blockers, isotretinoin, contraceptives, cardiac agents, anticonvulsants, antimigraine drugs, antipsychotics, and hormonal agents such as gonadotropin-releasing hormone agonist. Drug abuse in early age is also associated with increased risk of developing depression later in life. Depression that occurs as a result of pregnancy is called postpartum depression, and is thought to be the result of hormonal changes associated with pregnancy. Seasonal affective disorder, a type of depression associated with seasonal changes in sunlight, is thought to be the result of decreased sunlight.\nPathophysiology.\nThe pathophysiology of depression is not yet understood, but the current theories center around monoaminergic systems, the circadian rhythm, immunological dysfunction, HPA axis dysfunction and structural or functional abnormalities of emotional circuits.\nThe monoamine theory, derived from the efficacy of monoaminergic drugs in treating depression, was the dominant theory until recently . The theory postulates that insufficient activity of monoamine neurotransmitters is the primary cause of depression. Evidence for the monoamine theory comes from multiple areas. Firstly, acute depletion of tryptophan, a necessary precursor of serotonin, a monoamine, can cause depression in those in remission or relatives of depressed patients; this suggests that decreased serotonergic neurotransmission is important in depression. Secondly, the correlation between depression risk and polymorphisms in the 5-HTTLPR gene, which codes for serotonin receptors, suggests a link. Third, decreased size of the locus coeruleus, decreased activity of tyrosine hydroxylase, increased density of alpha-2 adrenergic receptor, and evidence from rat models suggest decreased adrenergic neurotransmission in depression. Furthermore, decreased levels of homovanillic acid, altered response to dextroamphetamine, responses of depressive symptoms to dopamine receptor agonists, decreased dopamine receptor D1 binding in the striatum, and polymorphism of dopamine receptor genes implicate dopamine, another monoamine, in depression. Lastly, increased activity of monoamine oxidase, which degrades monoamines, has been associated with depression. However, this theory is inconsistent with the fact that serotonin depletion does not cause depression in healthy persons, the fact that antidepressants instantly increase levels of monoamines but take weeks to work, and the existence of atypical antidepressants which can be effective despite not targeting this pathway. One proposed explanation for the therapeutic lag, and further support for the deficiency of monoamines, is a desensitization of self-inhibition in raphe nuclei by the increased serotonin mediated by antidepressants. However, disinhibition of the dorsal raphe has been proposed to occur as a result of \"decreased\" serotonergic activity in tryptophan depletion, resulting in a depressed state mediated by increased serotonin. Further countering the monoamine hypothesis is the fact that rats with lesions of the dorsal raphe are not more depressive than controls, the finding of increased jugular 5-HIAA in depressed patients that normalized with SSRI treatment, and the preference for carbohydrates in depressed patients. Already limited, the monoamine hypothesis has been further oversimplified when presented to the general public.\nImmune system abnormalities have been observed, including increased levels of cytokines involved in generating sickness behavior (which shares overlap with depression). The effectiveness of nonsteroidal anti-inflammatory drugs (NSAIDs) and cytokine inhibitors in treating depression, and normalization of cytokine levels after successful treatment further suggest immune system abnormalities in depression.\nHPA axis abnormalities have been suggested in depression given the association of CRHR1 with depression and the increased frequency of dexamethasone test non-suppression in depressed patients. However, this abnormality is not adequate as a diagnosis tool, because its sensitivity is only 44%. These stress-related abnormalities have been hypothesized to be the cause of hippocampal volume reductions seen in depressed patients. Furthermore, a meta-analysis yielded decreased dexamethasone suppression, and increased response to psychological stressors. Further abnormal results have been obscured with the cortisol awakening response, with increased response being associated with depression.\nTheories unifying neuroimaging findings have been proposed. The first model proposed is the \"Limbic Cortical Model\", which involves hyperactivity of the ventral paralimbic regions and hypoactivity of frontal regulatory regions in emotional processing. Another model, the \"Corito-Striatal model\", suggests that abnormalities of the prefrontal cortex in regulating striatal and subcortical structures results in depression. Another model proposes hyperactivity of salience structures in identifying negative stimuli, and hypoactivity of cortical regulatory structures resulting in a negative emotional bias and depression, consistent with emotional bias studies.\nDiagnosis.\nClinical assessment.\nA diagnostic assessment may be conducted by a suitably trained general practitioner, or by a psychiatrist or psychologist, who records the person's current circumstances, biographical history, current symptoms, family history, and alcohol and drug use. The assessment also includes a mental state examination, which is an assessment of the person's current mood and thought content, in particular the presence of themes of hopelessness or pessimism, self-harm or suicide, and an absence of positive thoughts or plans. Specialist mental health services are rare in rural areas, and thus diagnosis and management is left largely to primary-care clinicians. This issue is even more marked in developing countries. Rating scales are not used to diagnose depression, but they provide an indication of the severity of symptoms for a time period, so a person who scores above a given cut-off point can be more thoroughly evaluated for a depressive disorder diagnosis. Several rating scales are used for this purpose; these include the Hamilton Rating Scale for Depression, the Beck Depression Inventory or the Suicide Behaviors Questionnaire-Revised.\nPrimary-care physicians and other non-psychiatrist physicians have more difficulty with underrecognition and undertreatment of depression compared to psychiatric physicians, in part because of the physical symptoms that often accompany depression, in addition to many potential patient, provider, and system barriers. A review found that non-psychiatrist physicians miss about two-thirds of cases, though this has improved somewhat in more recent studies.\nBefore diagnosing major depressive disorder, a doctor generally performs a medical examination and selected investigations to rule out other causes of symptoms. These include blood tests measuring TSH and thyroxine to exclude hypothyroidism; basic electrolytes and serum calcium to rule out a metabolic disturbance; and a full blood count including ESR to rule out a systemic infection or chronic disease. Adverse affective reactions to medications or alcohol misuse are often ruled out, as well. Testosterone levels may be evaluated to diagnose hypogonadism, a cause of depression in men. Vitamin D levels might be evaluated, as low levels of vitamin D have been associated with greater risk for depression.\nSubjective cognitive complaints appear in older depressed people, but they can also be indicative of the onset of a dementing disorder, such as Alzheimer's disease. Cognitive testing and brain imaging can help distinguish depression from dementia. A CT scan can exclude brain pathology in those with psychotic, rapid-onset or otherwise unusual symptoms. No biological tests confirm major depression. In general, investigations are not repeated for a subsequent episode unless there is a medical indication.\nDSM and ICD criteria.\nThe most widely used criteria for diagnosing depressive conditions are found in the American Psychiatric Association's \"Diagnostic and Statistical Manual of Mental Disorders\" and the World Health Organization's \"International Statistical Classification of Diseases and Related Health Problems\" which uses the name \"depressive episode\" for a single episode and \"recurrent depressive disorder\" for repeated episodes. The latter system is typically used in European countries, while the former is used in the US and many other non-European nations, and the authors of both have worked towards conforming one with the other.\nBoth DSM-5 and ICD-10 mark out typical (main) depressive symptoms. ICD-10 defines three typical depressive symptoms (depressed mood, anhedonia, and reduced energy), two of which should be present to determine the depressive disorder diagnosis. According to DSM-5, there are two main depressive symptoms: a depressed mood, and loss of interest/pleasure in activities (anhedonia). These symptoms, as well as five out of the nine more specific symptoms listed, must frequently occur for more than two weeks (to the extent in which it impairs functioning) for the diagnosis.\nMajor depressive disorder is classified as a mood disorder in DSM-5. The diagnosis hinges on the presence of single or recurrent major depressive episodes. Further qualifiers are used to classify both the episode itself and the course of the disorder. The category Unspecified Depressive Disorder is diagnosed if the depressive episode's manifestation does not meet the criteria for a major depressive episode. The ICD-10 system does not use the term \"major depressive disorder\" but lists very similar criteria for the diagnosis of a depressive episode (mild, moderate or severe); the term \"recurrent\" may be added if there have been multiple episodes without mania.\nMajor depressive episode.\nA major depressive episode is characterized by the presence of a severely depressed mood that persists for at least two weeks. Episodes may be isolated or recurrent and are categorized as mild (few symptoms in excess of minimum criteria), moderate, or severe (marked impact on social or occupational functioning). An episode with psychotic features\u2014commonly referred to as \"psychotic depression\"\u2014is automatically rated as severe. If the patient has had an episode of mania or markedly elevated mood, a diagnosis of bipolar disorder is made instead. Depression without mania is sometimes referred to as \"unipolar\" because the mood remains at one emotional state or \"pole\".\nDSM-IV-TR excludes cases where the symptoms are a result of bereavement, although it is possible for normal bereavement to evolve into a depressive episode if the mood persists and the characteristic features of a major depressive episode develop. The criteria were criticized because they do not take into account any other aspects of the personal and social context in which depression can occur. In addition, some studies have found little empirical support for the DSM-IV cut-off criteria, indicating they are a diagnostic convention imposed on a continuum of depressive symptoms of varying severity and duration. Bereavement is no longer an exclusion criterion in DSM-5, and it is now up to the clinician to distinguish between normal reactions to a loss and MDD. Excluded are a range of related diagnoses, including dysthymia, which involves a chronic but milder mood disturbance; recurrent brief depression, consisting of briefer depressive episodes; minor depressive disorder, whereby only some symptoms of major depression are present; and adjustment disorder with depressed mood, which denotes low mood resulting from a psychological response to an identifiable event or stressor. Three new depressive disorders were added to the DSM-5: disruptive mood dysregulation disorder, classified by significant childhood irritability and tantrums, premenstrual dysphoric disorder (PMDD), causing periods of anxiety, depression, or irritability in the week or two before a woman's menstruation, and persistent depressive disorder.\nSubtypes.\nThe DSM-5 recognizes six further subtypes of MDD, called \"specifiers\", in addition to noting the length, severity and presence of psychotic features:\nDifferential diagnoses.\nTo confirm major depressive disorder as the most likely diagnosis, other potential diagnoses must be considered, including dysthymia, adjustment disorder with depressed mood, or bipolar disorder. Dysthymia is a chronic, milder mood disturbance in which a person reports a low mood almost daily over a span of at least two years. The symptoms are not as severe as those for major depression, although people with dysthymia are vulnerable to secondary episodes of major depression (sometimes referred to as \"double depression\"). Adjustment disorder with depressed mood is a mood disturbance appearing as a psychological response to an identifiable event or stressor, in which the resulting emotional or behavioral symptoms are significant but do not meet the criteria for a major depressive episode. Bipolar disorder, also known as \"manic\u2013depressive disorder\", is a condition in which depressive phases alternate with periods of mania or hypomania. Although depression is currently categorized as a separate disorder, there is ongoing debate because individuals diagnosed with major depression often experience some hypomanic symptoms, indicating a mood disorder continuum. Further differential diagnoses involve chronic fatigue syndrome.\nOther disorders need to be ruled out before diagnosing major depressive disorder. They include depressions due to physical illness, medications, and substance abuse. Depression due to physical illness is diagnosed as a mood disorder due to a general medical condition. This condition is determined based on history, laboratory findings, or physical examination. When the depression is caused by a medication, drug of abuse, or exposure to a toxin, it is then diagnosed as a specific mood disorder (previously called \"substance-induced mood disorder\" in the DSM-IV-TR).\nScreening and prevention.\nSince 2016, the United States Preventive Services Task Force (USPSTF) has recommended screening for depression among those over the age 12; a 2005 Cochrane review found that the routine use of screening questionnaires has little effect on detection or treatment.\nPreventive efforts may result in decreases in rates of the condition of between 22 and 38%. Eating large amounts of fish may also reduce the risk.\nBehavioral interventions, such as interpersonal therapy and cognitive-behavioral therapy, are effective at preventing new onset depression. Because such interventions appear to be most effective when delivered to individuals or small groups, it has been suggested that they may be able to reach their large target audience most efficiently through the Internet.\nHowever, an earlier meta-analysis found preventive programs with a competence-enhancing component to be superior to behavior-oriented programs overall, and found behavioral programs to be particularly unhelpful for older people, for whom social support programs were uniquely beneficial. In addition, the programs that best prevented depression comprised more than eight sessions, each lasting between 60 and 90 minutes, were provided by a combination of lay and professional workers, had a high-quality research design, reported attrition rates, and had a well-defined intervention.\nThe Netherlands mental health care system provides preventive interventions, such as the \"Coping with Depression\" course (CWD) for people with sub-threshold depression. The course is claimed to be the most successful of psychoeducational interventions for the treatment and prevention of depression (both for its adaptability to various populations and its results), with a risk reduction of 38% in major depression and an efficacy as a treatment comparing favorably to other psychotherapies.\nManagement.\nThe three most common treatments for depression are psychotherapy, medication, and electroconvulsive therapy. Psychotherapy is the treatment of choice (over medication) for people under 18. The UK National Institute for Health and Care Excellence (NICE) 2004 guidelines indicate that antidepressants should not be used for the initial treatment of mild depression because the risk-benefit ratio is poor. The guidelines recommend that antidepressants treatment in combination with psychosocial interventions should be considered for:\nThe guidelines further note that antidepressant treatment should be continued for at least six months to reduce the risk of relapse, and that SSRIs are better tolerated than tricyclic antidepressants.\nAmerican Psychiatric Association treatment guidelines recommend that initial treatment should be individually tailored based on factors including severity of symptoms, co-existing disorders, prior treatment experience, and patient preference. Options may include pharmacotherapy, psychotherapy, exercise, electroconvulsive therapy (ECT), transcranial magnetic stimulation (TMS) or light therapy. Antidepressant medication is recommended as an initial treatment choice in people with mild, moderate, or severe major depression, and should be given to all patients with severe depression unless ECT is planned. There is evidence that collaborative care by a team of health care practitioners produces better results than routine single-practitioner care.\nTreatment options are much more limited in developing countries, where access to mental health staff, medication, and psychotherapy is often difficult. Development of mental health services is minimal in many countries; depression is viewed as a phenomenon of the developed world despite evidence to the contrary, and not as an inherently life-threatening condition. A 2014 Cochrane review found insufficient evidence to determine the effectiveness of psychological versus medical therapy in children.\nLifestyle.\nPhysical exercise is recommended for management of mild depression, and has a moderate effect on symptoms. Exercise has also been found to be effective for (unipolar) major depression. It is equivalent to the use of medications or psychological therapies in most people. In older people it does appear to decrease depression. Exercise may be recommended to people who are willing, motivated, and physically healthy enough to participate in an exercise program as treatment.\nThere is a small amount of evidence that skipping a night's sleep may improve depressive symptoms, with the effects usually showing up within a day. This effect is usually temporary. Besides sleepiness, this method can cause a side effect of mania or hypomania.\nIn observational studies, smoking cessation has benefits in depression as large as or larger than those of medications.\nBesides exercise, sleep and diet may play a role in depression, and interventions in these areas may be an effective add-on to conventional methods.\nTalking therapies.\nTalking therapy (psychotherapy) can be delivered to individuals, groups, or families by mental health professionals. A 2017 review found that cognitive behavioral therapy appears to be similar to antidepressant medication in terms of effect. A 2012 review found psychotherapy to be better than no treatment but not other treatments. With more complex and chronic forms of depression, a combination of medication and psychotherapy may be used. There is moderate-quality evidence that psychological therapies are a useful addition to standard antidepressant treatment of treatment-resistant depression in the short term.\nPsychotherapy has been shown to be effective in older people. Successful psychotherapy appears to reduce the recurrence of depression even after it has been stopped or replaced by occasional booster sessions.\nCognitive behavioral therapy.\nCognitive behavioral therapy (CBT) currently has the most research evidence for the treatment of depression in children and adolescents, and CBT and interpersonal psychotherapy (IPT) are preferred therapies for adolescent depression. In people under 18, according to the National Institute for Health and Clinical Excellence, medication should be offered only in conjunction with a psychological therapy, such as CBT, interpersonal therapy, or family therapy. Cognitive behavioral therapy has also been shown to reduce the number of sick days taken by people with depression, when used in conjunction with primary care.\nThe most-studied form of psychotherapy for depression is CBT, which teaches clients to challenge self-defeating, but enduring ways of thinking (cognitions) and change counter-productive behaviors. Research beginning in the mid-1990s suggested that CBT could perform as well as or better than antidepressants in patients with moderate to severe depression. CBT may be effective in depressed adolescents, although its effects on severe episodes are not definitively known. Several variables predict success for cognitive behavioral therapy in adolescents: higher levels of rational thoughts, less hopelessness, fewer negative thoughts, and fewer cognitive distortions. CBT is particularly beneficial in preventing relapse.\nCognitive behavioral therapy and occupational programs (including modification of work activities and assistance) have been shown to be effective in reducing sick days taken by workers with depression.\nVariants.\nSeveral variants of cognitive behavior therapy have been used in those with depression, the most notable being rational emotive behavior therapy, and mindfulness-based cognitive therapy. Mindfulness-based stress reduction programs may reduce depression symptoms. Mindfulness programs also appear to be a promising intervention in youth.\nPsychoanalysis.\nPsychoanalysis is a school of thought, founded by Sigmund Freud, which emphasizes the resolution of unconscious mental conflicts. Psychoanalytic techniques are used by some practitioners to treat clients presenting with major depression. A more widely practiced therapy, called psychodynamic psychotherapy, is in the tradition of psychoanalysis but less intensive, meeting once or twice a week. It also tends to focus more on the person's immediate problems, and has an additional social and interpersonal focus. In a meta-analysis of three controlled trials of Short Psychodynamic Supportive Psychotherapy, this modification was found to be as effective as medication for mild to moderate depression.\nAntidepressants.\nConflicting results have arisen from studies that look at the effectiveness of antidepressants in people with acute, mild to moderate depression. Stronger evidence supports the usefulness of antidepressants in the treatment of depression that is chronic (dysthymia) or severe.\nWhile small benefits were found, researchers Irving Kirsch and Thomas Moore state they may be due to issues with the trials rather than a true effect of the medication. In a later publication, Kirsch concluded that the overall effect of new-generation antidepressant medication is below recommended criteria for clinical significance. Similar results were obtained in a meta-analysis by Fornier.\nA review commissioned by the National Institute for Health and Care Excellence (UK) concluded that there is strong evidence that selective serotonin reuptake inhibitors (SSRIs), such as escitalopram, paroxetine, and sertraline, have greater efficacy than placebo on achieving a 50% reduction in depression scores in moderate and severe major depression, and that there is some evidence for a similar effect in mild depression. Similarly, a Cochrane systematic review of clinical trials of the generic tricyclic antidepressant amitriptyline concluded that there is strong evidence that its efficacy is superior to placebo.\nA 2019 Cochrane review on the combined use of antidepressants plus benzodiazepines demonstrated improved effectiveness when compared to antidepressants alone; however, these effects were not maintained in the acute or continuous phase. The benefits of adding a benzodiazepine should be balanced against possible harms and other alternative treatment strategies when antidepressant mono-therapy is considered inadequate.\nIn 2014 the U.S. Food and Drug Administration published a systematic review of all antidepressant maintenance trials submitted to the agency between 1985 and 2012. The authors concluded that maintenance treatment reduced the risk of relapse by 52% compared to placebo, and that this effect was primarily due to recurrent depression in the placebo group rather than a drug withdrawal effect.\nTo find the most effective antidepressant medication with minimal side-effects, the dosages can be adjusted, and if necessary, combinations of different classes of antidepressants can be tried. Response rates to the first antidepressant administered range from 50 to 75%, and it can take at least six to eight weeks from the start of medication to improvement. Antidepressant medication treatment is usually continued for 16 to 20 weeks after remission, to minimize the chance of recurrence, and even up to one year of continuation is recommended. People with chronic depression may need to take medication indefinitely to avoid relapse.\nSSRIs are the primary medications prescribed, owing to their relatively mild side-effects, and because they are less toxic in overdose than other antidepressants. People who do not respond to one SSRI can be switched to another antidepressant, and this results in improvement in almost 50% of cases. Another option is to switch to the atypical antidepressant bupropion. Venlafaxine, an antidepressant with a different mechanism of action, may be modestly more effective than SSRIs. However, venlafaxine is not recommended in the UK as a first-line treatment because of evidence suggesting its risks may outweigh benefits, and it is specifically discouraged in children and adolescents.\nFor children, some research has supported the use of the SSRI antidepressant fluoxetine. The benefit however appears to be slight in children, while other antidepressants have not been shown to be effective. Medications are not recommended in children with mild disease. There is also insufficient evidence to determine effectiveness in those with depression complicated by dementia. Any antidepressant can cause low blood sodium levels; nevertheless, it has been reported more often with SSRIs. It is not uncommon for SSRIs to cause or worsen insomnia; the sedating atypical antidepressant mirtazapine can be used in such cases.\nIrreversible monoamine oxidase inhibitors, an older class of antidepressants, have been plagued by potentially life-threatening dietary and drug interactions. They are still used only rarely, although newer and better-tolerated agents of this class have been developed. The safety profile is different with reversible monoamine oxidase inhibitors, such as moclobemide, where the risk of serious dietary interactions is negligible and dietary restrictions are less strict.\nIt is unclear whether antidepressants affect a person's risk of suicide. For children, adolescents, and probably young adults between 18 and 24 years old, there is a higher risk of both suicidal ideations and suicidal behavior in those treated with SSRIs. For adults, it is unclear whether SSRIs affect the risk of suicidality. One review found no connection; another an increased risk; and a third no risk in those 25\u201365 years old and a decreased risk in those more than 65. A black box warning was introduced in the United States in 2007 on SSRIs and other antidepressant medications due to the increased risk of suicide in patients younger than 24 years old. Similar precautionary notice revisions were implemented by the Japanese Ministry of Health.\nOther medications.\nThere is some evidence that omega-3 fatty acids fish oil supplements containing high levels of eicosapentaenoic acid (EPA) to docosahexaenoic acid (DHA) are effective in the treatment of, but not the prevention of major depression. However, a Cochrane review determined there was insufficient high quality evidence to suggest omega-3 fatty acids were effective in depression. There is limited evidence that vitamin D supplementation is of value in alleviating the symptoms of depression in individuals who are vitamin D-deficient. There is some preliminary evidence that COX-2 inhibitors, such as celecoxib, have a beneficial effect on major depression. Lithium appears effective at lowering the risk of suicide in those with bipolar disorder and unipolar depression to nearly the same levels as the general population. There is a narrow range of effective and safe dosages of lithium thus close monitoring may be needed. Low-dose thyroid hormone may be added to existing antidepressants to treat persistent depression symptoms in people who have tried multiple courses of medication. Limited evidence suggests stimulants, such as amphetamine and modafinil, may be effective in the short term, or as adjuvant therapy. Also, it is suggested that folate supplements may have a role in depression management. There is tentative evidence for benefit from testosterone in males.\nElectroconvulsive therapy.\nElectroconvulsive therapy (ECT) is a standard psychiatric treatment in which seizures are electrically induced in patients to provide relief from psychiatric illnesses. ECT is used with informed consent as a last line of intervention for major depressive disorder.\nA round of ECT is effective for about 50% of people with treatment-resistant major depressive disorder, whether it is unipolar or bipolar. Follow-up treatment is still poorly studied, but about half of people who respond relapse within twelve months.\nAside from effects in the brain, the general physical risks of ECT are similar to those of brief general anesthesia. Immediately following treatment, the most common adverse effects are confusion and memory loss. ECT is considered one of the least harmful treatment options available for severely depressed pregnant women.\nA usual course of ECT involves multiple administrations, typically given two or three times per week, until the patient is no longer suffering symptoms. ECT is administered under anesthesia with a muscle relaxant. Electroconvulsive therapy can differ in its application in three ways: electrode placement, frequency of treatments, and the electrical waveform of the stimulus. These three forms of application have significant differences in both adverse side effects and symptom remission. After treatment, drug therapy is usually continued, and some patients receive maintenance ECT.\nECT appears to work in the short term via an anticonvulsant effect mostly in the frontal lobes, and longer term via neurotrophic effects primarily in the medial temporal lobe.\nTranscranial magnetic stimulation.\nTranscranial magnetic stimulation (TMS) or deep transcranial magnetic stimulation is a noninvasive method used to stimulate small regions of the brain. TMS was approved by the FDA for treatment-resistant major depressive disorder (trMDD) in 2008 and as of 2014 evidence supports that it is probably effective. The American Psychiatric Association the Canadian Network for Mood and Anxiety Disorders, and the Royal Australia and New Zealand College of Psychiatrists have endorsed TMS for trMDD.\nTranscranial direct current stimulation.\nTranscranial direct current stimulation (tDCS) is another noninvasive method used to stimulate small regions of the brain with the help of a weak electric current. Increasing evidence has been gathered for its efficiency as a depression treatment. A meta-analysis was published in 2020 summarising results across nine studies (572 participants) concluded that active tDCS was significantly superior to sham for response (30.9% vs. 18.9%, respectively), remission (19.9% vs. 11.7%) and depression improvement. According to a 2016 meta analysis,\u00a034% of tDCS-treated patients showed at least 50% symptom reduction compared to 19% sham-treated across 6 randomised controlled trials.\nLight therapy.\nBright light therapy reduces depression symptom severity, with benefit for both seasonal affective disorder and for nonseasonal depression, and an effect similar to those for conventional antidepressants. For nonseasonal depression, adding light therapy to the standard antidepressant treatment was not effective. For nonseasonal depression, where light was used mostly in combination with antidepressants or wake therapy, a moderate effect was found, with response better than control treatment in high-quality studies, in studies that applied morning light treatment, and with people who respond to total or partial sleep deprivation. Both analyses noted poor quality, short duration, and small size of most of the reviewed studies.\nOther.\nThere is insufficient evidence for Reiki and dance movement therapy in depression. As of 2019 cannabis is specifically not recommended as a treatment.\nPrognosis.\nMajor depressive episodes often resolve over time whether or not they are treated. Outpatients on a waiting list show a 10\u201315% reduction in symptoms within a few months, with approximately 20% no longer meeting the full criteria for a depressive disorder. The median duration of an episode has been estimated to be 23 weeks, with the highest rate of recovery in the first three months.\nStudies have shown that 80% of those suffering from their first major depressive episode will have at least one more depression during their life, with a lifetime average of 4 episodes. Other general population studies indicate that around half those who have an episode recover (whether treated or not) and remain well, while the other half will have at least one more, and around 15% of those experience chronic recurrence. Studies recruiting from selective inpatient sources suggest lower recovery and higher chronicity, while studies of mostly outpatients show that nearly all recover, with a median episode duration of 11 months. Around 90% of those with severe or psychotic depression, most of whom also meet criteria for other mental disorders, experience recurrence.\nA high proportion of people who experience full symptomatic remission still have at least one not fully resolved symptom after treatment. Recurrence or chronicity is more likely if symptoms have not fully resolved with treatment. Current guidelines recommend continuing antidepressants for four to six\u00a0months after remission to prevent relapse. Evidence from many randomized controlled trials indicate continuing antidepressant medications after recovery can reduce the chance of relapse by 70% (41% on placebo vs. 18% on antidepressant). The preventive effect probably lasts for at least the first 36\u00a0months of use.\nPeople experiencing repeated episodes of depression require ongoing treatment in order to prevent more severe, long-term depression. In some cases, people must take medications for the rest of their lives.\nCases when outcome is poor are associated with inappropriate treatment, severe initial symptoms including psychosis, early age of onset, previous episodes, incomplete recovery after one year of treatment, pre-existing severe mental or medical disorder, and family dysfunction.\nDepressed individuals have a shorter life expectancy than those without depression, in part because depressed patients are at risk of dying of suicide. They also have a higher rate of dying from other causes, being more susceptible to medical conditions such as heart disease. Up to 60% of people who die of suicide have a mood disorder such as major depression, and the risk is especially high if a person has a marked sense of hopelessness or has both depression and borderline personality disorder. About 2\u20138% of adults with major depression die by suicide, and about 50% of people who die by suicide had depression or another mood disorder. The lifetime risk of suicide associated with a diagnosis of major depression in the US is estimated at 3.4%, which averages two highly disparate figures of almost 7% for men and 1% for women (although suicide attempts are more frequent in women). The estimate is substantially lower than a previously accepted figure of 15%, which had been derived from older studies of hospitalized patients.\nMajor depression is currently the leading cause of disease burden in North America and other high-income countries, and the fourth-leading cause worldwide. In the year 2030, it is predicted to be the second-leading cause of disease burden worldwide after HIV, according to the WHO. Delay or failure in seeking treatment after relapse and the failure of health professionals to provide treatment are two barriers to reducing disability.\nDepression may affect people's ability to work. The combination of usual clinical care and support with return to work (like working less hours or changing tasks) probably reduces sick leave by 15%, and leads to fewer depressive symptoms and improved work capacity, reducing sick leave by an annual average of 25 days per year. Helping depressed people return to work without a connection to clinical care has not been shown to have an effect on sick leave days. Additional psychological interventions (such as online cognitive behavioral therapy) leads to fewer sick days compared to standard management only. Streamlining care or adding specific providers for depression care may help to reduce sick leave.\nEpidemiology.\nMajor depressive disorder affected approximately 163\u00a0million people in 2017 (2% of the global population). The percentage of people who are affected at one point in their life varies from 7% in Japan to 21% in France. In most countries the number of people who have depression during their lives falls within an 8\u201318% range. In North America, the probability of having a major depressive episode within a year-long period is 3\u20135% for males and 8\u201310% for females. Major depression is about twice as common in women as in men, although it is unclear why this is so, and whether factors unaccounted for are contributing to this. The relative increase in occurrence is related to pubertal development rather than chronological age, reaches adult ratios between the ages of 15 and 18, and appears associated with psychosocial more than hormonal factors. As of 2017, depression is the third most common worldwide cause of disability among both sexes, following low back pain and headache.\nPeople are most likely to develop their first depressive episode between the ages of 30 and 40, and there is a second, smaller peak of incidence between ages 50 and 60. The risk of major depression is increased with neurological conditions such as stroke, Parkinson's disease, or multiple sclerosis, and during the first year after childbirth. It is also more common after cardiovascular illnesses, and is related more to those with a poor cardiac disease outcome than to a better one. Studies conflict on the prevalence of depression in the elderly, but most data suggest there is a reduction in this age group. Depressive disorders are more common in urban populations than in rural ones and the prevalence is increased in groups with poorer socioeconomic factors, e.g., homelessness.\nHistory.\nThe Ancient Greek physician Hippocrates described a syndrome of melancholia as a distinct disease with particular mental and physical symptoms; he characterized all \"fears and despondencies, if they last a long time\" as being symptomatic of the ailment. It was a similar but far broader concept than today's depression; prominence was given to a clustering of the symptoms of sadness, dejection, and despondency, and often fear, anger, delusions and obsessions were included.\nThe term \"depression\" itself was derived from the Latin verb \"deprimere\", \"to press down\". From the 14th century, \"to depress\" meant to subjugate or to bring down in spirits. It was used in 1665 in English author Richard Baker's \"Chronicle\" to refer to someone having \"a great depression of spirit\", and by English author Samuel Johnson in a similar sense in 1753. The term also came into use in physiology and economics. An early usage referring to a psychiatric symptom was by French psychiatrist Louis Delasiauve in 1856, and by the 1860s it was appearing in medical dictionaries to refer to a physiological and metaphorical lowering of emotional function. Since Aristotle, melancholia had been associated with men of learning and intellectual brilliance, a hazard of contemplation and creativity. The newer concept abandoned these associations and through the 19th century, became more associated with women.\nAlthough \"melancholia\" remained the dominant diagnostic term, \"depression\" gained increasing currency in medical treatises and was a synonym by the end of the century; German psychiatrist Emil Kraepelin may have been the first to use it as the overarching term, referring to different kinds of melancholia as \"depressive states\".\nSigmund Freud likened the state of melancholia to mourning in his 1917 paper \"Mourning and Melancholia\". He theorized that objective loss, such as the loss of a valued relationship through death or a romantic break-up, results in subjective loss as well; the depressed individual has identified with the object of affection through an unconscious, narcissistic process called the \"libidinal cathexis\" of the ego. Such loss results in severe melancholic symptoms more profound than mourning; not only is the outside world viewed negatively but the ego itself is compromised. The patient's decline of self-perception is revealed in his belief of his own blame, inferiority, and unworthiness. He also emphasized early life experiences as a predisposing factor. Adolf Meyer put forward a mixed social and biological framework emphasizing \"reactions\" in the context of an individual's life, and argued that the term \"depression\" should be used instead of \"melancholia\". The first version of the DSM (DSM-I, 1952) contained \"depressive reaction\" and the DSM-II (1968) \"depressive neurosis\", defined as an excessive reaction to internal conflict or an identifiable event, and also included a depressive type of manic-depressive psychosis within Major affective disorders.\nIn the mid-20th century, researchers theorized that depression was caused by a chemical imbalance in neurotransmitters in the brain, a theory based on observations made in the 1950s of the effects of reserpine and isoniazid in altering monoamine neurotransmitter levels and affecting depressive symptoms. The chemical imbalance theory has never been proven.\nThe term \"unipolar\" (along with the related term \"bipolar\") was coined by the neurologist and psychiatrist Karl Kleist, and subsequently used by his disciples Edda Neele and Karl Leonhard.\nThe term \"Major depressive disorder\" was introduced by a group of US clinicians in the mid-1970s as part of proposals for diagnostic criteria based on patterns of symptoms (called the \"Research Diagnostic Criteria\", building on earlier Feighner Criteria), and was incorporated into the DSM-III in 1980. The American Psychiatric Association added \"major depressive disorder\" to the \"Diagnostic and Statistical Manual of Mental Disorders\" (DSM-III), as a split of the previous depressive neurosis in the DSM-II, which also encompassed the conditions now known as dysthymia and adjustment disorder with depressed mood. To maintain consistency the ICD-10 used the same criteria, with only minor alterations, but using the DSM diagnostic threshold to mark a \"mild depressive episode\", adding higher threshold categories for moderate and severe episodes. The ancient idea of \"melancholia\" still survives in the notion of a melancholic subtype.\nThe new definitions of depression were widely accepted, albeit with some conflicting findings and views. There have been some continued empirically based arguments for a return to the diagnosis of melancholia. There has been some criticism of the expansion of coverage of the diagnosis, related to the development and promotion of antidepressants and the biological model since the late 1950s.\nSociety and culture.\nTerminology.\nThe term \"depression\" is used in a number of different ways. It is often used to mean this syndrome but may refer to other mood disorders or simply to a low mood. People's conceptualizations of depression vary widely, both within and among cultures. \"Because of the lack of scientific certainty,\" one commentator has observed, \"the debate over depression turns on questions of language. What we call it\u2014'disease,' 'disorder,' 'state of mind'\u2014affects how we view, diagnose, and treat it.\" There are cultural differences in the extent to which serious depression is considered an illness requiring personal professional treatment, or is an indicator of something else, such as the need to address social or moral problems, the result of biological imbalances, or a reflection of individual differences in the understanding of distress that may reinforce feelings of powerlessness, and emotional struggle.\nThe diagnosis is less common in some countries, such as China. It has been argued that the Chinese traditionally deny or somatize emotional depression (although since the early 1980s, the Chinese denial of depression may have modified). Alternatively, it may be that Western cultures reframe and elevate some expressions of human distress to disorder status. Australian professor Gordon Parker and others have argued that the Western concept of depression \"medicalizes\" sadness or misery. Similarly, Hungarian-American psychiatrist Thomas Szasz and others argue that depression is a metaphorical illness that is inappropriately regarded as an actual disease. There has also been concern that the DSM, as well as the field of descriptive psychiatry that employs it, tends to reify abstract phenomena such as depression, which may in fact be social constructs. American archetypal psychologist James Hillman writes that depression can be healthy for the soul, insofar as \"it brings refuge, limitation, focus, gravity, weight, and humble powerlessness.\" Hillman argues that therapeutic attempts to eliminate depression echo the Christian theme of resurrection, but have the unfortunate effect of demonizing a soulful state of being.\nStigma.\nHistorical figures were often reluctant to discuss or seek treatment for depression due to social stigma about the condition, or due to ignorance of diagnosis or treatments. Nevertheless, analysis or interpretation of letters, journals, artwork, writings, or statements of family and friends of some historical personalities has led to the presumption that they may have had some form of depression. People who may have had depression include English author Mary Shelley, American-British writer Henry James, and American president Abraham Lincoln. Some well-known contemporary people with possible depression include Canadian songwriter Leonard Cohen and American playwright and novelist Tennessee Williams. Some pioneering psychologists, such as Americans William James and John B. Watson, dealt with their own depression.\nThere has been a continuing discussion of whether neurological disorders and mood disorders may be linked to creativity, a discussion that goes back to Aristotelian times. British literature gives many examples of reflections on depression. English philosopher John Stuart Mill experienced a several-months-long period of what he called \"a dull state of nerves\", when one is \"unsusceptible to enjoyment or pleasurable excitement; one of those moods when what is pleasure at other times, becomes insipid or indifferent\". He quoted English poet Samuel Taylor Coleridge's \"Dejection\" as a perfect description of his case: \"A grief without a pang, void, dark and drear, / A drowsy, stifled, unimpassioned grief, / Which finds no natural outlet or relief / In word, or sigh, or tear.\" English writer Samuel Johnson used the term \"the black dog\" in the 1780s to describe his own depression, and it was subsequently popularized by depression sufferer former British Prime Minister Sir Winston Churchill.\nSocial stigma of major depression is widespread, and contact with mental health services reduces this only slightly. Public opinions on treatment differ markedly to those of health professionals; alternative treatments are held to be more helpful than pharmacological ones, which are viewed poorly. In the UK, the Royal College of Psychiatrists and the Royal College of General Practitioners conducted a joint Five-year Defeat Depression campaign to educate and reduce stigma from 1992 to 1996; a MORI study conducted afterwards showed a small positive change in public attitudes to depression and treatment.\nElderly.\nDepression is especially common among those over 65 years of age and increases in frequency beyond this age. In addition, the risk of depression increases in relation to the frailty of the individual. Depression is one of the most important factors which negatively impact quality of life in adults, as well as the elderly. Both symptoms and treatment among the elderly differ from those of the rest of the population.\nAs with many other diseases, it is common among the elderly not to present with classical depressive symptoms. Diagnosis and treatment is further complicated in that the elderly are often simultaneously treated with a number of other drugs, and often have other concurrent diseases. Treatment differs in that studies of SSRIs have shown lesser and often inadequate effects among the elderly, while other drugs, such as duloxetine (a serotonin-norepinephrine reuptake inhibitor), with more clear effects have adverse effects, such as dizziness, dryness of the mouth, diarrhea and constipation, which can be especially difficult to handle among the elderly.\nProblem solving therapy was, as of 2015, the only psychological therapy with proven effect, and can be likened to a simpler form of cognitive behavioral therapy. However, elderly with depression are seldom offered any psychological treatment, and the evidence proving other treatments effective is incomplete. ECT has been used in the elderly, and register-studies suggest it is effective, although less so as compared to the rest of the population. The risks involved with treatment of depression among the elderly as opposed to benefits are not entirely clear.\nResearch.\nMRI scans of patients with depression have revealed a number of differences in brain structure compared to those who are not depressed. Meta-analyses of neuroimaging studies in major depression reported that, compared to controls, depressed patients had increased volume of the lateral ventricles and adrenal gland and smaller volumes of the basal ganglia, thalamus, hippocampus, and frontal lobe (including the orbitofrontal cortex and gyrus rectus). Hyperintensities have been associated with patients with a late age of onset, and have led to the development of the theory of vascular depression.\nTrials are looking at the effects of botulinum toxins on depression. The idea is that the drug is used to make the person look less frowning and that this stops the negative facial feedback from the face. In 2015 results showed, however, that the partly positive effects that had been observed until then could have been due to placebo effects.\nIn 2018\u20132019, the US Food and Drug Administration (FDA) granted Breakthrough therapy designation to Compass Pathways and, separately, Usona Institute. Compass is a for-profit company studying psilocybin for treatment-resistant depression; Usona is a non-profit organization studying psilocybin for major depressive disorder more broadly.\nAnimal models.\nModels of depression in animals for the purpose of study include iatrogenic depression models (such as drug-induced), forced swim tests, tail suspension test, and learned helplessness models. Criteria frequently used to assess depression in animals include expression of despair, neurovegetative changes, and anhedonia, as many other criteria for depression are untestable in animals, such as guilt and suicidality."}
{"id": "8390", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=8390", "title": "Don Delillo", "text": ""}
{"id": "8391", "revid": "41375404", "url": "https://en.wikipedia.org/wiki?curid=8391", "title": "Diana (mythology)", "text": "Diana is a goddess in Roman and Hellenistic religion, primarily considered a patroness of the countryside, hunters, crossroads, and the Moon. She is equated with the Greek goddess Artemis, and absorbed much of Artemis' mythology early in Roman history, including a birth on the island of Delos to parents Jupiter and Latona, and a twin brother, Apollo, though she had an independent origin in Italy.\nDiana is considered a virgin goddess and protector of childbirth. Historically, Diana made up a triad with two other Roman deities: Egeria the water nymph, her servant and assistant midwife; and Virbius, the woodland god.\nDiana is revered in modern neopagan religions including Roman neopaganism, Stregheria, and Wicca. From the medieval to the modern period, as folklore attached to her developed and was eventually adapted into neopagan religions, the mythology surrounding Diana grew to include a consort (Lucifer) and daughter (Aradia), figures sometimes recognized by modern traditions. In the ancient, medieval, and modern periods, Diana has been considered a triple deity, merged with a goddess of the moon (Luna/Selene) and the underworld (usually Hecate).\nEtymology.\nThe name \"D\u012b\u0101na\" probably derives from Latin \"d\u012bus\" ('godly'), ultimately from Proto-Italic *\"divios\" (\"diwios\"), meaning 'divine, heavenly'. It stems from Proto-Indo-European \"*diwy\u00f3s\" ('divine, heavenly'), formed with the root \"*dyew-\" ('daylight sky') attached the thematic suffix -\"y\u00f3s\". Cognates appear in Myceanean Greek \"di-wi-ja\", in Ancient Greek \"d\u00eeos\" (\u03b4\u1fd6\u03bf\u03c2; 'belonging to heaven, godlike'), or in Sanskrit \"divy\u00e1\" ('heavenly'). \nThe ancient Latin writers Varro and Cicero considered the etymology of D\u012b\u0101na as allied to that of \"dies\" and connected to the shine of the Moon, noting that one of her titles is Diana Lucifera (\"light-bearer\").\n... people regard Diana and the moon as one and the same. ... the moon \"(luna)\" is so called from the verb to shine \"(lucere)\". Lucina is identified with it, which is why in our country they invoke Juno Lucina in childbirth, just as the Greeks call on Diana the Light-bearer. Diana also has the name \"Omnivaga\" (\"wandering everywhere\"), not because of her hunting but because she is numbered as one of the seven planets; her name Diana derives from the fact that she turns darkness into daylight \"(dies)\". She is invoked at childbirth because children are born occasionally after seven, or usually after nine, lunar revolutions ...\nDescription.\nAs a goddess of the countryside.\nThe persona of Diana is complex, and contains a number of archaic features. Diana was originally considered to be a goddess of the wilderness and of the hunt, a central sport in both Roman and Greek culture. Early Roman inscriptions to Diana celebrated her primarily as a huntress and patron of hunters. Later, in the Hellenistic period, Diana came to be equally or more revered as a goddess not of the wild woodland but of the \"tame\" countryside, or \"villa rustica\", the idealization of which was common in Greek thought and poetry. This dual role as goddess of both civilization and the wild, and therefore the civilized countryside, first applied to the Greek goddess Artemis (for example, in the 3rd century BCE poetry of Anacreon). By the 3rd century CE, after Greek influence had a profound impact on Roman religion, Diana had been almost fully combined with Artemis and took on many of her attributes, both in her spiritual domains and in the description of her appearance. The Roman poet Nemesianus wrote a typical description of Diana: She carried a bow and a quiver full of golden arrows, wore a golden cloak, purple half-boots, and a belt with a jeweled buckle to hold her tunic together, and wore her hair gathered in a ribbon. By the 5th century CE, almost a millennia after her cult's entry into Rome, the philosopher Proclus could still characterize Diana as \"the inspective guardian of every thing rural, [who] represses every thing rustic and uncultivated.\"\nAs a triple goddess.\nDiana was often considered an aspect of a triple goddess, known as \"Diana triformis\": Diana, Luna, and Hecate. According to historian C.M. Green, \"these were neither different goddesses nor an amalgamation of different goddesses. They were Diana...Diana as huntress, Diana as the moon, Diana of the underworld.\" At her sacred grove on the shores of Lake Nemi, Diana was venerated as a triple goddess beginning in the late 6th century BCE.\nAndreas Alf\u00f6ldi interpreted an image on a late Republican coin as the Latin Diana \"conceived as a threefold unity of the divine huntress, the Moon goddess and the goddess of the nether world, Hekate\". This coin, minted by P. Accoleius Lariscolus in 43 BCE, has been acknowledged as representing an archaic statue of Diana Nemorensis. It represents Artemis with the bow at one extremity, Luna-Selene with flowers at the other and a central deity not immediately identifiable, all united by a horizontal bar. The iconographical analysis allows the dating of this image to the 6th century at which time there are Etruscan models. The coin shows that the triple goddess cult image still stood in the \"lucus\" of Nemi in 43 BCE. Lake Nemi was called \"Triviae lacus\" by Virgil (\"Aeneid\" 7.516), while Horace called Diana \"montium custos nemoremque virgo\" (\"keeper of the mountains and virgin of Nemi\") and \"diva triformis\" (\"three-form goddess\").\nTwo heads found in the sanctuary and the Roman theatre at Nemi, which have a hollow on their back, lend support to this interpretation of an archaic triple Diana.\nAs goddess of crossroads and the underworld.\nThe earliest epithet of Diana was \"Trivia\", and she was addressed with that title by Virgil, Catullus, and many others. \"Trivia\" comes from the Latin \"trivium\", \"triple way\", and refers to Diana's guardianship over roadways, particularly Y-junctions or three-way crossroads. This role carried a somewhat dark and dangerous connotation, as it metaphorically pointed the way to the underworld. In the 1st-century CE play \"Medea\", Seneca's titular sorceress calls on Trivia to cast a magic spell. She evokes the triple goddess of Diana, Selene, and Hecate, and specifies that she requires the powers of the latter. The 1st century poet Horace similarly wrote of a magic incantation invoking the power of both Diana and Proserpina. The symbol of the crossroads is relevant to several aspects of Diana's domain. It can symbolize the paths hunters may encounter in the forest, lit only by the full moon; this symbolizes making choices \"in the dark\" without the light of guidance.\nDiana's role as a goddess of the underworld, or at least of ushering people between life and death, caused her early on to be conflated with Hecate (and occasionally also with Proserpina). However, her role as an underworld goddess appears to pre-date strong Greek influence (though the early Greek colony of Cumae had a cult of Hekate and certainly had contacts with the Latins). A theater in her sanctuary at Lake Nemi included a pit and tunnel that would have allowed actors to easily descend on one side of the stage and ascend on the other, indicating a connection between the phases of the moon and a descent by the moon goddess into the underworld. It is likely that her underworld aspect in her original Latin worship did not have a distinct name, like Luna was for her moon aspect. This is due to a seeming reluctance or taboo by the early Latins to name underworld deities, and the fact that they believed the underworld to be silent, precluding naming. Hekate, a Greek goddess also associated with the boundary between the earth and the underworld, became attached to Diana as a name for her underworld aspect following Greek influence.\nAs goddess of childbirth.\nDiana was often considered to be a goddess associated with fertility and childbirth, and the protection of women during labor. This probably arose as an extension of her association with the moon, whose cycles were believed to parallel the menstrual cycle, and which was used to track the months during pregnancy. At her shrine in Aricia, worshipers left votive terracotta offerings for the goddess in the shapes of babies and wombs, and the temple there also offered care of pups and pregnant dogs. This care of infants also extended to the training of both young people and dogs, especially for hunting. In her role as a protector of childbirth, Diana was called \"Diana Lucina\" or even \"Juno Lucina\", because her domain overlapped with that of the goddess Juno. The title of Juno may also have had an independent origin as it applied to Diana, with the literal meaning of \"helper\" - Diana as \"Juno Lucina\" would be the \"helper of childbirth\".\nAs a \"frame god\".\nAccording to a theory proposed by Georges Dum\u00e9zil, Diana falls into a particular subset of celestial gods, referred to in histories of religion as \"frame gods\". Such gods, while keeping the original features of celestial divinities (i.e. transcendent heavenly power and abstention from direct rule in worldly matters), did not share the fate of other celestial gods in Indoeuropean religions - that of becoming \"dei otiosi\", or gods without practical purpose, since they did retain a particular sort of influence over the world and mankind. The celestial character of Diana is reflected in her connection with inaccessibility, virginity, light, and her preference for dwelling on high mountains and in sacred woods. Diana, therefore, reflects the heavenly world in its sovereignty, supremacy, impassibility, and indifference towards such secular matters as the fates of mortals and states. At the same time, however, she is seen as active in ensuring the succession of kings and in the preservation of humankind through the protection of childbirth. These functions are apparent in the traditional institutions and cults related to the goddess:\nAccording to Dumezil, the forerunner of all \"frame gods\" is an Indian epic hero who was the image (avatar) of the Vedic god Dyaus. Having renounced the world, in his roles of father and king, he attained the status of an immortal being while retaining the duty of ensuring that his dynasty is preserved and that there is always a new king for each generation. The Scandinavian god Heimdallr performs an analogous function: he is born first and will die last. He too gives origin to kingship and the first king, bestowing on him regal prerogatives.\nDiana, although a female deity, has exactly the same functions, preserving mankind through childbirth and royal succession.\nF. H. Pairault, in her essay on Diana, qualified Dum\u00e9zil's theory as \"impossible to verify\".\nMythology.\nUnlike the Greek gods, Roman gods were originally considered to be numina: divine powers of presence and will that did not necessarily have physical form. At the time Rome was founded, Diana and the other major Roman gods probably did not have much mythology per se, or any depictions in human form. The idea of gods as having anthropomorphic qualities and human-like personalities and actions developed later, under the influence of Greek and Etruscan religion.\nBy the 3rd century BCE, Diana is found listed among the twelve major gods of the Roman pantheon by the poet Ennius. Though the Capitoline Triad were the primary state gods of Rome, early Roman myth did not assign a strict hierarchy to the gods the way Greek mythology did, though the Greek hierarchy would eventually be adopted by Roman religion as well.\nOnce Greek influence had caused Diana to be considered identical to the Greek goddess Artemis, Diana acquired Artemis's physical description, attributes, and variants of her myths as well. Like Artemis, Diana is usually depicted in art wearing a women\u2019s chiton, shortened in the kolpos style to facilitate mobility during hunting, with a hunting bow and quiver, and often accompanied by hunting dogs. A 1st-century BCE Roman coin (see above) depicted her with a unique, short hairstyle, and in triple form, with one form holding a bow and another holding a poppy.\nFamily.\nWhen worship of Apollo was first introduced to Rome, Diana became conflated with Apollo's sister Artemis as in the earlier Greek myths, and as such she became identified as the daughter of Apollo's parents Latona and Jupiter. Though Diana was usually considered to be a virgin goddess like Artemis, later authors sometimes attributed consorts and children to her. According to Cicero and Ennius, Trivia (an epithet of Diana) and Caelus were the parents of Janus, as well as of Saturn and Ops.\nAccording to Macrobius (who cited Nigidius Figulus and Cicero), Janus and Jana (Diana) are a pair of divinities, worshiped as the sun and moon. Janus was said to receive sacrifices before all the others because, through him, the way of access to the desired deity is made apparent.\nMyth of Actaeon.\nDiana's mythology incorporated stories which were variants of earlier stories about Artemis. Possibly the most well-known of these is the myth of Actaeon. In Ovid's version of this myth, part of his poem \"Metamorphoses\", he tells of a pool or grotto hidden in the wooded valley of Gargaphie. There, Diana, the goddess of the woods, would bathe and rest after a hunt. Actaeon, a young hunter, stumbled across the grotto and accidentally witnessed the goddess bathing without invitation. In retaliation, Diana splashed him with water from the pool, cursing him, and he transformed into a deer. His own hunting dogs caught his scent, and tore him apart.\nOvid's version of the myth of Actaeon differs from most earlier sources. Unlike earlier myths about Artemis, Actaeon is killed for an innocent mistake, glimpsing Diana bathing. An earlier variant of this myth, known as the Bath of Pallas, had the hunter intentionally spy on the bathing goddess Pallas (Athena), and earlier versions of the myth involving Artemis did not involve the bath at all.\nWorship in the classical period.\nDiana was an ancient goddess common to all Latin tribes. Therefore, many sanctuaries were dedicated to her in the lands inhabited by Latins. Her primary sanctuary was a woodland grove overlooking Lake Nemi, a body of water also known as \"Diana's Mirror\", where she was worshiped as Diana Nemorensis, or \"Diana of the Wood\". In Rome, the cult of Diana may have been almost as old as the city itself. Varro mentions her in the list of deities to whom king Titus Tatius promised to build a shrine. His list included Luna and Diana Lucina as separate entities. Another testimony to the antiquity of her cult is to be found in the \"lex regia\" of King Tullus Hostilius that condemns those guilty of incest to the \"sacratio\" to Diana. She had a temple in Rome on the Aventine Hill, according to tradition dedicated by king Servius Tullius. Its location is remarkable as the Aventine is situated outside the pomerium, i.e. original territory of the city, in order to comply with the tradition that Diana was a goddess common to all Latins and not exclusively of the Romans. Being placed on the Aventine, and thus outside the \"pomerium\", meant that Diana's cult essentially remained a \"foreign\" one, like that of Bacchus; she was never officially \"transferred\" to Rome as Juno was after the sack of Veii.\nOther known sanctuaries and temples to Diana include Colle di Corne near Tusculum, where she is referred to with the archaic Latin name of \"deva Cornisca\" and where existed a collegium of worshippers; at \u00c9vora, Portugal; Mount Algidus, also near Tusculum; at Lavinium; and at Tibur (Tivoli), where she is referred to as \"Diana Opifera Nemorensis\". Diana was also worshiped at a sacred wood mentioned by Livy - \"ad compitum Anagninum\" (near Anagni), and on Mount Tifata in Campania.\nAccording to Plutarch, men and women alike were worshipers of Diana and were welcomed into all of her temples. The one exception seems to have been a temple on the Vicus Patricius, which men either did not enter due to tradition, or were not allowed to enter. Plutarch related a legend that a man had attempted to assault a woman worshiping in this temple and was killed by a pack of dogs (echoing the myth of Diana and Actaeon), which resulted in a superstition against men entering the temple.\nA feature common to nearly all of Diana's temples and shrines by the second century AD was the hanging up of stag antlers. Plutarch noted that the only exception to this was the temple on the Aventine Hill, in which bull horns had been hung up instead. Plutarch explains this by way of reference to a legend surrounding the sacrifice of an impressive Sabine bull by King Servius at the founding of the Aventine temple.\nSanctuary at Lake Nemi.\nDiana's worship may have originated at an open-air sanctuary overlooking Lake Nemi in the Alban Hills near Aricia, where she was worshiped as Diana Nemorensis, or (\"Diana of the Sylvan Glade\"). According to legendary accounts, the sanctuary was founded by Orestes and Iphigenia after they fled from the Tauri. In this tradition, the Nemi sanctuary was supposedly built on the pattern of an earlier Temple of Artemis Tauropolos, and the first cult statue at Nemi was said to have been stolen from the Tauri and brought to Nemi by Orestes. Historical evidence suggests that worship of Diana at Nemi flourished from at least the 6th century BCE until the 2nd century CE. Her cult there was first attested in Latin literature by Cato the Elder, in a surviving quote by the late grammarian Priscian. By the 4th century BCE, the simple shrine at Nemi had been joined by a temple complex. The sanctuary served an important political role as it was held in common by the Latin League.\nA festival to Diana, the Nemoralia, was held yearly at Nemi on the Ides of August (August 13\u201315). Worshipers traveled to Nemi carrying torches and garlands, and once at the lake, they left pieces of thread tied to fences and tablets inscribed with prayers. Diana's festival eventually became widely celebrated throughout Italy, which was unusual given the provincial nature of Diana's cult. The poet Statius wrote of the festival:\nStatius describes the triple nature of the goddess by invoking heavenly (the stars), earthly (the grove itself) and underworld (Hecate) imagery. He also suggests by the garlanding of the dogs and polishing of the spears that no hunting was allowed during the festival.\nLegend has it that Diana's high priest at Nemi, known as the Rex Nemorensis, was always an escaped slave who could only obtain the position by defeating his predecessor in a fight to the death. Sir James George Frazer wrote of this sacred grove in \"The Golden Bough\", basing his interpretation on brief remarks in Strabo (5.3.12), Pausanias (2,27.24) and Servius' commentary on the \"Aeneid\" (6.136). The legend tells of a tree that stood in the center of the grove and was heavily guarded. No one was allowed to break off its limbs, with the exception of a runaway slave, who was allowed, if he could, to break off one of the boughs. He was then in turn granted the privilege to engage the Rex Nemorensis, the current king and priest of Diana, in a fight to the death. If the slave prevailed, he became the next king for as long as he could defeat his challengers. However, Joseph Fontenrose criticised Frazer's assumption that a rite of this sort actually occurred at the sanctuary, and no contemporary records exist that support the historical existence of the \"Rex Nemorensis\".\nSpread and conflation with Artemis.\nRome hoped to unify into and control the Latin tribes around Nemi, so Diana's worship was imported to Rome as a show of political solidarity. Diana soon afterwards became Hellenized, and combined with the Greek goddess Artemis, \"a process which culminated with the appearance of Diana beside Apollo [the brother of Artemis] in the first \"lectisternium\" at Rome\" in 399 BCE. The process of identification between the two goddesses probably began when artists who were commissioned to create new cult statues for Diana's temples outside Nemi were struck by the similar attributes between Diana and the more familiar Artemis, and sculpted Diana in a manner inspired by previous depictions of Artemis. Sibyllene influence and trade with Massilia, where similar cult statues of Artemis existed, would have completed the process.\nAccording to Fran\u00e7oise H\u00e9l\u00e8ne Pairault's study, historical and archaeological evidence point to the fact that the characteristics given to both Diana of the Aventine Hill and Diana Nemorensis were the product of the direct or indirect influence of the cult of Artemis, which was spread by the Phoceans among the Greek towns of Campania Cuma and Capua, who in turn had passed it over to the Etruscans and the Latins by the 6th and 5th centuries BCE.\nEvidence suggests that a confrontation occurred between two groups of Etruscans who fought for supremacy, those from Tarquinia, Vulci and Caere (allied with the Greeks of Capua) and those of Clusium. This is reflected in the legend of the coming of Orestes to Nemi and of the inhumation of his bones in the Roman Forum near the temple of Saturn. The cult introduced by Orestes at Nemi is apparently that of the Artemis Tauropolos. The literary amplification reveals a confused religious background: different versions of Artemis were conflated under the epithet. As far as Nemi's Diana is concerned there are two different versions, by Strabo and Servius Honoratus. Strabo's version looks to be the most authoritative as he had access to first-hand primary sources on the sanctuaries of Artemis, i.e. the priest of Artemis Artemidoros of Ephesus. The meaning of \"Tauropolos\" denotes an Asiatic goddess with lunar attributes, lady of the herds. The only possible \"interpretatio graeca\" of high antiquity concerning \"Diana Nemorensis\" could have been the one based on this ancient aspect of a deity of light, master of wildlife. \"Tauropolos\" is an ancient epithet attached to Artemis, Hecate, and even Athena. According to the legend Orestes founded Nemi together with Iphigenia. At Cuma the Sybil is the priestess of both Phoibos and Trivia. Hesiod and Stesichorus tell the story according to which after her death Iphigenia was divinised under the name of Hecate, a fact which would support the assumption that Artemis Tauropolos had a real ancient alliance with the heroine, who was her priestess in Taurid and her human paragon. This religious complex is in turn supported by the triple statue of Artemis-Hecate.\nIn Rome, Diana was regarded with great reverence and was a patroness of lower-class citizens, called plebeians, as well as slaves, who could receive asylum in her temples. Georg Wissowa proposed that this might be because the first slaves of the Romans were Latins of the neighboring tribes. However, the Temple of Artemis at Ephesus had the same custom of the asylum.\nIn Rome.\nWorship of Diana probably spread into the city of Rome beginning around 550 BCE, during her Hellenization and combination with the Greek goddess Artemis. Diana was first worshiped along with her brother and mother, Apollo and Latona, in their temple in the Campus Martius, and later in the Temple of Apollo Palatinus.\nThe first major temple dedicated primarily to Diana in the vicinity of Rome was the Temple of Diana Aventina (Diana of the Aventine Hill). According to the Roman historian Livy, the construction of this temple began in the 6th century BCE and was inspired by stories of the massive Temple of Artemis at Ephesus, which was said to have been built through the combined efforts of all the cities of Asia Minor. Legend has it that Servius Tullius was impressed with this act of massive political and economic cooperation, and convinced the cities of the Latin League to work with the Romans to build their own temple to the goddess. However, there is no compelling evidence for such an early construction of the temple, and it is more likely that it was built in the 3rd century BCE, following the influence of the temple at Nemi, and probably about the same time the first temples to Vertumnus (who was associated with Diana) were built in Rome (264 BCE). The misconception that the Aventine Temple was inspired by the Ephesian Temple might originate in the fact that the cult images and statues used at the former were based heavily on those found in the latter. Whatever its initial construction date, records show that the Avantine Temple was rebuilt by Lucius Cornificius in 32 BCE. If it was still in use by the 4th century CE, the Aventine temple would have been permanently closed during the persecution of pagans in the late Roman Empire. Today, a short street named the \"Via del Tempio di Diana\" and an associated plaza, \"Piazza del Tempio di Diana\", commemorates the site of the temple. Part of its wall is located within one of the halls of the Apuleius restaurant.\nLater temple dedications often were based on the model for ritual formulas and regulations of the Temple of Diana. Roman politicians built several minor temples to Diana elsewhere in Rome to secure public support. One of these was built in the Campus Martius in 187 BCE; no Imperial period records of this temple have been found, and it is possible it was one of the temples demolished around 55 BCE in order to build a theater. Diana also had a public temple on the Quirinal Hill, the sanctuary of Diana Planciana. It was dedicated by Plancius in 55 BCE, though it is unclear which Plancius.\nIn their worship of Artemis, Greeks filled their temples with sculptures of the goddess created by well-known sculptors, and many were adapted for use in the worship of Diana by the Romans, beginning around the 2nd century BCE (the beginning of a period of strong Hellenistic influence on Roman religion). The earliest depictions of the Artemis of Ephesus are found on Ephesian coins from this period. By the Imperial period, small marble statues of the Ephesian Artemis were being produced in the Western region of the Mediterranean and were often bought by Roman patrons. The Romans obtained a large copy of an Ephesian Artemis statue for their temple on the Aventine Hill. Diana was usually depicted for educated Romans in her Greek guise. If she was shown accompanied by a deer, as in the \"Diana of Versailles\", this is because Diana was the patroness of hunting. The deer may also offer a covert reference to the myth of Acteon (or Actaeon), who saw her bathing naked. Diana transformed Acteon into a stag and set his own hunting dogs to kill him.\nAt Mount Tifata.\nIn Campania, Diana had a major temple at Mount Tifata, near Capua. She was worshiped there as \"Diana Tifatina\". This was one of the oldest sanctuaries in Campania. As a rural sanctuary, it included lands and estates that would have been worked by slaves following the Roman conquest of Campania, and records show that expansion and renovation projects at her temple were funded in part by other conquests by Roman military campaigns. The modern Christian church of Sant'Angelo in Formis was built on the ruins of the Tifata temple.\nRoman provinces.\nIn the Roman provinces, Diana was widely worshiped alongside local deities. Over 100 inscriptions to Diana have been cataloged in the provinces, mainly from Gaul, Upper Germania, and Britannia. Diana was commonly invoked alongside another forest god, Silvanus, as well as other \"mountain gods\". In the provinces, she was occasionally conflated with local goddesses such as Abnoba, and was given high status, with \"Augusta\" and \"regina\" (\"queen\") being common epithets.\nHousehold worship.\nDiana was not only regarded as a goddess of the wilderness and the hunt, but was often worshiped as a patroness of families. She served a similar function to the hearth goddess Vesta, and was sometimes considered to be a member of the Penates, the deities most often invoked in household rituals. In this role, she was often given a name reflecting the tribe of family who worshiped her and asked for her protection. For example, in what is now Wiesbaden, Diana was worshiped as \"Diana Mattiaca\" by the Mattiaci tribe. Other family-derived named attested in the ancient literature include \"Diana Cariciana\", \"Diana Valeriana\", and \"Diana Plancia\". As a house goddess, Diana often became reduced in stature compared to her official worship by the Roman state religion. In personal or family worship, Diana was brought to the level of other household spirits, and was believed to have a vested interest in the prosperity of the household and the continuation of the family. The Roman poet Horace regarded Diana as a household goddess in his \"Odes\", and had an altar dedicated to her in his villa where household worship could be conducted. In his poetry, Horace deliberately contrasted the kinds of grand, elevated hymns to Diana on behalf of the entire Roman state, the kind of worship that would have been typical at her Aventine temple, with a more personal form of devotion.\nImages of Diana and her associated myths have been found on sarcophagi of wealthy Romans. They often included scenes depicting sacrifices to the goddess, and on at least one example, the deceased man is shown joining Diana's hunt.\nTheology.\nSince ancient times, philosophers and theologians have examined the nature of Diana in light of her worship traditions, attributes, mythology, and identification with other gods.\nConflation with other goddesses.\nDiana was initially a hunting goddess and goddess of the local woodland at Nemi, but as her worship spread, she acquired attributes of other similar goddesses. As she became conflated with Artemis, she became a moon goddess, identified with the other lunar goddesses goddess Luna and Hekate. She also became the goddess of childbirth and ruled over the countryside. Catullus wrote a poem to Diana in which she has more than one alias: Latonia, Lucina, Juno, Trivia, Luna.\nAlong with Mars, Diana was often venerated at games held in Roman amphitheaters, and some inscriptions from the Danubian provinces show that she was conflated with Nemesis in this role, as \"Diana Nemesis\".\nOutside of Italy, Diana had important centers of worship where she was syncretised with similar local deities in Gaul, Upper Germania, and Britannia. Diana was particularly important in the region in and around the Black Forest, where she was conflated with the local goddess Abnoba and worshiped as \"Diana Abnoba\".\nSome late antique sources went even further, syncretizing many local \"great goddesses\" into a single \"Queen of Heaven\". The Platonist philosopher Apuleius, writing in the late 2nd century, depicted the goddess declaring:\n\"I come, Lucius, moved by your entreaties: I, mother of the universe, mistress of all the elements, first-born of the ages, highest of the gods, queen of the shades, first of those who dwell in heaven, representing in one shape all gods and goddesses. My will controls the shining heights of heaven, the health-giving sea-winds, and the mournful silences of hell; the entire world worships my single godhead in a thousand shapes, with divers rites, and under many a different name. The Phrygians, first-born of mankind, call me the Pessinuntian Mother of the gods; the native Athenians the Cecropian Minerva; the island-dwelling Cypriots Paphian Venus; the archer Cretans Dictynnan Diana; the triple-tongued Sicilians Stygian Proserpine; the ancient Eleusinians Actaean Ceres; some call me Juno, some Bellona, others Hecate, others Rhamnusia; but both races of Ethiopians, those on whom the rising and those on whom the setting sun shines, and the Egyptians who excel in ancient learning, honour me with the worship which is truly mine and call me by my true name: Queen Isis.\"\nLater poets and historians looked to Diana's identity as a triple goddess to merge her with triads heavenly, earthly, and underworld (cthonic) goddesses. Maurus Servius Honoratus said that the same goddess was called Luna in heaven, Diana on earth, and Proserpina in hell.\nMichael Drayton praises the Triple Diana in poem \"The Man in the Moone\" (1606): \"So these great three most powerful of the rest, Phoebe, Diana, Hecate, do tell. Her sovereignty in Heaven, in Earth and Hell\".\nIn Platonism.\nBased on the earlier writings of Plato, the Neoplatonist philosophers of late antiquity united the various major gods of Hellenic tradition into a series of monads containing within them triads, with some creating the world, some animating it or bringing it to life, and others harmonizing it. Within this system, Proclus considered Diana to be one of the primary animating, or life-giving, deities. Proclus, citing Orphic tradition, concludes that Diana \"presides over all the generation in nature, and is the midwife of physical productive principles\" and that she \"extends these genitals, distributing as far as to subterranean natures the prolific power of [Bacchus].\" Specifically, Proclus considered the life-generating principle of the highest order, within the Intellectual realm, to be Rhea, whom he identified with Ceres. Within her divinity was produced the cause of the basic principle of life. Projecting this principle into the lower, Hypercosmic realm of reality generated a lower monad, Kore, who could therefore be understood as Ceres' \"daughter\". Kore embodied the \"maidenly\" principle of generation that, more importantly, included a principle of division - where Demeter generates life indiscriminately, Kore distributes it individually. This division results in another triad or trinity, known as the Maidenly trinity, within the monad of Kore: namely, Diana, Proserpine, and Minerva, through whom individual living beings are given life and perfected. Specifically, according to a commentary by scholar Spyridon Rangos, Diana (equated with Hecate) gives existence, Proserpine (equated with \"Soul\") gives form, and Minerva (equated with \"Virtue\") gives intellect.\nIn his commentary on Proclus, the 19th century Platonist scholar Thomas Taylor expanded upon the theology of the classical philosophers, further interpreting the nature and roles of the gods in light of the whole body of Neoplatonist philosophy. He cites Plato in giving a three-form aspect to her central characteristic of virginity: the undefiled, the mundane, and the anagogic. Through the first form, Diana is regarded as a \"lover of virginity\". Through the second, she is the guardian of virtue. Through the third, she is considered to \"hate the impulses arising from generation.\" Through the principle of the undefiled, Taylor suggests that she is given supremacy in Proclus' triad of life-giving or animating deities, and in this role the theurgists called her Hekate. In this role, Diana is granted undefiled power (\"Amilieti\") from the other gods. This generative power does not proceed forth from the goddess (according to a statement by the Oracle of Delphi) but rather resides with her, giving her unparalleled virtue, and in this way she can be said to embody virginity. Later commentators on Proclus have clarified that the virginity of Diana is not an absence of sexual drive, but a renunciation of sexuality. Diana embodies virginity because she generates but precedes active fertility (within Neoplatonism, an important maxim is that \"every productive cause is superior to the nature of the produced effect\").\nUsing the ancient Neoplatonists as a basis, Taylor also commented on the triadic nature of Diana and related goddesses, and the ways in which they subsist within one another, partaking unevenly in each other's powers and attributes. For example, Kore is said to embody both Diana/Hecate and Minerva, who create the virtuous or virgin power within her, but also Proserpine (her sole traditional identification), through whom the generative power of the Kore as a whole is able to proceed forth into the world, where it joins with the demiurge to produce further deities, including Bacchus and \"nine azure-eyed, flower-producing daughters\".\nProclus also included Artemis/Diana in a second triad of deities, along with Ceres and Juno. According to Proclus:\nProclus pointed to the conflict between Hera and Artemis in the \"Illiad\" as a representation of the two kinds of human souls. Where Hera creates the higher, more cultured, or \"worthy\" souls, Artemis brings light to and perfects the \"less worthy\" or less rational. As explained by Ragnos (2000), \"The aspect of reality which Artemis and Hera share, and because of which they engage in a symbolic conflict, is the engendering of life.\" Hera elevates rational living beings up to intellectual rational existence, whereas Artemis's power pertains to human life as far as its physical existence as a living thing. \"Artemis deals with the most elementary forms of life or the most elementary part of all life, whereas Hera operates in the most elevated forms of life or the most elevated part of all life.\nWorship in Post Roman Europe.\nSermons and other religious documents have provided evidence for the worship of Diana during the Middle Ages. Though few details have been recorded, enough references to Diana worship during the early Christian period exist to give some indication that it may have been relatively widespread among remote and rural communities throughout Europe, and that such beliefs persisted into the Merovingian period. References to contemporary Diana worship exist from the 6th century on the Iberian peninsula and what is now southern France, though more detailed accounts of Dianic cults were given for the Low Countries, and southern Belgium in particular. Many of these were probably local goddesses, and wood nymphs or dryads, which had been conflated with Diana by Christian writers Latinizing local names and traditions.\nIn the Low Countries.\nThe 6th century bishop Gregory of Tours reported meeting with a deacon named Vulfilaic (also known as Saint Wulflaicus or Walfroy the Stylite), who founded a hermitage on a hill in what is now Margut, France. On the same hill, he found \"an image of Diana which the unbelieving people worshiped as a god.\" According to Gregory's report, worshipers would also sing chants in Diana's honor as they drank and feasted. Vulfilaic destroyed a number of smaller pagan statues in the area, but the statue of Diana was too large. After converting some of the local population to Christianity, Vulfilaic and a group of local residents attempted to pull the large statue down the mountain in order to destroy it, but failed, as it was too large to be moved. In Vulfilaic's account, after praying for a miracle, he was then able to single-handedly pull down the statue, at which point he and his group smashed it to dust with their hammers. According to Vulfilaic, this incident was quickly followed by an outbreak of pimples or sores that covered his entire body, which he attributed to demonic activity and similarly cured via what he described as a miracle. Vulfilaic would later found a church on the site, which is today known as Mont Saint-Walfroy.\nAdditional evidence for surviving pagan practices in the Low Countries region comes from the \"Vita Eligii\", or \"Life of Saint Eligius\", written by Audoin in the 7th century. Audoin drew together the familiar admonitions of Eligius to the people of Flanders. In his sermons, he denounced \"pagan customs\" that the people continued to follow. In particular, he denounced several Roman gods and goddesses alongside Druidic mythological beliefs and objects:\n\"I denounce and contest, that you shall observe no sacrilegious pagan customs. For no cause or infirmity should you consult magicians, diviners, sorcerers or incantators. ..Do not observe auguries ... No influence attaches to the first work of the day or the [phase of the] moon. ... [Do not] make vetulas, little deer or iotticos or set tables at night or exchange New Year gifts or supply superfluous drinks... No Christian... performs solestitia or dancing or leaping or diabolical chants. No Christian should presume to invoke the name of a demon, not Neptune or Orcus or Diana or Minerva or Geniscus... No one should observe Jove's day in idleness. ... No Christian should make or render any devotion to the gods of the trivium, where three roads meet, to the fanes or the rocks, or springs or groves or corners. None should presume to hang any phylacteries from the neck of man nor beast. ..None should presume to make lustrations or incantations with herbs, or to pass cattle through a hollow tree or ditch ... No woman should presume to hang amber from her neck or call upon Minerva or other ill-starred beings in their weaving or dyeing. .. None should call the sun or moon lord or swear by them. .. No one should tell fate or fortune or horoscopes by them as those do who believe that a person must be what he was born to be.\"\nLegends from medieval Belgium concern a natural spring which came to be known as the \"Fons Remacli\", a location which may have been home to late-surviving worship of Diana. Remacle was a monk appointed by Eligius to head a monastery at Solignac, and he is reported to have encountered Diana worship in the area around the river Warche. The population in this region was said to have been involved in the worship of \"Diana of the Ardennes\" (a syncretism of Diana and the Celtic goddess Arduinna), with effigies and \"stones of Diana\" used as evidence of pagan practices. Remacle believed that demonic entities were present in the spring, and had caused it to run dry. He performed and exorcism of the water source, and installed a lead pipe, which allowed the water to flow again.\nThe \"Society of Diana\".\nDiana is the only pagan goddess mentioned by name in the New Testament (Acts 19). As a result, she became associated with many folk beliefs involving goddess-like supernatural figures that Catholic clergy wished to demonize. In the Middle Ages, legends of night-time processions of spirits led by a female figure are recorded in the church records of Northern Italy, western Germany, and southern France. The spirits were said to enter houses and consume food which then miraculously re-appeared. They would sing and dance, and dispense advise regarding healing herbs and the whereabouts of lost objects. If the house was in good order, they would bring fertility and plenty. If not, they would bring curses to the family. Some women reported participating in these processions while their bodies still lay in bed. Historian Carlo Ginzburg has referred to these legendary spirit gatherings as \"The Society of Diana\".\nLocal clergy complained that women believed they were following Diana or Herodias, riding out on appointed nights to join the processions or carry out instructions from the goddess. The earliest reports of these legends appear in the writings of Regino of Pr\u00fcm in the year 899, followed by many additional reports and variants of the legend in documents by Ratherius and others. By 1310, the names of the goddess figures attached to the legend were sometimes combined as Herodiana. It is likely that the clergy of this time used the identification of the procession's leader as Diana or Herodias in order to fit an older folk belief into a Biblical framework, as both are featured and demonized in the New Testament. Herodias was often conflated with her daughter Salome in legend, which also holds that, upon being presented with the severed head of John the Baptist, she was blown into the air by wind from the saint's mouth, through which she continued to wander for eternity. Diana was often conflated with Hecate, a goddess associated with the spirits of the dead and with witchcraft. These associations, and the fact that both figures are attested to in the Bible, made them a natural fit for the leader of the ghostly procession. Clergy used this identification to assert that the spirits were evil, and that the women who followed them were inspired by demons. As was typical of this time period, though pagan beliefs and practices were near totally eliminated from Europe, the clergy and other authorities still treated paganism as a real threat, in part thanks to biblical influence; much of the Bible had been written when various forms of paganism were still active if not dominant, so medieval clergy applied the same kinds of warnings and admonitions for any non-standard folk beliefs and practices they encountered. Based on analysis of church documents and parishioner confessions, it is likely that the spirit identified by the Church as Diana or Herodias was called by names of pre-Christian figures like Holda (a Germanic goddess of the winter solstice), or with names referencing her bringing of prosperity, like the Latin Abundia (meaning \"plenty\"), Satia (meaning \"full\" or \"plentiful\") and the Italian Richella (meaning \"rich\"). Some of the local titles for her, such as \"bonae res\" (meaning \"good things\"), are similar to late classical titles for Hecate, like \"bona dea\". This might indicate a cultural mixture of medieval folk ideas with holdovers from earlier pagan belief systems. Whatever her true origin, by the 13th century, the leader of the legendary spirit procession had come to be firmly identified with Diana and Herodias through the influence of the Church.\nModern development and folklore.\n\"The Golden Bough\".\nIn his wide-ranging, comparative study of mythology and religion, \"The Golden Bough\", anthropologist James George Frazer drew on various lines of evidence to re-interpret the legendary rituals associated with Diana at Nemi, particularly that of the \"rex Nemorensis\". Frazer developed his ideas in relation to J. M. W. Turner's painting, also titled \"The Golden Bough\", depicting a dream-like vision of the woodland lake of Nemi. According to Frazer, the \"rex Nemorensis\" or king at Nemi was the incarnation of a dying and reviving god, a solar deity who participated in a mystical marriage to a goddess. He died at the harvest and was reincarnated in the spring. Frazer claimed that this motif of death and rebirth is central to nearly all of the world's religions and mythologies. In Frazer's theory, Diana functioned as a goddess of fertility and childbirth, who, assisted by the sacred king, ritually returned life to the land in spring. The king in this scheme served not only as a high priest but as a god of the grove. Frazer identifies this figure with Virbius, of which little is known, but also with Jupiter via an association with sacred oak trees. Frazer argued furthermore that Jupiter and Juno were simply duplicate names of Jana and Janus; that is, Diana and Dianus, all of whom had identical functions and origins.\nFrazer's speculatively reconstructed folklore of Diana's origins and the nature of her cult at Nemi were not well received even by his contemporaries. Godfrey Lienhardt noted that even during Frazer's lifetime, other anthropologists had \"for the most part distanced themselves from his theories and opinions\", and that the lasting influence of \"The Golden Bough\" and Frazer's wider body of work \"has been in the literary rather than the academic world.\" Robert Ackerman wrote that, for anthropologists, Frazer is \"an embarrassment\" for being \"the most famous of them all\" and that most distance themselves from his work. While \"The Golden Bough\" achieved wide \"popular appeal\" and exerted a \"disproportionate\" influence \"on so many [20th century] creative writers\", Frazer's ideas played \"a much smaller part\" in the history of academic social anthropology.\n\"The Gospel of the Witches\".\nFolk legends like the Society of Diana, which linked the goddess to forbidden gatherings of women with spirits, may have influenced later works of folklore. One of these is Charles Godfrey Leland's \"Aradia, or the Gospel of the Witches\", which prominently featured Diana at the center of an Italian witch-cult. In Leland's interpretation of supposed Italian folk witchcraft, Diana is considered Queen of the Witches. In this belief system, Diana is said to have created the world of her own being having in herself the seeds of all creation yet to come. It was said that out of herself she divided the darkness and the light, keeping for herself the darkness of creation and creating her brother Lucifer. Diana was believed to have loved and ruled with her brother, and with him bore a daughter, Aradia (a name likely derived from Herodias), who leads and teaches the witches on earth.\nLeland's claim that \"Aradia\" represented an authentic tradition from an underground witch-cult, which had secretly worshiped Diana since ancient times has been dismissed by most scholars of folklore, religion, and medieval history. After the 1921 publication of Margaret Murray's \"The Witch-cult in Western Europe\", which hypothesized that the European witch trials were actually a persecution of a pagan religious survival, American sensationalist author Theda Kenyon's 1929 book \"Witches Still Live\" connected Murray's thesis with the witchcraft religion in \"Aradia\". Arguments against Murray's thesis would eventually include arguments against Leland. Witchcraft scholar Jeffrey Russell devoted some of his 1980 book \"A History of Witchcraft: Sorcerers, Heretics and Pagans\" to arguing against the claims Leland presented in \"Aradia\". Historian Elliot Rose's \"A Razor for a Goat\" dismissed \"Aradia\" as a collection of incantations unsuccessfully attempting to portray a religion. In his book \"Triumph of the Moon\", historian Ronald Hutton doubted not only of the existence of the religion that \"Aradia\" claimed to represent, and that the traditions Leland presented were unlike anything found in actual medieval literature, but also of the existence of Leland's sources, arguing that it is more likely that Leland created the entire story than that Leland could be so easily \"duped\". Religious scholar Chas S. Clifton took exception to Hutton's position, writing that it amounted to an accusation of \"serious literary fraud\" made by an \"argument from absence\".\nBuilding on the work of Frazer, Murray, and others, some 20th and 21st century authors have attempted to identify links between Diana and more localized deities. R. Lowe Thompson, for example, in his 2013 book \"The History of the Devil\", speculated that Diana may have been linked as an occasional \"spouse\" to the Gaulish horned god Cernunnos. Thompson suggested that Diana in her role as wild goddess of the hunt would have made a fitting consort for Cernunnos in Western Europe, and further noted the link between Diana as Proserpina with Pluto, the Greek god associated with the riches of the earth who served a similar role to the Gaulish Cernunnos.\nModern worship.\nBecause Leland's claims about an Italian witch-cult are questionable, the first verifiable worship of Diana in the modern age was probably begun by Wicca. The earliest known practitioners of Neopagan witchcraft were members of a tradition begun by Gerald Gardner. Published versions of the devotional materials used by Gardner's group, dated to 1949, are heavily focused on the worship of Aradia, the daughter of Diana in Leland's folklore. Diana herself was recognized as an aspect of a single \"great goddess\" in the tradition of Apuleius, as described in the Wiccan Charge of the Goddess (itself adapted from Leland's text). Some later Wiccans, such as Scott Cunningham, would replace Aradia with Diana as the central focus of worship.\nIn the early 1960s, Victor Henry Anderson founded the Feri Tradition, a form of Wicca that draws from both Charles Leland's folklore and the Gardnerian tradition. Anderson claimed that he had first been initiated into a witchcraft tradition as a child in 1926, and that he had been told the name of the goddess worshiped by witches was Tana. The name Tana originated in Leland's \"Aradia\", where he claimed it was an old Etruscan name for Diana. The Feri Tradition founded by Anderson continues to recognize Tana/Diana as an aspect of the Star Goddess related to the element of fire, and representing \"the fiery womb that gives birth to and transforms all matter.\" (In \"Aradia\", Diana is also credited as the creatrix of the material world and Queen of Faeries).\nA few Wiccan traditions would elevate Diana to a more prominent position of worship, and there are two distinct modern branches of Wicca focused primarily on Diana. The first, founded during the early 1970s in the United States by Morgan McFarland and Mark Roberts, has a feminist theology and only occasionally accepts male participants, and leadership is limited to female priestesses. McFarland Dianic Wiccans base their tradition primarily on the work of Robert Graves and his book \"The White Goddess\", and were inspired by references to the existence of medieval European \"Dianic cults\" in Margaret Murray's book \"The Witch-Cult in Western Europe\". The second Dianic tradition, founded by Zsuzsanna Budapest in the mid 1970s, is characterized by an exclusive focus on the feminine aspect of the divine, and as a result is exclusively female. This tradition combines elements from British Traditional Wicca, Italian folk-magic based on the work of Charles Leland, feminist values, and healing practices drawn from a variety of different cultures.\nA third Neopagan tradition heavily inspired by the worship of Diana through the lens of Italian folklore is Stregheria, founded in the 1980s. It centers around a pair of deities regarded as divine lovers, who are known by several variant names including Diana and Dianus, alternately given as Tana and Tanus or Jana and Janus (the later two deity names were mentioned by James Frazer in \"The Golden Bough\" as later corruptions of Diana and Dianus, which themselves were alternate and possibly older names for Juno and Jupiter). The tradition was founded by author Raven Grimassi, and influenced by Italian folktales he was told by his mother. One such folktale describes the moon being impregnated by her lover the morning star, a parallel to Leland's mythology of Diana and her lover Lucifer.\nDiana was also a subject of worship in certain Feraferian rites, particularly those surrounding the autumnal equinox, beginning in 1967.\nLegacy.\nIn language.\nBoth the Romanian words for \"fairy\" \"Z\u00e2n\u0103\" and S\u00e2nzian\u0103, the Leonese and Portuguese word for \"water nymph\" \"xana\", and the Spanish word for \"shooting target\" and \"morning call\" (\"diana\") seem to come from the name of Diana.\nIn the arts.\nSince the Renaissance, Diana's myths have often been represented in the visual and dramatic arts, including the opera \"L'arbore di Diana\". In the 16th century, Diana's image figured prominently at the ch\u00e2teaus of Fontainebleau, Chenonceau, &amp; at Anet, in deference to Diane de Poitiers, mistress of Henri of France. At Versailles she was incorporated into the Olympian iconography with which Louis XIV, the Apollo-like \"Sun King\" liked to surround himself. Diana is also a character in the 1876 L\u00e9o Delibes ballet \"Sylvia\". The plot deals with Sylvia, one of Diana's nymphs and sworn to chastity, and Diana's assault on Sylvia's affections for the shepherd Amyntas.\nIn painting and sculpture.\nDiana has been one of the most popular themes in art. Painters like Titian, Peter Paul Rubens, Fran\u00e7ois Boucher, Nicholas Poussin and made use of her myth as a major theme. Most depictions of Diana in art featured the stories of Diana and Actaeon, or Callisto, or depicted her resting after hunting. Some famous work of arts with a Diana theme are:"}
{"id": "8396", "revid": "27089876", "url": "https://en.wikipedia.org/wiki?curid=8396", "title": "December 11", "text": ""}
{"id": "8397", "revid": "1012845404", "url": "https://en.wikipedia.org/wiki?curid=8397", "title": "Danny Elfman", "text": "Daniel Robert Elfman (born May 29, 1953) is an American composer, singer and songwriter. He was the singer-songwriter for the new wave band Oingo Boingo in the early 1980s, and has since garnered international recognition for composing over 100 feature film scores, as well as compositions for television, stage productions, and the concert hall.\nElfman has frequently worked with directors Tim Burton, Sam Raimi, and Gus Van Sant, with notable achievements the scores for 16 Burton-directed films including \"Batman,\" \"Edward Scissorhands, Charlie and the Chocolate Factory, Alice in Wonderland\", and \"Dumbo\"; Raimi's \"Spider-Man\", \"Spider-Man 2\", and \"Oz the Great and Powerful\"; and Van Sant's Academy Award-nominated films \"Good Will Hunting\" and \"Milk\". He wrote music for all of the \"Men in Black\" and \"Fifty Shades of Grey\" franchise films, the songs and score for the Burton-produced animated musical \"The Nightmare Before Christmas\", and the themes for the popular television series \"Desperate Housewives\" and \"The Simpsons\".\nAmong his honors are four Oscar nominations, two Emmy Awards, a Grammy, six Saturn Awards for Best Music, the 2002 Richard Kirk Award, the 2015 Disney Legend Award, and the Max Steiner Film Music Achievement Award in 2017.\nEarly life.\nElfman was born in Los Angeles, California, to a Jewish family of Polish-Jewish and Russian-Jewish descent. He is the son of Blossom Elfman (n\u00e9e Bernstein), a writer and teacher, and Milton Elfman, a teacher who was in the Air Force, and the brother of Richard Elfman. Elfman was raised in a racially mixed affluent community in Baldwin Hills, California, where he spent much of his time at the local movie theater discovering classic sci-fi, fantasy and horror films and first noticed the music of such film composers as Bernard Herrmann and Franz Waxman.\nIn his early school days, Elfman exhibited an aptitude for science with almost no interest in music, and was even rejected from elementary school orchestra \"for having no propensity for music.\" This would change when he switched high schools in the late 1960s and fell in with a musical crowd, who introduced him to early jazz and the work of Stravinsky and his 20th century contemporaries.\nAfter finishing high school early with plans to travel the world, Elfman followed his brother Richard to France, where he performed violin with J\u00e9r\u00f4me Savary's Le Grand Magic Circus, an avant-garde musical theater group. He then embarked on a ten-month, self-guided tour through Africa, busking and collecting a range of West African percussion instruments until a series of illnesses forced him to return home. At this time, Richard was forming a new musical theater group in Los Angeles.\nWhile Elfman was never officially a student at CalArts, an instructor in the Indonesian music department encouraged him to attend classes and perform music there for two years.\nCareer.\nThe Mystic Knights of the Oingo Boingo and Oingo Boingo.\nAfter returning to Los Angeles from Africa in the early 1970s, Elfman was asked by his brother Richard to serve as musical director of his street theatre performance art troupe The Mystic Knights of the Oingo Boingo.\nElfman was tasked with adapting and arranging 1920s and 1930s jazz and big band music by artists such as Cab Calloway, Duke Ellington, Django Reinhardt and Josephine Baker for the ensemble, which consisted of up to 15 performers playing upwards of 30 instruments. He also composed original pieces and helped build instruments unique for the group, including an aluminum gamelan, the 'Schlitz celeste' made from tuned beer cans, and a \"junkyard orchestra\" built from car parts and trash cans.\nThe Mystic Knights performed on the street and in nightclubs throughout Los Angeles until Richard left in 1979 to pursue filmmaking. As a send-off to the group's original concept, Richard created the film \"Forbidden Zone\" based on The Mystic Knights' stage performances. Elfman composed the songs and his first score for the film, and appeared as the character Satan, who performs a reworked version of Calloway's \"Minnie the Moocher\" with ensemble members playing backup as henchmen.\nBefore the release of \"Forbidden Zone\", Elfman had taken over The Mystic Knights as lead singer-songwriter in 1979, paring the group down to eight players, shortening the name to Oingo Boingo, and recording and touring as a ska-influenced new wave band. Their biggest success among eight studio albums penned by Elfman was 1985's \"Dead Man's Party\", featuring the hit song \"Weird Science\" from the movie of the same name. The band also appeared performing their single \"Dead Man's Party\" in the 1986 movie \"Back to School\", for which Elfman also composed the score. Elfman shifted the band to a more guitar-oriented rock sound in the late 1980s, which continued through their last album \"Boingo\" in 1994.\nCiting permanent hearing damage from performing live and conflicts with his film-scoring career, Elfman retired Oingo Boingo in 1995 with a series of five sold-out final concerts at the Universal Amphitheatre ending on Halloween night. On October 31, 2015, Elfman and Oingo Boingo guitarist Steve Bartek performed the song \"Dead Man's Party\" with an orchestra as an encore to a live-to-film concert of \"The Nightmare Before Christmas\" score at the Hollywood Bowl. Elfman told the audience the performance was \"20 years to the day\" of Oingo Boingo's retirement.\nFilm scoring.\nAs fans of Oingo Boingo and The Mystic Knights respectively, Tim Burton and Paul Reubens invited Elfman to write the score for their first feature film \"Pee-wee's Big Adventure\" in 1985. Elfman was initially apprehensive because of his lack of formal training and having never scored a studio feature, but after Burton accepted his initial demo of the title music and with orchestration assistance from Oingo Boingo guitarist and arranger Steve Bartek, he completed his score to great effect, while paying homage to his love of early film music and influential film composers Nino Rota and Bernard Herrmann. Elfman described the first time he heard his music played by a full orchestra as one of the most thrilling experiences of his life.\nFollowing \"Pee Wee's Big Adventure\", Elfman scored mainly quirky comedies in the late 1980s, including \"Back to School\" starring Rodney Dangerfield, Burton's \"Beetlejuice\" and the Bill Murray vehicle \"Scrooged\". Notable exceptions were the all-synth score to Emilio Estevez's crime drama \"Wisdom\" and the big band, blues-infused music for Martin Brest's buddy cop action film \"Midnight Run\".\nIn 1989, Elfman's influential, Grammy-winning score for Burton's \"Batman\" marked a major stylistic shift to dark, densely orchestrated music in the romantic idiom, which would carry over to his scores for Warren Beatty's \"Dick Tracy\", Sam Raimi's \"Darkman\" and Clive Barker's \"Nightbreed\", all released in 1990.\nWith \"Batman\", Elfman firmly established a career-spanning relationship with Burton, scoring all but three of the director's major studio releases. Highlights include \"Edward Scissorhands\" (1990), \"Batman Returns\" (1992), \"Sleepy Hollow\" (1999), \"Big Fish\" (2003) and \"Alice in Wonderland\" (2010). In 2005, he wrote the score and songs for Burton's \"Corpse Bride\" and provided the voice of the character of Bonejangles, as well as providing the score, songs and Oompa-Loompa vocals for Burton's \"Charlie and the Chocolate Factory\" that same year. In addition to writing the score and ten songs for the Burton-produced stop motion animated film \"The Nightmare Before Christmas\", Elfman also provided the singing voice for main character Jack Skellington, as well as the voices for side characters Barrel and the Clown with the Tear-Away Face.\nIn addition to frequent collaborations with Burton, Raimi and Gus Van Sant, Elfman has worked with esteemed directors such as Brian De Palma, Peter Jackson, Joss Whedon, Errol Morris, Ang Lee, Richard Donner, Guillermo del Toro, David O. Russell, Taylor Hackford, Jon Amiel, Joe Johnston, and Barry Sonnenfeld. His scores for Sonnenfeld's \"Men in Black\", Van Sant's \"Good Will Hunting\" and \"Milk\", and Burton's \"Big Fish\" all received Academy Award nominations.\nSince the mid 1990s, Elfman has expanded his craft to a range of genres, including thrillers (\"Dolores Claiborne\", \"A Simple Plan\", \"The Kingdom\"), dramas (\"Sommersby\", \"A Civil Action\", \"Hitchcock\"), indies (\"Freeway\", \"Silver Linings Playbook\", \"Don't Worry, He Won't Get Far on Foot\"), family (\"Flubber\", \"Charlotte's Web\", \"Frankenweenie\", \"Goosebumps\"), documentary (\"Standard Operating Procedure\", \"The Unknown Known\"), and straight horror (\"Red Dragon\", \"The Wolfman\"), as well as notable entries in his well-established areas of horror comedy (\"The Frighteners\", \"Mars Attacks!\", \"Dark Shadows\") and comic book-inspired action films (\"Hulk\", \"Wanted\", ', ').\nAmong his franchise work, Elfman composed the scores for all four \"Men in Black\" films (1997\u20132019) and all three \"Fifty Shades of Grey\" films (2015\u20132018). Elfman scored Raimi's \"Spider-Man\" in 2002 and \"Spider-Man 2\" in 2004, themes and selections from which were used for Raimi's \"Spider-Man 3\", though Elfman did not compose the score. In 1996, he also provided the score for the first film in the , adapting themes for the original television series by Lalo Schifrin as well as composing his own.\nFor several high-profile sequel and reboot projects in the 2010s, Elfman incorporated established musical themes with his own original thematic material, including the DC Extended Universe's \"Justice League\", \"The Grinch,\" \"Dumbo\" and .\nElfman was featured in the 2016 documentary \"Score\", in which he appeared among over 50 film composers to discuss the craft of movie music and influential figures in the business.\nConcert and stage music.\nElfman's first piece of original concert music, \"Serenada Schizophrana\", was commissioned by the American Composers Orchestra, who premiered the piece on February 23, 2005, at Carnegie Hall. Subsequent concert works include his first \"Violin Concerto \"Eleven Eleven\"\", co-commissioned by the Czech National Symphony Orchestra, Stanford Live at Stanford University, and the Royal Scottish National Orchestra, which premiered at Smetana Hall in Prague on June 21, 2017, with Sandy Cameron on violin and John Mauceri conducting the Czech National Symphony Orchestra; the \"Piano Quartet\", co-commissioned by the Lied Center for Performing Arts University of Nebraska and the Berlin Philharmonic Piano Quartet, which premiered February 6, 2018, in Lincoln, Nebraska; and the \"Percussion Quartet\", commissioned by Third Coast Percussion and premiered at the Philip Glass Days And Nights Festival in Big Sur on October 10, 2019.\nIn 2008, Elfman accepted his first commission for the stage, composing the music for Twyla Tharp's \"Rabbit and Rogue\" ballet, co-commissioned by American Ballet Theatre and Orange County Performing Arts Center and premiering on June 3, 2008, at the Metropolitan Opera House, Lincoln Center. Other works for stage include the music for Cirque Du Soleil's \"Iris\" in 2011, and incidental music for the Broadway production of Taylor Mac's \"\" in 2019.\nIn October 2013, Elfman returned to the stage for the first time since his band Oingo Boingo disbanded to sing his vocal parts to a handful of \"The Nightmare Before Christmas\" songs as part of a concert titled \"Danny Elfman's Music from the Films of Tim Burton\", featuring suites of music from 15 Tim Burton films newly arranged by Elfman. The concert has since toured internationally and has played in Japan, Australia, Mexico and throughout Europe and the United States. Since 2015, Elfman has appeared near annually in a Hollywood Bowl Halloween concert featuring full orchestra performing the \"Nightmare Before Christmas\" score live to the film projection.\nIn 2019, it was announced Elfman had been commissioned to write a piece for the National Youth Orchestra of Great Britain originally set to premiere in 2020, and a percussion concerto for Colin Currie and the London Philharmonic Orchestra originally for spring 2021. Other works in the planning phase are a cello concerto and a project that involves chamber orchestra and Elfman's own voice.\nIt was announced that Elfman would be taking part in Coachella 2020 with a set titled \"Past, Present and Future! From Boingo to Batman and Beyond!\" Elfman clarified on his Instagram page that this would not be an Oingo Boingo reunion, writing \"I\u2019m creating a live mix of my last 40 years\u2014 both film music and songs... that includes my Boingo years, my composer years and a few things I\u2019ve been working on for the last year or so, which will be world premieres.\"\nTelevision and other projects.\nIn addition to his music for film, Elfman has also penned themes for \"The Simpsons\", \"Tales from the Crypt\", \"The Flash\" and \"Desperate Housewives\", which won Elfman his first Emmy. He also adapted his original themes for the animated versions of \"\" and \"Beetlejuice\". Occasional forays into serial television include episodes of \"Alfred Hitchcock Presents\", \"Amazing Stories\" and Pee-wee's Playhouse, as well as the miniseries \"When We Rise\", co-composed with Chris Bacon.\nHe has composed music for animated shorts, including Sally Cruikshank's \"Face Like A Frog\" and Tim Burton's \"Stainboy\" internet series.\nElfman provided background music for Luigi Serafini's solo exhibition \"il Teatro della Pittura\" at the Fondazione Mudima di Milano in Milan, Italy in 1998 and for the \"Tim Burton\" exhibition at MoMA in 2009.\nIn the 1990s, Elfman composed music for advertising campaigns for Nike, Nissan and Lincoln-Mercury, and in 2002 wrote the music for Honda's \"Power of Dreams\" advertising campaign, which was the first cinema commercial to be shot in the IMAX format.\nIn 2013 he composed the music and provided the English-language vocals for the Hong Kong Disneyland attraction Mystic Manor.\nOn October 31, 2019, the MasterClass online educational series released \"Making Music out of Chaos,\" presenting 21 compositional and career lessons from Elfman's four decades of experience primarily in the film industry.\nElfman scored the 10-minute video \"Joe Biden,\" which introduced Joe Biden's acceptance of the presidential candidacy nomination at the 2020 Democratic National Convention.\nIn October 2020, Danny Elfman released a surprise single, \"Happy,\" on Anti- Records and Epitaph Records. He released the follow-up single \"Sorry\" on January 11, 2021, with plans to release a new single on the 11th of every month \"for the foreseeable future.\"\nInfluences and style.\nElfman has said his major influences are composers from Hollywood's Golden Age, such as Bernard Herrmann, Dimitri Tiomkin, Max Steiner, David Tamkin, Erich Wolfgang Korngold, and Carl Stalling; 20th century classical composers Sergei Prokofiev, Igor Stravinsky, B\u00e9la Bart\u00f3k, Dmitri Shostakovich, and Carl Orff; and jazz, experimental and minimalist composers Kurt Weill, Duke Ellington, Harry Partch, Philip Glass, Lou Harrison, Terry Riley, and Steve Reich. Influences on specific scores include Erik Satie (\"Forbidden Zone)\", Nino Rota (\"Pee-wee's Big Adventure\"), George Gershwin (\"Dick Tracy\"), Pyotr Ilyich Tchaikovsky (\"Edward Scissorhands\"), and Jimi Hendrix (\"Dead Presidents\"). Though not considered direct influences \"per se\", Elfman has discussed his respect and admiration for film composers Jerry Goldsmith, Ennio Morricone, Thomas Newman, Alexandre Desplat and John Williams, as well as classical composer John Adams.\nThough many believe Richard Wagner informed his influential score to \"Batman\", Elfman has said it was more likely from Wagner's influence on classic film composers such as Herrmann, Steiner, Waxman and Korngold, as he was unfamiliar with Wagner's work at the time.\nElfman counts Herrmann as his biggest influence, and has said hearing Herrmann's score to \"The Day the Earth Stood Still\" when he was a child was the first time he recognized film music as a cinematic artform and realized the powerful contribution a composer makes to the movies. Pastiche of Herrmann's music can be heard in Elfman's \"Pee-Wee's Big Adventure,\" especially the cues \"Stolen Bike\" and \"Clown Attack\", which directly reference Herrmann's music from \"Psycho\" and \"7th Voyage of Sinbad\" respectively. His score to \"Batman\" makes more subtle nods to Herrmann's \"Journey to the Center of the Earth\" and \"Vertigo\", and more integral homage can be heard in later scores for \"Mars Attacks!\" and \"Hitchcock,\" as well as the \"Blue Strings\" movement of his first concert work \"Serenada Schizophrana\".\nWhile Elfman is primarily known for writing large-scale orchestral works in the romantic, 20th century and Hollywood Golden Age film score traditions, his compositions have used a wide range of idioms, including rock and blues (\"Midnight Run, Hot to Trot\"), big band and jazz (\"Dick Tracy\", \"Chicago\"), operetta (\"The Nightmare Before Christmas\", \"Corpse Bride\"), funk and hip hop (\"Dead presidents\", \"Notorious\"), folk and indie rock (\"Taking Woodstock\", \"Silver Linings Playbook\"), Americana (\"Article 99\", \"Sommersby\", \"Big Fish),\" minimalism (\"Good Will Hunting\", \"Standard Operating Procedure\", \"The Unknown Known\"), and atonal or experimental (\"Freeway\", \"A Simple Plan, The Girl on the Train\").\nGiven his appreciation and study of world music and his vast collection of instruments from non-Western cultures, Elfman will often use traditional instruments in his scores when there is an international setting, such as African percussion for \"Instinct,\" the oud for \"The Kingdom\" set in Saudi Arabia, and pan flute for \"Proof of Life\" set in South America.\nWhen working on films with established musical identifiers, Elfman will often incorporate original themes in addition to his own thematic material. Examples include Lalo Schifrin's main theme and \"The Plot\" from the original for \"\"; John Williams' theme for \"Superman\", the Hans Zimmer/Junkie XL theme for \"Wonder Woman\" and his own original \"Batman\" theme for \"Justice League;\" the \"Welcome Christmas\" song from the 1966 \"How the Grinch Stole Christmas!\" for \"The Grinch\"; and \"Casey Junior,\" \"Pink Elephants on Parade,\" and \"When I See an Elephant Fly\" from Disney's original 1941 animated film for \"Dumbo\".\nEven when not directly quoting themes from related films, Elfman will often pay homage through established musical gesture or tonality, for example Howard Shore's \"The Silence of the Lambs\" for \"Red Dragon\", Brad Fiedel's music for the \"Terminator\" franchise for \"Terminator Salvation\", Robert Cobert's original television series music for \"Dark Shadows,\" and Alan Silvestri's work on \"The Avengers\" for the sequel \"\". Notable exceptions are Tim Burton's \"Batman\", \"Planet of the Apes\" and \"Charlie and the Chocolate Factory,\" which do not make musical reference to pre existing material.\nThe songs for \"The Nightmare Before Christmas\" and \"Corpse Bride\" were influenced by Kurt Weill, Gilbert and Sullivan and early Rodgers and Hammerstein. At the request of Tim Burton, \"Charlie and the Chocolate Factory\" songs drew inspiration from Bollywood, The Mamas and the Papas, ABBA, Queen, and Earth, Wind &amp; Fire individually.\nElfman's work in pop music and specifically as songwriter for Oingo Boingo was influenced by The Specials, Madness, the Selecter, and XTC.\nProcess.\nFilm music.\nFor his film scores, Elfman draws musical inspiration almost exclusively from viewing a cut of the film, and occasionally from visits to the set while the film is in production (he wrote and orchestrated his theme for \"Batman\" on an airplane to Los Angeles after visiting the set in London). While he prefers not to work from script, story or concept, notable exceptions are \"The Nightmare Before Christmas,\" for which ten songs needed to be written in advance of filmmaking, and \"Dumbo,\" for which he composed the main theme before filming began.\nOnce a rough cut of the film is ready, Elfman and the director have a spotting session to decide where to place music in the film, the emotional undercurrents of each scene, and overall tone. Elfman then spends a few weeks of free composition and experimentation to begin working out thematic material and to develop sounds and the harmonic pallette.\nWhen he has received approval on initial material from the filmmakers, Elfman begins to compose anywhere from 60 to 120 minutes of music cue-by-cue. He says two of the most important things to capture at this point are the tone of each scene and editorial rhythm. Next to thematic development, action set pieces tend to take Elfman the most time given the complexity of timing music to action. One element where Elfman's compositional process deviates from most film composers is that he will often compose three or more often radically different versions of a single cue to give the director more options for musicalizing a scene.\nEarly in his career, he wrote out his scores using pencil, but has composed largely digitally since the mid-1990s.\nBefore recording the score, he demos each cue by mocking orchestral and choral parts on synthesizer to get approval from the director. Once approved, he provides a detailed, multi-line sketch of his composition to his lead orchestrator Steve Bartek, who ensures the sketches are appropriately broken down for sections of the orchestra (i.e. string, brass woodwind, some percussion), choir (SATB) and individual players.\nElfman also typically samples or records his own percussion and guitar playing to overlay with live orchestra. More than half of some scores feature Elfman's performance, including \"Dead presidents\", \"\", \"Planet of the Apes\", \"The Kingdom\", \"The Girl on the Train\" and \"The Circle.\"\nTo produce the score, Elfman rents a recording studio and hires a conductor and orchestra/choir. He oversees the recording from the control booth so that he can troubleshoot with the film's director and recording engineers. The final recording is given to the film's sound department to mix with dialogue and sound effects for the film's complete soundtrack. Elfman will usually do a separate mix of select cues for an album presentation of the score, and has produced nearly 100 to date.\nOn the occasion that there are compressed deadlines or in the event he is not available to rescore or adapt his music if there are major edits to the film after the score's completion, Elfman will hire additional composers to work on small cues or sections of cues, adapting his existing material or themes. Examples include Jonathan Sheffer on \"Darkman\", David Buckley on the \"Fifty Shades of Grey\" films, and Pinar Toprak on \"Justice League.\" Since the 1990s, Elfman has occasionally co-composed music or shared music writing credit (e.g.\"When We Rise\", \"Spy Kids\", \", \"), or written themes that are then used or adapted by other composers, including Jonathan Sheffer (\"Pure Luck\"), Steve Bartek (\"Novacaine\"), John Debney (\"Heartbreakers),\" Deborah Lurie (\"9\"), and The Newton Brothers (\"Before I Wake\").\nConcert music.\nIn the liner notes for the 2006 CD recording of his first concert work \"Serenada Schizophrana\", Elfman wrote: \"I began composing several dozen short improvisational compositions, maybe a minute each. Slowly, some of them began to develop themselves until finally I had six separate movements that, in some abstract, absurd way, felt connected.\"\nTo create the cadenzas for his violin concerto \"Eleven Eleven\", Elfman collaborated with soloist Sandy Cameron, for whom the piece was written.\nVocals.\nElfman often incorporates choral or vocal arrangements into his film scores, notably the use of women's and children's choirs (\"Scrooged\", \"Nightbreed, Edward Scissorhands, Batman Returns\", \"Sleepy Hollow, Alice in Wonderland\", \"The Grinch\"), and solo voice or vocal effects (\"Beetlejuice\", \"Mars Attacks!\", \"Men in Black II\", \"Flubber\", \"Nacho Libre\", \"Iris\", \"Dark Shadows\", \"The Girl on the Train\"). Evoking the \"O Fortuna\" from Carl Orff's \"Carmina Burana\", he set made-up, Latin-sounding text for SATB choir in standout cue \"Descent into Mystery\" from \"Batman.\"\nElfman also adds his own vocals into compositions in much the same way he mixes his percussion and guitar performances into orchestral arrangements. Prominent use can be heard in the scores for \"To Die For\" (sung with director Gus Van Sant, credited to \"Little Gus and the Suzettes\"), \"Silver Linings Playbook\", and his music for the Hong Kong Disneyland ride Mystic Manor. He provided the singing voice for characters in \"The Nightmare Before Christmas\" and \"Corpse Bride\" in addition to composing the scores and songs\",\" and can be heard singing the \"Day-O\" call in the style of Harry Belafonte's \"Banana Boat Song\" in the first bars of the \"Beetlejuice\" main title.\nFor Tim Burton's \"Charlie and the Chocolate Factory,\" Elfman set Roald Dahl's text for the Oompa-Loompa characters as four stylistically distinct songs: the Bollywood-influenced \"Augustus Gloop,\" the funk-infused \"Violet Beauregarde,\" the psychedelic pop stylings of \"Veruca Salt,\" and the baroque rock of \"Mike Teevee.\" For all songs in the film, Elfman sang, manipulated and mixed several layers of his vocals to create the singing voices and harmonies of the Oompa Loompas, and incorporated his vocals into non-song score tracks that featured the characters, including \"Loompa Land,\" \"Chocolate River,\" \"The Boat Arrives,\" and \"The River Cruise.\"\nLyrics.\nRare among film composers, Elfman typically writes the lyrics to songs he has composed for movies. He employs song structures from Tin Pan Alley and early musical theatre composers (32-bar form), and pop and rock of the 1950s and 1960s (verse-chorus). As his songs serve to advance the plot and develop characters, lyrics reflect storylines and imagery specific to the film and express the inner life of characters.\nA major achievement was writing the lyrics and music for ten songs featured in the stop-motion musical \"The Nightmare Before Christmas\". Drawing from Tim Burton's parody poem of \"A Visit from St. Nicholas\" and concept drawings, Elfman wrote each song in consultation with Burton before the film even had a script. These include the full-cast songs \"This Is Halloween,\" \"Town Meeting Song,\" and \"Making Christmas\"; four songs for the main character Jack Skellington \"Jack's Lament,\" \"What's This,\" \"Jack's Obsession,\" and \"Poor Jack\" all sung by Elfman; and the other character songs \"Kidnap The Sandy Claws,\" \"Oogie Boogie's Song,\" and \"Sally's Song.\" An eleventh song, \"Finale/Reprise,\" reworks lyrics from the songs \"This Is Halloween,\" \"What's This\" and \"Sally's Song\" for the film's ending.\nThough uncredited, Burton contributed some lyrics to \"Nightmare\", including the line \"Perhaps it's the head that I found in the lake\" in \"Town Meeting Song.\"\nElfman composed five songs for Burton's \"Corpse Bride\": \"According to Plan\" with lyrics co-written by screenwriter John August; \"Remains of the Day,\" which he sung as the character Bonejangles, and \"Tears To Shed,\" both with additional lyrics by August, and \"The Wedding Song\" credited solely to Elfman. The song \"Erased\" was not used in the final film.\nHe wrote the lyrics to \"Lullaby\" from \"Charlotte's Web\", the rock track \"The Little Things\" from \"Wanted\" which he also sang in English and Russian, and \"Alice's Theme\" from \"Alice in Wonderland\". Elfman co-wrote the music and lyrics to Batman Returns's \"Face To Face\" with Siouxsie and the Banshees, and co-wrote the lyrics to \"Twice The Love\" from \"Big Fish\" and the \"Wonka's Welcome Song\" for \"Charlie and the Chocolate Factory\" with John August.\nElfman wrote the lyrics to all of Oingo Boingo's original songs 1979\u20131994 and has made residuals on the titular two-word opening phrase sung in his \"The Simpsons\" theme since the series first aired in 1989.\nPersonal life.\nAs a teenager, Elfman dated his classmate Kim Gordon, who would later become one of the members of the rock band Sonic Youth.\nHe has two daughters, Lola and Mali, from his marriage to Geri Eisenmenger. Mali is a film producer and actress. Elfman and his daughter collaborated on her 2011 film \"Do Not Disturb\".\nOn November 29, 2003, Elfman married actress Bridget Fonda. They have a son, Oliver. In 1998, Elfman scored \"A Simple Plan\", starring Fonda.\nHe is the uncle of actor Bodhi Elfman, who is married to actress Jenna Elfman.\nElfman has been an atheist since the age of 11 or 12. According to him, he is a cynicologist.\nDescribing his politics during the 1980s, Elfman said, \"I'm not a doomist. My attitude is always to be critical of what's around you, but not ever to forget how lucky we are. I've traveled around the world. I left thinking I was a revolutionary. I came back real right-wing patriotic. Since then, I've kind of mellowed in between.\" Several of his songs written for Oingo Boingo during this period satirized social politics, although Elfman stated his message was to \"question, resist, challenge\" and that his songs were not aligned to any one political agenda.\nIn 2008, Elfman expressed support for Barack Obama. For the 2020 Democratic National Convention, he scored the biographical video played ahead of Joe Biden's acceptance of the presidential nomination in the 2020 United States elections. In a series of posts on his Instagram page discussing the video, Elfman criticized Donald Trump, Richard Nixon, and the electoral college, and linked to several voter resources.\nDuring his 18 years with Oingo Boingo, Elfman developed significant hearing damage as a result of the continuous exposure to the high noise levels involved in performing in a rock band. Afraid of worsening his condition, he decided to leave the band, saying that he would never return to that kind of performance. His impairment was so bad that he could not \"even sit in a loud restaurant or bar anymore.\" However, he found performing in front of orchestras more tolerable, and returned several times to reprise his live performance of Jack Skellington.\nOn June 25, 2019, \"The New York Times Magazine\" listed Danny Elfman among hundreds of artists whose material was reportedly destroyed in the 2008 Universal fire.\nIn popular culture.\nSince \"The Simpsons\"' second annual \"Treehouse of Horror\" episode aired in 1991, launching \"scary names\" tradition in the opening and closing titles, Elfman has been alternately credited for the theme music as \"Red Wolf Elfman,\" \"Danny Skellingelfman,\" \"Li'l Leakin Brain Elfman,\" \"Boris Elfmonivich,\" \"Danny Elfblood,\" \"Danny 'Hell'fman,\" \"The Bloody Elf,\" \"Danny Elfbones,\" \"Elfmunster\" and \"Daniel Beilzebelsman.\"\nElfman's composition \"Clown Dream\" from \"Pee-wee's Big Adventure\" is used in the video game \"Grand Theft Auto V\" and has often been used as the opening music for Primus concerts.\nIn the 2007 sixth season \"Star Wars\" parody \"Blue Harvest\", \"Family Guy\" lampooned Elfman's orchestral style. A scene shows Elfman replacing an incinerated John Williams to conduct a full orchestra playing the score, only to be decapitated by a lightsaber after conducting a few bars of oom-pah music.\nEpisode five of the 14th season of \"South Park\" in 2010 criticized Tim Burton for using the \"same\" music in all his films, referring to Elfman's scores.\nIn October 2016, Elfman produced a video clip for Funny or Die with original \"horror\" music composed to footage of Donald Trump pacing around Hillary Clinton at the second United States presidential election debates, 2016.\nIn 2019, selections from Elfman's \"Midnight Run\" score were used in the third season of Netflix's \"Stranger Things,\" including \"Stairway Chase\" in episodes 5 and 6, and \"Wild Ride\" and \"Package Deal\" in episode 6.\nAwards and nominations.\nAmerican Film Institute.\nElfman's scores for \"Batman\" and \"Edward Scissorhands\" were nominated for AFI's 100 Years of Film Scores.\nDiscography.\nIncluding commercial recordings of his film scores and the Oingo Boingo discography, Elfman has produced over 100 albums as of 2019."}
{"id": "8398", "revid": "33839581", "url": "https://en.wikipedia.org/wiki?curid=8398", "title": "Dimension", "text": "In physics and mathematics, the dimension of a mathematical space (or object) is informally defined as the minimum number of coordinates needed to specify any point within it. Thus a line has a dimension of one (1D) because only one coordinate is needed to specify a point on itfor example, the point at 5 on a number line. A surface such as a plane or the surface of a cylinder or sphere has a dimension of two (2D) because two coordinates are needed to specify a point on itfor example, both a latitude and longitude are required to locate a point on the surface of a sphere. The inside of a cube, a cylinder or a sphere is three-dimensional (3D) because three coordinates are needed to locate a point within these spaces.\nIn classical mechanics, space and time are different categories and refer to absolute space and time. That conception of the world is a four-dimensional space but not the one that was found necessary to describe electromagnetism. The four dimensions (4D) of spacetime consist of events that are not absolutely defined spatially and temporally, but rather are known relative to the motion of an observer. Minkowski space first approximates the universe without gravity; the pseudo-Riemannian manifolds of general relativity describe spacetime with matter and gravity. 10 dimensions are used to describe superstring theory (6D hyperspace + 4D), 11 dimensions can describe supergravity and M-theory (7D hyperspace + 4D), and the state-space of quantum mechanics is an infinite-dimensional function space.\nThe concept of dimension is not restricted to physical objects. s frequently occur in mathematics and the sciences. They may be parameter spaces or configuration spaces such as in Lagrangian or Hamiltonian mechanics; these are abstract spaces, independent of the physical space we live in.\nIn mathematics.\nIn mathematics, the dimension of an object is, roughly speaking, the number of degrees of freedom of a point that moves on this object. In other words, the dimension is the number of independent parameters or coordinates that are needed for defining the position of a point that is constrained to be on the object. For example, the dimension of a point is zero; the dimension of a line is one, as a point can move on a line in only one direction (or its opposite); the dimension of a plane is two, etc.\nThe dimension is an intrinsic property of an object, in the sense that it is independent of the dimension of the space in which the object is or can be embedded. For example, a curve, such as a circle, is of dimension one, because the position of a point on a curve is determined by its signed distance along the curve to a fixed point on the curve. This is independent from the fact that a curve cannot be embedded in a Euclidean space of dimension lower than two, unless it is a line.\nThe dimension of Euclidean -space is . When trying to generalize to other types of spaces, one is faced with the question \"what makes -dimensional?\" One answer is that to cover a fixed ball in by small balls of radius , one needs on the order of such small balls. This observation leads to the definition of the Minkowski dimension and its more sophisticated variant, the Hausdorff dimension, but there are also other answers to that question. For example, the boundary of a ball in looks locally like and this leads to the notion of the inductive dimension. While these notions agree on , they turn out to be different when one looks at more general spaces.\nA tesseract is an example of a four-dimensional object. Whereas outside mathematics the use of the term \"dimension\" is as in: \"A tesseract \"has four dimensions\"\", mathematicians usually express this as: \"The tesseract \"has dimension 4\"\", or: \"The dimension of the tesseract \"is\" 4\" or: 4D.\nAlthough the notion of higher dimensions goes back to Ren\u00e9 Descartes, substantial development of a higher-dimensional geometry only began in the 19th century, via the work of Arthur Cayley, William Rowan Hamilton, Ludwig Schl\u00e4fli and Bernhard Riemann. Riemann's 1854 Habilitationsschrift, Schl\u00e4fli's 1852 \"Theorie der vielfachen Kontinuit\u00e4t\", and Hamilton's discovery of the quaternions and John T. Graves' discovery of the octonions in 1843 marked the beginning of higher-dimensional geometry.\nThe rest of this section examines some of the more important mathematical definitions of dimension.\nVector spaces.\nThe dimension of a vector space is the number of vectors in any basis for the space, i.e. the number of coordinates necessary to specify any vector. This notion of dimension (the cardinality of a basis) is often referred to as the \"Hamel dimension\" or \"algebraic dimension\" to distinguish it from other notions of dimension.\nFor the non-free case, this generalizes to the notion of the length of a module.\nManifolds.\nThe uniquely defined dimension of every connected topological manifold can be calculated. A connected topological manifold is locally homeomorphic to Euclidean -space, in which the number is the manifold's dimension.\nFor connected differentiable manifolds, the dimension is also the dimension of the tangent vector space at any point.\nIn geometric topology, the theory of manifolds is characterized by the way dimensions 1 and 2 are relatively elementary, the high-dimensional cases are simplified by having extra space in which to \"work\"; and the cases and are in some senses the most difficult. This state of affairs was highly marked in the various cases of the Poincar\u00e9 conjecture, where four different proof methods are applied.\nComplex dimension.\nThe dimension of a manifold depends on the base field with respect to which Euclidean space is defined. While analysis usually assumes a manifold to be over the real numbers, it is sometimes useful in the study of complex manifolds and algebraic varieties to work over the complex numbers instead. A complex number (\"x\" + \"iy\") has a real part \"x\" and an imaginary part \"y\", where x and y are both real numbers; hence, the complex dimension is half the real dimension.\nConversely, in algebraically unconstrained contexts, a single complex coordinate system may be applied to an object having two real dimensions. For example, an ordinary two-dimensional spherical surface, when given a complex metric, becomes a Riemann sphere of one complex dimension.\nVarieties.\nThe dimension of an algebraic variety may be defined in various equivalent ways. The most intuitive way is probably the dimension of the tangent space at any Regular point of an algebraic variety. Another intuitive way is to define the dimension as the number of hyperplanes that are needed in order to have an intersection with the variety that is reduced to a finite number of points (dimension zero). This definition is based on the fact that the intersection of a variety with a hyperplane reduces the dimension by one unless if the hyperplane contains the variety.\nAn algebraic set being a finite union of algebraic varieties, its dimension is the maximum of the dimensions of its components. It is equal to the maximal length of the chains formula_1 of sub-varieties of the given algebraic set (the length of such a chain is the number of \"formula_2\").\nEach variety can be considered as an algebraic stack, and its dimension as variety agrees with its dimension as stack. There are however many stacks which do not correspond to varieties, and some of these have negative dimension. Specifically, if \"V\" is a variety of dimension \"m\" and \"G\" is an algebraic group of dimension \"n\" acting on \"V\", then the quotient stack [\"V\"/\"G\"] has dimension \"m\"\u00a0\u2212\u00a0\"n\".\nKrull dimension.\nThe Krull dimension of a commutative ring is the maximal length of chains of prime ideals in it, a chain of length \"n\" being a sequence formula_3 of prime ideals related by inclusion. It is strongly related to the dimension of an algebraic variety, because of the natural correspondence between sub-varieties and prime ideals of the ring of the polynomials on the variety.\nFor an algebra over a field, the dimension as vector space is finite if and only if its Krull dimension is 0.\nTopological spaces.\nFor any normal topological space , the Lebesgue covering dimension of is defined to be the smallest integer \"n\" for which the following holds: any open cover has an open refinement (a second open cover where each element is a subset of an element in the first cover) such that no point is included in more than elements. In this case dim . For a manifold, this coincides with the dimension mentioned above. If no such integer exists, then the dimension of is said to be infinite, and one writes dim . Moreover, has dimension \u22121, i.e. dim if and only if is empty. This definition of covering dimension can be extended from the class of normal spaces to all Tychonoff spaces merely by replacing the term \"open\" in the definition by the term \"functionally open\".\nAn inductive dimension may be defined inductively as follows. Consider a discrete set of points (such as a finite collection of points) to be 0-dimensional. By dragging a 0-dimensional object in some direction, one obtains a 1-dimensional object. By dragging a 1-dimensional object in a \"new direction\", one obtains a 2-dimensional object. In general one obtains an ()-dimensional object by dragging an -dimensional object in a \"new\" direction. The inductive dimension of a topological space may refer to the \"small inductive dimension\" or the \"large inductive dimension\", and is based on the analogy that, in the case of metric spaces, balls have -dimensional boundaries, permitting an inductive definition based on the dimension of the boundaries of open sets. Moreover, the boundary of a discrete set of points is the empty set, and therefore the empty set can be taken to have dimension -1.\nSimilarly, for the class of CW complexes, the dimension of an object is the largest for which the -skeleton is nontrivial. Intuitively, this can be described as follows: if the original space can be continuously deformed into a collection of higher-dimensional triangles joined at their faces with a complicated surface, then the dimension of the object is the dimension of those triangles.\nHausdorff dimension.\nThe Hausdorff dimension is useful for studying structurally complicated sets, especially fractals. The Hausdorff dimension is defined for all metric spaces and, unlike the dimensions considered above, can also have non-integer real values. The box dimension or Minkowski dimension is a variant of the same idea. In general, there exist more definitions of fractal dimensions that work for highly irregular sets and attain non-integer positive real values. Fractals have been found useful to describe many natural objects and phenomena.\nHilbert spaces.\nEvery Hilbert space admits an orthonormal basis, and any two such bases for a particular space have the same cardinality. This cardinality is called the dimension of the Hilbert space. This dimension is finite if and only if the space's Hamel dimension is finite, and in this case the two dimensions coincide.\nIn physics.\nSpatial dimensions.\nClassical physics theories describe three physical dimensions: from a particular point in space, the basic directions in which we can move are up/down, left/right, and forward/backward. Movement in any other direction can be expressed in terms of just these three. Moving down is the same as moving up a negative distance. Moving diagonally upward and forward is just as the name of the direction implies; \"i.e.\", moving in a linear combination of up and forward. In its simplest form: a line describes one dimension, a plane describes two dimensions, and a cube describes three dimensions. (See Space and Cartesian coordinate system.)\nTime.\nA temporal dimension, or time dimension, is a dimension of time. Time is often referred to as the \"fourth dimension\" for this reason, but that is not to imply that it is a spatial dimension. A temporal dimension is one way to measure physical change. It is perceived differently from the three spatial dimensions in that there is only one of it, and that we cannot move freely in time but subjectively move in one direction.\nThe equations used in physics to model reality do not treat time in the same way that humans commonly perceive it. The equations of classical mechanics are symmetric with respect to time, and equations of quantum mechanics are typically symmetric if both time and other quantities (such as charge and parity) are reversed. In these models, the perception of time flowing in one direction is an artifact of the laws of thermodynamics (we perceive time as flowing in the direction of increasing entropy).\nThe best-known treatment of time as a dimension is Poincar\u00e9 and Einstein's special relativity (and extended to general relativity), which treats perceived space and time as components of a four-dimensional manifold, known as spacetime, and in the special, flat case as Minkowski space.\nAdditional dimensions.\nIn physics, three dimensions of space and one of time is the accepted norm. However, there are theories that attempt to unify the four fundamental forces by introducing extra dimensions/hyperspace. Most notably, superstring theory requires 10 spacetime dimensions, and originates from a more fundamental 11-dimensional theory tentatively called M-theory which subsumes five previously distinct superstring theories. Supergravity theory also promotes 11D spacetime = 7D hyperspace + 4 common dimensions. To date, no direct experimental or observational evidence is available to support the existence of these extra dimensions. If hyperspace exists, it must be hidden from us by some physical mechanism. One well-studied possibility is that the extra dimensions may be \"curled up\" at such tiny scales as to be effectively invisible to current experiments. Limits on the size and other properties of extra dimensions are set by particle experiments such as those at the Large Hadron Collider.\nIn 1921, Kaluza-Klein theory presented 5D including an extra dimension of space. At the level of quantum field theory, Kaluza\u2013Klein theory unifies gravity with gauge interactions, based on the realization that gravity propagating in small, compact extra dimensions is equivalent to gauge interactions at long distances. In particular when the geometry of the extra dimensions is trivial, it reproduces electromagnetism. However at sufficiently high energies or short distances, this setup still suffers from the same pathologies that famously obstruct direct attempts to describe quantum gravity. Therefore, these models still require a UV completion, of the kind that string theory is intended to provide. In particular, superstring theory requires six compact dimensions (6D hyperspace) forming a Calabi\u2013Yau manifold. Thus Kaluza-Klein theory may be considered either as an incomplete description on its own, or as a subset of string theory model building.\nIn addition to small and curled up extra dimensions, there may be extra dimensions that instead aren't apparent because the matter associated with our visible universe is localized on a subspace. Thus the extra dimensions need not be small and compact but may be large extra dimensions. D-branes are dynamical extended objects of various dimensionalities predicted by string theory that could play this role. They have the property that open string excitations, which are associated with gauge interactions, are confined to the brane by their endpoints, whereas the closed strings that mediate the gravitational interaction are free to propagate into the whole spacetime, or \"the bulk\". This could be related to why gravity is exponentially weaker than the other forces, as it effectively dilutes itself as it propagates into a higher-dimensional volume.\nSome aspects of brane physics have been applied to cosmology. For example, brane gas cosmology attempts to explain why there are three dimensions of space using topological and thermodynamic considerations. According to this idea it would be because three is the largest number of spatial dimensions where strings can generically intersect. If initially there are many windings of strings around compact dimensions, space could only expand to macroscopic sizes once these windings are eliminated, which requires oppositely wound strings to find each other and annihilate. But strings can only find each other to annihilate at a meaningful rate in three dimensions, so it follows that only three dimensions of space are allowed to grow large given this kind of initial configuration.\nExtra dimensions are said to be universal if all fields are equally free to propagate within them.\nIn computer graphics and spatial data.\nSeveral types of digital systems are based on the storage, analysis, and visualization of geometric shapes, including illustration software, Computer-aided design, and Geographic information systems. Different vector systems use a wide variety of data structures to represent shapes, but almost all are fundamentally based on a set of geometric primitives corresponding to the spatial dimensions:\nFrequently in these systems, especially GIS and Cartography, a representation of a real-world phenomena may have a different (usually lower) dimension than the phenomenon being represented. For example, a city (a two-dimensional region) may be represented as a point, or a road (a three-dimensional volume of material) may be represented as a line. This \"dimensional generalization\" correlates with tendencies in spatial cognition. For example, asking the distance between two cities presumes a conceptual model of the cities as points, while giving directions involving travel \"up,\" \"down,\" or \"along\" a road imply a one-dimensional conceptual model. This is frequently done for purposes of data efficiency, visual simplicity, or cognitive efficiency, and is acceptable if the distinction between the representation and the represented is understood, but can cause confusion if information users assume that the digital shape is a perfect representation of reality (i.e., believing that roads really are lines).\nNetworks and dimension.\nSome complex networks are characterized by fractal dimensions. The concept of dimension can be generalized to include networks embedded in space. The dimension characterize their spatial constraints.\nIn literature.\nScience fiction texts often mention the concept of \"dimension\" when referring to parallel or alternate universes or other imagined planes of existence. This usage is derived from the idea that to travel to parallel/alternate universes/planes of existence one must travel in a direction/dimension besides the standard ones. In effect, the other universes/planes are just a small distance away from our own, but the distance is in a fourth (or higher) spatial (or non-spatial) dimension, not the standard ones.\nOne of the most heralded science fiction stories regarding true geometric dimensionality, and often recommended as a starting point for those just starting to investigate such matters, is the 1884 novella \"Flatland\" by Edwin A. Abbott. Isaac Asimov, in his foreword to the Signet Classics 1984 edition, described \"Flatland\" as \"The best introduction one can find into the manner of perceiving dimensions.\"\nThe idea of other dimensions was incorporated into many early science fiction stories, appearing prominently, for example, in Miles J. Breuer's \"The Appendix and the Spectacles\" (1928) and Murray Leinster's \"The Fifth-Dimension Catapult\" (1931); and appeared irregularly in science fiction by the 1940s. Classic stories involving other dimensions include Robert A. Heinlein's \"\u2014And He Built a Crooked House\" (1941), in which a California architect designs a house based on a three-dimensional projection of a tesseract; and Alan E. Nourse's \"Tiger by the Tail\" and \"The Universe Between\" (both 1951). Another reference is Madeleine L'Engle's novel \"A Wrinkle In Time\" (1962), which uses the fifth dimension as a way for \"tesseracting the universe\" or \"folding\" space in order to move across it quickly. The fourth and fifth dimensions are also a key component of the book \"The Boy Who Reversed Himself\" by William Sleator.\nIn philosophy.\nImmanuel Kant, in 1783, wrote: \"That everywhere space (which is not itself the boundary of another space) has three dimensions and that space in general cannot have more dimensions is based on the proposition that not more than three lines can intersect at right angles in one point. This proposition cannot at all be shown from concepts, but rests immediately on intuition and indeed on pure intuition \"a priori\" because it is apodictically (demonstrably) certain.\"\n\"Space has Four Dimensions\" is a short story published in 1846 by German philosopher and experimental psychologist Gustav Fechner under the pseudonym \"Dr. Mises\". The protagonist in the tale is a shadow who is aware of and able to communicate with other shadows, but who is trapped on a two-dimensional surface. According to Fechner, this \"shadow-man\" would conceive of the third dimension as being one of time. The story bears a strong similarity to the \"Allegory of the Cave\" presented in Plato's \"The Republic\" (c. 380\u00a0BC).\nSimon Newcomb wrote an article for the \"Bulletin of the American Mathematical Society\" in 1898 entitled \"The Philosophy of Hyperspace\". Linda Dalrymple Henderson coined the term \"hyperspace philosophy\", used to describe writing that uses higher dimensions to explore metaphysical themes, in her 1983 thesis about the fourth dimension in early-twentieth-century art. Examples of \"hyperspace philosophers\" include Charles Howard Hinton, the first writer, in 1888, to use the word \"tesseract\"; and the Russian esotericist P. D. Ouspensky."}
{"id": "8399", "revid": "2952402", "url": "https://en.wikipedia.org/wiki?curid=8399", "title": "Dissolve", "text": "Dissolve may refer to:"}
{"id": "8400", "revid": "169132", "url": "https://en.wikipedia.org/wiki?curid=8400", "title": "Duodecimal", "text": "The duodecimal system (also known as base 12, dozenal, or, rarely, uncial) is a positional notation numeral system using twelve as its base. The number twelve (that is, the number written as \"12\" in the base ten numerical system) is instead written as \"10\" in duodecimal (meaning \"1 dozen and 0 units\", instead of \"1 ten and 0 units\"), whereas the digit string \"12\" means \"1 dozen and 2 units\" (i.e. the same number that in decimal is written as \"14\"). Similarly, in duodecimal \"100\" means \"1 gross\", \"1000\" means \"1 great gross\", and \"0.1\" means \"1 twelfth\" (instead of their decimal meanings \"1 hundred\", \"1 thousand\", and \"1 tenth\").\nThe number twelve, a superior highly composite number, is the smallest number with four non-trivial factors (2, 3, 4, 6), and the smallest to include as factors all four numbers (1 to 4) within the subitizing range, and the smallest abundant number. As a result of this increased factorability of the radix and its divisibility by a wide range of the most elemental numbers (whereas ten has only two non-trivial factors: 2 and 5, and not 3, 4, or 6), duodecimal representations fit more easily than decimal ones into many common patterns, as evidenced by the higher regularity observable in the duodecimal multiplication table. As a result, duodecimal has been described as the optimal number system. Of its factors, 2 and 3 are prime, which means the reciprocals of all 3-smooth numbers (such as 2, 3, 4, 6, 8, 9, 12, 16, 18, 24, 27, 32, 36, ...) have a terminating representation in duodecimal. In particular, the five most elementary fractions (, , , and ) all have a short terminating representation in duodecimal (0.6, 0.4, 0.8, 0.3 and 0.9, respectively), and twelve is the smallest radix with this feature (because it is the least common multiple of 3 and 4). This all makes it a more convenient number system for computing fractions than most other number systems in common use, such as the decimal, vigesimal, binary, octal and hexadecimal systems. Although the trigesimal and sexagesimal systems (where the reciprocals of all 5-smooth numbers terminate) do even better in this respect, this is at the cost of unwieldy multiplication tables and a much larger number of symbols to memorize.\nVarious symbols have been used to stand for ten and eleven in duodecimal notation; Unicode includes () and (). Using these symbols, a count from zero to twelve in duodecimal reads: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, , , 10. These were implemented in Unicode 8.0 (2015), but most general Unicode fonts in use by current operating systems and browsers have not yet included them. A more common alternative is to use A and B, as in hexadecimal, and this page uses and .\nOrigin.\nLanguages using duodecimal number systems are uncommon. Languages in the Nigerian Middle Belt such as Janji, Gbiri-Niragu (Gure-Kahugu), Piti, and the Nimbia dialect of Gwandara; and the Chepang language of Nepal are known to use duodecimal numerals.\nGermanic languages have special words for 11 and 12, such as \"eleven\" and \"twelve\" in English. They come from Proto-Germanic *\"ainlif\" and *\"twalif\" (meaning, respectively \"one left\" and \"two left\"), suggesting a decimal rather than duodecimal origin. However, Old Norse used a duodecimal counting system, with its words for \"one hundred and eighty\" meaning 200 and \"two hundred\" meaning 240. On British Isles, this style of counting survived well into the middle ages as the long hundred.\nHistorically, units of time in many civilizations are duodecimal. There are twelve signs of the zodiac, twelve months in a year, and the Babylonians had twelve hours in a day (although at some point this was changed to 24). Traditional Chinese calendars, clocks, and compasses are based on the twelve Earthly Branches. There are 12\u00a0inches in an imperial foot, 12\u00a0troy ounces in a troy pound, 12\u00a0old British pence in a shilling, 24\u00a0(12\u00d72) hours in a day, and many other items counted by the dozen, gross (144, square of 12), or great gross (1728, cube of 12). The Romans used a fraction system based on 12, including the uncia which became both the English words \"ounce\" and \"inch\". Pre-decimalisation, Ireland and the United Kingdom used a mixed duodecimal-vigesimal currency system (12\u00a0pence = 1\u00a0shilling, 20\u00a0shillings or 240\u00a0pence to the pound sterling or Irish pound), and Charlemagne established a monetary system that also had a mixed base of twelve and twenty, the remnants of which persist in many places.\nThe importance of 12 has been attributed to the number of lunar cycles in a year as well as the fact that humans have 12 finger bones (phalanges) on one hand (three in each of four fingers). It is possible to count to 12 with the thumb acting as a pointer, touching each finger bone in turn. A traditional finger counting system still in use in many regions of Asia works in this way and could help to explain the occurrence of numeral systems based on 12 and 60 besides those based on 10, 20, and 5. In this system, the one (usually right) hand counts repeatedly to 12, displaying the number of iterations on the other (usually left), until five dozens, i.e. the 60, are full.\nNotations and pronunciations.\nTransdecimal symbols.\nIn a numbering system the base (twelve for duodecimal) must be written as 10, but there are numerous proposals for how to write duodecimal ten and eleven.\nTo allow entry on typewriters, letters such as A and B (as in hexadecimal), T and E (initials of Ten and Eleven), X and E (X from the Roman numeral for ten), or X and Z are used. Some employ Greek letters such as \u03b4 (standing for Greek \u03b4\u03ad\u03ba\u03b1 'ten') and \u03b5 (for Greek \u03ad\u03bd\u03b4\u03b5\u03ba\u03b1 'eleven'), or \u03c4 and \u03b5. Frank Emerson Andrews, an early American advocate for duodecimal, suggested and used in his book \"New Numbers\" an X and \u2130 (script E, ).\nEdna Kramer in her 1951 book \"The Main Stream of Mathematics\" used a six-pointed asterisk (sextile) \u26b9 and a hash (or octothorpe) #. The symbols were chosen because they were available on some typewriters; they are also on push-button telephones. This notation was used in publications of the Dozenal Society of America (DSA) from 1974\u20132008.\nFrom 2008 to 2015, the DSA used and , the symbols devised by William Addison Dwiggins.\nThe Dozenal Society of Great Britain (DSGB) proposed symbols and . This notation, derived from Arabic digits by 180\u00b0 rotation, was introduced by Isaac Pitman. In March 2013, a proposal was submitted to include the digit forms for ten and eleven propagated by the Dozenal Societies in the Unicode Standard. Of these, the British/Pitman forms were accepted for encoding as characters at code points and . They were included in the Unicode 8.0 release in June 2015 and are available in LaTeX as codice_1 and codice_2.\nAfter the Pitman digits were added to Unicode, the DSA took a vote and then began publishing content using the Pitman digits instead. They still use the letters X and E in ASCII text. As the Unicode characters are poorly supported, this page uses and .\nOther proposals are more creative or aesthetic; for example, many do not use any Arabic numerals under the principle of \"separate identity.\"\nBase notation.\nThere are also varying proposals of how to distinguish a duodecimal number from a decimal one. They include italicizing duodecimal numbers \"\"54\" = 64\", adding a \"Humphrey point\" (a semicolon instead of a decimal point) to duodecimal numbers \"54;6 = 64.5\", or some combination of the two. Others use subscript or affixed labels to indicate the base, allowing for more than decimal and duodecimal to be represented (for single letters 'z' from \"dozenal\" is used as 'd' would mean decimal) such as \"54z = 64d,\" \"5412 = 6410\" or \"doz 54 = dec 64.\"\nPronunciation.\nThe Dozenal Society of America suggested the pronunciation of ten and eleven as \"dek\" and \"el\". For the names of powers of twelve there are two prominent systems.\n\"Do-gro-mo\" system.\nIn this system, the prefix \"e\"- is added for fractions.\nMultiple digits in this series are pronounced differently: 12 is \"do two\"; 30 is \"three do\"; 100 is \"gro\"; 9 is \"el gro dek do nine\"; 86 is \"el gro eight do six\"; 8,15 is \"eight gro el do el mo, one gro five do dek\"; and so on.\nSystematic Dozenal Nomenclature (SDN).\nThis system uses \"-qua\" ending for the positive powers of 12 and \"-cia\" ending for the negative powers of 12, and an extension of the IUPAC systematic element names (with syllables dec and lev for the two extra digits needed for duodecimal) to express which power is meant.\nAdvocacy and \"dozenalism\".\nWilliam James Sidis used 12 as the base for his constructed language Vendergood in 1906, noting it being the smallest number with four factors and its prevalence in commerce.\nThe case for the duodecimal system was put forth at length in Frank Emerson Andrews' 1935 book \"New Numbers: How Acceptance of a Duodecimal Base Would Simplify Mathematics\". Emerson noted that, due to the prevalence of factors of twelve in many traditional units of weight and measure, many of the computational advantages claimed for the metric system could be realized \"either\" by the adoption of ten-based weights and measure \"or\" by the adoption of the duodecimal number system.\nBoth the Dozenal Society of America and the Dozenal Society of Great Britain promote widespread adoption of the base-twelve system. They use the word \"dozenal\" instead of \"duodecimal\" to avoid the more overtly base-ten terminology. However, the etymology of \"dozenal\" itself is also an expression based on base-ten terminology since \"dozen\" is a direct derivation of the French word \"douzaine\" which is a derivative of the French word for twelve, \"douze\", descended from Latin \"duodecim\".\nSince at least as far back as 1945 some members of the Dozenal Society of America and Dozenal Society of Great Britain have suggested that a more apt word would be \"uncial\". Uncial is a derivation of the Latin word \"uncia\", meaning \"one-twelfth\", and also the base-twelve analogue of the Latin word \"decima\", meaning \"one-tenth\".\nMathematician and mental calculator Alexander Craig Aitken was an outspoken advocate of duodecimal:\nIn media.\nIn \"Little Twelvetoes\", American television series \"Schoolhouse Rock!\" portrayed an alien child using base-twelve arithmetic, using \"dek\", \"el\" and \"doh\" as names for ten, eleven and twelve, and Andrews' script-X and script-E for the digit symbols.\nDuodecimal systems of measurements.\nSystems of measurement proposed by dozenalists include:\nComparison to other number systems.\nThe number 12 has six factors, which are 1, 2, 3, 4, 6, and 12, of which 2 and 3 are prime. The decimal system has only four factors, which are 1, 2, 5, and 10, of which 2 and 5 are prime. Vigesimal (base 20) adds two factors to those of ten, namely 4 and 20, but no additional prime factor. Although twenty has 6 factors, 2 of them prime, similarly to twelve, it is also a much larger base, and so the digit set and the multiplication table are much larger. Binary has only two factors, 1 and 2, the latter being prime. Hexadecimal (base 16) has five factors, adding 4, 8 and 16 to those of 2, but no additional prime. Trigesimal (base 30) is the smallest system that has three different prime factors (all of the three smallest primes: 2, 3 and 5) and it has eight factors in total (1, 2, 3, 5, 6, 10, 15, and 30). Sexagesimal\u2014which the ancient Sumerians and Babylonians among others actually used\u2014adds the four convenient factors 4, 12, 20, and 60 to this but no new prime factors. The smallest system that has four different prime factors is base 210 and the pattern follows the primorials. In all base systems, there are similarities to the representation of multiples of numbers which are one less than the base.\nConversion tables to and from decimal.\nTo convert numbers between bases, one can use the general conversion algorithm (see the relevant section under positional notation). Alternatively, one can use digit-conversion tables. The ones provided below can be used to convert any duodecimal number between 0;01 and ,; to decimal, or any decimal number between 0.01 and 999,999.99 to duodecimal. To use them, the given number must first be decomposed into a sum of numbers with only one significant digit each. For example:\nThis decomposition works the same no matter what base the number is expressed in. Just isolate each non-zero digit, padding them with as many zeros as necessary to preserve their respective place values. If the digits in the given number include zeroes (for example, 102,304.05), these are, of course, left out in the digit decomposition (102,304.05 = 100,000 + 2,000 + 300 + 4 + 0.05). Then the digit conversion tables can be used to obtain the equivalent value in the target base for each digit. If the given number is in duodecimal and the target base is decimal, we get:\nNow, because the summands are already converted to base ten, the usual decimal arithmetic is used to perform the addition and recompose the number, arriving at the conversion result:\n Duodecimal -----&gt; Decimal\n 100,000 = 248,832\n 20,000 = 41,472\n 3,000 = 5,184\n 400 = 576\n 50 = 60\n + 6 = + 6\n 0;7 = 0.58333333333...\n 0;08 = 0.05555555555...\n 123,456;78 = 296,130.63888888888...\nThat is, 123,456.78 equals 296,130.63 \u2248 296,130.64\nIf the given number is in decimal and the target base is duodecimal, the method is basically same. Using the digit conversion tables:\n 100,000 + 20,000 + 3,000 + 400 + 50 + 6 + 0.7 + 0.08 = 49,54 + ,68 + 1,80 + 294 + 42 + 6 + 0;84972497249724972497... + 0;062...\nHowever, in order to do this sum and recompose the number, now the addition tables for the duodecimal system have to be used, instead of the addition tables for decimal most people are already familiar with, because the summands are now in base twelve and so the arithmetic with them has to be in duodecimal as well. In decimal, 6 + 6 equals 12, but in duodecimal it equals 10; so, if using decimal arithmetic with duodecimal numbers one would arrive at an incorrect result. Doing the arithmetic properly in duodecimal, one gets the result:\n Decimal -----&gt; Duodecimal\n 100,000 = 49,54\n 20,000 = ,68\n 3,000 = 1,80\n 400 = 294\n 50 = 42\n + 6 = + 6\n 0;7 = 0.84972497249724972497...\n 0;08 = 0.062...\n 123,456.78 = 5,540.943...\nThat is, 123,456.78 equals 5,540;9... \u2248 5,540;94\nDivisibility rules.\nThis section is about the divisibility rules in duodecimal.\nAny integer is divisible by 1.\nIf a number is divisible by 2 then the unit digit of that number will be 0, 2, 4, 6, 8 or .\nIf a number is divisible by 3 then the unit digit of that number will be 0, 3, 6 or 9.\nIf a number is divisible by 4 then the unit digit of that number will be 0, 4 or 8.\nTo test for divisibility by 5, double the units digit and subtract the result from the number formed by the rest of the digits. If the result is divisible by 5 then the given number is divisible by 5.\nThis rule comes from 21(5*5)\nExamples: &lt;br&gt;\n13 \u00a0\u00a0\u00a0 rule =&gt; |1-2*3| = 5 which is divisible by 5.&lt;br&gt;\n25 \u00a0 rule =&gt; |2-2*5| = 20(5*70) which is divisible by 5(or apply the rule on 20).\nOR\nTo test for divisibility by 5, subtract the units digit and triple of the result to the number formed by the rest of the digits. If the result is divisible by 5 then the given number is divisible by 5.\nThis rule comes from 13(5*3)\nExamples: &lt;br&gt;\n13 \u00a0\u00a0\u00a0 rule =&gt; |3-3*1| = 0 which is divisible by 5.&lt;br&gt;\n25 \u00a0 rule =&gt; |5-3*2| = 81(5*195) which is divisible by 5(or apply the rule on 81).\nOR\nForm the alternating sum of blocks of two from right to left. If the result is divisible by 5 then the given number is divisible by 5.\nThis rule comes from 101, since 101 = 5*25, thus this rule can be also tested for the divisibility by 25.\nExample:\n97,374,627 =&gt; 27-46+37-97 = -7 which is divisible by 5.\nIf a number is divisible by 6 then the unit digit of that number will be 0 or 6.\nTo test for divisibility by 7, triple the units digit and add the result to the number formed by the rest of the digits. If the result is divisible by 7 then the given number is divisible by 7.\nThis rule comes from 2(7*5)\nExamples:&lt;br&gt;\n12\u00a0\u00a0\u00a0\u00a0\u00a0rule =&gt; |3*2+1| = 7 which is divisible by 7.&lt;br&gt;\n271\u00a0\u00a0\u00a0\u00a0rule =&gt; |3*+271| = 29(7*4) which is divisible by 7(or apply the rule on 29).\nOR\nTo test for divisibility by 7, subtract the units digit and double the result from the number formed by the rest of the digits. If the result is divisible by 7 then the given number is divisible by 7.\nThis rule comes from 12(7*2)\nExamples:&lt;br&gt;\n12\u00a0\u00a0\u00a0\u00a0\u00a0rule =&gt; |2-2*1| = 0 which is divisible by 7.&lt;br&gt;\n271\u00a0\u00a0\u00a0\u00a0rule =&gt; |-2*271| = 513(7*89) which is divisible by 7(or apply the rule on 513).\nOR\nTo test for divisibility by 7, 4 times the units digit and subtract the result from the number formed by the rest of the digits. If the result is divisible by 7 then the given number is divisible by 7.\nThis rule comes from 41(7*7)\nExamples:&lt;br&gt;\n12\u00a0\u00a0\u00a0\u00a0\u00a0rule =&gt; |4*2-1| = 7 which is divisible by 7.&lt;br&gt;\n271\u00a0\u00a0\u00a0\u00a0rule =&gt; |4*-271| = 235(7*3) which is divisible by 7(or apply the rule on 235).\nOR\nForm the alternating sum of blocks of three from right to left. If the result is divisible by 7 then the given number is divisible by 7.\nThis rule comes from 1001, since 1001 = 7*11*17, thus this rule can be also tested for the divisibility by 11 and 17.\nExample:\n386,967,443 =&gt; 443-967+386 = -168 which is divisible by 7.\nIf the 2-digit number formed by the last 2 digits of the given number is divisible by 8 then the given number is divisible by 8.\nExample: 148, 4120\n rule =&gt; since 48(8*7) divisible by 8, then 148 is divisible by 8.\n rule =&gt; since 20(8*3) divisible by 8, then 4120 is divisible by 8.\nIf the 2-digit number formed by the last 2 digits of the given number is divisible by 9 then the given number is divisible by 9.\nExample: 7423, 8330\n rule =&gt; since 23(9*3) divisible by 9, then 7423 is divisible by 9.\n rule =&gt; since 30(9*4) divisible by 9, then 8330 is divisible by 9.\nIf the number is divisible by 2 and 5 then the number is divisible by .\nIf the sum of the digits of a number is divisible by then the number is divisible by (the equivalent of casting out nines in decimal).\nExample: 29, 6113\n rule =&gt; 2+9 = which is divisible by , then 29 is divisible by .\n rule =&gt; 6+1++1+3 = 1 which is divisible by , then 6113 is divisible by .\nIf a number is divisible by 10 then the unit digit of that number will be 0.\nSum the alternate digits and subtract the sums. If the result is divisible by 11 the number is divisible by 11 (the equivalent of divisibility by eleven in decimal).\nExample: 66, 9427\n rule =&gt; |6-6| = 0 which is divisible by 11, then 66 is divisible by 11.\n rule =&gt; |(9+2)-(4+7)| = |-| = 0 which is divisible by 11, then 9427 is divisible by 11.\nIf the number is divisible by 2 and 7 then the number is divisible by 12.\nIf the number is divisible by 3 and 5 then the number is divisible by 13.\nIf the 2-digit number formed by the last 2 digits of the given number is divisible by 14 then the given number is divisible by 14.\nExample: 1468, 7394\n rule =&gt; since 68(14*5) divisible by 14, then 1468 is divisible by 14.\n rule =&gt; since 94(14*7) divisible by 14, then 7394 is divisible by 14.\nFractions and irrational numbers.\nFractions.\nDuodecimal fractions may be simple:\nor complicated:\nAs explained in recurring decimals, whenever an irreducible fraction is written in radix point notation in any base, the fraction can be expressed exactly (terminates) if and only if all the prime factors of its denominator are also prime factors of the base. Thus, in base-ten (= 2\u2009\u00d7\u20095) system, fractions whose denominators are made up solely of multiples of 2 and 5 terminate: \u00a0=\u00a0, \u00a0=\u00a0 and \u00a0=\u00a0 can be expressed exactly as 0.125, 0.05 and 0.002 respectively. and , however, recur (0.333... and 0.142857142857...). In the duodecimal (= 2\u2009\u00d7\u20092\u2009\u00d7\u20093) system, is exact; and recur because they include 5 as a factor; is exact; and recurs, just as it does in decimal.\nThe number of denominators which give terminating fractions within a given number of digits, say \"n\", in a base \"b\" is the number of factors (divisors) of \"bn\", the \"n\"th power of the base \"b\" (although this includes the divisor 1, which does not produce fractions when used as the denominator). The number of factors of \"bn\" is given using its prime factorization.\nFor decimal, 10\"n\" = 2\"n\" \u00d7 5\"n\". The number of divisors is found by adding one to each exponent of each prime and multiplying the resulting quantities together, so the number of factors of 10\"n\" is (\"n\" +\u20091)(\"n\" +\u20091) = (\"n\" +\u20091)2.\nFor example, the number 8 is a factor of 103 (1000), so 1/8 and other fractions with a denominator of 8 cannot require more than 3 fractional decimal digits to terminate. 5/8 = 0.625ten\nFor duodecimal, 12\"n\" = 22\"n\" \u00d7 3\"n\". This has (2\"n\" +\u20091)(\"n\" +\u20091) divisors. The sample denominator of 8 is a factor of a gross (122 =\u2009144), so eighths cannot need more than two duodecimal fractional places to terminate. 5/8 = 0;76twelve\nBecause both ten and twelve have two unique prime factors, the number of divisors of \"bn\" for \"b\" = 10 or 12 grows quadratically with the exponent \"n\" (in other words, of the order of \"n\"2).\nRecurring digits.\nThe Dozenal Society of America argues that factors of 3 are more commonly encountered in real-life division problems than factors of 5. Thus, in practical applications, the nuisance of repeating decimals is encountered less often when duodecimal notation is used. Advocates of duodecimal systems argue that this is particularly true of financial calculations, in which the twelve months of the year often enter into calculations.\nHowever, when recurring fractions \"do\" occur in duodecimal notation, they are less likely to have a very short period than in decimal notation, because 12 (twelve) is between two prime numbers, 11 (eleven) and 13 (thirteen), whereas ten is adjacent to the composite number 9. Nonetheless, having a shorter or longer period doesn't help the main inconvenience that one does not get a finite representation for such fractions in the given base (so rounding, which introduces inexactitude, is necessary to handle them in calculations), and overall one is more likely to have to deal with infinite recurring digits when fractions are expressed in decimal than in duodecimal, because one out of every three consecutive numbers contains the prime factor 3 in its factorization, whereas only one out of every five contains the prime factor 5. All other prime factors, except 2, are not shared by either ten or twelve, so they do not\ninfluence the relative likeliness of encountering recurring digits (any irreducible fraction that contains any of these other factors in its denominator will recur in either base). Also, the prime factor 2 appears twice in the factorization of twelve, whereas only once in the factorization of ten; which means that most fractions whose denominators are powers of two will have a shorter, more convenient terminating representation in duodecimal than in decimal representation (e.g. 1/(22) = 0.25ten = 0.3twelve; 1/(23) = 0.125ten = 0.16twelve; 1/(24) = 0.062510 = 0.0912; 1/(25) = 0.0312510 = 0.04612; etc.).\nThe duodecimal period length of 1/\"n\" are (in base 10)\nThe duodecimal period length of 1/(\"n\"th prime) are (in base 10)\nSmallest prime with duodecimal period \"n\" are (in base 10)\nIrrational numbers.\nThe representations of irrational numbers in any positional number system (including decimal and duodecimal) neither terminate nor repeat. The following table gives the first digits for some important algebraic and transcendental numbers in both decimal and duodecimal."}
{"id": "8401", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=8401", "title": "David Hayes Agnew", "text": "David Hayes Agnew (November 24, 1818March 22, 1892) was an American surgeon.\nBiography.\nAgnew was born on November 24, 1818, Nobleville, Pennsylvania (present-day Christiana). His parents were Robert Agnew and Agnes Noble. Agnew grew up as a Christian. He was surrounded by a family of doctors and had always known he was going to become a physician. As a young boy, he had a sharp sense of humor and was very intelligent. \nHe was educated at Jefferson College, and at Delaware College in Newark, Delaware. He graduated from the University of Pennsylvania School of Medicine on April 6, 1838. He returned to Nobleville to help his father in his clinic. He worked there for two years. His father was an asthmatic and moved to Maryland in 1840 because the climate was more suited to his condition. Agnew moved with him. On November 21, 1841, he married Margaret Irwin. In 1852, he bought and revived the Philadelphia School of Anatomy. He held responsibility for ten years until 1862. During the American Civil War he was consulting surgeon in the Mower Army Hospital, near Philadelphia, and acquired a considerable reputation for his operations in cases of gunshot wounds. On December 21, 1863, he became the Demonstrator of Anatomy and Assistant Lecturer on Clinical Surgery at The University of Pennsylvania. Later, he was requested to assist the Professor of Surgery in the Conduct of the surgical clinics. In the year 1865, he gave summer instruction courses. For the next seven years, he worked for the University as Demonstrator of Anatomy. A large portion of his success was due to his wife's energy, intelligence, and determination. She gave him an impetus to try harder and not be satisfied with his first try.\nGarfield case.\nOn July 2, 1881, President James A. Garfield was shot by Charles J. Guiteau. He held the position of chief consulting surgeon. When a committee came to give him his money for helping, Agnew said, \"Gentlemen, I present no bill for my attendance to President Garfield. I gave my services freely and gratuitously\". He was never optimistic about the President's case and was not fooled by fallacious beliefs. This procedure helped create Agnew's reputation.\n\"The Agnew Clinic\".\n\"The Agnew Clinic\" is an 1889 painting by Thomas Eakins which depicts Agnew conducting a mastectomy operation before a gallery of students and doctors.\nAccomplishments.\nDavid Agnew wrote \"The Principles and Practice of Surgery\", covers an experience of fifty active years, and its value, preserving and presenting as it does the life-work of such a recognized authority, can hardly be overrated. It was a three-volume set that he published from 1878\u20131883. He also helped found the Irwin &amp; Agnew Iron Foundry in 1846.\nDeath.\nAgnew caught a severe attack of epidemic influenza in 1890. He never fully recovered. Following this, he had an attack of broncho-vesicular catarrh. On March 9, 1892, he was put to bed for a series of medical problems. After a few days his condition began to improve, but suddenly, on March 12 it became much worse. On March 20, he fell into a comatose condition. Agnew stayed like this until he died at 3:20\u00a0p.m. on March 22, 1892. He is now buried in West Laurel Hill Cemetery.\nReferences.\nCitations\nSources"}
{"id": "8402", "revid": "35687467", "url": "https://en.wikipedia.org/wiki?curid=8402", "title": "Diving (sport)", "text": "Diving is the sport of jumping or falling into water from a platform or springboard, usually while performing acrobatics. Diving is an internationally recognized sport that is part of the Olympic Games. In addition, unstructured and non-competitive diving is a recreational pastime.\nCompetitors possess many of the same characteristics as gymnasts and dancers, including strength, flexibility, kinaesthetic judgment and air awareness. Some professional divers were originally gymnasts or dancers as both the sports have similar characteristics to diving. Dmitri Sautin holds the record for most Olympic diving medals won, by winning eight medals in total between 1992 and 2008.\nHistory.\nPlunging.\nAlthough diving has been a popular pastime across the world since ancient times, the first modern diving competitions were held in England in the 1880s. The exact origins of the sport are unclear, though it likely derives from the act of diving at the start of swimming races. The 1904 book \"Swimming\" by Ralph Thomas notes English reports of plunging records dating back to at least 1865. The 1877 edition to \"British Rural Sports\" by John Henry Walsh makes note of a \"Mr. Young\" plunging in 1870, and also states that 25 years prior, a swimmer named Drake could cover .\nThe English Amateur Swimming Association (at the time called the Swimming Association of Great Britain) first started a \"plunging championship\" in 1883. The Plunging Championship was discontinued in 1937.\nFancy diving.\nDiving into a body of water had also been a method used by gymnasts in Germany and Sweden since the early 19th century. The soft landing allowed for more elaborate gymnastic feats in midair as the jump could be made from a greater height. This tradition evolved into 'fancy diving', while diving as a preliminary to swimming became known as 'Plain diving'.\nIn England, the practice of high diving \u2013 diving from a great height \u2013 gained popularity; the first diving stages were erected at the Highgate Ponds at a height of in 1893 and the first world championship event, the National Graceful Diving Competition, was held there by the Royal Life Saving Society in 1895. The event consisted of standing and running dives from either .\nIt was at this event that the Swedish tradition of fancy diving was introduced to the sport by the athletes Otto Hagborg and C F Mauritzi. They demonstrated their acrobatic techniques from the 10m diving board at Highgate Pond and stimulated the establishment of the Amateur Diving Association in 1901, the first organization devoted to diving in the world (later amalgamated with the Amateur Swimming Association). Fancy diving was formally introduced into the championship in 1903.\nOlympic era.\nPlain diving was first introduced into the Olympics at the 1904 event. The 1908 Olympics in London added 'fancy diving' and introduced elastic boards rather than fixed platforms. Women were first allowed to participate in the diving events for the 1912 Olympics in Stockholm.\nIn the 1928 Olympics, 'plain' and 'fancy' diving were amalgamated into one event \u2013 'Highboard Diving'. The diving event was first held indoors in the Empire Pool for the 1934 British Empire Games and 1948 Summer Olympics in London.\nCompetitive diving.\nMost diving competitions consist of three disciplines: 1\u00a0m and 3\u00a0m springboards, and the platform. Competitive athletes are divided by gender, and often by age group. In platform events, competitors are allowed to perform their dives on either the five, seven and a half (generally just called seven), nine, or ten meter towers. In major diving meets, including the Olympic Games and the World Championships, platform diving is from the 10 meter height.\nDivers have to perform a set number of dives according to established requirements, including somersaults and twists. Divers are judged on whether and how well they completed all aspects of the dive, the conformance of their body to the requirements of the dive, and the amount of splash created by their entry to the water. A possible score out of ten is broken down into three points for the takeoff (meaning the hurdle), three for the flight (the actual dive), and three for the entry (how the diver hits the water), with one more available to give the judges flexibility.\nThe raw score is multiplied by a degree of difficulty factor, derived from the number and combination of movements attempted. The diver with the highest total score after a sequence of dives is declared the winner.\nSynchronized diving.\nSynchronized diving was adopted as an Olympic sport in 2000. Two divers form a team and perform dives simultaneously. The dives are identical. It used to be possible to dive opposites, also known as a pinwheel, but this is no longer part of competitive synchronized diving. For example, one diver would perform a forward dive and the other an inward dive in the same position, or one would do a reverse and the other a back movement. In these events, the diving would be judged both on the quality of execution and the synchronicity \u2013 in timing of take-off and entry, height and forward travel.\nScoring the dive.\nThere are rules governing the scoring of a dive. Usually a score considers three elements of the dive: the approach, the flight, and the entry. The primary factors affecting the scoring are:\nEach dive is assigned a \"degree of difficulty\" (DD), which is determined from a combination of the moves undertaken, position used, and height. The DD value is multiplied by the scores given by the judges.\nTo reduce the subjectivity of scoring in major meets, panels of five or seven judges are assembled; major international events such as the Olympics use seven-judge panels. For a five-judge panel, the highest and lowest scores are discarded and the middle three are summed and multiplied by the DD. For seven-judge panels, as of the 2012 London Olympics, the two highest scores and two lowest are discarded, leaving three to be summed and multiplied by the DD. (Prior to the London Olympics, the highest and lowest scores were eliminated, and the remaining five scores were multiplied by , to allow for comparison to five-judge panels.) The canceling of scores is used to make it difficult for a single judge to manipulate scores.\nThere is a general misconception about scoring and judging. In serious meets, the absolute score is somewhat meaningless. It is the relative score, not the absolute score that wins meets. Accordingly, good judging implies consistent scoring across the dives. Specifically, if a judge consistently gives low scores for all divers, or consistently gives high scores for the same divers, the judging will yield fair relative results and will cause divers to place in the correct order. However, absolute scores have significance to the individual divers. Besides the obvious instances of setting records, absolute scores are also used for rankings and qualifications for higher level meets.\nIn synchronised diving events, there is a panel of seven, nine, or eleven judges; two or three to mark the execution of one diver, two or three to mark the execution of the other, and the remaining three or five to judge the synchronisation. The execution judges are positioned two on each side of the pool, and they score the diver which is nearer to them. The 2012 London Olympics saw the first use of eleven judges.\nThe score is computed similarly to the scores from other diving events, but has been modified starting with the 2012 London Olympics for the use of the larger judging panels. Each group of judges will have the highest and lowest scores dropped, leaving the middle score for each diver's execution and the three middle scores for synchronization. The total is then weighted by and multiplied by the DD. The result is that the emphasis is on the synchronization of the divers.\nThe synchronisation scores are based on:\nThe judges may also disqualify the diver for certain violations during the dive, including:\nCompetitive strategy.\nTo win dive meets, divers create a dive list in advance of the meet. To win the meet the diver must accumulate more points than other divers. Often, simple dives with low DDs will look good to spectators but will not win meets. The competitive diver will attempt the highest DD dives possible with which they can achieve consistent, high scores. If divers are scoring 8 or 9 on most dives, it may be a sign of their extreme skill, or it may be a sign that their dive list is not competitive, and they may lose the meet to a diver with higher DDs and lower scores.\nIn competition, divers must submit their lists beforehand, and once past a deadline (usually when the event is announced or shortly before it begins) they cannot change their dives. If they fail to perform the dive announced, even if they physically cannot execute the dive announced or if they perform a more difficult dive, they will receive a score of zero. Under exceptional circumstances, a redive may be granted, but these are exceedingly rare (usually for very young divers just learning how to compete, or if some event outside the diver's control has caused them to be unable to perform-such as a loud noise).\nIn the Olympics or other highly competitive meets, many divers will have nearly the same list of dives as their competitors. The importance for divers competing at this level is not so much the DD, but how they arrange their list. Once the more difficult rounds of dives begin it is important to lead off with a confident dive to build momentum. They also tend to put a very confident dive in front of a very difficult dive to ensure that they will have a good mentality for the difficult dive. Most divers have pre-dive and post-dive rituals that help them either maintain or regain focus. Coaches also play a role in this aspect of the sport. Many divers rely on their coaches to help keep their composure during the meet. In a large meet coaches are rarely allowed on the deck to talk to their athlete so it is common to see coaches using hand gestures or body movements to communicate.\nThere are some American meets which will allow changes of the position of the dive even after the dive has been announced immediately before execution, but these are an exception to the rules generally observed internationally.\nGenerally, NCAA rules allow for dives to be changed while the diver is on the board, but the diver must request the change directly after the dive is announced. This applies especially in cases where the wrong dive is announced. If the diver pauses during his or her hurdle to ask for a change of dive, it will be declared a balk (when the diver stops mid-hurdle) and the change of dive will not be permitted.\nUnder FINA law, no dive may be changed after the deadline for the dive-sheet to be submitted (generally a period ranging from one hour to 24 hours, depending on the rulings made by the event organiser).\nIt is the diver's responsibility to ensure that the dive-sheet is filled in correctly, and also to correct the referee or announcer before the dive if they describe it incorrectly. If a dive is performed which is as submitted but not as (incorrectly) announced, it is declared failed and scores zero according to a strict reading of the FINA law. But in practice, a re-dive would usually be granted in these circumstances.\nGovernance.\nThe global governing body of diving is FINA, which also governs swimming, synchronised swimming, water polo and open water swimming. Almost invariably, at national level, diving shares a governing body with the other aquatic sports.\nThis is frequently a source of political friction as the committees are naturally dominated by swimming officials who do not necessarily share or understand the concerns of the diving community. Divers often feel, for example, that they do not get adequate support over issues like the provision of facilities. Other areas of concern are the selection of personnel for the specialised Diving committees and for coaching and officiating at events, and the team selection for international competitions.\nThere are sometimes attempts to separate the governing body as a means to resolve these frustrations, but they are rarely successful. For example, in the UK the Great Britain Diving Federation was formed in 1992 with the intention of taking over the governance of Diving from the ASA (Amateur Swimming Association). Although it initially received widespread support from the diving community, the FINA requirement that international competitors had to be registered with their National Governing Body was a major factor in the abandonment of this ambition a few years later.\nSince FINA refused to rescind recognition of the ASA as the British governing body for all aquatic sports including diving, this meant that the elite divers had to belong to ASA-affiliated clubs to be eligible for selection to international competition.\nIn the United States scholastic diving is almost always part of the school's swim team. Diving is a separate sport in Olympic and Club Diving. The NCAA will separate diving from swimming in special diving competitions after the swim season is completed.\nSafety.\nDespite the apparent risk, the statistical incidence of injury in supervised training and competition is extremely low.\nThe majority of accidents that are classified as 'diving-related' are incidents caused by individuals jumping from structures such as bridges or piers into water of inadequate depth. Many accidents also occur when divers do not account for rocks and logs in the water. Because of this many beaches and pools prohibit diving in shallow waters or when a lifeguard is not on duty.\nAfter an incident in Washington in 1993, most US and other pool builders are reluctant to equip a residential swimming pool with a diving springboard so home diving pools are much less common these days. In the incident, 14-year-old Shawn Meneely made a \"suicide dive\" (holding his hands at his sides, so that his head hit the bottom first) in a private swimming pool and became a tetraplegic. The lawyers for the family, Jan Eric Peterson and Fred Zeder, successfully sued the diving board manufacturer, the pool builder, and the National Spa and Pool Institute over the inappropriate depth of the pool.\nThe NSPI had specified a minimum depth of 7\u00a0ft 6 in (2.29 m) which proved to be insufficient in the above case. The pool into which Meneely dived was not constructed to the published standards. The standards had changed after the diving board was installed on the non-compliant pool by the homeowner. But the courts held that the pool \"was close enough\" to the standards to hold NSPI liable. The multimillion-dollar lawsuit was eventually resolved in 2001 for US$6.6\u00a0million ($8\u00a0million after interest was added) in favor of the plaintiff. The NSPI was held to be liable, and was financially strained by the case. It filed twice for Chapter 11 bankruptcy protection and was successfully reorganized into a new swimming pool industry association.\nIn competitive diving, FINA takes regulatory steps to ensure that athletes are protected from the inherent dangers of the sport. For example, they impose restrictions according to age on the heights of platforms which divers may compete on.\nGroup D divers have only recently been allowed to compete on the tower. In the past, the age group could compete only springboard, to discourage children from taking on the greater risks of tower diving. Group D tower was introduced to counteract the phenomenon of coaches pushing young divers to compete in higher age categories, thus putting them at even greater risk.\nHowever, some divers may safely dive in higher age categories to dive on higher platforms. Usually this occurs when advanced Group C divers wish to compete on the 10\u00a0m.\nPoints on pool depths in connection with safety:\nDive groups.\nThere are six \"groups\" into which dives are classified: \"Forward, Back, Inward, Reverse, Twist,\" and \"Armstand\". The latter applies only to Platform competitions, whereas the other five apply to both Springboard and Platform.\nDive positions.\nDuring the flight of the dive, one of four positions is assumed:\nThese positions are referred to by the letters A, B, C and D respectively.\nAdditionally, some dives can be started in a flying position. The body is kept straight with the arms extended to the side, and the regular dive position is assumed at about half the dive.\nDifficulty is rated according to the Degree of Difficulty of the dives. Some divers may find pike easier in a flip than tuck, and most find straight the easiest in a front/back dive, although it is still rated the most difficult because of the risk of overrotation.\nAn armstand dive may have a higher degree of difficulty outdoors compared to indoors as wind can destabilize the equilibrium of the diver.\nDive numbers.\nIn competition, the dives are referred to by a schematic system of three- or four-digit numbers. The letter to indicate the position is appended to the end of the number.\nThe first digit of the number indicates the dive group as defined above.\nFor groups 1 to 4, the number consists of three digits and a letter of the alphabet. The third digit represents the number of half-somersaults. The second digit is either 0 or 1, with 0 representing a normal somersault, and 1 signifying a \"flying\" variation of the basic movement (i.e. the first half somersault is performed in the straight position, and then the pike or tuck shape is assumed). No flying dive has been competed at a high level competition for many years.\nFor example:\nFor Group 5, the dive number has 4 digits. The first digit indicates that it is a twisting dive. The second digit indicates the group (1\u20134) of the underlying movement; the third digit indicates the number of half-somersaults, and the fourth indicates the number of half-twists.\nFor example:\nFor Group 6 \u2013 Armstand \u2013 the dive number has either three or four digits: Three digits for dives without twist and four for dives with twists.\nIn non-twisting armstand dives, the second digit indicates the direction of rotation (0 = no rotation, 1 = forward, 2 = backward, 3 = reverse, 4 = inward) and the third digit indicates the number of half-somersaults. Inward-rotating armstand dives have never been performed, and are generally regarded as physically impossible.\nFor example:\nFor twisting Armstand dives, the dive number again has 4 digits, but rather than beginning with the number 5, the number 6 remains as the first digit, indicating that the \"twister\" will be performed from an Armstand. The second digit indicates the direction of rotation \u2013 as above, the third is the number of half-somersaults, and the fourth is the number of half-twists:\ne.g. 6243D \u2013 armstand back double-somersault with one and a half twists in the free position\nAll of these dives come with DD (degree of difficulty) this is an indication of how difficult/complex a dive is. The score that the dive receives is multiplied by the DD (also known as tariff) to give the dive a final score. Before a diver competes they must decide on a \"list\" this is a number of optional dives and compulsory dives. The optionals come with a DD limit. this means that a diver must select X number of dives and the combined DD limit must be no more than the limit set by the competition/organisation etc.\nUntil the mid-1990s the tariff was decided by the FINA diving committee, and divers could only select from the range of dives in the published tariff table. Since then, the tariff is calculated by a formula based on various factors such as the number of twist and somersaults, the height, the group etc., and divers are free to submit new combinations. This change was implemented because new dives were being invented too frequently for an annual meeting to accommodate the progress of the sport.\nMechanics of diving.\nAt the moment of take-off, two critical aspects of the dive are determined, and cannot subsequently be altered during the execution. One is the trajectory of the dive, and the other is the magnitude of the angular momentum.\nThe speed of rotation \u2013 and therefore the total amount of rotation \u2013 may be varied from moment to moment by changing the shape of the body, in accordance with the law of conservation of angular momentum.\nThe center of mass of the diver follows a parabolic path in free-fall under the influence of gravity (ignoring the effects of air resistance, which are negligible at the speeds involved).\nTrajectory.\nSince the parabola is symmetrical, the travel away from the board as the diver passes it is twice the amount of the forward travel at the peak of the flight. Excessive forward distance to the entry point is penalized when scoring a dive, but obviously an adequate clearance from the diving board is essential on safety grounds.\nThe greatest possible height that can be achieved is desirable for several reasons:\nControl of rotation.\nThe magnitude of angular momentum remains constant throughout the dive, but since\nand the moment of inertia is larger when the body has an increased radius, the speed of rotation may be increased by moving the body into a compact shape, and reduced by opening out into a straight position.\nSince the tucked shape is the most compact, it gives the most control over rotational speed, and dives in this position are easier to perform. Dives in the straight position are hardest, since there is almost no scope for altering the speed, so the angular momentum must be created at take-off with a very high degree of accuracy. (A small amount of control is available by moving the position of the arms and by a slight hollowing of the back).\nThe opening of the body for the entry does not stop the rotation, but merely slows it down. The vertical entry achieved by expert divers is largely an illusion created by starting the entry slightly short of vertical, so that the legs are vertical as they disappear beneath the surface. A small amount of additional tuning is available by 'entry save' techniques, whereby underwater movements of the upper body and arms against the viscosity of the water affect the position of the legs.\nTwisting.\nDives with multiple twists and somersaults are some of the most spectacular movements, as well as the most challenging to perform.\nThe rules state that twisting 'must not be generated manifestly on take-off'. Consequently, divers must use some of the somersaulting angular momentum to generate twisting movements. The physics of twisting can be explained by looking at the components of the angular momentum vector.\nAs the diver leaves the board, the total angular momentum vector is horizontal, pointing directly to the left for a forward dive for example. For twisting rotation to exist, it is necessary to tilt the body sideways after takeoff, so that there is now a small component of this horizontal angular momentum vector along the body's long axis. The tilt can be seen in the photo.\nThe tilting is done by the arms, which are outstretched to the sides just before the twist. When one arm is moved up and the other is moved down (like turning a big steering wheel), the body reacts by tilting to the side, which then begins the twisting rotation. At the completion of the required number of twist rotations, the arm motion is reversed (the steering wheel is turned back), which removes the body's tilt and stops the twisting rotation.\nAn alternative explanation is that the moving arms have precession torque on them which set the body into twisting rotation. Moving the arms back produces opposite torque which stops the twisting rotation.\nEntry.\nThe rules state that the body should be vertical, or nearly so, for entry. Strictly speaking, it is physically impossible to achieve a literally vertical position throughout the entry as there will inevitably still be some rotational momentum while the body is entering the water. Divers therefore attempt to create the illusion of being vertical, especially when performing rapidly rotating multiple somersault movements. For back entries, one technique is to allow the upper body to enter slightly short of vertical so that the continuing rotation leaves the final impression of the legs entering vertically. This is called \"Pike save\". Another is to use \"knee save\" movements of scooping the upper body underwater in the direction of rotation so as to counteract the rotation of the legs.\nThe arms must be beside the body for feet-first dives, which are typically competed only on the 1m springboard and only at fairly low levels of 3m springboard, and extended forwards in line for \"head-first\" dives, which are much more common competitively. It used to be common for the hands to be interlocked with the fingers extended towards the water, but a different technique has become favoured during the last few decades. Now the usual practice is for one hand to grasp the other with palms down to strike the water with a flat surface. This creates a vacuum between the hands, arms and head which, with a vertical entry, will pull down and under any splash until deep enough to have minimal effect on the surface of the water (the so-called \"rip entry\").\nOnce a diver is completely under the water they may choose to roll or scoop in the same direction their dive was rotating to pull their legs into a more vertical position. Apart from aesthetic considerations, it is important from a safety point of view that divers reinforce the habit of rolling in the direction of rotation, especially for forward and inward entries. Back injuries such as hyperextension are caused by attempting to re-surface in the opposite direction. Diving from the higher levels increases the danger and likelihood of such injuries.\nBy country.\nCanada.\nIn Canada, elite competitive diving is regulated by DPC (Diving Plongeon Canada), although the individual provinces also have organizational bodies. The main competitive season runs from February to July, although some competitions may be held in January or December, and many divers (particularly international level athletes) will train and compete year round.\nMost provincial level competitions consist of events for 6 age groups (Groups A, B, C, D, E, and Open) for both genders on each of the three board levels. These age groups roughly correspond to those standardized by FINA, with the addition of a youngest age group for divers 9 and younger, Group E, which does not compete nationally and does not have a tower event (although divers of this age may choose to compete in Group D). The age group Open is so called because divers of any age, including those over 18, may compete in these events, so long as their dives meet a minimum standard of difficulty.\nAlthough Canada is internationally a fairly strong country in diving, the vast majority of Canadian high schools and universities do not have diving teams, and many Canadian divers accept athletic scholarships from American colleges.\nAdult divers who are not competitive at an elite level may compete in masters diving. Typically, masters are either adults who never practiced the sport as children or teenagers, or former elite athletes who have retired but still seek a way to be involved in the sport. Many diving clubs have masters teams in addition to their primary competitive ones, and while some masters dive only for fun and fitness, there are also masters competitions, which range from the local to world championship level.\nNational championships.\nDivers can qualify to compete at the age group national championships, or junior national championships, in their age groups as assigned by FINA up to the age of 18. This competition is held annually in July. Qualification is based on achieving minimum scores at earlier competitions in the season, although athletes who place very highly at a national championship will be automatically qualified to compete at the next. Divers must qualify at two different competitions, at least one of which must be a level 1 competition, i.e. a competition with fairly strict judging patterns. Such competitions include the Polar Bear Invitational in Winnipeg, the Sting in Victoria, and the Alberta Provincial Championships in Edmonton or Calgary. The qualifying scores are determined by DPC according to the results of the preceding year's national competition, and typically do not have much variation from year to year.\nDivers older than 18, or advanced divers of younger ages, can qualify for the senior national championships, which are held twice each year, once roughly in March and once in June or July. Once again, qualification is based on achieving minimum scores at earlier competitions (in this case, within the 12 months preceding the national championships, and in an Open age group event), or high placements in previous national championships or international competitions. It is no longer the case that divers may use results from age group events to qualify for senior nationals, or results from Open events to qualify for age group nationals.\nRepublic of Ireland.\nIn the Republic of Ireland facilities are limited to one pool at the National Aquatic Centre in Dublin.\nNational championships.\nNational championships take place late in the year, usually during November. The competition is held at the National Aquatic Centre in Dublin and consists of four events:\nUnited Kingdom.\nIn the United Kingdom, diving competitions on all boards run throughout the year. National Masters' Championships are held two or three times per year.\nUnited States.\nSummer diving.\nIn the United States, summer diving is usually limited to one meter diving at community or country club pools. Some pools organize to form intra-pool competitions. These competitions are usually designed to accommodate all school-age children.\nHigh school diving.\nIn the United States scholastic diving at the high school level is usually limited to one meter diving (but some schools use three meter springboards.). Scores from those one meter dives contribute to the swim team's overall score. High school diving and swimming concludes their season with a state competition. Depending on the state and the number of athletes competing in the state, certain qualifications must be achieved to compete in the state's championship meet. There are often regional championships and district championships which are necessary to compete in before reaching the state meet to narrow the field to only the most competitive athletes. Most state championship meets consist of eleven dives. The eleven dives are usually split up between two categories: five required (voluntary) dives and six optional dives.\nClub diving.\nIn the United States, pre-college divers interested in learning one and three meter or platform diving should consider a club sanctioned by either USA Diving or AAU Diving. In USA Diving, Future Champions is the entry level or novice diver category with 8 levels of competition. From Future Champions, divers graduate to \"Junior Olympic\", or JO. JO divers compete in age groups at inter-club competitions, at invitationals, and if qualified, at regional, zone and national competitions. Divers over the age of 19 years of age cannot compete in these events as a JO diver.\nUSA Diving sanctions the Winter Nationals championship with one, three meter, and platform events. In the summer USA Diving sanctions the Summer Nationals including all three events with both Junior and Senior divers. USA Diving is sanctioned by the United States Olympic Committee to select team representatives for international diving competitions including the World Championships and Olympic Games.\nAAU Diving sanctions one national event per year in the summer. AAU competes on the one, three, and tower to determine the All-American team.\nCollege diving.\nIn the United States scholastic diving at the college level requires one and three meter diving. Scores from the one and three meter competition contribute to the swim team's overall meet score. College divers interested in tower diving may compete in the NCAA separate from swim team events. NCAA Divisions II and III do not usually compete platform; if a diver wishes to compete platform in college, he or she must attend a Division I school.\nEach division also has rules on the number of dives in each competition. Division II schools compete with 10 dives in competition whereas Division III schools compete with 11. Division I schools only compete with 6 dives in competition. These 6 dives consist of either 5 optionals and 1 voluntary, or 6 optionals. If the meet is a 5 optional meet, then the divers will perform 1 optional from each category (Front, Back, Inward, Reverse, and Twister) and then 1 voluntary from the category of their choice. The voluntary in this type of meet is always worth a DD (Degree of Difficulty) of 2.0 even if the real DD is worth more or less on a DD sheet. In a 6 optional meet, the divers will yet again perform one dive from each category, but this time they will perform a 6th optional from the category of their choosing, which is worth its actual DD from the DD sheet.\nThe highest level of collegiate competition is the NCAA Division 1 Swimming and Diving Championship. Events at the championship include 1 meter springboard, 3 meter springboard, and platform, as well as various swimming individual and relay events. The points scored by swimmers and divers are combined to determine a team swimming &amp; diving champion. To qualify for a diving event at the NCAA championships, a competitor must first finish in the top three at one of five zone championships, which are held after the various conference championship meets. A diver who scores at least 310 points on the 3 meter springboard and 300 points on the 1 meter springboard in a 6 optional meet can participate in the particular zone championship corresponding to the geographic region in which his or her school lies.\nA number of colleges and universities offer scholarships to men and women who have competitive diving skills. These scholarships are usually offered to divers with age-group or club diving experience.\nThe NCAA limits the number of years a college student can represent any school in competitions. The limit is four years, but could be less under certain circumstances.\nMasters' Diving.\nDivers who continue diving past their college years can compete in Masters' Diving programs. Masters' diving programs are frequently offered by college or club programs.\nMasters' Diving events are normally conducted in age-groups separated by five or ten years, and attract competitors of a wide range of ages and experience (many, indeed, are newcomers to the sport); the oldest competitor in a Masters' Diving Championship was Viola Krahn, who at the age of 101 was the first person in any sport, male or female, anywhere in the world, to compete in an age-group of 100+ years in a nationally organized competition.\nNon-competitive diving.\nDiving is also popular as a non-competitive activity. Such diving usually emphasizes the airborne experience, and the height of the dive, but does not emphasize what goes on once the diver enters the water. The ability to dive underwater can be a useful emergency skill, and is an important part of watersport and navy safety training. Entering water from a height is an enjoyable leisure activity, as is underwater swimming.\nSuch non-competitive diving can occur indoors and outdoors. Outdoor diving typically takes place from cliffs or other rock formations either into fresh or salt water. However, man-made diving platforms are sometimes constructed in popular swimming destinations. Outdoor diving requires knowledge of the water depth and currents as conditions can be dangerous.\nOn occasion, the diver will inadvertently belly flop, entering the water horizontally or nearly so. The diver typically displaces a larger than usual amount of water.\nHigh diving.\nA recently developing section of the sport is \"High Diving\" (e.g. see 2013 World Aquatics Championships), conducted in open air locations, usually from improvised platforms up to high (as compared with as used in Olympic and World Championship events). Entry to the water is invariably feet-first to avoid the risk of injury that would be involved in head-first entry from that height. The final half-somersault is almost always performed backwards, enabling the diver to spot the entry point and control their rotation."}
{"id": "8405", "revid": "1893265", "url": "https://en.wikipedia.org/wiki?curid=8405", "title": "Dative", "text": ""}
{"id": "8406", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=8406", "title": "Dative case", "text": "In grammar, the dative case (abbreviated , or sometimes when it is a core argument) is a grammatical case used in some languages to indicate the recipient or beneficiary of an action, as in \"Maria Jacobo potum dedit\", Latin for \"Maria gave Jacob a drink\". In this example, the dative marks what would be considered the indirect object of a verb in English.\nSometimes the dative has functions unrelated to giving. In Scottish Gaelic and Irish, the term \"dative case\" is used in traditional grammars to refer to the prepositional case-marking of nouns following simple prepositions and the definite article. In Georgian and Hindustani (Hindi-Urdu), the dative case can also mark the subject of a sentence. This is called the dative construction. In Hindi, the dative construction is not limited to only certain verbs or tenses and it can be used with any verb in any tense or mood.\nThe dative was common among early Indo-European languages and has survived to the present in the Balto-Slavic branch and the Germanic branch, among others. It also exists in similar forms in several non-Indo-European languages, such as the Uralic family of languages. In some languages, the dative case has assimilated the functions of other, now extinct cases. In Ancient Greek, the dative has the functions of the Proto-Indo-European locative and instrumental as well as those of the original dative.\nUnder the influence of English, which uses the preposition \"to\" for (among other uses) both indirect objects (\"give to\") and directions of movement (\"go to\"), the term \"dative\" has sometimes been used to describe cases that in other languages would more appropriately be called lative.\nEtymology.\n\"Dative\" comes from Latin \"c\u0101sus dat\u012bvus\" (\"case for giving\"), a translation of Greek \u03b4\u03bf\u03c4\u03b9\u03ba\u1f74 \u03c0\u03c4\u1ff6\u03c3\u03b9\u03c2, \"dotik\u0113 pt\u00f4sis\" (\"inflection for giving\"). Dionysius Thrax in his Art of Grammar also refers to it as \"epistaltik\u0113\u0301\" \"for sending (a letter)\", from the verb \"epist\u00e9ll\u014d\" \"send to\", a word from the same root as epistle.\nEnglish.\nThe Old English language, which continued in use until after the Norman Conquest of 1066, had a dative case; however, the English case system gradually fell into disuse during the Middle English period, when the accusative and dative of pronouns merged into a single oblique case that was also used with all prepositions. This conflation of case in Middle and Modern English has led most modern grammarians to discard the \"accusative\" and \"dative\" labels as obsolete in reference to English, often using the term \"objective\" for oblique.\nSet expressions.\nThe dative case is rare in modern English usage, but it can be argued that it survives in a few set expressions. One example is the word \"methinks\", with the meaning \"it seems to me\". It survives in this fixed form from Old English (having undergone, however, phonetic changes with the rest of the language), in which it was constructed as \"[it]\" + \"me\" (the dative case of the personal pronoun) + \"thinks\" (i.e., \"seems\", &lt; Old English \u00feyncan, \"to seem\", a verb closely related to the verb \u00feencan, \"to think\", but distinct from it in Old English; later it merged with \"think\" and lost this meaning).\nRelic pronouns.\nThe modern objective case pronoun whom is derived from the dative case in Old English, specifically the Old English dative pronoun \"hw\u0101m\" (as opposed to the modern subjective \"who\", which descends from Old English \"hw\u0101\") \u2013 though \"whom\" \"also\" absorbed the functions of the Old English accusative pronoun \"hwone\". It is also cognate to the word \"\"wem\" (the dative form of \"wer\"\") in German. The OED defines all classical uses of the word \"whom\" in situations where the indirect object \"is not known\" \u2013 in effect, indicating the anonymity of the indirect object.\nLikewise, some of the object forms of personal pronouns are remnants of Old English datives. For example, \"him\" goes back to the Old English dative \"him\" (accusative was \"hine\"), and \"her\" goes back to the dative \"hire\" (accusative was \"h\u012be\"). These pronouns are not datives in modern English; they are also used for functions previously indicated by the accusative.\nModern English.\nThe indirect object of the verb may be placed between the verb and the direct object of the verb: \"he gave me a book\" or \"he wrote me a poem.\"\nThe indirect object may also be expressed using a prepositional phrase using \"to\" or \"for\": \"he gave a book to me \" or \"he wrote a poem for me.\"\nGerman.\nIn general, the dative (German: \"Dativ\") is used to mark the indirect object of a German sentence. For example:\nIn English, the first sentence can be rendered as \"I sent the book \"to the man\"\" and as \"I sent \"the man\" the book\", where the indirect object is identified in English by standing in front of the direct object. The normal word order in German is to put the dative in front of the accusative (as in the example above). However, since the German dative is marked in form, it can also be put \"after\" the accusative: \"Ich schickte das Buch dem Mann(e). The (e)\" after \"Mann\" and \"Kind\" signifies a now largely archaic -e ending for certain nouns in the dative. It survives today almost exclusively in set phrases such as \"zu Hause\" (at home, \"lit.\" to house), \"im Zuge\" (in the course of), and \"am Tage\" (during the day, \"lit.\" at the day), as well as in occasional usage in formal prose, poetry, and song lyrics.\nSome masculine nouns (and one neuter noun, \"Herz\" [heart]), referred to as \"weak nouns\" or \"n-nouns\", take an -n or -en in the dative singular and plural. Many are masculine nouns ending in -e in the nominative (such as \"Name\" [name], \"Beamte\" [officer], and \"Junge\" [boy]), although not all such nouns follow this rule. Many also, whether or not they fall into the former category, refer to people, animals, professions, or titles; exceptions to this include the aforementioned \"Herz\" and \"Name\", as well as \"Buchstabe\" (letter), \"Friede\" (peace), \"Obelisk\" (obelisk), \"Planet\" (planet), and others.\nCertain German prepositions require the dative: \"aus\" (from), \"au\u00dfer\" (out of), \"bei\" (at, near), \"entgegen\" (against), \"gegen\u00fcber\" (opposite), \"mit\" (with), \"nach\" (after, to), \"seit\" (since), \"von\" (from), and \"zu\" (at, in, to). Some other prepositions (\"an\" [at], \"auf\" [on], \"entlang\" [along], \"hinter\" [behind], \"in\" [in, into], \"neben\" (beside, next to), \"\u00fcber\" [over, across], \"unter\" [under, below], \"vor\" [in front of], and \"zwischen\" [among, between]) may be used with dative (indicating current location), or accusative (indicating direction toward something). \"Das Buch liegt auf dem Tisch(e)\" (dative: The book is lying on the table), but \"Ich lege das Buch auf den Tisch\" (accusative: I put the book onto the table).\nIn addition the four prepositions \"[an]statt\" (in place of), \"trotz\" (in spite of), \"w\u00e4hrend\" (during), and \"wegen\" (because of) which require the genitive in modern formal language, are most commonly used with the dative in colloquial German. For example, \"because of the weather\" is expressed as \"wegen dem Wetter\" instead of the formally correct \"wegen des Wetters\". Other prepositions requiring the genitive in formal language, are combined with \"von\" (\"of\") in colloquial style, e.g. \"au\u00dferhalb vom Garten\" instead of \"au\u00dferhalb des Gartens\" (\"outside the garden\").\nNote that the concept of an indirect object may be rendered by a prepositional phrase. In this case, the noun's or pronoun's case is determined by the preposition, NOT by its function in the sentence. Consider this sentence:\nHere, the subject, \"Ich\", is in the nominative case, the direct object, \"das Buch\", is in the accusative case, and \"zum Verleger\" is in the dative case, since \"zu\" always requires the dative (\"zum\" is a contraction of \"zu\" + \"dem\"). However:\nIn this sentence, \"Freund\" is the indirect object, but, because it follows \"an\" (direction), the accusative is required, not the dative.\nAll of the articles change in the dative case.\nSome German verbs require the dative for their direct objects. Common examples are \"antworten\" (to answer), \"danken\" (to thank), \"gefallen\" (to please), \"folgen\" (to follow), \"glauben\" (to believe), \"helfen\" (to help), and \"raten\" (to advise). In each case, the direct object of the verb is rendered in the dative. For example:\nThese verbs cannot be used in normal passive constructions, because German allows these only for verbs with accusative objects. It is therefore ungrammatical to say: *\"Ich werde geholfen.\" \"I am helped.\" Instead a special construction called \"impersonal passive\" must be used: \"Mir wird geholfen\", literally: \"To me is helped.\" A colloquial (non-standard) and rarely used way to form the passive voice for dative verbs is the following: \"Ich kriege geholfen\", or: \"Ich bekomme geholfen\", literally: \"I get helped\". The use of the verb \"to get\" here reminds us that the dative case has something to do with giving and receiving. In German, help is not something you \"perform on\" somebody, but rather something you \"offer\" them.\nThe dative case is also used with reflexive (\"sich\") verbs when specifying what part of the self the verb is being done to:\nCf. the respective \"accord\" in French: \"Les enfants se sont lav\u00e9s\" (\"the children have washed themselves\") vs. \"Les enfants se sont lav\u00e9\" [uninflected] \"les mains\" (\"... their hands\").\nGerman can use two datives to make sentences like: \"Sei mir meinem Sohn(e) gn\u00e4dig!\" \"For my sake, have mercy on my son!\" Literally: \"Be for me to my son merciful.\" The first dative \"mir\" (\"for me\") expresses the speaker's commiseration (much like the \"dativus ethicus\" in Latin, see below). The second dative \"meinem Sohn(e)\" (\"to my son\") names the actual object of the plea. Mercy is to be given \"to\" the son \"for\" or \"on behalf of\" his mother/father.\nAdjective endings also change in the dative case. There are three inflection possibilities depending on what precedes the adjective. They most commonly use \"weak inflection\" when preceded by a definite article (the), \"mixed inflection\" after an indefinite article (a/an), and \"strong inflection\" when a quantity is indicated (many green apples).\nLatin.\nThere are several uses for the dative case ():\nGreek.\nAncient.\nIn addition to its main function as the \"dativus\", the dative case has other functions in Classical Greek: (The chart below uses the Latin names for the types of dative; the Greek name for the dative is \u03b4\u03bf\u03c4\u03b9\u03ba\u03ae \u03c0\u03c4\u1ff6\u03c3\u03b9\u03c2, like its Latin equivalent, derived from the verb \"to give\"; in Ancient Greek, \u03b4\u03af\u03b4\u03c9\u03bc\u03b9.)\nThe articles in the Greek dative are\nModern.\nThe dative case, strictly speaking, no longer exists in Modern Greek, except in fossilized expressions like \u03b4\u03cc\u03be\u03b1 \u03c4\u03c9 \u0398\u03b5\u03ce (from the ecclesiastical \u03c4\u1ff7 \u0398\u03b5\u1ff7 \u03b4\u03cc\u03be\u03b1, \"Glory to God\") or \u03b5\u03bd \u03c4\u03ac\u03be\u03b5\u03b9 (\u1f11\u03bd \u03c4\u03ac\u03be\u03b5\u03b9, lit. \"in order\", i.e. \"all right\" or \"OK\"). Otherwise, most of the functions of the dative have been subsumed in the accusative.\nSlavic languages.\nIn Russian, the dative case is used for indicating the indirect object of an action (that to which something is given, thrown, read, etc.). In the instance where a person is the goal of motion, dative is used instead of accusative to indicate motion toward. This is usually achieved with the preposition \"\u03ba\" + destination in dative case; \"\u041a \u0432\u0440\u0430\u0447\u0443\", meaning \"to the doctor.\"\nDative is also the necessary case taken by certain prepositions when expressing certain ideas. For instance, when the preposition \"\u043f\u043e\" is used to mean \"along,\" its object is always in dative case, as in \"\u041f\u043e \u0431\u043e\u043a\u0430\u043c\", meaning \"along the sides.\"\nOther Slavic languages apply the dative case (and the other cases) more or less the same way as does Russian; some languages may use the dative in other ways. The following examples are from Polish:\nSome other kinds of dative use as found in the Serbo-Croatian language are: \"Dativus finalis\" (Titaniku u pomo\u0107 \"to Titanic's rescue\"), \"Dativus commodi/incommodi\" (Operi svojoj majci su\u0111e \"Wash the dishes for your mother\"), \"Dativus possessivus\" (Ovcama je dlaka gusta \"Sheep's hair is thick\"), \"Dativus ethicus\" (\u0160ta mi radi Boni? \"What is Boni doing? (I am especially interested in what it is)\") and Dativus auctoris (Izgleda mi okej \"It seems okay to me\").\nUnusual in other Indo-European branches but common among Slavic languages, endings of nouns and adjectives are different based on grammatical function. Other factors are gender and number. In some cases, the ending may not be obvious, even when those three factors (function, gender, number) are considered. For example, in Polish, 'syn' (\"son\") and 'ojciec' (\"father\") are both masculine singular nouns, yet appear as \"syn \u2192 synowi and \"ojciec \u2192 ojcu in the dative.\nBaltic languages.\nBoth Lithuanian and Latvian have a distinct dative case in the system of nominal declensions.\nLithuanian nouns preserve Indo-European inflections in the dative case fairly well: (o-stems) vaikas -&gt; sg. vaikui, pl. vaikams; (\u0101-stems) ranka -&gt; sg. rankai, pl. rankoms; (i-stems) viltis -&gt; sg. vil\u010diai, pl. viltims; (u-stems) s\u016bnus -&gt; sg. s\u016bnui, pl. s\u016bnums; (consonant stems) vanduo -&gt; sg. vandeniui, pl. vandenims.\nAdjectives in the dative case receive pronominal endings (this might be the result of a more recent development): tas geras vaikas -&gt; sg. tam geram vaikui, pl. tiems geriems vaikams.\nThe dative case in Latvian underwent further simplifications \u2013 the original masculine endings of \"both\" nouns and adjectives have been replaced with pronominal inflections: tas v\u012brs -&gt; sg. tam v\u012bram, pl. v\u012briem. Also, the final \"s\" in all Dative forms has been dropped. The only exception is personal pronouns in the plural: mums (to us), jums (to you). Note that in colloquial Lithuanian the final \"s\" in the dative is often omitted, as well: time geriem vaikam.\nIn both Latvian and Lithuanian, the main function of the dative case is to render the indirect object in a sentence: (lt) a\u0161 duodu vyrui knyg\u0105; (lv) es dodu [duodu] v\u012bram gr\u0101matu \u2013 \"I am giving a book to the man\".\nThe dative case can also be used with gerundives to indicate an action preceding or simultaneous with the main action in a sentence: (lt) jam \u012f\u0117jus, visi atsistojo \u2013 \"when he walked in, everybody stood up\", lit. \"to him having walked in, all stood up\"; (lt) jai miegant, visi dirbo \u2013 \"while she slept, everybody was working\", lit. \"to her sleeping, all were working\".\nIn modern standard Lithuanian, Dative case is not required by prepositions, although in many dialects it is done frequently: (dial.) iki (+D) \u0161iai dienai, (stand.) iki (+G) \u0161ios dienos \u2013 \"up until this day\".\nIn Latvian, the dative case is taken by several prepositions in the singular and all prepositions in the plural (due to peculiar historical changes): sg. bez (+G) tevis \"(without thee)\" ~ pl. bez (+D) jums \"(without you)\"; sg. pa (+A) ce\u013cu \"(along the road)\" ~ pl. pa (+D) ce\u013ciem \"(along the roads)\".\nArmenian.\nIn modern Eastern Armenian, the dative is attained by adding any article to the genitive:\n\"dog\" = \u0577\u0578\u0582\u0576\nGEN &gt; \u0577\u0561\u0576 \"(of the dog; dog's)\" with no articles\nDAT &gt; \u0577\u0561\u0576\u0568 or \u0577\u0561\u0576\u0576 \"(to the dog)\" with definite articles (-\u0576 if preceding a vowel)\nDAT &gt; \u0574\u056b \u0577\u0561\u0576 \"(to a dog)\" with indefinite article\nDAT &gt; \u0577\u0561\u0576\u057d \"(to my dog)\" with 1st person possessive article\nDAT &gt; \u0577\u0561\u0576\u0564 \"(to your dog)\" with 2nd person possessive article\nThere is a general tendency to view -\u056b\u0576 as the standard dative suffix, but only because that is its most productive (and therefore common) form. The suffix -\u056b\u0576 as a dative marker is nothing but the standard, most common, genitive suffix -\u056b accompanied by the definite article -\u0576. But the dative case encompasses indefinite objects as well, which will not be marked by -\u056b\u0576:\nDefinite DAT &gt; \u0535\u057d \u0563\u056b\u0580\u0584\u0568 \u057f\u057e\u0565\u0581\u056b \u057f\u0572\u0561\u0575\u056b\u0576: \"(I gave the book to the boy)\"\nIndefinite DAT&gt; \u0535\u057d \u0563\u056b\u0580\u0584\u0568 \u057f\u057e\u0565\u0581\u056b \u0574\u056b \u057f\u0572\u0561\u0575\u056b: \"(I gave the book to a boy)\"\nThe main function of the dative marking in Armenian is to indicate the receiving end of an action, more commonly the indirect object which in English is preceded by the preposition \"to\". In the use of \"giving\" verbs like \"give, donate, offer, deliver, sell, bring...\" the dative marks the recipient. With communicative verbs like \"tell, say, advise, explain, ask, answer...\" the dative marks the listener. Other verbs whose indirect objects are marked by the dative case in Armenian are \"show, reach, look, approach...\"\nEastern Armenian also uses the dative case to mark the time of an event, in the same way English uses the preposition \"at\", as in \"Meet me at nine o' clock.\"\nIndo-Aryan languages.\nHindustani (Hindi-Urdu).\nHindustani (Hindi-Urdu) has true dative case for pronouns, but for nouns the dative case has to be constructed using the dative case-marker (postposition) \u0915\u094b \u06a9\u0648 (ko) to the nouns in their oblique case. Pronouns in Hindustani also have an oblique case, so dative pronouns can also be alternatively constructed using the dative case-marker \u0915\u094b \u06a9\u0648 (ko) with the pronouns in their oblique case, hence forming two sets of synonymous dative pronouns. The following table shows the pronouns in their nominative and their dative forms. Hindustani lacks pronouns in the third person and the demonstrative pronouns double as the third person pronouns. \nThe table below shows the oblique cases of Hindustani for the nouns \"boy\" and \"girl\" which take in the dative case-marker after them to assign the combination of the oblique case and the case-marker the dative case. The oblique case of Hindustani by itself has no meaning and adding the case-marker \u0915\u094b \u06a9\u0648 (ko) assigns the oblique case the function of the dative case.\nDative case in Hindustani can also mark the subject of a sentence. This is called the dative construction or quirky subjects. In the examples below the dative pronoun passes the subjecthood test of subject-oriented anaphora binding. The dative subject \u092e\u0941\u091d\u0947 \u0645\u062c\u06be\u06d2 (\"mujhe\") binds the anaphora \u0905\u092a\u0928\u0947 \u0627\u067e\u0646\u06d2 (\"apne\").\nSanskrit.\nThe dative case is known as the \"fourth case\" (chaturthi-vibhakti) in the usual procedure in the declension of nouns. Its use is mainly for the indirect object.\nNon-Indo-European languages.\nHungarian.\nAs with many other languages, the dative case is used in Hungarian to show the indirect object of a verb. For example, \"D\u00e1nielnek adtam ezt a k\u00f6nyvet\" (I gave this book to D\u00e1niel). It has two suffixes, \"-nak\" and \"-nek\"; the correct one is selected by vowel harmony. The personal dative pronouns follow the \"-nek\" version: \"nekem\", \"neked\", etc. This case is also used to express \"for\" in certain circumstances, such as \"I bought a gift for Mother\". In possessive constructions the nak/nek endings are also used but this is not the dative form (rather, the attributive or possessive case)\nFinnish.\nFinnish does not have a separate dative case. However, the allative case can fulfill essentially the same role as dative, beyond its primary meaning of directional movement (that is, going somewhere or approaching someone). For example: \"He lahjoittivat kaikki rahansa k\u00f6yhille (They donated all their money to the poor.)\nTsez.\nIn the Northeast Caucasian languages, such as Tsez, the dative also takes the functions of the lative case in marking the direction of an action. By some linguists, they are still regarded as two separate cases in those languages, although the suffixes are exactly the same for both cases. Other linguists list them separately only for the purpose of separating syntactic cases from locative cases. An example with the ditransitive verb \"show\" (literally: \"make see\") is given below:\nThe dative/lative is also used to indicate possession, as in the example below, because there is no such verb as \"to have\".\nAs in the examples above, the dative/lative case usually occurs in combination with another suffix as poss-lative case; this should not be regarded as a separate case, however, as many of the locative cases in Tsez are constructed analytically; hence, they are, in fact, a combination of two case suffixes. See Tsez language#Locative case suffixes for further details.\nVerbs of perception or emotion (like \"see\", \"know\", \"love\", \"want\") also require the logical subject to stand in the dative/lative case. Note that in this example the \"pure\" dative/lative without its POSS-suffix is used.\nTurkish.\nThe dative case (\"y\u00f6nelme durumu\") in Turkish language is formed by adding the \"-e\" or \"-a\" suffixes to the end of the noun, in accordance with the effected noun's vowel harmony. The word that should be in the dative case can be found as an answer to the questions 'neye?' (to what?), 'kime?' (to whom?) and 'nereye?' (to where?) will lead to find a dative case in a sentence. There are many different uses for the dative case.\nThe dative also is for objects, usually indirect objects, but sometimes objects that in English would be considered direct:\nThe dative case tells \"whither\", that is, the place \"to which\". Thus it has roughly the meaning of the English prepositions \"to\" and \"into\", and also \"in\" when it can be replaced with \"into\":"}
