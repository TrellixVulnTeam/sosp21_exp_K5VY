diff --git a/Megatron-LM/arguments.py b/Megatron-LM/arguments.py
index 67c726c..d3a01b3 100755
--- a/Megatron-LM/arguments.py
+++ b/Megatron-LM/arguments.py
@@ -329,18 +329,19 @@ def get_args():
     args.rank = int(os.getenv('RANK', '0'))
     args.world_size = int(os.getenv("WORLD_SIZE", '1'))
 
-    if os.getenv('OMPI_COMM_WORLD_LOCAL_RANK'):
-        # We are using (OpenMPI) mpirun for launching distributed data parallel processes
-        local_rank = int(os.getenv('OMPI_COMM_WORLD_LOCAL_RANK'))
-        local_size = int(os.getenv('OMPI_COMM_WORLD_LOCAL_SIZE'))
-
-        # Possibly running with Slurm
-        num_nodes = int(os.getenv('SLURM_JOB_NUM_NODES', '1'))
-        nodeid = int(os.getenv('SLURM_NODEID', '0'))
-
-        args.local_rank = local_rank
-        args.rank = nodeid*local_size + local_rank
-        args.world_size = num_nodes*local_size
+#    if os.getenv('OMPI_COMM_WORLD_LOCAL_RANK'):
+#        # We are using (OpenMPI) mpirun for launching distributed data parallel processes
+#        local_rank = int(os.getenv('OMPI_COMM_WORLD_LOCAL_RANK'))
+#        local_size = int(os.getenv('OMPI_COMM_WORLD_LOCAL_SIZE'))
+
+#        # Possibly running with Slurm
+#        num_nodes = int(os.getenv('SLURM_JOB_NUM_NODES', '1'))
+#        nodeid = int(os.getenv('SLURM_NODEID', '0'))
+
+#        args.local_rank = local_rank
+#        args.rank = nodeid*local_size + local_rank
+#        args.world_size = num_nodes*local_size
+    print("rank:", args.rank, " local rank:", args.local_rank, " size:", args.world_size)
 
     args.model_parallel_size = min(args.model_parallel_size, args.world_size)
     if args.rank == 0:
diff --git a/Megatron-LM/data_utils/corpora.py b/Megatron-LM/data_utils/corpora.py
index 49877ac..04d5d17 100755
--- a/Megatron-LM/data_utils/corpora.py
+++ b/Megatron-LM/data_utils/corpora.py
@@ -22,7 +22,7 @@ class wikipedia(json_dataset):
 
     command line usage: `--train-data wikipedia`
     """
-    PATH = 'data/wikipedia/wikidump_lines.json'
+    PATH = 'data/wikipedia/wiki_AA_presplited.json'
     assert_str = "make sure to set PATH for wikipedia data_utils/corpora.py"
     def __init__(self, **kwargs):
         assert os.path.exists(wikipedia.PATH), \
diff --git a/Megatron-LM/data_utils/wordpiece.py b/Megatron-LM/data_utils/wordpiece.py
index 81121e4..9b2f233 100755
--- a/Megatron-LM/data_utils/wordpiece.py
+++ b/Megatron-LM/data_utils/wordpiece.py
@@ -28,7 +28,8 @@ logger = logging.getLogger(__name__)
 
 PRETRAINED_VOCAB_ARCHIVE_MAP = {
     'bert-base-uncased': "https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt",
-    'bert-large-uncased': "https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt",
+    'bert-large-uncased': "bert-large-uncased-vocab.txt",
+#    'bert-large-uncased': "https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt",
     'bert-base-cased': "https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt",
     'bert-large-cased': "https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt",
     'bert-base-multilingual-uncased': "https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-vocab.txt",
